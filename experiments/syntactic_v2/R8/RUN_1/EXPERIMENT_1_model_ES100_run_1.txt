
==========: 201306664674500
Epoch:0001, train_loss=2.15031, train_acc=0.08203, val_loss=2.05934, val_acc=0.60766, time=1.52801
Epoch:0002, train_loss=1.89024, train_acc=0.60847, val_loss=2.04533, val_acc=0.69343, time=1.31600
Epoch:0003, train_loss=1.76200, train_acc=0.70306, val_loss=2.03824, val_acc=0.73723, time=1.06303
Epoch:0004, train_loss=1.69324, train_acc=0.74823, val_loss=2.03342, val_acc=0.77007, time=1.29599
Epoch:0005, train_loss=1.64482, train_acc=0.78529, val_loss=2.02941, val_acc=0.79745, time=1.06000
Epoch:0006, train_loss=1.60444, train_acc=0.82155, val_loss=2.02594, val_acc=0.83759, time=1.15902
Epoch:0007, train_loss=1.56975, train_acc=0.85416, val_loss=2.02315, val_acc=0.86314, time=1.01701
Epoch:0008, train_loss=1.54190, train_acc=0.88981, val_loss=2.02101, val_acc=0.88686, time=1.04000
Epoch:0009, train_loss=1.52083, train_acc=0.91148, val_loss=2.01935, val_acc=0.90693, time=1.10901
Epoch:0010, train_loss=1.50458, train_acc=0.92769, val_loss=2.01800, val_acc=0.91606, time=1.03200
Epoch:0011, train_loss=1.49126, train_acc=0.94004, val_loss=2.01689, val_acc=0.92153, time=1.19300
Epoch:0012, train_loss=1.48011, train_acc=0.95098, val_loss=2.01601, val_acc=0.92518, time=0.95201
Epoch:0013, train_loss=1.47104, train_acc=0.95848, val_loss=2.01534, val_acc=0.92883, time=1.01800
Epoch:0014, train_loss=1.46402, train_acc=0.96698, val_loss=2.01485, val_acc=0.93613, time=1.11000
Epoch:0015, train_loss=1.45879, train_acc=0.97185, val_loss=2.01446, val_acc=0.93978, time=1.12601
Epoch:0016, train_loss=1.45478, train_acc=0.97428, val_loss=2.01411, val_acc=0.94343, time=1.09001
Epoch:0017, train_loss=1.45135, train_acc=0.97569, val_loss=2.01374, val_acc=0.94343, time=1.19999
Epoch:0018, train_loss=1.44803, train_acc=0.97752, val_loss=2.01336, val_acc=0.94708, time=1.02201
Epoch:0019, train_loss=1.44472, train_acc=0.97914, val_loss=2.01297, val_acc=0.94891, time=1.16001
Epoch:0020, train_loss=1.44150, train_acc=0.98218, val_loss=2.01260, val_acc=0.95073, time=1.18602
Epoch:0021, train_loss=1.43857, train_acc=0.98400, val_loss=2.01228, val_acc=0.95073, time=0.96101
Epoch:0022, train_loss=1.43606, train_acc=0.98542, val_loss=2.01201, val_acc=0.95073, time=1.20200
Epoch:0023, train_loss=1.43401, train_acc=0.98724, val_loss=2.01180, val_acc=0.94526, time=1.03101
Epoch:0024, train_loss=1.43240, train_acc=0.98704, val_loss=2.01164, val_acc=0.94343, time=1.24701
Epoch:0025, train_loss=1.43112, train_acc=0.98744, val_loss=2.01151, val_acc=0.94708, time=1.01301
Epoch:0026, train_loss=1.43006, train_acc=0.98825, val_loss=2.01140, val_acc=0.95073, time=1.03701
Epoch:0027, train_loss=1.42913, train_acc=0.98805, val_loss=2.01131, val_acc=0.95073, time=0.97901
Epoch:0028, train_loss=1.42827, train_acc=0.98845, val_loss=2.01124, val_acc=0.95073, time=0.97700
Epoch:0029, train_loss=1.42743, train_acc=0.98906, val_loss=2.01117, val_acc=0.95438, time=1.06601
Epoch:0030, train_loss=1.42661, train_acc=0.98906, val_loss=2.01111, val_acc=0.95438, time=1.09100
Epoch:0031, train_loss=1.42583, train_acc=0.99007, val_loss=2.01106, val_acc=0.95620, time=1.16200
Epoch:0032, train_loss=1.42509, train_acc=0.99170, val_loss=2.01102, val_acc=0.95803, time=1.16202
Epoch:0033, train_loss=1.42441, train_acc=0.99170, val_loss=2.01099, val_acc=0.95985, time=1.07201
Epoch:0034, train_loss=1.42377, train_acc=0.99251, val_loss=2.01096, val_acc=0.96168, time=1.02800
Epoch:0035, train_loss=1.42318, train_acc=0.99372, val_loss=2.01093, val_acc=0.96168, time=1.09500
Epoch:0036, train_loss=1.42261, train_acc=0.99352, val_loss=2.01090, val_acc=0.95985, time=1.02202
Epoch:0037, train_loss=1.42207, train_acc=0.99372, val_loss=2.01088, val_acc=0.95985, time=1.06900
Epoch:0038, train_loss=1.42155, train_acc=0.99392, val_loss=2.01086, val_acc=0.95620, time=1.03801
Epoch:0039, train_loss=1.42105, train_acc=0.99473, val_loss=2.01084, val_acc=0.95803, time=1.00000
Epoch:0040, train_loss=1.42058, train_acc=0.99534, val_loss=2.01083, val_acc=0.95803, time=0.96801
Epoch:0041, train_loss=1.42015, train_acc=0.99575, val_loss=2.01082, val_acc=0.95803, time=1.18000
Epoch:0042, train_loss=1.41975, train_acc=0.99595, val_loss=2.01081, val_acc=0.95803, time=1.09500
Epoch:0043, train_loss=1.41940, train_acc=0.99595, val_loss=2.01081, val_acc=0.95620, time=1.05501
Epoch:0044, train_loss=1.41908, train_acc=0.99656, val_loss=2.01081, val_acc=0.95803, time=1.24702
Epoch:0045, train_loss=1.41880, train_acc=0.99676, val_loss=2.01081, val_acc=0.95803, time=1.07101
Epoch:0046, train_loss=1.41853, train_acc=0.99696, val_loss=2.01081, val_acc=0.95985, time=1.07801
Epoch:0047, train_loss=1.41828, train_acc=0.99716, val_loss=2.01081, val_acc=0.95985, time=1.11901
Epoch:0048, train_loss=1.41804, train_acc=0.99696, val_loss=2.01081, val_acc=0.95803, time=1.05198
Epoch:0049, train_loss=1.41781, train_acc=0.99696, val_loss=2.01081, val_acc=0.95803, time=0.98501
Epoch:0050, train_loss=1.41759, train_acc=0.99696, val_loss=2.01081, val_acc=0.95803, time=1.03101
Epoch:0051, train_loss=1.41738, train_acc=0.99716, val_loss=2.01082, val_acc=0.95985, time=0.97401
Epoch:0052, train_loss=1.41719, train_acc=0.99737, val_loss=2.01082, val_acc=0.95985, time=0.99498
Epoch:0053, train_loss=1.41701, train_acc=0.99737, val_loss=2.01082, val_acc=0.96168, time=0.96101
Epoch:0054, train_loss=1.41684, train_acc=0.99757, val_loss=2.01083, val_acc=0.95985, time=1.06401
Epoch:0055, train_loss=1.41669, train_acc=0.99777, val_loss=2.01083, val_acc=0.95985, time=1.04501
Epoch:0056, train_loss=1.41654, train_acc=0.99777, val_loss=2.01083, val_acc=0.95985, time=1.11901
Epoch:0057, train_loss=1.41640, train_acc=0.99797, val_loss=2.01084, val_acc=0.95985, time=1.33300
Epoch:0058, train_loss=1.41627, train_acc=0.99797, val_loss=2.01084, val_acc=0.95985, time=1.01102
Epoch:0059, train_loss=1.41614, train_acc=0.99797, val_loss=2.01085, val_acc=0.95985, time=1.08601
Epoch:0060, train_loss=1.41602, train_acc=0.99797, val_loss=2.01085, val_acc=0.95985, time=1.04202
Epoch:0061, train_loss=1.41590, train_acc=0.99797, val_loss=2.01085, val_acc=0.95803, time=1.01501
Epoch:0062, train_loss=1.41579, train_acc=0.99797, val_loss=2.01085, val_acc=0.96168, time=1.24701
Epoch:0063, train_loss=1.41568, train_acc=0.99797, val_loss=2.01086, val_acc=0.96168, time=0.95501
Epoch:0064, train_loss=1.41558, train_acc=0.99797, val_loss=2.01086, val_acc=0.96350, time=1.01502
Epoch:0065, train_loss=1.41549, train_acc=0.99797, val_loss=2.01086, val_acc=0.96350, time=1.09300
Epoch:0066, train_loss=1.41540, train_acc=0.99797, val_loss=2.01086, val_acc=0.96350, time=1.29801
Epoch:0067, train_loss=1.41531, train_acc=0.99797, val_loss=2.01086, val_acc=0.96350, time=1.07502
Epoch:0068, train_loss=1.41523, train_acc=0.99818, val_loss=2.01087, val_acc=0.96350, time=1.07901
Epoch:0069, train_loss=1.41515, train_acc=0.99838, val_loss=2.01087, val_acc=0.96350, time=1.10000
Epoch:0070, train_loss=1.41507, train_acc=0.99838, val_loss=2.01087, val_acc=0.96168, time=1.02600
Epoch:0071, train_loss=1.41499, train_acc=0.99838, val_loss=2.01087, val_acc=0.96168, time=1.16200
Epoch:0072, train_loss=1.41492, train_acc=0.99838, val_loss=2.01087, val_acc=0.96350, time=1.03001
Epoch:0073, train_loss=1.41486, train_acc=0.99838, val_loss=2.01087, val_acc=0.96350, time=1.10000
Epoch:0074, train_loss=1.41479, train_acc=0.99838, val_loss=2.01087, val_acc=0.96350, time=1.13601
Epoch:0075, train_loss=1.41473, train_acc=0.99838, val_loss=2.01088, val_acc=0.96350, time=1.09901
Epoch:0076, train_loss=1.41467, train_acc=0.99838, val_loss=2.01088, val_acc=0.96350, time=1.16800
Epoch:0077, train_loss=1.41461, train_acc=0.99838, val_loss=2.01088, val_acc=0.96350, time=1.06502
Epoch:0078, train_loss=1.41456, train_acc=0.99838, val_loss=2.01089, val_acc=0.96350, time=1.00000
Epoch:0079, train_loss=1.41451, train_acc=0.99838, val_loss=2.01089, val_acc=0.96350, time=1.02800
Epoch:0080, train_loss=1.41445, train_acc=0.99858, val_loss=2.01089, val_acc=0.96168, time=1.05201
Epoch:0081, train_loss=1.41440, train_acc=0.99858, val_loss=2.01090, val_acc=0.96168, time=1.09600
Epoch:0082, train_loss=1.41436, train_acc=0.99858, val_loss=2.01090, val_acc=0.96168, time=1.06401
Epoch:0083, train_loss=1.41431, train_acc=0.99858, val_loss=2.01090, val_acc=0.96168, time=1.01002
Epoch:0084, train_loss=1.41427, train_acc=0.99858, val_loss=2.01091, val_acc=0.96168, time=1.00799
Epoch:0085, train_loss=1.41422, train_acc=0.99858, val_loss=2.01091, val_acc=0.96168, time=1.04800
Epoch:0086, train_loss=1.41418, train_acc=0.99858, val_loss=2.01092, val_acc=0.96168, time=0.99701
Epoch:0087, train_loss=1.41414, train_acc=0.99858, val_loss=2.01092, val_acc=0.96168, time=1.02800
Epoch:0088, train_loss=1.41410, train_acc=0.99858, val_loss=2.01093, val_acc=0.96168, time=1.08901
Epoch:0089, train_loss=1.41406, train_acc=0.99858, val_loss=2.01093, val_acc=0.96168, time=1.07500
Epoch:0090, train_loss=1.41402, train_acc=0.99858, val_loss=2.01094, val_acc=0.96350, time=1.14400
Epoch:0091, train_loss=1.41399, train_acc=0.99858, val_loss=2.01094, val_acc=0.96350, time=1.05802
Epoch:0092, train_loss=1.41395, train_acc=0.99858, val_loss=2.01095, val_acc=0.96350, time=1.11100
Epoch:0093, train_loss=1.41392, train_acc=0.99858, val_loss=2.01095, val_acc=0.96350, time=1.43602
Epoch:0094, train_loss=1.41388, train_acc=0.99858, val_loss=2.01096, val_acc=0.96350, time=1.07601
Epoch:0095, train_loss=1.41385, train_acc=0.99858, val_loss=2.01096, val_acc=0.96350, time=0.95700
Epoch:0096, train_loss=1.41382, train_acc=0.99858, val_loss=2.01097, val_acc=0.96350, time=1.22501
Epoch:0097, train_loss=1.41379, train_acc=0.99858, val_loss=2.01097, val_acc=0.96350, time=1.14502
Epoch:0098, train_loss=1.41376, train_acc=0.99858, val_loss=2.01098, val_acc=0.96350, time=1.20700
Epoch:0099, train_loss=1.41373, train_acc=0.99858, val_loss=2.01099, val_acc=0.96168, time=1.15101
Epoch:0100, train_loss=1.41370, train_acc=0.99818, val_loss=2.01099, val_acc=0.96168, time=1.14600
Epoch:0101, train_loss=1.41367, train_acc=0.99858, val_loss=2.01100, val_acc=0.96168, time=1.12300
Epoch:0102, train_loss=1.41364, train_acc=0.99858, val_loss=2.01100, val_acc=0.96168, time=1.07601
Epoch:0103, train_loss=1.41362, train_acc=0.99858, val_loss=2.01101, val_acc=0.96168, time=1.18201
Epoch:0104, train_loss=1.41359, train_acc=0.99858, val_loss=2.01101, val_acc=0.96168, time=0.97301
Epoch:0105, train_loss=1.41357, train_acc=0.99818, val_loss=2.01102, val_acc=0.96350, time=1.15201
Epoch:0106, train_loss=1.41354, train_acc=0.99838, val_loss=2.01102, val_acc=0.96350, time=1.08701
Epoch:0107, train_loss=1.41352, train_acc=0.99858, val_loss=2.01103, val_acc=0.96350, time=1.07001
Epoch:0108, train_loss=1.41349, train_acc=0.99858, val_loss=2.01103, val_acc=0.96350, time=1.12602
Epoch:0109, train_loss=1.41347, train_acc=0.99858, val_loss=2.01104, val_acc=0.96350, time=1.18901
Epoch:0110, train_loss=1.41345, train_acc=0.99858, val_loss=2.01104, val_acc=0.96350, time=1.13600
Epoch:0111, train_loss=1.41343, train_acc=0.99858, val_loss=2.01105, val_acc=0.96350, time=1.01601
Epoch:0112, train_loss=1.41340, train_acc=0.99858, val_loss=2.01105, val_acc=0.96350, time=0.97400
Epoch:0113, train_loss=1.41338, train_acc=0.99858, val_loss=2.01106, val_acc=0.96350, time=1.03701
Epoch:0114, train_loss=1.41336, train_acc=0.99858, val_loss=2.01106, val_acc=0.96350, time=1.00401
Epoch:0115, train_loss=1.41334, train_acc=0.99858, val_loss=2.01107, val_acc=0.96350, time=1.04202
Epoch:0116, train_loss=1.41332, train_acc=0.99858, val_loss=2.01107, val_acc=0.96168, time=0.97799
Epoch:0117, train_loss=1.41330, train_acc=0.99818, val_loss=2.01108, val_acc=0.96168, time=1.17501
Early stopping...

Optimization Finished!

Test set results: loss= 1.80455, accuracy= 0.95614, time= 0.32200

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9675    0.9898    0.9785      1083
           1     0.9763    0.9454    0.9606       696
           2     0.9120    0.9421    0.9268       121
           3     0.8667    0.8966    0.8814        87
           4     0.8571    0.9600    0.9057        75
           5     0.9014    0.7901    0.8421        81
           6     0.9615    0.6944    0.8065        36
           7     0.9091    1.0000    0.9524        10

    accuracy                         0.9561      2189
   macro avg     0.9190    0.9023    0.9067      2189
weighted avg     0.9566    0.9561    0.9556      2189


Macro average Test Precision, Recall and F1-Score...
(0.9189521872512896, 0.9023142141472306, 0.9067394944805068, None)

Micro average Test Precision, Recall and F1-Score...
(0.9561443581544085, 0.9561443581544085, 0.9561443581544085, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
