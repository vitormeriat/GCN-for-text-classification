
==========: 202548511248300
Epoch:0001, train_loss=2.28763, train_acc=0.05793, val_loss=2.08220, val_acc=0.25000, time=1.16301
Epoch:0002, train_loss=2.10312, train_acc=0.26231, val_loss=2.06698, val_acc=0.50547, time=1.27202
Epoch:0003, train_loss=1.96328, train_acc=0.51914, val_loss=2.05615, val_acc=0.64051, time=1.00700
Epoch:0004, train_loss=1.86315, train_acc=0.63743, val_loss=2.04869, val_acc=0.69708, time=1.00700
Epoch:0005, train_loss=1.79255, train_acc=0.69475, val_loss=2.04364, val_acc=0.72993, time=1.03801
Epoch:0006, train_loss=1.74335, train_acc=0.72271, val_loss=2.04014, val_acc=0.73905, time=1.18500
Epoch:0007, train_loss=1.70813, train_acc=0.74357, val_loss=2.03746, val_acc=0.76095, time=1.03698
Epoch:0008, train_loss=1.68053, train_acc=0.75896, val_loss=2.03514, val_acc=0.78102, time=0.96501
Epoch:0009, train_loss=1.65643, train_acc=0.77598, val_loss=2.03297, val_acc=0.79197, time=1.18302
Epoch:0010, train_loss=1.63400, train_acc=0.79623, val_loss=2.03092, val_acc=0.80474, time=0.97200
Epoch:0011, train_loss=1.61291, train_acc=0.81527, val_loss=2.02900, val_acc=0.81204, time=1.10401
Epoch:0012, train_loss=1.59336, train_acc=0.83451, val_loss=2.02724, val_acc=0.83029, time=1.21701
Epoch:0013, train_loss=1.57553, train_acc=0.85173, val_loss=2.02563, val_acc=0.85036, time=1.09900
Epoch:0014, train_loss=1.55942, train_acc=0.87138, val_loss=2.02415, val_acc=0.86861, time=1.19101
Epoch:0015, train_loss=1.54492, train_acc=0.88738, val_loss=2.02280, val_acc=0.87591, time=1.11500
Epoch:0016, train_loss=1.53192, train_acc=0.90156, val_loss=2.02158, val_acc=0.89051, time=1.10601
Epoch:0017, train_loss=1.52037, train_acc=0.91513, val_loss=2.02048, val_acc=0.89964, time=0.98001
Epoch:0018, train_loss=1.51024, train_acc=0.92607, val_loss=2.01950, val_acc=0.90511, time=1.07400
Epoch:0019, train_loss=1.50146, train_acc=0.93741, val_loss=2.01865, val_acc=0.90876, time=1.20001
Epoch:0020, train_loss=1.49392, train_acc=0.94450, val_loss=2.01792, val_acc=0.91241, time=1.07100
Epoch:0021, train_loss=1.48749, train_acc=0.95139, val_loss=2.01729, val_acc=0.91423, time=1.01501
Epoch:0022, train_loss=1.48206, train_acc=0.95402, val_loss=2.01676, val_acc=0.91788, time=1.05801
Epoch:0023, train_loss=1.47749, train_acc=0.95969, val_loss=2.01632, val_acc=0.92153, time=1.05101
Epoch:0024, train_loss=1.47366, train_acc=0.96374, val_loss=2.01593, val_acc=0.92518, time=1.07502
Epoch:0025, train_loss=1.47041, train_acc=0.96536, val_loss=2.01560, val_acc=0.92701, time=1.05301
Epoch:0026, train_loss=1.46759, train_acc=0.96678, val_loss=2.01530, val_acc=0.93431, time=1.12101
Epoch:0027, train_loss=1.46505, train_acc=0.96759, val_loss=2.01502, val_acc=0.93431, time=1.03100
Epoch:0028, train_loss=1.46267, train_acc=0.96840, val_loss=2.01475, val_acc=0.93613, time=1.06501
Epoch:0029, train_loss=1.46036, train_acc=0.96982, val_loss=2.01449, val_acc=0.93796, time=1.12401
Epoch:0030, train_loss=1.45808, train_acc=0.97225, val_loss=2.01424, val_acc=0.94161, time=1.12397
Epoch:0031, train_loss=1.45582, train_acc=0.97367, val_loss=2.01398, val_acc=0.94161, time=1.02100
Epoch:0032, train_loss=1.45361, train_acc=0.97529, val_loss=2.01374, val_acc=0.94708, time=1.07801
Epoch:0033, train_loss=1.45147, train_acc=0.97650, val_loss=2.01351, val_acc=0.94708, time=0.98202
Epoch:0034, train_loss=1.44945, train_acc=0.97731, val_loss=2.01330, val_acc=0.94526, time=0.95003
Epoch:0035, train_loss=1.44757, train_acc=0.97833, val_loss=2.01311, val_acc=0.94708, time=1.03200
Epoch:0036, train_loss=1.44586, train_acc=0.98076, val_loss=2.01293, val_acc=0.95073, time=1.22901
Epoch:0037, train_loss=1.44431, train_acc=0.98177, val_loss=2.01278, val_acc=0.94891, time=1.18701
Epoch:0038, train_loss=1.44292, train_acc=0.98299, val_loss=2.01264, val_acc=0.94343, time=1.04101
Epoch:0039, train_loss=1.44166, train_acc=0.98461, val_loss=2.01252, val_acc=0.94343, time=1.04702
Epoch:0040, train_loss=1.44053, train_acc=0.98481, val_loss=2.01242, val_acc=0.94161, time=1.08998
Epoch:0041, train_loss=1.43949, train_acc=0.98542, val_loss=2.01232, val_acc=0.94343, time=1.06301
Epoch:0042, train_loss=1.43853, train_acc=0.98542, val_loss=2.01223, val_acc=0.94343, time=1.12901
Epoch:0043, train_loss=1.43762, train_acc=0.98602, val_loss=2.01215, val_acc=0.94708, time=1.09000
Epoch:0044, train_loss=1.43677, train_acc=0.98623, val_loss=2.01208, val_acc=0.94708, time=1.02602
Epoch:0045, train_loss=1.43596, train_acc=0.98704, val_loss=2.01201, val_acc=0.94708, time=1.01301
Epoch:0046, train_loss=1.43519, train_acc=0.98744, val_loss=2.01194, val_acc=0.94708, time=0.97201
Epoch:0047, train_loss=1.43445, train_acc=0.98825, val_loss=2.01188, val_acc=0.95073, time=1.09400
Epoch:0048, train_loss=1.43376, train_acc=0.98906, val_loss=2.01183, val_acc=0.95255, time=1.02501
Epoch:0049, train_loss=1.43310, train_acc=0.98967, val_loss=2.01178, val_acc=0.95438, time=0.98800
Epoch:0050, train_loss=1.43247, train_acc=0.99028, val_loss=2.01173, val_acc=0.95255, time=1.23402
Epoch:0051, train_loss=1.43188, train_acc=0.99048, val_loss=2.01168, val_acc=0.95255, time=1.11601
Epoch:0052, train_loss=1.43131, train_acc=0.99048, val_loss=2.01164, val_acc=0.95255, time=1.09800
Epoch:0053, train_loss=1.43077, train_acc=0.99068, val_loss=2.01160, val_acc=0.95255, time=1.09702
Epoch:0054, train_loss=1.43026, train_acc=0.99068, val_loss=2.01156, val_acc=0.95255, time=1.04300
Epoch:0055, train_loss=1.42976, train_acc=0.99109, val_loss=2.01152, val_acc=0.95255, time=1.08101
Epoch:0056, train_loss=1.42928, train_acc=0.99170, val_loss=2.01149, val_acc=0.95073, time=0.95500
Epoch:0057, train_loss=1.42881, train_acc=0.99230, val_loss=2.01146, val_acc=0.95073, time=0.96303
Epoch:0058, train_loss=1.42837, train_acc=0.99251, val_loss=2.01143, val_acc=0.94891, time=0.97201
Epoch:0059, train_loss=1.42794, train_acc=0.99291, val_loss=2.01140, val_acc=0.94891, time=1.05601
Epoch:0060, train_loss=1.42752, train_acc=0.99291, val_loss=2.01137, val_acc=0.94708, time=1.03101
Epoch:0061, train_loss=1.42713, train_acc=0.99291, val_loss=2.01135, val_acc=0.94526, time=1.04800
Epoch:0062, train_loss=1.42675, train_acc=0.99311, val_loss=2.01133, val_acc=0.94526, time=1.17700
Epoch:0063, train_loss=1.42639, train_acc=0.99352, val_loss=2.01131, val_acc=0.94526, time=1.07001
Epoch:0064, train_loss=1.42605, train_acc=0.99332, val_loss=2.01129, val_acc=0.94526, time=1.02899
Epoch:0065, train_loss=1.42572, train_acc=0.99372, val_loss=2.01128, val_acc=0.94526, time=1.08201
Epoch:0066, train_loss=1.42540, train_acc=0.99372, val_loss=2.01126, val_acc=0.94343, time=1.01401
Epoch:0067, train_loss=1.42509, train_acc=0.99372, val_loss=2.01125, val_acc=0.94343, time=1.05201
Epoch:0068, train_loss=1.42480, train_acc=0.99413, val_loss=2.01123, val_acc=0.94161, time=1.07100
Epoch:0069, train_loss=1.42451, train_acc=0.99433, val_loss=2.01122, val_acc=0.94343, time=1.03301
Epoch:0070, train_loss=1.42423, train_acc=0.99494, val_loss=2.01121, val_acc=0.94526, time=1.04099
Epoch:0071, train_loss=1.42396, train_acc=0.99514, val_loss=2.01120, val_acc=0.94526, time=1.13701
Epoch:0072, train_loss=1.42371, train_acc=0.99534, val_loss=2.01119, val_acc=0.94526, time=1.06802
Epoch:0073, train_loss=1.42346, train_acc=0.99534, val_loss=2.01118, val_acc=0.94526, time=1.11300
Epoch:0074, train_loss=1.42322, train_acc=0.99554, val_loss=2.01117, val_acc=0.94708, time=1.26700
Epoch:0075, train_loss=1.42298, train_acc=0.99575, val_loss=2.01116, val_acc=0.94891, time=1.03000
Epoch:0076, train_loss=1.42276, train_acc=0.99575, val_loss=2.01115, val_acc=0.94891, time=1.10899
Epoch:0077, train_loss=1.42254, train_acc=0.99575, val_loss=2.01114, val_acc=0.94891, time=1.07702
Epoch:0078, train_loss=1.42233, train_acc=0.99595, val_loss=2.01113, val_acc=0.94891, time=1.00400
Epoch:0079, train_loss=1.42213, train_acc=0.99615, val_loss=2.01112, val_acc=0.94891, time=1.15802
Epoch:0080, train_loss=1.42193, train_acc=0.99615, val_loss=2.01110, val_acc=0.95073, time=1.11798
Epoch:0081, train_loss=1.42173, train_acc=0.99635, val_loss=2.01109, val_acc=0.95073, time=1.04602
Epoch:0082, train_loss=1.42154, train_acc=0.99635, val_loss=2.01108, val_acc=0.94891, time=1.15101
Epoch:0083, train_loss=1.42136, train_acc=0.99635, val_loss=2.01107, val_acc=0.94891, time=1.29400
Epoch:0084, train_loss=1.42118, train_acc=0.99635, val_loss=2.01106, val_acc=0.95073, time=1.12700
Epoch:0085, train_loss=1.42101, train_acc=0.99635, val_loss=2.01106, val_acc=0.95073, time=1.15600
Epoch:0086, train_loss=1.42084, train_acc=0.99635, val_loss=2.01105, val_acc=0.95255, time=1.15900
Epoch:0087, train_loss=1.42068, train_acc=0.99656, val_loss=2.01104, val_acc=0.95255, time=1.04202
Epoch:0088, train_loss=1.42052, train_acc=0.99676, val_loss=2.01103, val_acc=0.94891, time=1.09301
Epoch:0089, train_loss=1.42037, train_acc=0.99676, val_loss=2.01102, val_acc=0.94891, time=1.08501
Epoch:0090, train_loss=1.42022, train_acc=0.99676, val_loss=2.01101, val_acc=0.95073, time=0.98401
Epoch:0091, train_loss=1.42007, train_acc=0.99676, val_loss=2.01101, val_acc=0.95255, time=1.05001
Epoch:0092, train_loss=1.41993, train_acc=0.99716, val_loss=2.01100, val_acc=0.95438, time=1.10101
Epoch:0093, train_loss=1.41979, train_acc=0.99716, val_loss=2.01099, val_acc=0.95255, time=0.99300
Epoch:0094, train_loss=1.41965, train_acc=0.99716, val_loss=2.01099, val_acc=0.95255, time=1.21701
Epoch:0095, train_loss=1.41952, train_acc=0.99716, val_loss=2.01098, val_acc=0.95255, time=1.30201
Epoch:0096, train_loss=1.41939, train_acc=0.99737, val_loss=2.01098, val_acc=0.95255, time=1.03702
Epoch:0097, train_loss=1.41927, train_acc=0.99757, val_loss=2.01097, val_acc=0.95255, time=1.05701
Epoch:0098, train_loss=1.41915, train_acc=0.99757, val_loss=2.01096, val_acc=0.95255, time=1.14599
Epoch:0099, train_loss=1.41903, train_acc=0.99757, val_loss=2.01096, val_acc=0.95255, time=1.04902
Epoch:0100, train_loss=1.41891, train_acc=0.99777, val_loss=2.01095, val_acc=0.95255, time=1.09301
Epoch:0101, train_loss=1.41880, train_acc=0.99777, val_loss=2.01095, val_acc=0.95438, time=0.94700
Epoch:0102, train_loss=1.41869, train_acc=0.99777, val_loss=2.01095, val_acc=0.95438, time=1.04900
Epoch:0103, train_loss=1.41859, train_acc=0.99797, val_loss=2.01094, val_acc=0.95438, time=1.04401
Epoch:0104, train_loss=1.41848, train_acc=0.99797, val_loss=2.01094, val_acc=0.95438, time=1.19101
Epoch:0105, train_loss=1.41838, train_acc=0.99797, val_loss=2.01093, val_acc=0.95438, time=1.07601
Epoch:0106, train_loss=1.41828, train_acc=0.99797, val_loss=2.01093, val_acc=0.95438, time=1.19000
Epoch:0107, train_loss=1.41818, train_acc=0.99797, val_loss=2.01092, val_acc=0.95438, time=1.14301
Epoch:0108, train_loss=1.41809, train_acc=0.99797, val_loss=2.01092, val_acc=0.95438, time=0.99301
Epoch:0109, train_loss=1.41799, train_acc=0.99797, val_loss=2.01092, val_acc=0.95438, time=1.05801
Epoch:0110, train_loss=1.41790, train_acc=0.99797, val_loss=2.01091, val_acc=0.95438, time=1.01100
Epoch:0111, train_loss=1.41782, train_acc=0.99797, val_loss=2.01091, val_acc=0.95620, time=1.12101
Epoch:0112, train_loss=1.41773, train_acc=0.99797, val_loss=2.01091, val_acc=0.95620, time=1.06000
Epoch:0113, train_loss=1.41765, train_acc=0.99818, val_loss=2.01091, val_acc=0.95620, time=0.98602
Epoch:0114, train_loss=1.41756, train_acc=0.99818, val_loss=2.01090, val_acc=0.95620, time=1.09600
Epoch:0115, train_loss=1.41748, train_acc=0.99818, val_loss=2.01090, val_acc=0.95620, time=0.97401
Epoch:0116, train_loss=1.41740, train_acc=0.99838, val_loss=2.01090, val_acc=0.95803, time=1.14301
Epoch:0117, train_loss=1.41733, train_acc=0.99838, val_loss=2.01090, val_acc=0.95803, time=1.00301
Epoch:0118, train_loss=1.41725, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.04801
Epoch:0119, train_loss=1.41718, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=0.96200
Epoch:0120, train_loss=1.41710, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.07499
Epoch:0121, train_loss=1.41703, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.01500
Epoch:0122, train_loss=1.41696, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.07501
Epoch:0123, train_loss=1.41690, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.00100
Epoch:0124, train_loss=1.41683, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.01499
Epoch:0125, train_loss=1.41676, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.01501
Epoch:0126, train_loss=1.41670, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.27602
Epoch:0127, train_loss=1.41664, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.09700
Epoch:0128, train_loss=1.41658, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.13501
Epoch:0129, train_loss=1.41652, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.05802
Epoch:0130, train_loss=1.41646, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.03901
Epoch:0131, train_loss=1.41640, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.06300
Epoch:0132, train_loss=1.41634, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=0.98102
Epoch:0133, train_loss=1.41629, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.05801
Epoch:0134, train_loss=1.41623, train_acc=0.99838, val_loss=2.01089, val_acc=0.95803, time=1.06402
Epoch:0135, train_loss=1.41618, train_acc=0.99838, val_loss=2.01089, val_acc=0.95620, time=0.95401
Early stopping...

Optimization Finished!

Test set results: loss= 1.80397, accuracy= 0.95569, time= 0.29700

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9656    0.9861    0.9758      1083
           1     0.9792    0.9454    0.9620       696
           2     0.9008    0.9752    0.9365       121
           3     0.8837    0.8736    0.8786        87
           4     0.8642    0.9333    0.8974        75
           5     0.8608    0.8395    0.8500        81
           6     1.0000    0.6944    0.8197        36
           7     1.0000    0.9000    0.9474        10

    accuracy                         0.9557      2189
   macro avg     0.9318    0.8935    0.9084      2189
weighted avg     0.9565    0.9557    0.9553      2189


Macro average Test Precision, Recall and F1-Score...
(0.9317812416495824, 0.8934507079895557, 0.908421679758124, None)

Micro average Test Precision, Recall and F1-Score...
(0.9556875285518501, 0.9556875285518501, 0.9556875285518501, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
