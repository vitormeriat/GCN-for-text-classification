
==========: 211438744420500
Epoch:0001, train_loss=2.30296, train_acc=0.07737, val_loss=2.06800, val_acc=0.53467, time=1.17400
Epoch:0002, train_loss=1.99423, train_acc=0.51732, val_loss=2.04952, val_acc=0.67336, time=0.98401
Epoch:0003, train_loss=1.80966, train_acc=0.64067, val_loss=2.04026, val_acc=0.72445, time=1.10201
Epoch:0004, train_loss=1.71209, train_acc=0.72554, val_loss=2.03602, val_acc=0.74088, time=1.06101
Epoch:0005, train_loss=1.66504, train_acc=0.75957, val_loss=2.03287, val_acc=0.77555, time=1.04200
Epoch:0006, train_loss=1.63071, train_acc=0.78995, val_loss=2.02953, val_acc=0.79927, time=1.08402
Epoch:0007, train_loss=1.59686, train_acc=0.81892, val_loss=2.02636, val_acc=0.83212, time=0.99100
Epoch:0008, train_loss=1.56588, train_acc=0.85376, val_loss=2.02382, val_acc=0.85766, time=1.29602
Epoch:0009, train_loss=1.54148, train_acc=0.88455, val_loss=2.02193, val_acc=0.88321, time=1.06400
Epoch:0010, train_loss=1.52323, train_acc=0.90622, val_loss=2.02046, val_acc=0.89234, time=1.11501
Epoch:0011, train_loss=1.50880, train_acc=0.92364, val_loss=2.01924, val_acc=0.90146, time=1.45999
Epoch:0012, train_loss=1.49667, train_acc=0.93356, val_loss=2.01820, val_acc=0.90146, time=1.17801
Epoch:0013, train_loss=1.48632, train_acc=0.93883, val_loss=2.01732, val_acc=0.90876, time=1.17501
Epoch:0014, train_loss=1.47753, train_acc=0.94713, val_loss=2.01657, val_acc=0.90876, time=1.22299
Epoch:0015, train_loss=1.47004, train_acc=0.95301, val_loss=2.01590, val_acc=0.91971, time=1.14701
Epoch:0016, train_loss=1.46350, train_acc=0.95746, val_loss=2.01531, val_acc=0.92336, time=1.04400
Epoch:0017, train_loss=1.45768, train_acc=0.96212, val_loss=2.01476, val_acc=0.92701, time=1.09701
Epoch:0018, train_loss=1.45256, train_acc=0.96698, val_loss=2.01428, val_acc=0.92883, time=1.16000
Epoch:0019, train_loss=1.44818, train_acc=0.97164, val_loss=2.01388, val_acc=0.93431, time=1.12602
Epoch:0020, train_loss=1.44459, train_acc=0.97529, val_loss=2.01355, val_acc=0.93613, time=1.16901
Epoch:0021, train_loss=1.44175, train_acc=0.97671, val_loss=2.01329, val_acc=0.93613, time=1.22102
Epoch:0022, train_loss=1.43955, train_acc=0.97995, val_loss=2.01309, val_acc=0.94161, time=1.02501
Epoch:0023, train_loss=1.43782, train_acc=0.98157, val_loss=2.01293, val_acc=0.94343, time=1.11599
Epoch:0024, train_loss=1.43640, train_acc=0.98359, val_loss=2.01279, val_acc=0.94343, time=1.00001
Epoch:0025, train_loss=1.43518, train_acc=0.98481, val_loss=2.01268, val_acc=0.94343, time=1.04601
Epoch:0026, train_loss=1.43406, train_acc=0.98643, val_loss=2.01257, val_acc=0.94343, time=1.26900
Epoch:0027, train_loss=1.43299, train_acc=0.98744, val_loss=2.01246, val_acc=0.94161, time=1.11001
Epoch:0028, train_loss=1.43194, train_acc=0.98764, val_loss=2.01237, val_acc=0.94343, time=1.15501
Epoch:0029, train_loss=1.43089, train_acc=0.98805, val_loss=2.01227, val_acc=0.94343, time=1.13599
Epoch:0030, train_loss=1.42986, train_acc=0.98906, val_loss=2.01219, val_acc=0.94526, time=1.10000
Epoch:0031, train_loss=1.42885, train_acc=0.98987, val_loss=2.01211, val_acc=0.94891, time=1.11901
Epoch:0032, train_loss=1.42788, train_acc=0.99129, val_loss=2.01205, val_acc=0.94891, time=1.06803
Epoch:0033, train_loss=1.42696, train_acc=0.99149, val_loss=2.01200, val_acc=0.95073, time=0.99100
Epoch:0034, train_loss=1.42611, train_acc=0.99170, val_loss=2.01196, val_acc=0.95073, time=1.03901
Epoch:0035, train_loss=1.42532, train_acc=0.99210, val_loss=2.01193, val_acc=0.95073, time=1.01201
Epoch:0036, train_loss=1.42461, train_acc=0.99230, val_loss=2.01191, val_acc=0.95255, time=1.01100
Epoch:0037, train_loss=1.42395, train_acc=0.99210, val_loss=2.01189, val_acc=0.95438, time=1.11500
Epoch:0038, train_loss=1.42336, train_acc=0.99332, val_loss=2.01188, val_acc=0.95620, time=1.00601
Epoch:0039, train_loss=1.42282, train_acc=0.99413, val_loss=2.01187, val_acc=0.95620, time=1.08001
Epoch:0040, train_loss=1.42232, train_acc=0.99413, val_loss=2.01187, val_acc=0.95620, time=1.30301
Epoch:0041, train_loss=1.42186, train_acc=0.99473, val_loss=2.01186, val_acc=0.95620, time=1.13700
Epoch:0042, train_loss=1.42145, train_acc=0.99534, val_loss=2.01185, val_acc=0.95985, time=0.97702
Epoch:0043, train_loss=1.42106, train_acc=0.99554, val_loss=2.01185, val_acc=0.95803, time=1.17900
Epoch:0044, train_loss=1.42071, train_acc=0.99595, val_loss=2.01184, val_acc=0.95985, time=1.15202
Epoch:0045, train_loss=1.42037, train_acc=0.99595, val_loss=2.01183, val_acc=0.96168, time=1.02200
Epoch:0046, train_loss=1.42006, train_acc=0.99615, val_loss=2.01182, val_acc=0.96350, time=1.07101
Epoch:0047, train_loss=1.41977, train_acc=0.99635, val_loss=2.01181, val_acc=0.96350, time=1.15601
Epoch:0048, train_loss=1.41949, train_acc=0.99656, val_loss=2.01180, val_acc=0.96350, time=1.10100
Epoch:0049, train_loss=1.41923, train_acc=0.99676, val_loss=2.01179, val_acc=0.96350, time=1.19801
Epoch:0050, train_loss=1.41897, train_acc=0.99676, val_loss=2.01178, val_acc=0.96350, time=1.13702
Epoch:0051, train_loss=1.41872, train_acc=0.99696, val_loss=2.01178, val_acc=0.96350, time=1.19300
Epoch:0052, train_loss=1.41849, train_acc=0.99696, val_loss=2.01177, val_acc=0.96350, time=1.09399
Epoch:0053, train_loss=1.41826, train_acc=0.99696, val_loss=2.01176, val_acc=0.96350, time=1.04901
Epoch:0054, train_loss=1.41804, train_acc=0.99716, val_loss=2.01176, val_acc=0.96350, time=1.12501
Epoch:0055, train_loss=1.41783, train_acc=0.99716, val_loss=2.01175, val_acc=0.96350, time=1.09300
Epoch:0056, train_loss=1.41764, train_acc=0.99716, val_loss=2.01175, val_acc=0.96350, time=1.11602
Epoch:0057, train_loss=1.41745, train_acc=0.99716, val_loss=2.01175, val_acc=0.96168, time=0.99301
Epoch:0058, train_loss=1.41728, train_acc=0.99716, val_loss=2.01175, val_acc=0.96168, time=1.21001
Epoch:0059, train_loss=1.41712, train_acc=0.99716, val_loss=2.01175, val_acc=0.96168, time=1.12801
Epoch:0060, train_loss=1.41697, train_acc=0.99737, val_loss=2.01175, val_acc=0.95985, time=1.19400
Epoch:0061, train_loss=1.41683, train_acc=0.99716, val_loss=2.01176, val_acc=0.95985, time=1.18600
Epoch:0062, train_loss=1.41669, train_acc=0.99757, val_loss=2.01176, val_acc=0.96168, time=1.09102
Early stopping...

Optimization Finished!

Test set results: loss= 1.80426, accuracy= 0.95477, time= 0.31700

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9666    0.9889    0.9776      1083
           1     0.9835    0.9425    0.9626       696
           2     0.8881    0.9835    0.9333       121
           3     0.8667    0.8966    0.8814        87
           4     0.8642    0.9333    0.8974        75
           5     0.8784    0.8025    0.8387        81
           6     0.9130    0.5833    0.7119        36
           7     0.8333    1.0000    0.9091        10

    accuracy                         0.9548      2189
   macro avg     0.8992    0.8913    0.8890      2189
weighted avg     0.9554    0.9548    0.9540      2189


Macro average Test Precision, Recall and F1-Score...
(0.8992242291334988, 0.8913258755261805, 0.8890010596910156, None)

Micro average Test Precision, Recall and F1-Score...
(0.9547738693467337, 0.9547738693467337, 0.9547738693467337, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
