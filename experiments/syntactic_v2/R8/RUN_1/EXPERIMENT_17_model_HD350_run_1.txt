
==========: 211706327001100
Epoch:0001, train_loss=2.42904, train_acc=0.00770, val_loss=2.07717, val_acc=0.37044, time=1.02501
Epoch:0002, train_loss=2.04927, train_acc=0.37756, val_loss=2.05226, val_acc=0.64964, time=1.04601
Epoch:0003, train_loss=1.82445, train_acc=0.66721, val_loss=2.04015, val_acc=0.73175, time=1.06201
Epoch:0004, train_loss=1.71613, train_acc=0.73324, val_loss=2.03466, val_acc=0.74635, time=1.20200
Epoch:0005, train_loss=1.66484, train_acc=0.75937, val_loss=2.03111, val_acc=0.77007, time=1.04401
Epoch:0006, train_loss=1.62884, train_acc=0.79137, val_loss=2.02787, val_acc=0.81022, time=0.98001
Epoch:0007, train_loss=1.59422, train_acc=0.82682, val_loss=2.02493, val_acc=0.84854, time=0.98200
Epoch:0008, train_loss=1.56197, train_acc=0.86611, val_loss=2.02262, val_acc=0.87226, time=0.96100
Epoch:0009, train_loss=1.53570, train_acc=0.89933, val_loss=2.02101, val_acc=0.89051, time=1.07002
Epoch:0010, train_loss=1.51661, train_acc=0.92263, val_loss=2.01993, val_acc=0.90693, time=1.06000
Epoch:0011, train_loss=1.50326, train_acc=0.93518, val_loss=2.01917, val_acc=0.91241, time=1.19602
Epoch:0012, train_loss=1.49350, train_acc=0.94349, val_loss=2.01857, val_acc=0.92153, time=1.02899
Epoch:0013, train_loss=1.48577, train_acc=0.95179, val_loss=2.01805, val_acc=0.92701, time=1.16601
Epoch:0014, train_loss=1.47923, train_acc=0.95787, val_loss=2.01759, val_acc=0.93066, time=1.14002
Epoch:0015, train_loss=1.47359, train_acc=0.96334, val_loss=2.01717, val_acc=0.93796, time=1.01000
Epoch:0016, train_loss=1.46874, train_acc=0.96678, val_loss=2.01681, val_acc=0.93796, time=0.99402
Epoch:0017, train_loss=1.46467, train_acc=0.97043, val_loss=2.01648, val_acc=0.93978, time=1.09400
Epoch:0018, train_loss=1.46124, train_acc=0.97043, val_loss=2.01617, val_acc=0.93796, time=1.02701
Epoch:0019, train_loss=1.45816, train_acc=0.97164, val_loss=2.01585, val_acc=0.93978, time=1.03101
Epoch:0020, train_loss=1.45513, train_acc=0.97306, val_loss=2.01553, val_acc=0.93978, time=1.15700
Epoch:0021, train_loss=1.45203, train_acc=0.97488, val_loss=2.01520, val_acc=0.93978, time=1.11001
Epoch:0022, train_loss=1.44894, train_acc=0.97650, val_loss=2.01489, val_acc=0.93978, time=0.94500
Epoch:0023, train_loss=1.44602, train_acc=0.97833, val_loss=2.01462, val_acc=0.94161, time=1.04404
Epoch:0024, train_loss=1.44342, train_acc=0.98055, val_loss=2.01439, val_acc=0.94343, time=1.05199
Epoch:0025, train_loss=1.44120, train_acc=0.98278, val_loss=2.01421, val_acc=0.94343, time=1.04202
Epoch:0026, train_loss=1.43931, train_acc=0.98218, val_loss=2.01405, val_acc=0.94343, time=1.23400
Epoch:0027, train_loss=1.43766, train_acc=0.98278, val_loss=2.01391, val_acc=0.94161, time=1.23700
Epoch:0028, train_loss=1.43617, train_acc=0.98238, val_loss=2.01379, val_acc=0.94161, time=1.16201
Epoch:0029, train_loss=1.43477, train_acc=0.98380, val_loss=2.01369, val_acc=0.94161, time=1.17399
Epoch:0030, train_loss=1.43346, train_acc=0.98481, val_loss=2.01359, val_acc=0.94161, time=1.17901
Epoch:0031, train_loss=1.43223, train_acc=0.98582, val_loss=2.01351, val_acc=0.94343, time=1.05502
Epoch:0032, train_loss=1.43108, train_acc=0.98643, val_loss=2.01343, val_acc=0.94343, time=1.02601
Epoch:0033, train_loss=1.43002, train_acc=0.98704, val_loss=2.01335, val_acc=0.94708, time=1.03502
Epoch:0034, train_loss=1.42904, train_acc=0.98724, val_loss=2.01327, val_acc=0.94708, time=1.21001
Epoch:0035, train_loss=1.42814, train_acc=0.98926, val_loss=2.01320, val_acc=0.94891, time=1.02400
Epoch:0036, train_loss=1.42730, train_acc=0.99028, val_loss=2.01311, val_acc=0.95255, time=0.99301
Epoch:0037, train_loss=1.42649, train_acc=0.99089, val_loss=2.01302, val_acc=0.95073, time=1.00602
Epoch:0038, train_loss=1.42571, train_acc=0.99109, val_loss=2.01292, val_acc=0.95073, time=0.94701
Epoch:0039, train_loss=1.42496, train_acc=0.99109, val_loss=2.01282, val_acc=0.95255, time=0.97700
Epoch:0040, train_loss=1.42422, train_acc=0.99149, val_loss=2.01271, val_acc=0.95255, time=0.96900
Epoch:0041, train_loss=1.42352, train_acc=0.99230, val_loss=2.01261, val_acc=0.95255, time=1.19602
Epoch:0042, train_loss=1.42286, train_acc=0.99332, val_loss=2.01251, val_acc=0.95803, time=1.04302
Epoch:0043, train_loss=1.42226, train_acc=0.99372, val_loss=2.01242, val_acc=0.95620, time=1.03301
Epoch:0044, train_loss=1.42172, train_acc=0.99453, val_loss=2.01233, val_acc=0.95438, time=1.11001
Epoch:0045, train_loss=1.42123, train_acc=0.99473, val_loss=2.01226, val_acc=0.95438, time=1.02701
Epoch:0046, train_loss=1.42079, train_acc=0.99554, val_loss=2.01219, val_acc=0.95438, time=1.03199
Epoch:0047, train_loss=1.42040, train_acc=0.99575, val_loss=2.01213, val_acc=0.95620, time=1.08402
Epoch:0048, train_loss=1.42005, train_acc=0.99575, val_loss=2.01208, val_acc=0.95620, time=1.08900
Epoch:0049, train_loss=1.41973, train_acc=0.99575, val_loss=2.01203, val_acc=0.95803, time=0.99902
Epoch:0050, train_loss=1.41943, train_acc=0.99635, val_loss=2.01199, val_acc=0.95620, time=1.17401
Epoch:0051, train_loss=1.41915, train_acc=0.99615, val_loss=2.01195, val_acc=0.95620, time=1.13100
Epoch:0052, train_loss=1.41889, train_acc=0.99615, val_loss=2.01192, val_acc=0.95620, time=1.01802
Epoch:0053, train_loss=1.41865, train_acc=0.99635, val_loss=2.01190, val_acc=0.95620, time=1.10301
Epoch:0054, train_loss=1.41842, train_acc=0.99676, val_loss=2.01187, val_acc=0.95620, time=1.03300
Epoch:0055, train_loss=1.41821, train_acc=0.99635, val_loss=2.01185, val_acc=0.95620, time=1.27102
Epoch:0056, train_loss=1.41802, train_acc=0.99656, val_loss=2.01183, val_acc=0.95438, time=1.16800
Epoch:0057, train_loss=1.41783, train_acc=0.99676, val_loss=2.01182, val_acc=0.95073, time=0.98703
Epoch:0058, train_loss=1.41766, train_acc=0.99696, val_loss=2.01180, val_acc=0.95073, time=1.15501
Epoch:0059, train_loss=1.41749, train_acc=0.99716, val_loss=2.01179, val_acc=0.95073, time=1.07300
Epoch:0060, train_loss=1.41733, train_acc=0.99716, val_loss=2.01177, val_acc=0.94891, time=1.04101
Epoch:0061, train_loss=1.41717, train_acc=0.99757, val_loss=2.01176, val_acc=0.94891, time=1.10200
Epoch:0062, train_loss=1.41702, train_acc=0.99757, val_loss=2.01174, val_acc=0.94891, time=1.15401
Epoch:0063, train_loss=1.41688, train_acc=0.99777, val_loss=2.01173, val_acc=0.94891, time=1.16800
Epoch:0064, train_loss=1.41674, train_acc=0.99777, val_loss=2.01171, val_acc=0.94891, time=1.05603
Epoch:0065, train_loss=1.41662, train_acc=0.99777, val_loss=2.01170, val_acc=0.94891, time=1.02800
Epoch:0066, train_loss=1.41649, train_acc=0.99797, val_loss=2.01169, val_acc=0.94891, time=1.18400
Epoch:0067, train_loss=1.41637, train_acc=0.99797, val_loss=2.01167, val_acc=0.94891, time=1.15601
Epoch:0068, train_loss=1.41626, train_acc=0.99797, val_loss=2.01166, val_acc=0.94891, time=1.11000
Epoch:0069, train_loss=1.41615, train_acc=0.99797, val_loss=2.01165, val_acc=0.95073, time=1.04401
Epoch:0070, train_loss=1.41604, train_acc=0.99797, val_loss=2.01163, val_acc=0.95073, time=1.06101
Epoch:0071, train_loss=1.41594, train_acc=0.99797, val_loss=2.01162, val_acc=0.95073, time=1.04300
Epoch:0072, train_loss=1.41584, train_acc=0.99797, val_loss=2.01161, val_acc=0.95073, time=1.06100
Epoch:0073, train_loss=1.41575, train_acc=0.99818, val_loss=2.01160, val_acc=0.95255, time=1.03700
Epoch:0074, train_loss=1.41566, train_acc=0.99858, val_loss=2.01159, val_acc=0.95438, time=1.11601
Epoch:0075, train_loss=1.41558, train_acc=0.99818, val_loss=2.01158, val_acc=0.95438, time=1.02600
Epoch:0076, train_loss=1.41550, train_acc=0.99818, val_loss=2.01158, val_acc=0.95438, time=1.03801
Epoch:0077, train_loss=1.41542, train_acc=0.99818, val_loss=2.01157, val_acc=0.95438, time=1.01701
Epoch:0078, train_loss=1.41534, train_acc=0.99818, val_loss=2.01156, val_acc=0.95438, time=1.12100
Epoch:0079, train_loss=1.41527, train_acc=0.99818, val_loss=2.01156, val_acc=0.95438, time=1.04402
Epoch:0080, train_loss=1.41520, train_acc=0.99818, val_loss=2.01155, val_acc=0.95438, time=1.08900
Epoch:0081, train_loss=1.41513, train_acc=0.99818, val_loss=2.01155, val_acc=0.95438, time=1.17901
Epoch:0082, train_loss=1.41506, train_acc=0.99858, val_loss=2.01154, val_acc=0.95255, time=1.08400
Epoch:0083, train_loss=1.41500, train_acc=0.99818, val_loss=2.01154, val_acc=0.95255, time=1.26302
Epoch:0084, train_loss=1.41494, train_acc=0.99818, val_loss=2.01154, val_acc=0.95255, time=1.11600
Epoch:0085, train_loss=1.41488, train_acc=0.99818, val_loss=2.01153, val_acc=0.95255, time=1.05400
Epoch:0086, train_loss=1.41482, train_acc=0.99818, val_loss=2.01153, val_acc=0.95255, time=1.19801
Epoch:0087, train_loss=1.41476, train_acc=0.99818, val_loss=2.01153, val_acc=0.95255, time=1.15201
Epoch:0088, train_loss=1.41471, train_acc=0.99818, val_loss=2.01153, val_acc=0.95255, time=1.04301
Epoch:0089, train_loss=1.41466, train_acc=0.99818, val_loss=2.01153, val_acc=0.95255, time=1.09199
Epoch:0090, train_loss=1.41461, train_acc=0.99818, val_loss=2.01153, val_acc=0.95255, time=1.12301
Epoch:0091, train_loss=1.41456, train_acc=0.99818, val_loss=2.01153, val_acc=0.95438, time=0.98902
Epoch:0092, train_loss=1.41451, train_acc=0.99858, val_loss=2.01153, val_acc=0.95438, time=1.05600
Epoch:0093, train_loss=1.41446, train_acc=0.99878, val_loss=2.01152, val_acc=0.95438, time=1.00401
Epoch:0094, train_loss=1.41442, train_acc=0.99858, val_loss=2.01152, val_acc=0.95438, time=1.21203
Epoch:0095, train_loss=1.41437, train_acc=0.99858, val_loss=2.01152, val_acc=0.95438, time=1.27299
Epoch:0096, train_loss=1.41433, train_acc=0.99858, val_loss=2.01152, val_acc=0.95438, time=1.17200
Epoch:0097, train_loss=1.41429, train_acc=0.99858, val_loss=2.01152, val_acc=0.95438, time=1.10799
Epoch:0098, train_loss=1.41425, train_acc=0.99899, val_loss=2.01152, val_acc=0.95438, time=1.02302
Epoch:0099, train_loss=1.41421, train_acc=0.99899, val_loss=2.01152, val_acc=0.95255, time=1.07800
Epoch:0100, train_loss=1.41417, train_acc=0.99858, val_loss=2.01152, val_acc=0.95255, time=1.06800
Epoch:0101, train_loss=1.41413, train_acc=0.99858, val_loss=2.01152, val_acc=0.95255, time=1.02701
Epoch:0102, train_loss=1.41410, train_acc=0.99858, val_loss=2.01152, val_acc=0.95255, time=1.15199
Epoch:0103, train_loss=1.41406, train_acc=0.99858, val_loss=2.01152, val_acc=0.95255, time=1.01000
Epoch:0104, train_loss=1.41403, train_acc=0.99858, val_loss=2.01152, val_acc=0.95255, time=1.08001
Epoch:0105, train_loss=1.41399, train_acc=0.99858, val_loss=2.01152, val_acc=0.95255, time=1.03899
Epoch:0106, train_loss=1.41396, train_acc=0.99858, val_loss=2.01152, val_acc=0.95438, time=1.00201
Early stopping...

Optimization Finished!

Test set results: loss= 1.80356, accuracy= 0.95523, time= 0.29800

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9666    0.9898    0.9781      1083
           1     0.9776    0.9425    0.9598       696
           2     0.9113    0.9339    0.9224       121
           3     0.8617    0.9310    0.8950        87
           4     0.8642    0.9333    0.8974        75
           5     0.9155    0.8025    0.8553        81
           6     0.8621    0.6944    0.7692        36
           7     0.9000    0.9000    0.9000        10

    accuracy                         0.9552      2189
   macro avg     0.9074    0.8909    0.8972      2189
weighted avg     0.9555    0.9552    0.9548      2189


Macro average Test Precision, Recall and F1-Score...
(0.907379227430057, 0.8909421822644881, 0.8971593161246412, None)

Micro average Test Precision, Recall and F1-Score...
(0.9552306989492919, 0.9552306989492919, 0.9552306989492919, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
