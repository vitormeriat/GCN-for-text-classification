
==========: 201011878898800
Epoch:0001, train_loss=2.16488, train_acc=0.07981, val_loss=2.05971, val_acc=0.59307, time=1.14001
Epoch:0002, train_loss=1.90404, train_acc=0.56937, val_loss=2.04720, val_acc=0.67883, time=1.14400
Epoch:0003, train_loss=1.78276, train_acc=0.67794, val_loss=2.04066, val_acc=0.72080, time=1.13100
Epoch:0004, train_loss=1.71676, train_acc=0.73263, val_loss=2.03573, val_acc=0.76642, time=1.01202
Epoch:0005, train_loss=1.66693, train_acc=0.77233, val_loss=2.03126, val_acc=0.79927, time=1.01699
Epoch:0006, train_loss=1.62246, train_acc=0.81041, val_loss=2.02715, val_acc=0.82299, time=1.17001
Epoch:0007, train_loss=1.58242, train_acc=0.84525, val_loss=2.02364, val_acc=0.85036, time=1.09201
Epoch:0008, train_loss=1.54895, train_acc=0.88211, val_loss=2.02092, val_acc=0.87774, time=1.09801
Epoch:0009, train_loss=1.52353, train_acc=0.90966, val_loss=2.01890, val_acc=0.90511, time=1.09502
Epoch:0010, train_loss=1.50522, train_acc=0.92971, val_loss=2.01738, val_acc=0.91606, time=1.00900
Epoch:0011, train_loss=1.49178, train_acc=0.94470, val_loss=2.01619, val_acc=0.92336, time=1.09001
Epoch:0012, train_loss=1.48134, train_acc=0.95524, val_loss=2.01520, val_acc=0.93248, time=1.09401
Epoch:0013, train_loss=1.47282, train_acc=0.96131, val_loss=2.01438, val_acc=0.93613, time=1.17801
Epoch:0014, train_loss=1.46575, train_acc=0.96719, val_loss=2.01370, val_acc=0.93978, time=1.24501
Epoch:0015, train_loss=1.45997, train_acc=0.97104, val_loss=2.01315, val_acc=0.94343, time=1.14902
Epoch:0016, train_loss=1.45534, train_acc=0.97529, val_loss=2.01271, val_acc=0.94161, time=1.10700
Epoch:0017, train_loss=1.45169, train_acc=0.97812, val_loss=2.01235, val_acc=0.94161, time=1.13101
Epoch:0018, train_loss=1.44873, train_acc=0.97812, val_loss=2.01203, val_acc=0.94526, time=1.10701
Epoch:0019, train_loss=1.44616, train_acc=0.97974, val_loss=2.01175, val_acc=0.94891, time=1.01002
Epoch:0020, train_loss=1.44379, train_acc=0.98157, val_loss=2.01149, val_acc=0.94708, time=1.25501
Epoch:0021, train_loss=1.44152, train_acc=0.98278, val_loss=2.01126, val_acc=0.94708, time=1.07401
Epoch:0022, train_loss=1.43937, train_acc=0.98339, val_loss=2.01105, val_acc=0.94891, time=0.97100
Epoch:0023, train_loss=1.43734, train_acc=0.98461, val_loss=2.01087, val_acc=0.95073, time=0.98400
Epoch:0024, train_loss=1.43546, train_acc=0.98602, val_loss=2.01073, val_acc=0.94891, time=1.25100
Epoch:0025, train_loss=1.43376, train_acc=0.98683, val_loss=2.01061, val_acc=0.95073, time=1.19202
Epoch:0026, train_loss=1.43223, train_acc=0.98704, val_loss=2.01052, val_acc=0.95073, time=1.20402
Epoch:0027, train_loss=1.43086, train_acc=0.98724, val_loss=2.01046, val_acc=0.95073, time=1.22400
Epoch:0028, train_loss=1.42964, train_acc=0.98845, val_loss=2.01041, val_acc=0.94891, time=1.07302
Epoch:0029, train_loss=1.42853, train_acc=0.98926, val_loss=2.01038, val_acc=0.94708, time=1.13100
Epoch:0030, train_loss=1.42753, train_acc=0.98967, val_loss=2.01037, val_acc=0.94708, time=1.16600
Epoch:0031, train_loss=1.42661, train_acc=0.98987, val_loss=2.01036, val_acc=0.95073, time=1.27702
Epoch:0032, train_loss=1.42578, train_acc=0.99068, val_loss=2.01036, val_acc=0.95073, time=1.05500
Epoch:0033, train_loss=1.42503, train_acc=0.99109, val_loss=2.01037, val_acc=0.95255, time=1.16401
Epoch:0034, train_loss=1.42435, train_acc=0.99190, val_loss=2.01038, val_acc=0.95073, time=1.11100
Epoch:0035, train_loss=1.42374, train_acc=0.99271, val_loss=2.01039, val_acc=0.95255, time=1.16301
Epoch:0036, train_loss=1.42319, train_acc=0.99311, val_loss=2.01039, val_acc=0.95255, time=1.16300
Epoch:0037, train_loss=1.42268, train_acc=0.99413, val_loss=2.01040, val_acc=0.94891, time=0.99901
Early stopping...

Optimization Finished!

Test set results: loss= 1.80370, accuracy= 0.95660, time= 0.34000

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9683    0.9880    0.9781      1083
           1     0.9778    0.9483    0.9628       696
           2     0.9134    0.9587    0.9355       121
           3     0.9036    0.8621    0.8824        87
           4     0.8118    0.9200    0.8625        75
           5     0.9079    0.8519    0.8790        81
           6     0.9615    0.6944    0.8065        36
           7     0.8333    1.0000    0.9091        10

    accuracy                         0.9566      2189
   macro avg     0.9097    0.9029    0.9020      2189
weighted avg     0.9574    0.9566    0.9563      2189


Macro average Test Precision, Recall and F1-Score...
(0.9097043864790266, 0.9029143895485976, 0.9019654072941028, None)

Micro average Test Precision, Recall and F1-Score...
(0.9566011877569667, 0.9566011877569667, 0.9566011877569667, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
