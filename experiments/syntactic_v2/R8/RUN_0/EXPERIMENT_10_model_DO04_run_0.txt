
==========: 200217221549100
Epoch:0001, train_loss=2.15863, train_acc=0.19182, val_loss=2.06167, val_acc=0.57482, time=1.34501
Epoch:0002, train_loss=1.89874, train_acc=0.59571, val_loss=2.04493, val_acc=0.70620, time=1.18803
Epoch:0003, train_loss=1.75588, train_acc=0.70245, val_loss=2.03690, val_acc=0.73905, time=1.08100
Epoch:0004, train_loss=1.68266, train_acc=0.72392, val_loss=2.03103, val_acc=0.77920, time=1.00601
Epoch:0005, train_loss=1.62466, train_acc=0.77922, val_loss=2.02695, val_acc=0.84124, time=1.02201
Epoch:0006, train_loss=1.58235, train_acc=0.84991, val_loss=2.02468, val_acc=0.86496, time=1.05901
Epoch:0007, train_loss=1.55683, train_acc=0.88333, val_loss=2.02324, val_acc=0.87409, time=1.05302
Epoch:0008, train_loss=1.53997, train_acc=0.89265, val_loss=2.02183, val_acc=0.87774, time=1.10001
Epoch:0009, train_loss=1.52482, train_acc=0.90359, val_loss=2.02024, val_acc=0.88686, time=0.98301
Epoch:0010, train_loss=1.50920, train_acc=0.91351, val_loss=2.01858, val_acc=0.89964, time=1.19500
Epoch:0011, train_loss=1.49392, train_acc=0.92607, val_loss=2.01704, val_acc=0.90876, time=1.19402
Epoch:0012, train_loss=1.48061, train_acc=0.94268, val_loss=2.01577, val_acc=0.91971, time=1.08801
Epoch:0013, train_loss=1.47040, train_acc=0.95483, val_loss=2.01481, val_acc=0.92336, time=1.06201
Epoch:0014, train_loss=1.46323, train_acc=0.96192, val_loss=2.01408, val_acc=0.92518, time=1.10201
Epoch:0015, train_loss=1.45806, train_acc=0.96516, val_loss=2.01351, val_acc=0.93248, time=1.18101
Epoch:0016, train_loss=1.45383, train_acc=0.96921, val_loss=2.01303, val_acc=0.93613, time=1.09500
Epoch:0017, train_loss=1.44997, train_acc=0.97225, val_loss=2.01263, val_acc=0.93978, time=1.02200
Epoch:0018, train_loss=1.44644, train_acc=0.97488, val_loss=2.01233, val_acc=0.94343, time=0.99400
Epoch:0019, train_loss=1.44341, train_acc=0.97772, val_loss=2.01212, val_acc=0.94526, time=1.08702
Epoch:0020, train_loss=1.44103, train_acc=0.98035, val_loss=2.01200, val_acc=0.94526, time=0.97201
Epoch:0021, train_loss=1.43924, train_acc=0.98218, val_loss=2.01193, val_acc=0.94343, time=0.98801
Epoch:0022, train_loss=1.43782, train_acc=0.98258, val_loss=2.01188, val_acc=0.94526, time=1.34300
Epoch:0023, train_loss=1.43651, train_acc=0.98238, val_loss=2.01183, val_acc=0.95255, time=1.11401
Epoch:0024, train_loss=1.43515, train_acc=0.98278, val_loss=2.01175, val_acc=0.95073, time=1.11300
Epoch:0025, train_loss=1.43366, train_acc=0.98400, val_loss=2.01167, val_acc=0.94891, time=1.03701
Epoch:0026, train_loss=1.43208, train_acc=0.98623, val_loss=2.01157, val_acc=0.95073, time=1.05001
Epoch:0027, train_loss=1.43051, train_acc=0.98805, val_loss=2.01146, val_acc=0.95073, time=1.17101
Epoch:0028, train_loss=1.42906, train_acc=0.98866, val_loss=2.01137, val_acc=0.94891, time=1.02898
Epoch:0029, train_loss=1.42781, train_acc=0.98987, val_loss=2.01130, val_acc=0.95073, time=1.05201
Epoch:0030, train_loss=1.42680, train_acc=0.99068, val_loss=2.01124, val_acc=0.95255, time=1.13000
Epoch:0031, train_loss=1.42600, train_acc=0.99109, val_loss=2.01119, val_acc=0.95438, time=1.19700
Epoch:0032, train_loss=1.42535, train_acc=0.99190, val_loss=2.01115, val_acc=0.95255, time=1.27802
Epoch:0033, train_loss=1.42481, train_acc=0.99089, val_loss=2.01111, val_acc=0.95255, time=1.08800
Epoch:0034, train_loss=1.42429, train_acc=0.99048, val_loss=2.01108, val_acc=0.95438, time=1.05101
Epoch:0035, train_loss=1.42378, train_acc=0.99089, val_loss=2.01104, val_acc=0.95438, time=1.10999
Epoch:0036, train_loss=1.42324, train_acc=0.99170, val_loss=2.01101, val_acc=0.95620, time=1.06001
Epoch:0037, train_loss=1.42267, train_acc=0.99230, val_loss=2.01098, val_acc=0.95620, time=1.05201
Epoch:0038, train_loss=1.42210, train_acc=0.99311, val_loss=2.01096, val_acc=0.95803, time=1.04401
Epoch:0039, train_loss=1.42155, train_acc=0.99372, val_loss=2.01093, val_acc=0.95803, time=1.03402
Epoch:0040, train_loss=1.42103, train_acc=0.99372, val_loss=2.01092, val_acc=0.95803, time=0.99602
Epoch:0041, train_loss=1.42058, train_acc=0.99453, val_loss=2.01091, val_acc=0.95985, time=1.11900
Epoch:0042, train_loss=1.42019, train_acc=0.99494, val_loss=2.01090, val_acc=0.95803, time=0.98200
Epoch:0043, train_loss=1.41985, train_acc=0.99514, val_loss=2.01090, val_acc=0.95803, time=1.20300
Epoch:0044, train_loss=1.41956, train_acc=0.99494, val_loss=2.01090, val_acc=0.95803, time=0.98902
Epoch:0045, train_loss=1.41930, train_acc=0.99514, val_loss=2.01089, val_acc=0.95803, time=1.07901
Epoch:0046, train_loss=1.41904, train_acc=0.99514, val_loss=2.01089, val_acc=0.95985, time=1.20602
Epoch:0047, train_loss=1.41879, train_acc=0.99554, val_loss=2.01088, val_acc=0.96168, time=1.12400
Epoch:0048, train_loss=1.41853, train_acc=0.99595, val_loss=2.01087, val_acc=0.96168, time=0.99300
Epoch:0049, train_loss=1.41828, train_acc=0.99595, val_loss=2.01086, val_acc=0.96168, time=1.07100
Epoch:0050, train_loss=1.41803, train_acc=0.99615, val_loss=2.01085, val_acc=0.96168, time=1.21900
Epoch:0051, train_loss=1.41779, train_acc=0.99656, val_loss=2.01084, val_acc=0.96168, time=1.01101
Epoch:0052, train_loss=1.41757, train_acc=0.99676, val_loss=2.01084, val_acc=0.96168, time=0.99801
Epoch:0053, train_loss=1.41738, train_acc=0.99676, val_loss=2.01083, val_acc=0.95985, time=1.10301
Epoch:0054, train_loss=1.41721, train_acc=0.99696, val_loss=2.01082, val_acc=0.95803, time=1.08801
Epoch:0055, train_loss=1.41705, train_acc=0.99716, val_loss=2.01082, val_acc=0.95803, time=1.03702
Epoch:0056, train_loss=1.41690, train_acc=0.99716, val_loss=2.01081, val_acc=0.95803, time=1.18801
Epoch:0057, train_loss=1.41676, train_acc=0.99757, val_loss=2.01081, val_acc=0.95803, time=1.23600
Epoch:0058, train_loss=1.41663, train_acc=0.99757, val_loss=2.01081, val_acc=0.95985, time=1.20501
Epoch:0059, train_loss=1.41649, train_acc=0.99777, val_loss=2.01080, val_acc=0.95985, time=1.12601
Epoch:0060, train_loss=1.41636, train_acc=0.99797, val_loss=2.01080, val_acc=0.95985, time=1.07502
Epoch:0061, train_loss=1.41623, train_acc=0.99838, val_loss=2.01079, val_acc=0.95803, time=0.97700
Epoch:0062, train_loss=1.41610, train_acc=0.99838, val_loss=2.01079, val_acc=0.95803, time=1.12001
Epoch:0063, train_loss=1.41598, train_acc=0.99838, val_loss=2.01079, val_acc=0.95803, time=1.15900
Epoch:0064, train_loss=1.41587, train_acc=0.99838, val_loss=2.01079, val_acc=0.95803, time=1.23000
Epoch:0065, train_loss=1.41577, train_acc=0.99838, val_loss=2.01079, val_acc=0.95620, time=1.08400
Epoch:0066, train_loss=1.41568, train_acc=0.99838, val_loss=2.01079, val_acc=0.95620, time=1.12401
Epoch:0067, train_loss=1.41559, train_acc=0.99838, val_loss=2.01080, val_acc=0.95803, time=1.09800
Epoch:0068, train_loss=1.41551, train_acc=0.99858, val_loss=2.01080, val_acc=0.95803, time=1.05101
Early stopping...

Optimization Finished!

Test set results: loss= 1.80518, accuracy= 0.94975, time= 0.33801

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9563    0.9889    0.9723      1083
           1     0.9847    0.9253    0.9541       696
           2     0.9055    0.9504    0.9274       121
           3     0.8636    0.8736    0.8686        87
           4     0.8554    0.9467    0.8987        75
           5     0.8701    0.8272    0.8481        81
           6     0.8966    0.7222    0.8000        36
           7     0.8182    0.9000    0.8571        10

    accuracy                         0.9497      2189
   macro avg     0.8938    0.8918    0.8908      2189
weighted avg     0.9506    0.9497    0.9494      2189


Macro average Test Precision, Recall and F1-Score...
(0.8937990942473647, 0.8917791060199021, 0.8907942054207951, None)

Micro average Test Precision, Recall and F1-Score...
(0.949748743718593, 0.949748743718593, 0.949748743718593, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
