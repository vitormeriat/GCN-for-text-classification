
==========: 190722233619800
Epoch:0001, train_loss=2.26991, train_acc=0.27750, val_loss=2.08047, val_acc=0.49453, time=1.20000
Epoch:0002, train_loss=2.12077, train_acc=0.47600, val_loss=2.06749, val_acc=0.55839, time=1.13302
Epoch:0003, train_loss=1.99074, train_acc=0.52056, val_loss=2.05688, val_acc=0.60036, time=1.04399
Epoch:0004, train_loss=1.88144, train_acc=0.57788, val_loss=2.04891, val_acc=0.65693, time=1.09801
Epoch:0005, train_loss=1.79754, train_acc=0.65060, val_loss=2.04351, val_acc=0.68978, time=1.31501
Epoch:0006, train_loss=1.73961, train_acc=0.70346, val_loss=2.03985, val_acc=0.70438, time=1.21100
Epoch:0007, train_loss=1.70021, train_acc=0.72655, val_loss=2.03703, val_acc=0.72993, time=1.27601
Epoch:0008, train_loss=1.67026, train_acc=0.75025, val_loss=2.03448, val_acc=0.74818, time=1.23900
Epoch:0009, train_loss=1.64406, train_acc=0.76950, val_loss=2.03199, val_acc=0.76825, time=1.09601
Epoch:0010, train_loss=1.61932, train_acc=0.79421, val_loss=2.02958, val_acc=0.78650, time=1.01500
Epoch:0011, train_loss=1.59589, train_acc=0.82115, val_loss=2.02735, val_acc=0.81387, time=1.27100
Epoch:0012, train_loss=1.57450, train_acc=0.84667, val_loss=2.02540, val_acc=0.84124, time=1.20001
Epoch:0013, train_loss=1.55588, train_acc=0.86956, val_loss=2.02376, val_acc=0.86314, time=1.12902
Epoch:0014, train_loss=1.54034, train_acc=0.89204, val_loss=2.02241, val_acc=0.87226, time=1.21200
Epoch:0015, train_loss=1.52766, train_acc=0.90743, val_loss=2.02131, val_acc=0.88869, time=1.04700
Epoch:0016, train_loss=1.51728, train_acc=0.92181, val_loss=2.02040, val_acc=0.89599, time=1.15701
Epoch:0017, train_loss=1.50861, train_acc=0.92911, val_loss=2.01960, val_acc=0.89964, time=1.05703
Epoch:0018, train_loss=1.50112, train_acc=0.93620, val_loss=2.01890, val_acc=0.90328, time=1.04800
Epoch:0019, train_loss=1.49446, train_acc=0.94248, val_loss=2.01827, val_acc=0.90876, time=1.14001
Epoch:0020, train_loss=1.48845, train_acc=0.94794, val_loss=2.01770, val_acc=0.91423, time=1.12202
Epoch:0021, train_loss=1.48300, train_acc=0.95159, val_loss=2.01719, val_acc=0.91971, time=1.21900
Epoch:0022, train_loss=1.47805, train_acc=0.95665, val_loss=2.01673, val_acc=0.92336, time=1.13900
Epoch:0023, train_loss=1.47360, train_acc=0.96010, val_loss=2.01633, val_acc=0.92518, time=1.25800
Epoch:0024, train_loss=1.46962, train_acc=0.96435, val_loss=2.01598, val_acc=0.93066, time=1.33301
Epoch:0025, train_loss=1.46610, train_acc=0.96617, val_loss=2.01568, val_acc=0.93431, time=1.11199
Epoch:0026, train_loss=1.46298, train_acc=0.96901, val_loss=2.01540, val_acc=0.93431, time=1.58002
Epoch:0027, train_loss=1.46023, train_acc=0.97104, val_loss=2.01516, val_acc=0.93978, time=1.12900
Epoch:0028, train_loss=1.45779, train_acc=0.97266, val_loss=2.01493, val_acc=0.93066, time=1.11901
Epoch:0029, train_loss=1.45558, train_acc=0.97387, val_loss=2.01471, val_acc=0.93066, time=1.14599
Epoch:0030, train_loss=1.45355, train_acc=0.97529, val_loss=2.01450, val_acc=0.93066, time=1.22802
Epoch:0031, train_loss=1.45166, train_acc=0.97691, val_loss=2.01430, val_acc=0.93066, time=1.03201
Epoch:0032, train_loss=1.44986, train_acc=0.97752, val_loss=2.01409, val_acc=0.93431, time=1.01501
Epoch:0033, train_loss=1.44814, train_acc=0.97792, val_loss=2.01389, val_acc=0.93248, time=1.03001
Epoch:0034, train_loss=1.44651, train_acc=0.97954, val_loss=2.01370, val_acc=0.93613, time=1.27001
Epoch:0035, train_loss=1.44496, train_acc=0.98096, val_loss=2.01351, val_acc=0.93796, time=1.06501
Epoch:0036, train_loss=1.44352, train_acc=0.98238, val_loss=2.01334, val_acc=0.93978, time=0.97303
Epoch:0037, train_loss=1.44219, train_acc=0.98299, val_loss=2.01318, val_acc=0.94161, time=1.17399
Epoch:0038, train_loss=1.44096, train_acc=0.98542, val_loss=2.01303, val_acc=0.94161, time=1.17102
Epoch:0039, train_loss=1.43984, train_acc=0.98562, val_loss=2.01289, val_acc=0.93978, time=1.30000
Epoch:0040, train_loss=1.43881, train_acc=0.98602, val_loss=2.01277, val_acc=0.94161, time=1.13902
Epoch:0041, train_loss=1.43786, train_acc=0.98623, val_loss=2.01266, val_acc=0.93978, time=1.12201
Epoch:0042, train_loss=1.43698, train_acc=0.98623, val_loss=2.01257, val_acc=0.94161, time=1.21201
Epoch:0043, train_loss=1.43614, train_acc=0.98643, val_loss=2.01248, val_acc=0.94161, time=1.22099
Epoch:0044, train_loss=1.43535, train_acc=0.98663, val_loss=2.01240, val_acc=0.94161, time=1.25800
Epoch:0045, train_loss=1.43459, train_acc=0.98663, val_loss=2.01233, val_acc=0.94161, time=1.14901
Epoch:0046, train_loss=1.43387, train_acc=0.98704, val_loss=2.01227, val_acc=0.93978, time=1.26601
Epoch:0047, train_loss=1.43317, train_acc=0.98825, val_loss=2.01222, val_acc=0.93978, time=1.04200
Epoch:0048, train_loss=1.43251, train_acc=0.98845, val_loss=2.01217, val_acc=0.93978, time=1.19999
Epoch:0049, train_loss=1.43188, train_acc=0.98886, val_loss=2.01214, val_acc=0.93978, time=1.07801
Epoch:0050, train_loss=1.43128, train_acc=0.98926, val_loss=2.01210, val_acc=0.94161, time=1.05501
Epoch:0051, train_loss=1.43071, train_acc=0.98947, val_loss=2.01208, val_acc=0.94161, time=1.06301
Epoch:0052, train_loss=1.43018, train_acc=0.99048, val_loss=2.01205, val_acc=0.94161, time=1.06401
Epoch:0053, train_loss=1.42967, train_acc=0.99149, val_loss=2.01203, val_acc=0.94343, time=1.23601
Epoch:0054, train_loss=1.42919, train_acc=0.99170, val_loss=2.01201, val_acc=0.94891, time=1.10700
Epoch:0055, train_loss=1.42873, train_acc=0.99230, val_loss=2.01199, val_acc=0.94891, time=1.10101
Epoch:0056, train_loss=1.42829, train_acc=0.99230, val_loss=2.01197, val_acc=0.94891, time=1.08001
Epoch:0057, train_loss=1.42786, train_acc=0.99271, val_loss=2.01195, val_acc=0.95073, time=1.14800
Epoch:0058, train_loss=1.42745, train_acc=0.99271, val_loss=2.01193, val_acc=0.94891, time=1.07901
Epoch:0059, train_loss=1.42705, train_acc=0.99311, val_loss=2.01191, val_acc=0.94891, time=1.15601
Epoch:0060, train_loss=1.42667, train_acc=0.99372, val_loss=2.01189, val_acc=0.94891, time=1.11999
Epoch:0061, train_loss=1.42630, train_acc=0.99372, val_loss=2.01188, val_acc=0.95255, time=1.14001
Epoch:0062, train_loss=1.42595, train_acc=0.99392, val_loss=2.01186, val_acc=0.95438, time=1.16501
Epoch:0063, train_loss=1.42561, train_acc=0.99433, val_loss=2.01184, val_acc=0.95073, time=1.23200
Epoch:0064, train_loss=1.42528, train_acc=0.99453, val_loss=2.01182, val_acc=0.95073, time=1.23002
Epoch:0065, train_loss=1.42497, train_acc=0.99473, val_loss=2.01181, val_acc=0.94891, time=1.12299
Epoch:0066, train_loss=1.42468, train_acc=0.99494, val_loss=2.01179, val_acc=0.94891, time=1.16201
Epoch:0067, train_loss=1.42439, train_acc=0.99554, val_loss=2.01178, val_acc=0.94891, time=1.11601
Epoch:0068, train_loss=1.42412, train_acc=0.99554, val_loss=2.01177, val_acc=0.95073, time=1.14802
Epoch:0069, train_loss=1.42385, train_acc=0.99554, val_loss=2.01176, val_acc=0.95073, time=1.12100
Epoch:0070, train_loss=1.42359, train_acc=0.99554, val_loss=2.01175, val_acc=0.94891, time=1.13101
Epoch:0071, train_loss=1.42334, train_acc=0.99554, val_loss=2.01173, val_acc=0.95073, time=1.22603
Epoch:0072, train_loss=1.42310, train_acc=0.99595, val_loss=2.01173, val_acc=0.95073, time=1.05100
Epoch:0073, train_loss=1.42287, train_acc=0.99595, val_loss=2.01172, val_acc=0.95073, time=1.03701
Epoch:0074, train_loss=1.42264, train_acc=0.99595, val_loss=2.01171, val_acc=0.95073, time=1.20800
Epoch:0075, train_loss=1.42242, train_acc=0.99615, val_loss=2.01170, val_acc=0.95073, time=1.07401
Epoch:0076, train_loss=1.42221, train_acc=0.99615, val_loss=2.01169, val_acc=0.95073, time=1.19001
Epoch:0077, train_loss=1.42200, train_acc=0.99656, val_loss=2.01168, val_acc=0.95073, time=1.22399
Epoch:0078, train_loss=1.42180, train_acc=0.99656, val_loss=2.01168, val_acc=0.95073, time=1.11400
Epoch:0079, train_loss=1.42161, train_acc=0.99656, val_loss=2.01167, val_acc=0.95073, time=1.10301
Epoch:0080, train_loss=1.42142, train_acc=0.99656, val_loss=2.01166, val_acc=0.95073, time=0.98401
Epoch:0081, train_loss=1.42123, train_acc=0.99676, val_loss=2.01166, val_acc=0.95255, time=1.09000
Epoch:0082, train_loss=1.42106, train_acc=0.99716, val_loss=2.01165, val_acc=0.95255, time=1.25001
Epoch:0083, train_loss=1.42088, train_acc=0.99716, val_loss=2.01165, val_acc=0.95255, time=1.24801
Epoch:0084, train_loss=1.42072, train_acc=0.99716, val_loss=2.01164, val_acc=0.95255, time=1.12401
Epoch:0085, train_loss=1.42055, train_acc=0.99716, val_loss=2.01163, val_acc=0.95438, time=1.06300
Epoch:0086, train_loss=1.42040, train_acc=0.99716, val_loss=2.01163, val_acc=0.95255, time=1.08601
Epoch:0087, train_loss=1.42024, train_acc=0.99716, val_loss=2.01162, val_acc=0.95255, time=1.28001
Epoch:0088, train_loss=1.42009, train_acc=0.99716, val_loss=2.01161, val_acc=0.95255, time=1.07401
Epoch:0089, train_loss=1.41995, train_acc=0.99716, val_loss=2.01161, val_acc=0.95255, time=1.03901
Epoch:0090, train_loss=1.41981, train_acc=0.99737, val_loss=2.01160, val_acc=0.95255, time=1.07902
Epoch:0091, train_loss=1.41967, train_acc=0.99757, val_loss=2.01160, val_acc=0.95255, time=1.17799
Epoch:0092, train_loss=1.41954, train_acc=0.99757, val_loss=2.01159, val_acc=0.95255, time=1.08302
Epoch:0093, train_loss=1.41941, train_acc=0.99757, val_loss=2.01158, val_acc=0.95438, time=1.13301
Epoch:0094, train_loss=1.41928, train_acc=0.99757, val_loss=2.01158, val_acc=0.95438, time=1.06401
Epoch:0095, train_loss=1.41916, train_acc=0.99757, val_loss=2.01157, val_acc=0.95438, time=1.05700
Epoch:0096, train_loss=1.41903, train_acc=0.99757, val_loss=2.01157, val_acc=0.95438, time=1.07702
Epoch:0097, train_loss=1.41892, train_acc=0.99757, val_loss=2.01156, val_acc=0.95438, time=1.08500
Epoch:0098, train_loss=1.41880, train_acc=0.99757, val_loss=2.01156, val_acc=0.95438, time=1.16701
Epoch:0099, train_loss=1.41869, train_acc=0.99757, val_loss=2.01156, val_acc=0.95438, time=1.13400
Epoch:0100, train_loss=1.41858, train_acc=0.99757, val_loss=2.01155, val_acc=0.95438, time=1.19201
Epoch:0101, train_loss=1.41848, train_acc=0.99777, val_loss=2.01155, val_acc=0.95438, time=1.14998
Epoch:0102, train_loss=1.41837, train_acc=0.99777, val_loss=2.01155, val_acc=0.95438, time=1.09300
Epoch:0103, train_loss=1.41827, train_acc=0.99777, val_loss=2.01154, val_acc=0.95438, time=1.02001
Epoch:0104, train_loss=1.41817, train_acc=0.99777, val_loss=2.01154, val_acc=0.95438, time=1.20600
Epoch:0105, train_loss=1.41808, train_acc=0.99777, val_loss=2.01154, val_acc=0.95438, time=1.01602
Epoch:0106, train_loss=1.41798, train_acc=0.99777, val_loss=2.01154, val_acc=0.95438, time=0.97999
Epoch:0107, train_loss=1.41789, train_acc=0.99777, val_loss=2.01154, val_acc=0.95438, time=1.21200
Epoch:0108, train_loss=1.41780, train_acc=0.99777, val_loss=2.01154, val_acc=0.95438, time=1.09402
Epoch:0109, train_loss=1.41771, train_acc=0.99777, val_loss=2.01153, val_acc=0.95438, time=1.06300
Epoch:0110, train_loss=1.41763, train_acc=0.99777, val_loss=2.01153, val_acc=0.95438, time=1.05500
Epoch:0111, train_loss=1.41754, train_acc=0.99777, val_loss=2.01153, val_acc=0.95438, time=0.95500
Epoch:0112, train_loss=1.41746, train_acc=0.99777, val_loss=2.01153, val_acc=0.95620, time=1.06802
Epoch:0113, train_loss=1.41738, train_acc=0.99797, val_loss=2.01153, val_acc=0.95620, time=1.06901
Epoch:0114, train_loss=1.41730, train_acc=0.99797, val_loss=2.01153, val_acc=0.95620, time=1.04200
Epoch:0115, train_loss=1.41722, train_acc=0.99797, val_loss=2.01153, val_acc=0.95620, time=1.12802
Epoch:0116, train_loss=1.41715, train_acc=0.99818, val_loss=2.01153, val_acc=0.95620, time=1.15200
Epoch:0117, train_loss=1.41708, train_acc=0.99818, val_loss=2.01153, val_acc=0.95620, time=1.11302
Epoch:0118, train_loss=1.41700, train_acc=0.99818, val_loss=2.01153, val_acc=0.95620, time=1.10800
Early stopping...

Optimization Finished!

Test set results: loss= 1.80561, accuracy= 0.95066, time= 0.32000

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9639    0.9871    0.9754      1083
           1     0.9775    0.9368    0.9567       696
           2     0.8582    0.9504    0.9020       121
           3     0.8602    0.9195    0.8889        87
           4     0.8554    0.9467    0.8987        75
           5     0.9014    0.7901    0.8421        81
           6     0.9167    0.6111    0.7333        36
           7     1.0000    0.8000    0.8889        10

    accuracy                         0.9507      2189
   macro avg     0.9167    0.8677    0.8857      2189
weighted avg     0.9516    0.9507    0.9500      2189


Macro average Test Precision, Recall and F1-Score...
(0.9166704409094523, 0.8677136552888195, 0.8857486790121094, None)

Micro average Test Precision, Recall and F1-Score...
(0.9506624029237094, 0.9506624029237094, 0.9506624029237094, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
