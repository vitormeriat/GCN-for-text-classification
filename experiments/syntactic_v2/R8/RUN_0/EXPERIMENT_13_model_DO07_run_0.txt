
==========: 200424320884100
Epoch:0001, train_loss=2.21796, train_acc=0.09398, val_loss=2.06670, val_acc=0.50730, time=1.30301
Epoch:0002, train_loss=1.94865, train_acc=0.52866, val_loss=2.04902, val_acc=0.67153, time=1.15299
Epoch:0003, train_loss=1.79400, train_acc=0.69496, val_loss=2.03938, val_acc=0.72810, time=1.09602
Epoch:0004, train_loss=1.71049, train_acc=0.73709, val_loss=2.03472, val_acc=0.75182, time=1.17200
Epoch:0005, train_loss=1.66712, train_acc=0.74965, val_loss=2.03112, val_acc=0.79015, time=1.15801
Epoch:0006, train_loss=1.62946, train_acc=0.79198, val_loss=2.02785, val_acc=0.84672, time=1.12700
Epoch:0007, train_loss=1.59319, train_acc=0.84788, val_loss=2.02528, val_acc=0.86679, time=1.10301
Epoch:0008, train_loss=1.56345, train_acc=0.88151, val_loss=2.02344, val_acc=0.87591, time=1.10402
Epoch:0009, train_loss=1.54120, train_acc=0.90277, val_loss=2.02206, val_acc=0.88504, time=1.10699
Epoch:0010, train_loss=1.52424, train_acc=0.91554, val_loss=2.02089, val_acc=0.89781, time=1.20901
Epoch:0011, train_loss=1.51050, train_acc=0.92587, val_loss=2.01982, val_acc=0.89234, time=1.11600
Epoch:0012, train_loss=1.49893, train_acc=0.93478, val_loss=2.01880, val_acc=0.89964, time=1.17701
Epoch:0013, train_loss=1.48902, train_acc=0.94389, val_loss=2.01782, val_acc=0.91241, time=1.01299
Epoch:0014, train_loss=1.48033, train_acc=0.94875, val_loss=2.01689, val_acc=0.91606, time=1.08201
Epoch:0015, train_loss=1.47256, train_acc=0.95605, val_loss=2.01604, val_acc=0.92701, time=1.08300
Epoch:0016, train_loss=1.46560, train_acc=0.96293, val_loss=2.01529, val_acc=0.93248, time=0.97801
Epoch:0017, train_loss=1.45948, train_acc=0.96678, val_loss=2.01466, val_acc=0.93248, time=1.02700
Epoch:0018, train_loss=1.45427, train_acc=0.97164, val_loss=2.01414, val_acc=0.93796, time=1.04601
Epoch:0019, train_loss=1.44994, train_acc=0.97387, val_loss=2.01372, val_acc=0.94161, time=1.10301
Epoch:0020, train_loss=1.44645, train_acc=0.97650, val_loss=2.01338, val_acc=0.94161, time=1.03898
Epoch:0021, train_loss=1.44367, train_acc=0.97792, val_loss=2.01310, val_acc=0.94526, time=1.22502
Epoch:0022, train_loss=1.44142, train_acc=0.97974, val_loss=2.01286, val_acc=0.94343, time=1.04602
Epoch:0023, train_loss=1.43951, train_acc=0.98197, val_loss=2.01265, val_acc=0.94526, time=1.12701
Epoch:0024, train_loss=1.43779, train_acc=0.98319, val_loss=2.01246, val_acc=0.95073, time=1.13900
Epoch:0025, train_loss=1.43615, train_acc=0.98440, val_loss=2.01229, val_acc=0.95073, time=1.20701
Epoch:0026, train_loss=1.43455, train_acc=0.98542, val_loss=2.01213, val_acc=0.94708, time=1.05901
Epoch:0027, train_loss=1.43299, train_acc=0.98643, val_loss=2.01197, val_acc=0.94891, time=1.05700
Epoch:0028, train_loss=1.43150, train_acc=0.98704, val_loss=2.01184, val_acc=0.95438, time=1.19400
Epoch:0029, train_loss=1.43014, train_acc=0.98764, val_loss=2.01172, val_acc=0.95255, time=1.02702
Epoch:0030, train_loss=1.42895, train_acc=0.98866, val_loss=2.01163, val_acc=0.95073, time=1.06800
Epoch:0031, train_loss=1.42797, train_acc=0.99007, val_loss=2.01156, val_acc=0.95073, time=1.12600
Epoch:0032, train_loss=1.42716, train_acc=0.99048, val_loss=2.01150, val_acc=0.94891, time=1.07501
Epoch:0033, train_loss=1.42650, train_acc=0.99109, val_loss=2.01146, val_acc=0.95073, time=1.02201
Epoch:0034, train_loss=1.42591, train_acc=0.99068, val_loss=2.01141, val_acc=0.94891, time=1.22700
Epoch:0035, train_loss=1.42537, train_acc=0.99109, val_loss=2.01136, val_acc=0.94891, time=1.11999
Epoch:0036, train_loss=1.42482, train_acc=0.99109, val_loss=2.01131, val_acc=0.94891, time=1.10301
Epoch:0037, train_loss=1.42426, train_acc=0.99251, val_loss=2.01126, val_acc=0.95255, time=1.02201
Epoch:0038, train_loss=1.42370, train_acc=0.99251, val_loss=2.01121, val_acc=0.95438, time=1.12899
Epoch:0039, train_loss=1.42313, train_acc=0.99332, val_loss=2.01117, val_acc=0.95620, time=1.13401
Epoch:0040, train_loss=1.42257, train_acc=0.99392, val_loss=2.01113, val_acc=0.95620, time=1.21600
Epoch:0041, train_loss=1.42205, train_acc=0.99473, val_loss=2.01109, val_acc=0.95620, time=1.05001
Epoch:0042, train_loss=1.42156, train_acc=0.99494, val_loss=2.01106, val_acc=0.95620, time=1.00702
Epoch:0043, train_loss=1.42112, train_acc=0.99554, val_loss=2.01103, val_acc=0.95620, time=1.06000
Epoch:0044, train_loss=1.42072, train_acc=0.99615, val_loss=2.01101, val_acc=0.95985, time=1.05401
Epoch:0045, train_loss=1.42036, train_acc=0.99615, val_loss=2.01100, val_acc=0.96168, time=1.08300
Epoch:0046, train_loss=1.42004, train_acc=0.99595, val_loss=2.01098, val_acc=0.96168, time=0.99602
Epoch:0047, train_loss=1.41974, train_acc=0.99615, val_loss=2.01097, val_acc=0.95985, time=1.12501
Epoch:0048, train_loss=1.41946, train_acc=0.99595, val_loss=2.01097, val_acc=0.96168, time=1.11301
Epoch:0049, train_loss=1.41920, train_acc=0.99635, val_loss=2.01096, val_acc=0.96168, time=1.16602
Epoch:0050, train_loss=1.41894, train_acc=0.99635, val_loss=2.01096, val_acc=0.96350, time=1.03799
Epoch:0051, train_loss=1.41868, train_acc=0.99635, val_loss=2.01096, val_acc=0.96168, time=1.05001
Epoch:0052, train_loss=1.41844, train_acc=0.99656, val_loss=2.01096, val_acc=0.96168, time=1.05401
Epoch:0053, train_loss=1.41821, train_acc=0.99656, val_loss=2.01097, val_acc=0.96168, time=0.97300
Epoch:0054, train_loss=1.41799, train_acc=0.99737, val_loss=2.01098, val_acc=0.96168, time=1.02501
Early stopping...

Optimization Finished!

Test set results: loss= 1.80289, accuracy= 0.95706, time= 0.32998

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9666    0.9889    0.9776      1083
           1     0.9821    0.9454    0.9634       696
           2     0.8881    0.9835    0.9333       121
           3     0.8851    0.8851    0.8851        87
           4     0.8947    0.9067    0.9007        75
           5     0.8846    0.8519    0.8679        81
           6     1.0000    0.6389    0.7797        36
           7     0.7692    1.0000    0.8696        10

    accuracy                         0.9571      2189
   macro avg     0.9088    0.9000    0.8972      2189
weighted avg     0.9581    0.9571    0.9565      2189


Macro average Test Precision, Recall and F1-Score...
(0.9087995273927593, 0.9000322399365679, 0.8971545475699778, None)

Micro average Test Precision, Recall and F1-Score...
(0.9570580173595249, 0.9570580173595249, 0.9570580173595249, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
