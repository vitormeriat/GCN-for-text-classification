
==========: 200968955962500
Epoch:0001, train_loss=2.44144, train_acc=0.04497, val_loss=2.05542, val_acc=0.71350, time=1.41101
Epoch:0002, train_loss=1.85663, train_acc=0.69415, val_loss=2.06297, val_acc=0.68613, time=1.14300
Epoch:0003, train_loss=1.88222, train_acc=0.71622, val_loss=2.03728, val_acc=0.80109, time=1.18300
Epoch:0004, train_loss=1.64350, train_acc=0.81851, val_loss=2.02628, val_acc=0.88686, time=1.07301
Epoch:0005, train_loss=1.53966, train_acc=0.91229, val_loss=2.02553, val_acc=0.87409, time=1.06500
Epoch:0006, train_loss=1.53156, train_acc=0.92060, val_loss=2.02488, val_acc=0.88504, time=1.10502
Epoch:0007, train_loss=1.52403, train_acc=0.92526, val_loss=2.02312, val_acc=0.90693, time=1.16901
Epoch:0008, train_loss=1.50707, train_acc=0.93539, val_loss=2.02084, val_acc=0.91971, time=1.12601
Epoch:0009, train_loss=1.48621, train_acc=0.94632, val_loss=2.01855, val_acc=0.91971, time=1.00900
Epoch:0010, train_loss=1.46636, train_acc=0.95868, val_loss=2.01662, val_acc=0.92518, time=1.17800
Epoch:0011, train_loss=1.45090, train_acc=0.96860, val_loss=2.01521, val_acc=0.93796, time=1.02402
Epoch:0012, train_loss=1.44129, train_acc=0.97509, val_loss=2.01436, val_acc=0.94161, time=0.99601
Epoch:0013, train_loss=1.43645, train_acc=0.97812, val_loss=2.01396, val_acc=0.93613, time=1.04400
Epoch:0014, train_loss=1.43446, train_acc=0.97792, val_loss=2.01383, val_acc=0.93796, time=0.96101
Epoch:0015, train_loss=1.43374, train_acc=0.97772, val_loss=2.01378, val_acc=0.93613, time=0.98601
Epoch:0016, train_loss=1.43308, train_acc=0.97873, val_loss=2.01372, val_acc=0.93431, time=1.01600
Epoch:0017, train_loss=1.43182, train_acc=0.97974, val_loss=2.01357, val_acc=0.93431, time=1.16201
Epoch:0018, train_loss=1.42985, train_acc=0.98055, val_loss=2.01337, val_acc=0.93978, time=1.10500
Epoch:0019, train_loss=1.42746, train_acc=0.98420, val_loss=2.01315, val_acc=0.93796, time=1.33201
Epoch:0020, train_loss=1.42520, train_acc=0.98562, val_loss=2.01297, val_acc=0.94161, time=0.97500
Epoch:0021, train_loss=1.42355, train_acc=0.98764, val_loss=2.01283, val_acc=0.94526, time=1.27400
Epoch:0022, train_loss=1.42253, train_acc=0.98845, val_loss=2.01273, val_acc=0.94526, time=1.34401
Epoch:0023, train_loss=1.42187, train_acc=0.99007, val_loss=2.01265, val_acc=0.94526, time=1.11901
Epoch:0024, train_loss=1.42134, train_acc=0.99170, val_loss=2.01258, val_acc=0.94526, time=1.07301
Epoch:0025, train_loss=1.42077, train_acc=0.99149, val_loss=2.01251, val_acc=0.94708, time=1.02000
Epoch:0026, train_loss=1.42009, train_acc=0.99230, val_loss=2.01243, val_acc=0.94891, time=1.08601
Epoch:0027, train_loss=1.41928, train_acc=0.99311, val_loss=2.01235, val_acc=0.95073, time=1.18102
Epoch:0028, train_loss=1.41839, train_acc=0.99372, val_loss=2.01227, val_acc=0.95073, time=1.09502
Epoch:0029, train_loss=1.41751, train_acc=0.99433, val_loss=2.01220, val_acc=0.95438, time=1.18300
Epoch:0030, train_loss=1.41677, train_acc=0.99554, val_loss=2.01216, val_acc=0.95438, time=1.25502
Epoch:0031, train_loss=1.41627, train_acc=0.99575, val_loss=2.01214, val_acc=0.95255, time=0.95801
Epoch:0032, train_loss=1.41602, train_acc=0.99615, val_loss=2.01214, val_acc=0.95073, time=0.96302
Epoch:0033, train_loss=1.41592, train_acc=0.99656, val_loss=2.01215, val_acc=0.95438, time=1.12301
Epoch:0034, train_loss=1.41584, train_acc=0.99635, val_loss=2.01215, val_acc=0.95438, time=0.97100
Epoch:0035, train_loss=1.41572, train_acc=0.99635, val_loss=2.01216, val_acc=0.95255, time=1.09001
Early stopping...

Optimization Finished!

Test set results: loss= 1.80963, accuracy= 0.95112, time= 0.38301

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9639    0.9871    0.9754      1083
           1     0.9788    0.9296    0.9536       696
           2     0.8881    0.9835    0.9333       121
           3     0.8298    0.8966    0.8619        87
           4     0.8488    0.9733    0.9068        75
           5     0.9130    0.7778    0.8400        81
           6     1.0000    0.6389    0.7797        36
           7     0.7692    1.0000    0.8696        10

    accuracy                         0.9511      2189
   macro avg     0.8990    0.8983    0.8900      2189
weighted avg     0.9530    0.9511    0.9505      2189


Macro average Test Precision, Recall and F1-Score...
(0.8989637289830593, 0.8983366806486526, 0.8900261678475216, None)

Micro average Test Precision, Recall and F1-Score...
(0.9511192325262677, 0.9511192325262677, 0.9511192325262677, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
