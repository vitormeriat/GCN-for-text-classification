
==========: 304796695673200
Epoch:0001, train_loss=1.79256, train_acc=0.21169, val_loss=1.79201, val_acc=0.20779, time=0.30800
Epoch:0002, train_loss=1.79238, train_acc=0.21121, val_loss=1.79200, val_acc=0.20779, time=0.31801
Epoch:0003, train_loss=1.79220, train_acc=0.21169, val_loss=1.79199, val_acc=0.20779, time=0.31901
Epoch:0004, train_loss=1.79201, train_acc=0.21216, val_loss=1.79198, val_acc=0.20779, time=0.27101
Epoch:0005, train_loss=1.79183, train_acc=0.21169, val_loss=1.79197, val_acc=0.20779, time=0.31300
Epoch:0006, train_loss=1.79166, train_acc=0.21073, val_loss=1.79197, val_acc=0.20779, time=0.27800
Epoch:0007, train_loss=1.79148, train_acc=0.21025, val_loss=1.79196, val_acc=0.20779, time=0.26102
Epoch:0008, train_loss=1.79130, train_acc=0.20977, val_loss=1.79195, val_acc=0.20779, time=0.28701
Epoch:0009, train_loss=1.79113, train_acc=0.20977, val_loss=1.79195, val_acc=0.20779, time=0.29501
Epoch:0010, train_loss=1.79095, train_acc=0.20929, val_loss=1.79194, val_acc=0.20779, time=0.32001
Epoch:0011, train_loss=1.79078, train_acc=0.20881, val_loss=1.79193, val_acc=0.20779, time=0.30400
Epoch:0012, train_loss=1.79061, train_acc=0.20929, val_loss=1.79193, val_acc=0.20779, time=0.29402
Epoch:0013, train_loss=1.79044, train_acc=0.20929, val_loss=1.79192, val_acc=0.20779, time=0.30500
Epoch:0014, train_loss=1.79027, train_acc=0.20977, val_loss=1.79191, val_acc=0.20779, time=0.32901
Epoch:0015, train_loss=1.79010, train_acc=0.20977, val_loss=1.79191, val_acc=0.20779, time=0.27900
Epoch:0016, train_loss=1.78994, train_acc=0.20929, val_loss=1.79190, val_acc=0.20779, time=0.26899
Epoch:0017, train_loss=1.78977, train_acc=0.20929, val_loss=1.79190, val_acc=0.20779, time=0.31400
Epoch:0018, train_loss=1.78961, train_acc=0.20833, val_loss=1.79189, val_acc=0.20779, time=0.29201
Epoch:0019, train_loss=1.78945, train_acc=0.20929, val_loss=1.79188, val_acc=0.20779, time=0.33501
Epoch:0020, train_loss=1.78929, train_acc=0.20977, val_loss=1.79188, val_acc=0.20779, time=0.28300
Epoch:0021, train_loss=1.78913, train_acc=0.20977, val_loss=1.79187, val_acc=0.20779, time=0.27201
Epoch:0022, train_loss=1.78897, train_acc=0.21073, val_loss=1.79187, val_acc=0.20779, time=0.24699
Epoch:0023, train_loss=1.78881, train_acc=0.21121, val_loss=1.79186, val_acc=0.20779, time=0.29300
Epoch:0024, train_loss=1.78866, train_acc=0.21169, val_loss=1.79186, val_acc=0.20779, time=0.24000
Epoch:0025, train_loss=1.78851, train_acc=0.21264, val_loss=1.79185, val_acc=0.20779, time=0.25300
Epoch:0026, train_loss=1.78835, train_acc=0.21264, val_loss=1.79185, val_acc=0.20779, time=0.24901
Epoch:0027, train_loss=1.78820, train_acc=0.21312, val_loss=1.79184, val_acc=0.20779, time=0.21300
Epoch:0028, train_loss=1.78805, train_acc=0.21216, val_loss=1.79184, val_acc=0.20779, time=0.24600
Epoch:0029, train_loss=1.78791, train_acc=0.21216, val_loss=1.79184, val_acc=0.20779, time=0.26701
Epoch:0030, train_loss=1.78776, train_acc=0.21121, val_loss=1.79183, val_acc=0.20779, time=0.28901
Epoch:0031, train_loss=1.78761, train_acc=0.20977, val_loss=1.79183, val_acc=0.20779, time=0.31601
Epoch:0032, train_loss=1.78747, train_acc=0.21025, val_loss=1.79182, val_acc=0.20779, time=0.22700
Epoch:0033, train_loss=1.78733, train_acc=0.21073, val_loss=1.79182, val_acc=0.20346, time=0.21300
Epoch:0034, train_loss=1.78718, train_acc=0.21073, val_loss=1.79182, val_acc=0.20346, time=0.27600
Epoch:0035, train_loss=1.78704, train_acc=0.21025, val_loss=1.79181, val_acc=0.20346, time=0.26000
Epoch:0036, train_loss=1.78690, train_acc=0.20929, val_loss=1.79181, val_acc=0.20779, time=0.28501
Epoch:0037, train_loss=1.78677, train_acc=0.20881, val_loss=1.79181, val_acc=0.20779, time=0.33901
Epoch:0038, train_loss=1.78663, train_acc=0.20881, val_loss=1.79180, val_acc=0.20779, time=0.30202
Epoch:0039, train_loss=1.78649, train_acc=0.20881, val_loss=1.79180, val_acc=0.20346, time=0.32100
Epoch:0040, train_loss=1.78636, train_acc=0.20881, val_loss=1.79180, val_acc=0.20779, time=0.28002
Epoch:0041, train_loss=1.78623, train_acc=0.20833, val_loss=1.79179, val_acc=0.20779, time=0.30200
Epoch:0042, train_loss=1.78609, train_acc=0.20881, val_loss=1.79179, val_acc=0.20779, time=0.20901
Epoch:0043, train_loss=1.78596, train_acc=0.20929, val_loss=1.79179, val_acc=0.20779, time=0.27103
Epoch:0044, train_loss=1.78583, train_acc=0.20929, val_loss=1.79179, val_acc=0.20779, time=0.29701
Epoch:0045, train_loss=1.78570, train_acc=0.21025, val_loss=1.79178, val_acc=0.20779, time=0.29102
Epoch:0046, train_loss=1.78558, train_acc=0.20977, val_loss=1.79178, val_acc=0.20779, time=0.24299
Epoch:0047, train_loss=1.78545, train_acc=0.21025, val_loss=1.79178, val_acc=0.20779, time=0.25900
Epoch:0048, train_loss=1.78532, train_acc=0.21121, val_loss=1.79178, val_acc=0.20346, time=0.21900
Epoch:0049, train_loss=1.78520, train_acc=0.21121, val_loss=1.79177, val_acc=0.20346, time=0.27700
Epoch:0050, train_loss=1.78508, train_acc=0.21216, val_loss=1.79177, val_acc=0.20346, time=0.31200
Epoch:0051, train_loss=1.78495, train_acc=0.21169, val_loss=1.79177, val_acc=0.19481, time=0.29000
Epoch:0052, train_loss=1.78483, train_acc=0.21025, val_loss=1.79177, val_acc=0.19048, time=0.27402
Epoch:0053, train_loss=1.78471, train_acc=0.21025, val_loss=1.79177, val_acc=0.19048, time=0.28100
Epoch:0054, train_loss=1.78459, train_acc=0.20977, val_loss=1.79176, val_acc=0.18615, time=0.26101
Epoch:0055, train_loss=1.78447, train_acc=0.21025, val_loss=1.79176, val_acc=0.18615, time=0.24800
Epoch:0056, train_loss=1.78436, train_acc=0.21025, val_loss=1.79176, val_acc=0.18615, time=0.29002
Epoch:0057, train_loss=1.78424, train_acc=0.21216, val_loss=1.79176, val_acc=0.19048, time=0.29100
Epoch:0058, train_loss=1.78412, train_acc=0.21121, val_loss=1.79176, val_acc=0.19048, time=0.21401
Epoch:0059, train_loss=1.78401, train_acc=0.21169, val_loss=1.79176, val_acc=0.19481, time=0.21900
Epoch:0060, train_loss=1.78390, train_acc=0.21121, val_loss=1.79176, val_acc=0.19481, time=0.22100
Epoch:0061, train_loss=1.78378, train_acc=0.21169, val_loss=1.79175, val_acc=0.19048, time=0.30602
Epoch:0062, train_loss=1.78367, train_acc=0.21121, val_loss=1.79175, val_acc=0.19048, time=0.28100
Epoch:0063, train_loss=1.78356, train_acc=0.21025, val_loss=1.79175, val_acc=0.19048, time=0.23500
Epoch:0064, train_loss=1.78345, train_acc=0.21073, val_loss=1.79175, val_acc=0.19048, time=0.22800
Epoch:0065, train_loss=1.78334, train_acc=0.21073, val_loss=1.79175, val_acc=0.19048, time=0.28700
Epoch:0066, train_loss=1.78323, train_acc=0.21121, val_loss=1.79175, val_acc=0.19048, time=0.25603
Epoch:0067, train_loss=1.78312, train_acc=0.21073, val_loss=1.79175, val_acc=0.19048, time=0.26801
Epoch:0068, train_loss=1.78302, train_acc=0.21073, val_loss=1.79175, val_acc=0.18615, time=0.26400
Epoch:0069, train_loss=1.78291, train_acc=0.21169, val_loss=1.79175, val_acc=0.19048, time=0.25801
Epoch:0070, train_loss=1.78280, train_acc=0.21264, val_loss=1.79175, val_acc=0.19048, time=0.21401
Epoch:0071, train_loss=1.78270, train_acc=0.21312, val_loss=1.79174, val_acc=0.19048, time=0.24401
Epoch:0072, train_loss=1.78259, train_acc=0.21408, val_loss=1.79174, val_acc=0.19048, time=0.24601
Epoch:0073, train_loss=1.78249, train_acc=0.21408, val_loss=1.79174, val_acc=0.19048, time=0.21201
Epoch:0074, train_loss=1.78239, train_acc=0.21504, val_loss=1.79174, val_acc=0.19048, time=0.28199
Epoch:0075, train_loss=1.78229, train_acc=0.21504, val_loss=1.79174, val_acc=0.19048, time=0.31500
Epoch:0076, train_loss=1.78218, train_acc=0.21504, val_loss=1.79174, val_acc=0.19048, time=0.27600
Epoch:0077, train_loss=1.78208, train_acc=0.21600, val_loss=1.79174, val_acc=0.18615, time=0.22302
Epoch:0078, train_loss=1.78198, train_acc=0.21648, val_loss=1.79174, val_acc=0.18615, time=0.31098
Epoch:0079, train_loss=1.78189, train_acc=0.21743, val_loss=1.79174, val_acc=0.18615, time=0.21701
Epoch:0080, train_loss=1.78179, train_acc=0.21743, val_loss=1.79174, val_acc=0.18615, time=0.30700
Epoch:0081, train_loss=1.78169, train_acc=0.21791, val_loss=1.79174, val_acc=0.18615, time=0.28301
Epoch:0082, train_loss=1.78159, train_acc=0.21791, val_loss=1.79174, val_acc=0.18615, time=0.27500
Epoch:0083, train_loss=1.78150, train_acc=0.21743, val_loss=1.79174, val_acc=0.18615, time=0.21900
Epoch:0084, train_loss=1.78140, train_acc=0.21839, val_loss=1.79174, val_acc=0.18615, time=0.24400
Epoch:0085, train_loss=1.78130, train_acc=0.21887, val_loss=1.79174, val_acc=0.18182, time=0.24304
Epoch:0086, train_loss=1.78121, train_acc=0.21983, val_loss=1.79174, val_acc=0.18182, time=0.29100
Epoch:0087, train_loss=1.78112, train_acc=0.22079, val_loss=1.79174, val_acc=0.18182, time=0.24099
Epoch:0088, train_loss=1.78102, train_acc=0.22031, val_loss=1.79174, val_acc=0.18182, time=0.24601
Epoch:0089, train_loss=1.78093, train_acc=0.22079, val_loss=1.79174, val_acc=0.18182, time=0.28701
Early stopping...

Optimization Finished!

Test set results: loss= 1.78758, accuracy= 0.21047, time= 0.10000

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3333    0.0053    0.0104       189
           1     0.0000    0.0000    0.0000       150
           2     0.2019    0.1029    0.1364       204
           3     0.2164    0.8125    0.3418       208
           4     0.1765    0.1040    0.1309       173
           5     0.0000    0.0000    0.0000        69

    accuracy                         0.2105       993
   macro avg     0.1547    0.1708    0.1032       993
weighted avg     0.1810    0.2105    0.1244       993


Macro average Test Precision, Recall and F1-Score...
(0.15468604050832716, 0.17079640408936, 0.10324145780351542, None)

Micro average Test Precision, Recall and F1-Score...
(0.2104733131923464, 0.2104733131923464, 0.2104733131923464, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
