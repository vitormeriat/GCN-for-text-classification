
==========: 305557128500400
Epoch:0001, train_loss=1.80262, train_acc=0.18008, val_loss=1.79210, val_acc=0.18615, time=0.32200
Epoch:0002, train_loss=1.77681, train_acc=0.21216, val_loss=1.79357, val_acc=0.15584, time=0.29102
Epoch:0003, train_loss=1.77243, train_acc=0.26293, val_loss=1.79441, val_acc=0.19048, time=0.30299
Epoch:0004, train_loss=1.76862, train_acc=0.32759, val_loss=1.79465, val_acc=0.19048, time=0.30300
Epoch:0005, train_loss=1.76297, train_acc=0.33669, val_loss=1.79445, val_acc=0.18182, time=0.30400
Epoch:0006, train_loss=1.75518, train_acc=0.35967, val_loss=1.79403, val_acc=0.19913, time=0.29202
Epoch:0007, train_loss=1.74661, train_acc=0.41475, val_loss=1.79358, val_acc=0.17749, time=0.32302
Epoch:0008, train_loss=1.73839, train_acc=0.45785, val_loss=1.79316, val_acc=0.17749, time=0.32099
Epoch:0009, train_loss=1.73072, train_acc=0.48563, val_loss=1.79284, val_acc=0.16017, time=0.30301
Epoch:0010, train_loss=1.72360, train_acc=0.49042, val_loss=1.79268, val_acc=0.15584, time=0.26900
Epoch:0011, train_loss=1.71691, train_acc=0.49569, val_loss=1.79268, val_acc=0.16450, time=0.26702
Epoch:0012, train_loss=1.71028, train_acc=0.49282, val_loss=1.79281, val_acc=0.15584, time=0.33099
Epoch:0013, train_loss=1.70334, train_acc=0.50192, val_loss=1.79304, val_acc=0.16883, time=0.29202
Epoch:0014, train_loss=1.69591, train_acc=0.51533, val_loss=1.79333, val_acc=0.16450, time=0.31300
Epoch:0015, train_loss=1.68804, train_acc=0.53400, val_loss=1.79370, val_acc=0.16450, time=0.30900
Early stopping...

Optimization Finished!

Test set results: loss= 1.79202, accuracy= 0.21249, time= 0.06400

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.1986    0.1534    0.1731       189
           1     0.1346    0.0467    0.0693       150
           2     0.2064    0.2843    0.2392       204
           3     0.2226    0.3317    0.2664       208
           4     0.2353    0.2775    0.2546       173
           5     0.0000    0.0000    0.0000        69

    accuracy                         0.2125       993
   macro avg     0.1663    0.1823    0.1671       993
weighted avg     0.1882    0.2125    0.1927       993


Macro average Test Precision, Recall and F1-Score...
(0.16625432972670218, 0.18226782703760488, 0.1671112821678045, None)

Micro average Test Precision, Recall and F1-Score...
(0.21248741188318226, 0.21248741188318226, 0.21248741188318226, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
