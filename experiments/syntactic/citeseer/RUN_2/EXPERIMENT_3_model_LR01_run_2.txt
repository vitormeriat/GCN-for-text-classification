
==========: 305378613426200
Epoch:0001, train_loss=1.79372, train_acc=0.19828, val_loss=1.83083, val_acc=0.21645, time=0.32800
Epoch:0002, train_loss=2.05141, train_acc=0.21216, val_loss=1.82014, val_acc=0.14719, time=0.29701
Epoch:0003, train_loss=1.92453, train_acc=0.18822, val_loss=1.81388, val_acc=0.18182, time=0.27400
Epoch:0004, train_loss=1.88056, train_acc=0.23659, val_loss=1.80648, val_acc=0.14286, time=0.31501
Epoch:0005, train_loss=1.83926, train_acc=0.29023, val_loss=1.79806, val_acc=0.16883, time=0.30100
Epoch:0006, train_loss=1.78597, train_acc=0.31944, val_loss=1.79358, val_acc=0.16450, time=0.30700
Epoch:0007, train_loss=1.76091, train_acc=0.35776, val_loss=1.79219, val_acc=0.16017, time=0.33301
Epoch:0008, train_loss=1.75614, train_acc=0.39033, val_loss=1.79195, val_acc=0.14719, time=0.31199
Epoch:0009, train_loss=1.75605, train_acc=0.40900, val_loss=1.79197, val_acc=0.16017, time=0.33001
Epoch:0010, train_loss=1.75429, train_acc=0.43630, val_loss=1.79202, val_acc=0.16883, time=0.30098
Epoch:0011, train_loss=1.75005, train_acc=0.44923, val_loss=1.79211, val_acc=0.16450, time=0.30601
Epoch:0012, train_loss=1.74354, train_acc=0.45067, val_loss=1.79232, val_acc=0.16450, time=0.30300
Epoch:0013, train_loss=1.73535, train_acc=0.44157, val_loss=1.79274, val_acc=0.16450, time=0.32099
Epoch:0014, train_loss=1.72625, train_acc=0.42960, val_loss=1.79325, val_acc=0.17749, time=0.30001
Epoch:0015, train_loss=1.71583, train_acc=0.44349, val_loss=1.79377, val_acc=0.19913, time=0.32201
Early stopping...

Optimization Finished!

Test set results: loss= 1.79490, accuracy= 0.19134, time= 0.10200

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.1826    0.2116    0.1961       189
           1     0.1604    0.1133    0.1328       150
           2     0.2145    0.3186    0.2564       204
           3     0.1850    0.3077    0.2310       208
           4     0.1875    0.0173    0.0317       173
           5     0.3333    0.0145    0.0278        69

    accuracy                         0.1913       993
   macro avg     0.2106    0.1639    0.1460       993
weighted avg     0.1976    0.1913    0.1659       993


Macro average Test Precision, Recall and F1-Score...
(0.2105586073435823, 0.16385451628864348, 0.14597865478575953, None)

Micro average Test Precision, Recall and F1-Score...
(0.19133937562940584, 0.19133937562940584, 0.19133937562940587, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
