
==========: 305570003207900
Epoch:0001, train_loss=1.80783, train_acc=0.19061, val_loss=1.79238, val_acc=0.22078, time=0.31399
Epoch:0002, train_loss=1.77760, train_acc=0.21743, val_loss=1.79405, val_acc=0.13853, time=0.30201
Epoch:0003, train_loss=1.77508, train_acc=0.22126, val_loss=1.79482, val_acc=0.19481, time=0.28898
Epoch:0004, train_loss=1.77172, train_acc=0.29215, val_loss=1.79481, val_acc=0.16883, time=0.31301
Epoch:0005, train_loss=1.76584, train_acc=0.34962, val_loss=1.79447, val_acc=0.16450, time=0.28700
Epoch:0006, train_loss=1.75910, train_acc=0.37021, val_loss=1.79396, val_acc=0.17316, time=0.28000
Epoch:0007, train_loss=1.75130, train_acc=0.40517, val_loss=1.79338, val_acc=0.16883, time=0.31399
Epoch:0008, train_loss=1.74299, train_acc=0.43008, val_loss=1.79292, val_acc=0.19913, time=0.32201
Epoch:0009, train_loss=1.73545, train_acc=0.44971, val_loss=1.79266, val_acc=0.19481, time=0.31400
Epoch:0010, train_loss=1.72913, train_acc=0.45115, val_loss=1.79254, val_acc=0.19481, time=0.28301
Epoch:0011, train_loss=1.72346, train_acc=0.45833, val_loss=1.79251, val_acc=0.17749, time=0.32701
Epoch:0012, train_loss=1.71773, train_acc=0.46121, val_loss=1.79255, val_acc=0.17316, time=0.31201
Epoch:0013, train_loss=1.71157, train_acc=0.46887, val_loss=1.79265, val_acc=0.17316, time=0.28200
Epoch:0014, train_loss=1.70481, train_acc=0.47749, val_loss=1.79280, val_acc=0.16450, time=0.28401
Epoch:0015, train_loss=1.69750, train_acc=0.49377, val_loss=1.79307, val_acc=0.15584, time=0.31500
Early stopping...

Optimization Finished!

Test set results: loss= 1.79167, accuracy= 0.19436, time= 0.09300

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.1026    0.0423    0.0599       189
           1     0.1463    0.0800    0.1034       150
           2     0.1965    0.3284    0.2459       204
           3     0.2086    0.3510    0.2616       208
           4     0.2340    0.1908    0.2102       173
           5     0.0000    0.0000    0.0000        69

    accuracy                         0.1944       993
   macro avg     0.1480    0.1654    0.1468       993
weighted avg     0.1665    0.1944    0.1690       993


Macro average Test Precision, Recall and F1-Score...
(0.14800008102634615, 0.1654120664042176, 0.14684745957505274, None)

Micro average Test Precision, Recall and F1-Score...
(0.19436052366565962, 0.19436052366565962, 0.1943605236656596, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
