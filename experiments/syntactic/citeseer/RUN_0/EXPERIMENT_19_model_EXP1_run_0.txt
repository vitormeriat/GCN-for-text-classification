
==========: 304359780440100
Epoch:0001, train_loss=1.79560, train_acc=0.19013, val_loss=1.79186, val_acc=0.20346, time=0.29602
Epoch:0002, train_loss=1.78138, train_acc=0.20211, val_loss=1.79248, val_acc=0.19913, time=0.31701
Epoch:0003, train_loss=1.77634, train_acc=0.23084, val_loss=1.79319, val_acc=0.16450, time=0.30900
Epoch:0004, train_loss=1.77401, train_acc=0.25527, val_loss=1.79356, val_acc=0.16883, time=0.32601
Epoch:0005, train_loss=1.77080, train_acc=0.27778, val_loss=1.79361, val_acc=0.16883, time=0.32002
Epoch:0006, train_loss=1.76653, train_acc=0.30939, val_loss=1.79349, val_acc=0.19048, time=0.31299
Epoch:0007, train_loss=1.76200, train_acc=0.33908, val_loss=1.79330, val_acc=0.18182, time=0.32300
Early stopping...

Optimization Finished!

Test set results: loss= 1.78591, accuracy= 0.20544, time= 0.09702

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.1692    0.0582    0.0866       189
           1     0.1875    0.0200    0.0361       150
           2     0.2035    0.3382    0.2541       204
           3     0.2155    0.4423    0.2898       208
           4     0.1986    0.1676    0.1818       173
           5     0.0000    0.0000    0.0000        69

    accuracy                         0.2054       993
   macro avg     0.1624    0.1711    0.1414       993
weighted avg     0.1821    0.2054    0.1665       993


Macro average Test Precision, Recall and F1-Score...
(0.16239290061649803, 0.17106235040497764, 0.1414140598826967, None)

Micro average Test Precision, Recall and F1-Score...
(0.2054380664652568, 0.2054380664652568, 0.2054380664652568, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
