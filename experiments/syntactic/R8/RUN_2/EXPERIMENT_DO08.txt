
==========: 282779778771900
Epoch:0001, train_loss=2.34409, train_acc=0.04638, val_loss=2.07714, val_acc=0.29745, time=1.17700
Epoch:0002, train_loss=2.04327, train_acc=0.31132, val_loss=2.06229, val_acc=0.44526, time=1.29001
Epoch:0003, train_loss=1.89850, train_acc=0.48045, val_loss=2.06179, val_acc=0.46715, time=1.16801
Epoch:0004, train_loss=1.88531, train_acc=0.51975, val_loss=2.06322, val_acc=0.47993, time=1.12600
Epoch:0005, train_loss=1.89371, train_acc=0.53109, val_loss=2.06338, val_acc=0.46533, time=1.17802
Epoch:0006, train_loss=1.89132, train_acc=0.54608, val_loss=2.06397, val_acc=0.45620, time=1.14401
Epoch:0007, train_loss=1.88917, train_acc=0.55054, val_loss=2.06413, val_acc=0.45620, time=1.16200
Epoch:0008, train_loss=1.87752, train_acc=0.56026, val_loss=2.06348, val_acc=0.45620, time=1.19502
Epoch:0009, train_loss=1.85503, train_acc=0.58315, val_loss=2.06288, val_acc=0.46533, time=1.18400
Epoch:0010, train_loss=1.83185, train_acc=0.58922, val_loss=2.06255, val_acc=0.47080, time=1.28001
Epoch:0011, train_loss=1.81186, train_acc=0.59024, val_loss=2.06226, val_acc=0.46898, time=1.25600
Epoch:0012, train_loss=1.79385, train_acc=0.59631, val_loss=2.06199, val_acc=0.46350, time=1.16201
Epoch:0013, train_loss=1.77802, train_acc=0.61150, val_loss=2.06196, val_acc=0.45803, time=1.28399
Epoch:0014, train_loss=1.76583, train_acc=0.62244, val_loss=2.06227, val_acc=0.45073, time=1.25001
Epoch:0015, train_loss=1.75774, train_acc=0.63662, val_loss=2.06285, val_acc=0.43978, time=1.27600
Epoch:0016, train_loss=1.75258, train_acc=0.64999, val_loss=2.06350, val_acc=0.43066, time=1.20102
Early stopping...

Optimization Finished!

Test set results: loss= 2.01829, accuracy= 0.42988, time= 0.32999

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.0833    0.0115    0.0202        87
           1     0.4935    0.7322    0.5896      1083
           2     0.3085    0.2083    0.2487       696
           3     0.0000    0.0000    0.0000        10
           4     0.0270    0.0133    0.0179        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.0238    0.0123    0.0163        81

    accuracy                         0.4299      2189
   macro avg     0.1170    0.1222    0.1116      2189
weighted avg     0.3474    0.4299    0.3728      2189


Macro average Test Precision, Recall and F1-Score...
(0.11701832604275707, 0.12221648733061397, 0.11157799429100583, None)

Micro average Test Precision, Recall and F1-Score...
(0.4298766560073093, 0.4298766560073093, 0.4298766560073093, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
