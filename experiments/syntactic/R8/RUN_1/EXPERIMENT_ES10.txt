
==========: 275959472153700
Epoch:0001, train_loss=2.23454, train_acc=0.22544, val_loss=2.07513, val_acc=0.48905, time=1.40801
Epoch:0002, train_loss=2.03580, train_acc=0.50233, val_loss=2.06502, val_acc=0.50182, time=1.28302
Epoch:0003, train_loss=1.94400, train_acc=0.51631, val_loss=2.05911, val_acc=0.45985, time=1.21000
Epoch:0004, train_loss=1.89350, train_acc=0.47519, val_loss=2.06010, val_acc=0.39051, time=1.28101
Epoch:0005, train_loss=1.90420, train_acc=0.40004, val_loss=2.06118, val_acc=0.40146, time=1.24100
Epoch:0006, train_loss=1.90357, train_acc=0.41483, val_loss=2.06047, val_acc=0.43613, time=1.27501
Epoch:0007, train_loss=1.87769, train_acc=0.48126, val_loss=2.06062, val_acc=0.43796, time=1.23399
Epoch:0008, train_loss=1.85597, train_acc=0.53433, val_loss=2.06183, val_acc=0.48540, time=1.19901
Epoch:0009, train_loss=1.84672, train_acc=0.55358, val_loss=2.06264, val_acc=0.48905, time=1.21201
Epoch:0010, train_loss=1.83896, train_acc=0.55641, val_loss=2.06246, val_acc=0.48540, time=1.28500
Epoch:0011, train_loss=1.82656, train_acc=0.56431, val_loss=2.06172, val_acc=0.47993, time=1.16700
Epoch:0012, train_loss=1.81171, train_acc=0.57748, val_loss=2.06097, val_acc=0.47080, time=1.32000
Epoch:0013, train_loss=1.79789, train_acc=0.59854, val_loss=2.06051, val_acc=0.46168, time=1.28401
Epoch:0014, train_loss=1.78642, train_acc=0.60928, val_loss=2.06032, val_acc=0.45073, time=1.32801
Epoch:0015, train_loss=1.77649, train_acc=0.61535, val_loss=2.06030, val_acc=0.43978, time=1.33900
Epoch:0016, train_loss=1.76679, train_acc=0.61414, val_loss=2.06040, val_acc=0.44161, time=1.23601
Epoch:0017, train_loss=1.75678, train_acc=0.62568, val_loss=2.06063, val_acc=0.44343, time=1.25100
Epoch:0018, train_loss=1.74699, train_acc=0.63156, val_loss=2.06105, val_acc=0.46350, time=1.25299
Epoch:0019, train_loss=1.73829, train_acc=0.64006, val_loss=2.06164, val_acc=0.46168, time=1.19302
Early stopping...

Optimization Finished!

Test set results: loss= 2.01342, accuracy= 0.45957, time= 0.32200

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.2000    0.0345    0.0588        87
           1     0.5012    0.8006    0.6164      1083
           2     0.3268    0.1925    0.2423       696
           3     0.0000    0.0000    0.0000        10
           4     0.0833    0.0133    0.0230        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.2000    0.0123    0.0233        81

    accuracy                         0.4596      2189
   macro avg     0.1639    0.1317    0.1205      2189
weighted avg     0.3701    0.4596    0.3860      2189


Macro average Test Precision, Recall and F1-Score...
(0.16391483387377226, 0.13165556540238138, 0.12047578042246998, None)

Micro average Test Precision, Recall and F1-Score...
(0.45957058017359526, 0.45957058017359526, 0.45957058017359526, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
