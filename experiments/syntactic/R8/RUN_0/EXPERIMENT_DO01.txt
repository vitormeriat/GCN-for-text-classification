
==========: 275350696241800
Epoch:0001, train_loss=2.29094, train_acc=0.05206, val_loss=2.07602, val_acc=0.40511, time=1.34501
Epoch:0002, train_loss=2.03332, train_acc=0.43934, val_loss=2.06529, val_acc=0.49818, time=1.25802
Epoch:0003, train_loss=1.93054, train_acc=0.51043, val_loss=2.06081, val_acc=0.49453, time=1.11701
Epoch:0004, train_loss=1.88610, train_acc=0.52299, val_loss=2.05985, val_acc=0.43613, time=1.30199
Epoch:0005, train_loss=1.87525, train_acc=0.50841, val_loss=2.06233, val_acc=0.42336, time=1.10201
Epoch:0006, train_loss=1.89141, train_acc=0.47174, val_loss=2.06287, val_acc=0.42336, time=1.27302
Epoch:0007, train_loss=1.88215, train_acc=0.50314, val_loss=2.06257, val_acc=0.46715, time=1.19299
Epoch:0008, train_loss=1.86136, train_acc=0.54649, val_loss=2.06272, val_acc=0.48358, time=1.16801
Epoch:0009, train_loss=1.84550, train_acc=0.56816, val_loss=2.06241, val_acc=0.49270, time=1.17901
Epoch:0010, train_loss=1.82863, train_acc=0.57383, val_loss=2.06128, val_acc=0.49453, time=1.25801
Epoch:0011, train_loss=1.80711, train_acc=0.58234, val_loss=2.06013, val_acc=0.47263, time=1.23701
Epoch:0012, train_loss=1.78702, train_acc=0.59793, val_loss=2.05977, val_acc=0.44526, time=1.23101
Epoch:0013, train_loss=1.77442, train_acc=0.62001, val_loss=2.06019, val_acc=0.41423, time=1.16901
Epoch:0014, train_loss=1.76822, train_acc=0.61880, val_loss=2.06085, val_acc=0.40328, time=1.20101
Epoch:0015, train_loss=1.76315, train_acc=0.62487, val_loss=2.06141, val_acc=0.42518, time=1.20401
Epoch:0016, train_loss=1.75628, train_acc=0.64128, val_loss=2.06188, val_acc=0.42518, time=1.26201
Early stopping...

Optimization Finished!

Test set results: loss= 2.01021, accuracy= 0.45592, time= 0.36899

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.0769    0.0115    0.0200        87
           1     0.5088    0.7775    0.6150      1083
           2     0.3393    0.2184    0.2657       696
           3     0.0000    0.0000    0.0000        10
           4     0.0800    0.0267    0.0400        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.1429    0.0123    0.0227        81

    accuracy                         0.4559      2189
   macro avg     0.1435    0.1308    0.1204      2189
weighted avg     0.3707    0.4559    0.3918      2189


Macro average Test Precision, Recall and F1-Score...
(0.14347840792138378, 0.1307959242395833, 0.1204386272967354, None)

Micro average Test Precision, Recall and F1-Score...
(0.4559159433531293, 0.4559159433531293, 0.45591594335312924, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
