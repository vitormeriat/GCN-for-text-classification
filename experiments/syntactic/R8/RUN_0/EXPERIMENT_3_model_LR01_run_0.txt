
==========: 434808226948900
Epoch:0001, train_loss=2.21741, train_acc=0.07069, val_loss=2.05356, val_acc=0.74453, time=1.34401
Epoch:0002, train_loss=1.84195, train_acc=0.75106, val_loss=2.04349, val_acc=0.80657, time=1.20601
Epoch:0003, train_loss=1.73654, train_acc=0.81325, val_loss=2.03358, val_acc=0.85219, time=1.22902
Epoch:0004, train_loss=1.62450, train_acc=0.87908, val_loss=2.03169, val_acc=0.85584, time=1.29500
Epoch:0005, train_loss=1.58506, train_acc=0.89224, val_loss=2.02665, val_acc=0.86314, time=1.26302
Epoch:0006, train_loss=1.53254, train_acc=0.91007, val_loss=2.02064, val_acc=0.88321, time=1.38400
Epoch:0007, train_loss=1.48704, train_acc=0.93964, val_loss=2.01675, val_acc=0.91241, time=1.24901
Epoch:0008, train_loss=1.46271, train_acc=0.96172, val_loss=2.01498, val_acc=0.91788, time=1.25302
Epoch:0009, train_loss=1.45202, train_acc=0.96820, val_loss=2.01425, val_acc=0.93066, time=1.31601
Epoch:0010, train_loss=1.44759, train_acc=0.96901, val_loss=2.01404, val_acc=0.93613, time=1.32201
Epoch:0011, train_loss=1.44560, train_acc=0.96941, val_loss=2.01393, val_acc=0.93978, time=1.29801
Epoch:0012, train_loss=1.44350, train_acc=0.97002, val_loss=2.01373, val_acc=0.94161, time=1.27001
Epoch:0013, train_loss=1.44033, train_acc=0.97468, val_loss=2.01341, val_acc=0.94161, time=1.32600
Epoch:0014, train_loss=1.43641, train_acc=0.97711, val_loss=2.01303, val_acc=0.94343, time=1.29701
Epoch:0015, train_loss=1.43239, train_acc=0.97995, val_loss=2.01266, val_acc=0.94343, time=1.20501
Epoch:0016, train_loss=1.42878, train_acc=0.98278, val_loss=2.01232, val_acc=0.94708, time=1.29700
Epoch:0017, train_loss=1.42584, train_acc=0.98744, val_loss=2.01202, val_acc=0.94891, time=1.28301
Epoch:0018, train_loss=1.42353, train_acc=0.98906, val_loss=2.01177, val_acc=0.95073, time=1.28500
Epoch:0019, train_loss=1.42185, train_acc=0.98987, val_loss=2.01161, val_acc=0.95255, time=1.24401
Epoch:0020, train_loss=1.42081, train_acc=0.99190, val_loss=2.01153, val_acc=0.94891, time=1.33397
Epoch:0021, train_loss=1.42033, train_acc=0.99129, val_loss=2.01152, val_acc=0.95255, time=1.31403
Epoch:0022, train_loss=1.42018, train_acc=0.99109, val_loss=2.01154, val_acc=0.95255, time=1.26802
Epoch:0023, train_loss=1.42007, train_acc=0.99048, val_loss=2.01155, val_acc=0.95438, time=1.33899
Epoch:0024, train_loss=1.41978, train_acc=0.99129, val_loss=2.01155, val_acc=0.95438, time=1.21900
Epoch:0025, train_loss=1.41925, train_acc=0.99210, val_loss=2.01152, val_acc=0.95438, time=1.28602
Epoch:0026, train_loss=1.41855, train_acc=0.99291, val_loss=2.01148, val_acc=0.95620, time=1.20601
Epoch:0027, train_loss=1.41778, train_acc=0.99473, val_loss=2.01146, val_acc=0.95620, time=1.19902
Epoch:0028, train_loss=1.41708, train_acc=0.99473, val_loss=2.01145, val_acc=0.95803, time=1.27301
Epoch:0029, train_loss=1.41650, train_acc=0.99554, val_loss=2.01146, val_acc=0.95438, time=1.24702
Epoch:0030, train_loss=1.41608, train_acc=0.99595, val_loss=2.01149, val_acc=0.95803, time=1.22200
Epoch:0031, train_loss=1.41578, train_acc=0.99595, val_loss=2.01151, val_acc=0.95620, time=1.25702
Early stopping...

Optimization Finished!

Test set results: loss= 1.81255, accuracy= 0.94427, time= 0.40299

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9569    0.9843    0.9704      1083
           1     0.9815    0.9167    0.9480       696
           2     0.8322    0.9835    0.9015       121
           3     0.8000    0.8000    0.8000        10
           4     0.8875    0.9467    0.9161        75
           5     0.7889    0.8765    0.8304        81
           6     1.0000    0.6111    0.7586        36
           7     0.9000    0.8276    0.8623        87

    accuracy                         0.9443      2189
   macro avg     0.8934    0.8683    0.8734      2189
weighted avg     0.9470    0.9443    0.9439      2189


Macro average Test Precision, Recall and F1-Score...
(0.8933759014150622, 0.8682934747521138, 0.8734197421127949, None)

Micro average Test Precision, Recall and F1-Score...
(0.944266788487894, 0.944266788487894, 0.944266788487894, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
