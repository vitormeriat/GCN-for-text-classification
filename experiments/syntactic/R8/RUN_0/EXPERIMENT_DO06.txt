
==========: 275523387508900
Epoch:0001, train_loss=2.30770, train_acc=0.05145, val_loss=2.07669, val_acc=0.29015, time=1.20401
Epoch:0002, train_loss=2.04591, train_acc=0.28621, val_loss=2.06286, val_acc=0.42336, time=1.31303
Epoch:0003, train_loss=1.90538, train_acc=0.45230, val_loss=2.06105, val_acc=0.48358, time=1.31001
Epoch:0004, train_loss=1.87531, train_acc=0.51813, val_loss=2.06350, val_acc=0.49088, time=1.27000
Epoch:0005, train_loss=1.88701, train_acc=0.52866, val_loss=2.06391, val_acc=0.48723, time=1.30900
Epoch:0006, train_loss=1.88315, train_acc=0.53616, val_loss=2.06309, val_acc=0.49270, time=1.19601
Epoch:0007, train_loss=1.86880, train_acc=0.54345, val_loss=2.06288, val_acc=0.44891, time=1.28101
Epoch:0008, train_loss=1.85827, train_acc=0.55378, val_loss=2.06304, val_acc=0.43613, time=1.28000
Epoch:0009, train_loss=1.84831, train_acc=0.55499, val_loss=2.06274, val_acc=0.43613, time=1.30901
Epoch:0010, train_loss=1.83227, train_acc=0.58234, val_loss=2.06237, val_acc=0.45803, time=1.25201
Epoch:0011, train_loss=1.81439, train_acc=0.60097, val_loss=2.06236, val_acc=0.47080, time=1.34001
Epoch:0012, train_loss=1.79957, train_acc=0.60543, val_loss=2.06256, val_acc=0.46715, time=1.26801
Epoch:0013, train_loss=1.78738, train_acc=0.60178, val_loss=2.06260, val_acc=0.46715, time=1.33401
Epoch:0014, train_loss=1.77562, train_acc=0.60583, val_loss=2.06243, val_acc=0.46715, time=1.23701
Epoch:0015, train_loss=1.76397, train_acc=0.61353, val_loss=2.06223, val_acc=0.47445, time=1.25399
Epoch:0016, train_loss=1.75386, train_acc=0.62852, val_loss=2.06223, val_acc=0.47080, time=1.17100
Epoch:0017, train_loss=1.74664, train_acc=0.63824, val_loss=2.06248, val_acc=0.44708, time=1.19700
Epoch:0018, train_loss=1.74220, train_acc=0.64756, val_loss=2.06288, val_acc=0.43613, time=1.28901
Early stopping...

Optimization Finished!

Test set results: loss= 2.01171, accuracy= 0.43125, time= 0.37401

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.1111    0.0115    0.0208        87
           1     0.4884    0.7165    0.5808      1083
           2     0.3179    0.2371    0.2716       696
           3     0.0000    0.0000    0.0000        10
           4     0.0571    0.0267    0.0364        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.0000    0.0000    0.0000        81

    accuracy                         0.4312      2189
   macro avg     0.1218    0.1240    0.1137      2189
weighted avg     0.3491    0.4312    0.3758      2189


Macro average Test Precision, Recall and F1-Score...
(0.12181631261486625, 0.12396975594612666, 0.11370502891523354, None)

Micro average Test Precision, Recall and F1-Score...
(0.431247144814984, 0.431247144814984, 0.431247144814984, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
