
==========: 433269669713900
Epoch:0001, train_loss=2.33895, train_acc=0.15232, val_loss=2.08073, val_acc=0.38869, time=1.27201
Epoch:0002, train_loss=2.08249, train_acc=0.37452, val_loss=2.05940, val_acc=0.60584, time=1.28101
Epoch:0003, train_loss=1.88794, train_acc=0.58983, val_loss=2.04393, val_acc=0.72263, time=1.24601
Epoch:0004, train_loss=1.74566, train_acc=0.74620, val_loss=2.03639, val_acc=0.71350, time=1.26801
Epoch:0005, train_loss=1.67357, train_acc=0.75309, val_loss=2.03393, val_acc=0.70255, time=1.33700
Epoch:0006, train_loss=1.64597, train_acc=0.73142, val_loss=2.03135, val_acc=0.71898, time=1.28201
Epoch:0007, train_loss=1.62020, train_acc=0.74965, val_loss=2.02747, val_acc=0.75547, time=1.25601
Epoch:0008, train_loss=1.58628, train_acc=0.79603, val_loss=2.02330, val_acc=0.80839, time=1.29401
Epoch:0009, train_loss=1.55207, train_acc=0.85619, val_loss=2.02000, val_acc=0.88139, time=1.16602
Epoch:0010, train_loss=1.52548, train_acc=0.90541, val_loss=2.01795, val_acc=0.90328, time=1.20001
Epoch:0011, train_loss=1.50827, train_acc=0.92911, val_loss=2.01684, val_acc=0.91241, time=1.27900
Epoch:0012, train_loss=1.49774, train_acc=0.93620, val_loss=2.01620, val_acc=0.91788, time=1.27501
Epoch:0013, train_loss=1.49045, train_acc=0.93984, val_loss=2.01571, val_acc=0.91788, time=1.32501
Epoch:0014, train_loss=1.48413, train_acc=0.94470, val_loss=2.01522, val_acc=0.92336, time=1.22002
Epoch:0015, train_loss=1.47784, train_acc=0.95058, val_loss=2.01470, val_acc=0.92336, time=1.21800
Epoch:0016, train_loss=1.47144, train_acc=0.95686, val_loss=2.01417, val_acc=0.92518, time=1.26999
Epoch:0017, train_loss=1.46520, train_acc=0.96131, val_loss=2.01366, val_acc=0.92883, time=1.20900
Epoch:0018, train_loss=1.45941, train_acc=0.96476, val_loss=2.01321, val_acc=0.93613, time=1.25201
Epoch:0019, train_loss=1.45430, train_acc=0.97043, val_loss=2.01282, val_acc=0.93796, time=1.18900
Epoch:0020, train_loss=1.44995, train_acc=0.97245, val_loss=2.01250, val_acc=0.93978, time=1.18300
Epoch:0021, train_loss=1.44632, train_acc=0.97610, val_loss=2.01224, val_acc=0.94161, time=1.22400
Epoch:0022, train_loss=1.44333, train_acc=0.97893, val_loss=2.01202, val_acc=0.93796, time=1.26999
Epoch:0023, train_loss=1.44087, train_acc=0.97995, val_loss=2.01183, val_acc=0.94161, time=1.26601
Epoch:0024, train_loss=1.43881, train_acc=0.98116, val_loss=2.01167, val_acc=0.94526, time=1.27800
Epoch:0025, train_loss=1.43705, train_acc=0.98339, val_loss=2.01151, val_acc=0.94708, time=1.16401
Epoch:0026, train_loss=1.43550, train_acc=0.98542, val_loss=2.01136, val_acc=0.95073, time=1.25001
Epoch:0027, train_loss=1.43410, train_acc=0.98683, val_loss=2.01122, val_acc=0.95073, time=1.38701
Epoch:0028, train_loss=1.43281, train_acc=0.98805, val_loss=2.01108, val_acc=0.95073, time=1.25301
Epoch:0029, train_loss=1.43162, train_acc=0.98926, val_loss=2.01095, val_acc=0.95255, time=1.23501
Epoch:0030, train_loss=1.43052, train_acc=0.98967, val_loss=2.01084, val_acc=0.95255, time=1.24001
Epoch:0031, train_loss=1.42952, train_acc=0.99007, val_loss=2.01074, val_acc=0.95255, time=1.23701
Epoch:0032, train_loss=1.42860, train_acc=0.99028, val_loss=2.01066, val_acc=0.95255, time=1.18201
Epoch:0033, train_loss=1.42778, train_acc=0.99028, val_loss=2.01060, val_acc=0.95255, time=1.24301
Epoch:0034, train_loss=1.42702, train_acc=0.99068, val_loss=2.01054, val_acc=0.95255, time=1.19602
Epoch:0035, train_loss=1.42633, train_acc=0.99129, val_loss=2.01050, val_acc=0.95073, time=1.28003
Epoch:0036, train_loss=1.42569, train_acc=0.99109, val_loss=2.01047, val_acc=0.95255, time=1.25900
Epoch:0037, train_loss=1.42509, train_acc=0.99170, val_loss=2.01043, val_acc=0.95255, time=1.23901
Epoch:0038, train_loss=1.42452, train_acc=0.99190, val_loss=2.01040, val_acc=0.95620, time=1.23403
Epoch:0039, train_loss=1.42397, train_acc=0.99210, val_loss=2.01037, val_acc=0.95803, time=1.18301
Epoch:0040, train_loss=1.42344, train_acc=0.99230, val_loss=2.01034, val_acc=0.95803, time=1.27100
Epoch:0041, train_loss=1.42292, train_acc=0.99332, val_loss=2.01030, val_acc=0.95803, time=1.23600
Epoch:0042, train_loss=1.42243, train_acc=0.99413, val_loss=2.01027, val_acc=0.95803, time=1.27502
Epoch:0043, train_loss=1.42196, train_acc=0.99413, val_loss=2.01024, val_acc=0.95803, time=1.26600
Epoch:0044, train_loss=1.42152, train_acc=0.99473, val_loss=2.01021, val_acc=0.95803, time=1.25001
Epoch:0045, train_loss=1.42111, train_acc=0.99494, val_loss=2.01018, val_acc=0.95803, time=1.31701
Epoch:0046, train_loss=1.42073, train_acc=0.99534, val_loss=2.01015, val_acc=0.95803, time=1.23500
Epoch:0047, train_loss=1.42038, train_acc=0.99534, val_loss=2.01013, val_acc=0.95620, time=1.24300
Epoch:0048, train_loss=1.42005, train_acc=0.99575, val_loss=2.01011, val_acc=0.95620, time=1.31201
Epoch:0049, train_loss=1.41975, train_acc=0.99575, val_loss=2.01009, val_acc=0.95620, time=1.28400
Epoch:0050, train_loss=1.41948, train_acc=0.99595, val_loss=2.01007, val_acc=0.95620, time=1.30701
Epoch:0051, train_loss=1.41922, train_acc=0.99615, val_loss=2.01006, val_acc=0.95803, time=1.24901
Epoch:0052, train_loss=1.41898, train_acc=0.99615, val_loss=2.01004, val_acc=0.95803, time=1.22000
Epoch:0053, train_loss=1.41875, train_acc=0.99635, val_loss=2.01003, val_acc=0.95803, time=1.31001
Epoch:0054, train_loss=1.41853, train_acc=0.99656, val_loss=2.01002, val_acc=0.95803, time=1.22100
Epoch:0055, train_loss=1.41832, train_acc=0.99676, val_loss=2.01000, val_acc=0.95803, time=1.26900
Epoch:0056, train_loss=1.41812, train_acc=0.99676, val_loss=2.00999, val_acc=0.95803, time=1.29600
Epoch:0057, train_loss=1.41792, train_acc=0.99716, val_loss=2.00998, val_acc=0.95985, time=1.30100
Epoch:0058, train_loss=1.41773, train_acc=0.99716, val_loss=2.00996, val_acc=0.95985, time=1.20900
Epoch:0059, train_loss=1.41755, train_acc=0.99716, val_loss=2.00995, val_acc=0.95985, time=1.31301
Epoch:0060, train_loss=1.41737, train_acc=0.99737, val_loss=2.00994, val_acc=0.96168, time=1.22602
Epoch:0061, train_loss=1.41721, train_acc=0.99757, val_loss=2.00994, val_acc=0.95985, time=1.29300
Epoch:0062, train_loss=1.41705, train_acc=0.99777, val_loss=2.00993, val_acc=0.95803, time=1.20202
Epoch:0063, train_loss=1.41690, train_acc=0.99777, val_loss=2.00993, val_acc=0.95803, time=1.28200
Epoch:0064, train_loss=1.41676, train_acc=0.99797, val_loss=2.00992, val_acc=0.95803, time=1.22401
Epoch:0065, train_loss=1.41663, train_acc=0.99797, val_loss=2.00992, val_acc=0.95803, time=1.24902
Epoch:0066, train_loss=1.41650, train_acc=0.99797, val_loss=2.00992, val_acc=0.95803, time=1.25501
Epoch:0067, train_loss=1.41638, train_acc=0.99797, val_loss=2.00992, val_acc=0.95803, time=1.31401
Epoch:0068, train_loss=1.41626, train_acc=0.99818, val_loss=2.00992, val_acc=0.95803, time=1.24300
Epoch:0069, train_loss=1.41615, train_acc=0.99797, val_loss=2.00992, val_acc=0.95803, time=1.30502
Epoch:0070, train_loss=1.41604, train_acc=0.99797, val_loss=2.00992, val_acc=0.95803, time=1.28700
Epoch:0071, train_loss=1.41594, train_acc=0.99797, val_loss=2.00992, val_acc=0.95985, time=1.21600
Epoch:0072, train_loss=1.41585, train_acc=0.99797, val_loss=2.00992, val_acc=0.96168, time=1.21400
Epoch:0073, train_loss=1.41575, train_acc=0.99797, val_loss=2.00992, val_acc=0.96168, time=1.35601
Early stopping...

Optimization Finished!

Test set results: loss= 1.80375, accuracy= 0.95386, time= 0.39502

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9674    0.9852    0.9762      1083
           1     0.9778    0.9483    0.9628       696
           2     0.8779    0.9504    0.9127       121
           3     0.9091    1.0000    0.9524        10
           4     0.8452    0.9467    0.8931        75
           5     0.9403    0.7778    0.8514        81
           6     0.9600    0.6667    0.7869        36
           7     0.8387    0.8966    0.8667        87

    accuracy                         0.9539      2189
   macro avg     0.9145    0.8964    0.9003      2189
weighted avg     0.9550    0.9539    0.9534      2189


Macro average Test Precision, Recall and F1-Score...
(0.9145424128894791, 0.8964472679889842, 0.9002596906392688, None)

Micro average Test Precision, Recall and F1-Score...
(0.9538602101416171, 0.9538602101416171, 0.9538602101416171, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
