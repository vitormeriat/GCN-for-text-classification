
==========: 298344313161000
Epoch:0001, train_loss=2.15139, train_acc=0.13064, val_loss=1.94802, val_acc=0.29101, time=0.12401
Epoch:0002, train_loss=2.00215, train_acc=0.22496, val_loss=1.93938, val_acc=0.32804, time=0.12598
Epoch:0003, train_loss=1.91237, train_acc=0.30931, val_loss=1.93448, val_acc=0.36508, time=0.13099
Epoch:0004, train_loss=1.85406, train_acc=0.35559, val_loss=1.93139, val_acc=0.39683, time=0.11801
Epoch:0005, train_loss=1.81155, train_acc=0.40363, val_loss=1.92930, val_acc=0.42328, time=0.13100
Epoch:0006, train_loss=1.77899, train_acc=0.47159, val_loss=1.92757, val_acc=0.40741, time=0.13102
Epoch:0007, train_loss=1.75149, train_acc=0.51904, val_loss=1.92555, val_acc=0.42857, time=0.10502
Epoch:0008, train_loss=1.72385, train_acc=0.54071, val_loss=1.92297, val_acc=0.44444, time=0.11101
Epoch:0009, train_loss=1.69318, train_acc=0.56122, val_loss=1.91992, val_acc=0.48148, time=0.11899
Epoch:0010, train_loss=1.65993, train_acc=0.60105, val_loss=1.91672, val_acc=0.51852, time=0.12799
Epoch:0011, train_loss=1.62637, train_acc=0.63210, val_loss=1.91364, val_acc=0.58201, time=0.12202
Epoch:0012, train_loss=1.59448, train_acc=0.66667, val_loss=1.91081, val_acc=0.61905, time=0.11001
Epoch:0013, train_loss=1.56519, train_acc=0.68893, val_loss=1.90829, val_acc=0.63492, time=0.10001
Epoch:0014, train_loss=1.53872, train_acc=0.72056, val_loss=1.90609, val_acc=0.67196, time=0.10600
Epoch:0015, train_loss=1.51504, train_acc=0.75337, val_loss=1.90425, val_acc=0.67725, time=0.12001
Epoch:0016, train_loss=1.49418, train_acc=0.77680, val_loss=1.90274, val_acc=0.67725, time=0.10100
Epoch:0017, train_loss=1.47607, train_acc=0.80141, val_loss=1.90153, val_acc=0.70899, time=0.11100
Epoch:0018, train_loss=1.46032, train_acc=0.82132, val_loss=1.90054, val_acc=0.71958, time=0.10802
Epoch:0019, train_loss=1.44628, train_acc=0.83656, val_loss=1.89967, val_acc=0.72487, time=0.12201
Epoch:0020, train_loss=1.43319, train_acc=0.84066, val_loss=1.89884, val_acc=0.73016, time=0.14200
Epoch:0021, train_loss=1.42046, train_acc=0.84944, val_loss=1.89802, val_acc=0.74074, time=0.12803
Epoch:0022, train_loss=1.40779, train_acc=0.85589, val_loss=1.89719, val_acc=0.74603, time=0.12600
Epoch:0023, train_loss=1.39521, train_acc=0.86409, val_loss=1.89639, val_acc=0.74074, time=0.10801
Epoch:0024, train_loss=1.38295, train_acc=0.87112, val_loss=1.89562, val_acc=0.74074, time=0.12200
Epoch:0025, train_loss=1.37126, train_acc=0.87756, val_loss=1.89492, val_acc=0.73545, time=0.12800
Epoch:0026, train_loss=1.36037, train_acc=0.88225, val_loss=1.89430, val_acc=0.73016, time=0.12499
Epoch:0027, train_loss=1.35036, train_acc=0.88518, val_loss=1.89375, val_acc=0.71429, time=0.12601
Epoch:0028, train_loss=1.34118, train_acc=0.88869, val_loss=1.89326, val_acc=0.71429, time=0.11000
Epoch:0029, train_loss=1.33274, train_acc=0.89338, val_loss=1.89283, val_acc=0.71429, time=0.09700
Epoch:0030, train_loss=1.32492, train_acc=0.89982, val_loss=1.89245, val_acc=0.71429, time=0.13101
Epoch:0031, train_loss=1.31761, train_acc=0.90393, val_loss=1.89211, val_acc=0.72487, time=0.13202
Epoch:0032, train_loss=1.31069, train_acc=0.91037, val_loss=1.89182, val_acc=0.73016, time=0.12601
Epoch:0033, train_loss=1.30408, train_acc=0.91154, val_loss=1.89155, val_acc=0.73016, time=0.12000
Epoch:0034, train_loss=1.29767, train_acc=0.91506, val_loss=1.89132, val_acc=0.73545, time=0.09801
Epoch:0035, train_loss=1.29141, train_acc=0.91798, val_loss=1.89110, val_acc=0.74074, time=0.11398
Epoch:0036, train_loss=1.28526, train_acc=0.92091, val_loss=1.89092, val_acc=0.74603, time=0.11701
Epoch:0037, train_loss=1.27928, train_acc=0.92619, val_loss=1.89076, val_acc=0.75132, time=0.11400
Epoch:0038, train_loss=1.27351, train_acc=0.93087, val_loss=1.89064, val_acc=0.74603, time=0.13201
Epoch:0039, train_loss=1.26803, train_acc=0.93615, val_loss=1.89055, val_acc=0.74603, time=0.13098
Epoch:0040, train_loss=1.26287, train_acc=0.94025, val_loss=1.89049, val_acc=0.75661, time=0.11600
Epoch:0041, train_loss=1.25801, train_acc=0.94318, val_loss=1.89045, val_acc=0.75132, time=0.08901
Epoch:0042, train_loss=1.25344, train_acc=0.94669, val_loss=1.89043, val_acc=0.75132, time=0.12100
Epoch:0043, train_loss=1.24910, train_acc=0.94962, val_loss=1.89040, val_acc=0.75661, time=0.08401
Epoch:0044, train_loss=1.24496, train_acc=0.95313, val_loss=1.89039, val_acc=0.75661, time=0.10600
Epoch:0045, train_loss=1.24098, train_acc=0.95489, val_loss=1.89037, val_acc=0.75661, time=0.13001
Epoch:0046, train_loss=1.23714, train_acc=0.95958, val_loss=1.89035, val_acc=0.75661, time=0.11799
Epoch:0047, train_loss=1.23343, train_acc=0.96368, val_loss=1.89034, val_acc=0.75661, time=0.12899
Epoch:0048, train_loss=1.22984, train_acc=0.96602, val_loss=1.89033, val_acc=0.75661, time=0.10001
Epoch:0049, train_loss=1.22637, train_acc=0.96895, val_loss=1.89033, val_acc=0.75661, time=0.11600
Epoch:0050, train_loss=1.22302, train_acc=0.97129, val_loss=1.89034, val_acc=0.76190, time=0.10801
Epoch:0051, train_loss=1.21980, train_acc=0.97422, val_loss=1.89035, val_acc=0.76190, time=0.11700
Epoch:0052, train_loss=1.21672, train_acc=0.97598, val_loss=1.89038, val_acc=0.76190, time=0.13000
Early stopping...

Optimization Finished!

Test set results: loss= 1.72849, accuracy= 0.72291, time= 0.03800

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8000    0.7714    0.7855       140
           1     0.6579    0.5556    0.6024        45
           2     0.6899    0.7355    0.7120       121
           3     0.7500    0.7500    0.7500        92
           4     0.6667    0.6207    0.6429       116
           5     0.8333    0.6154    0.7080        65
           6     0.7023    0.7897    0.7434       233

    accuracy                         0.7229       812
   macro avg     0.7286    0.6912    0.7063       812
weighted avg     0.7256    0.7229    0.7217       812


Macro average Test Precision, Recall and F1-Score...
(0.7285867562568769, 0.6911850226341788, 0.7063028960100229, None)

Micro average Test Precision, Recall and F1-Score...
(0.7229064039408867, 0.7229064039408867, 0.7229064039408866, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
