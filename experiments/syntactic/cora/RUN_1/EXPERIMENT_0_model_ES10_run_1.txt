
==========: 298192203969100
Epoch:0001, train_loss=2.39175, train_acc=0.07381, val_loss=1.96003, val_acc=0.15344, time=0.12701
Epoch:0002, train_loss=2.04321, train_acc=0.15349, val_loss=1.94055, val_acc=0.29630, time=0.10600
Epoch:0003, train_loss=1.88961, train_acc=0.28295, val_loss=1.93538, val_acc=0.35450, time=0.12200
Epoch:0004, train_loss=1.85800, train_acc=0.35442, val_loss=1.93275, val_acc=0.39153, time=0.12300
Epoch:0005, train_loss=1.83478, train_acc=0.37434, val_loss=1.92689, val_acc=0.40741, time=0.11401
Epoch:0006, train_loss=1.77233, train_acc=0.41301, val_loss=1.91974, val_acc=0.47090, time=0.11400
Epoch:0007, train_loss=1.69561, train_acc=0.51904, val_loss=1.91419, val_acc=0.58730, time=0.12600
Epoch:0008, train_loss=1.63447, train_acc=0.63503, val_loss=1.91081, val_acc=0.64021, time=0.12499
Epoch:0009, train_loss=1.59423, train_acc=0.71763, val_loss=1.90836, val_acc=0.64550, time=0.12800
Epoch:0010, train_loss=1.56283, train_acc=0.75103, val_loss=1.90579, val_acc=0.67725, time=0.12601
Epoch:0011, train_loss=1.53023, train_acc=0.76977, val_loss=1.90286, val_acc=0.68254, time=0.13100
Epoch:0012, train_loss=1.49428, train_acc=0.79496, val_loss=1.89992, val_acc=0.69312, time=0.11701
Epoch:0013, train_loss=1.45806, train_acc=0.81312, val_loss=1.89744, val_acc=0.70899, time=0.12800
Epoch:0014, train_loss=1.42578, train_acc=0.83128, val_loss=1.89575, val_acc=0.71429, time=0.12800
Epoch:0015, train_loss=1.40026, train_acc=0.84241, val_loss=1.89489, val_acc=0.71429, time=0.12301
Epoch:0016, train_loss=1.38185, train_acc=0.84183, val_loss=1.89464, val_acc=0.71958, time=0.13201
Epoch:0017, train_loss=1.36883, train_acc=0.84886, val_loss=1.89466, val_acc=0.70370, time=0.13199
Epoch:0018, train_loss=1.35856, train_acc=0.84944, val_loss=1.89462, val_acc=0.69841, time=0.11901
Epoch:0019, train_loss=1.34872, train_acc=0.85823, val_loss=1.89434, val_acc=0.69841, time=0.12899
Epoch:0020, train_loss=1.33805, train_acc=0.86936, val_loss=1.89377, val_acc=0.69841, time=0.12800
Epoch:0021, train_loss=1.32639, train_acc=0.88284, val_loss=1.89299, val_acc=0.71429, time=0.12999
Epoch:0022, train_loss=1.31430, train_acc=0.89397, val_loss=1.89211, val_acc=0.71429, time=0.12103
Epoch:0023, train_loss=1.30253, train_acc=0.90568, val_loss=1.89125, val_acc=0.73016, time=0.11100
Epoch:0024, train_loss=1.29163, train_acc=0.91506, val_loss=1.89050, val_acc=0.73545, time=0.12299
Epoch:0025, train_loss=1.28183, train_acc=0.92091, val_loss=1.88989, val_acc=0.76720, time=0.12600
Epoch:0026, train_loss=1.27315, train_acc=0.92443, val_loss=1.88944, val_acc=0.76190, time=0.13200
Epoch:0027, train_loss=1.26546, train_acc=0.93146, val_loss=1.88914, val_acc=0.76190, time=0.12399
Epoch:0028, train_loss=1.25859, train_acc=0.93439, val_loss=1.88897, val_acc=0.75661, time=0.12100
Epoch:0029, train_loss=1.25230, train_acc=0.93556, val_loss=1.88890, val_acc=0.75132, time=0.12500
Epoch:0030, train_loss=1.24638, train_acc=0.93732, val_loss=1.88889, val_acc=0.75661, time=0.12800
Epoch:0031, train_loss=1.24067, train_acc=0.94025, val_loss=1.88894, val_acc=0.75661, time=0.12902
Epoch:0032, train_loss=1.23512, train_acc=0.94435, val_loss=1.88903, val_acc=0.75132, time=0.12200
Epoch:0033, train_loss=1.22976, train_acc=0.94962, val_loss=1.88917, val_acc=0.74603, time=0.09701
Epoch:0034, train_loss=1.22466, train_acc=0.95313, val_loss=1.88934, val_acc=0.74603, time=0.08500
Early stopping...

Optimization Finished!

Test set results: loss= 1.72728, accuracy= 0.72167, time= 0.02302

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7754    0.7643    0.7698       140
           1     0.6875    0.4889    0.5714        45
           2     0.7323    0.7686    0.7500       121
           3     0.6923    0.6848    0.6885        92
           4     0.6768    0.5776    0.6233       116
           5     0.7818    0.6615    0.7167        65
           6     0.7074    0.8197    0.7594       233

    accuracy                         0.7217       812
   macro avg     0.7219    0.6808    0.6970       812
weighted avg     0.7216    0.7217    0.7185       812


Macro average Test Precision, Recall and F1-Score...
(0.7219209631012096, 0.6807742015568526, 0.6970147364049671, None)

Micro average Test Precision, Recall and F1-Score...
(0.7216748768472906, 0.7216748768472906, 0.7216748768472906, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
