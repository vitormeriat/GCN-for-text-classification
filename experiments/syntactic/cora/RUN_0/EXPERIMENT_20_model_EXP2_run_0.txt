
==========: 298145129678200
Epoch:0001, train_loss=2.07705, train_acc=0.11248, val_loss=1.99850, val_acc=0.34392, time=0.13000
Epoch:0002, train_loss=2.56957, train_acc=0.31107, val_loss=1.94198, val_acc=0.42328, time=0.11900
Epoch:0003, train_loss=1.94337, train_acc=0.47335, val_loss=1.94228, val_acc=0.47090, time=0.12700
Epoch:0004, train_loss=1.87478, train_acc=0.54130, val_loss=1.93353, val_acc=0.52381, time=0.12100
Epoch:0005, train_loss=1.75723, train_acc=0.57411, val_loss=1.91539, val_acc=0.62434, time=0.12201
Epoch:0006, train_loss=1.57055, train_acc=0.71002, val_loss=1.90202, val_acc=0.70370, time=0.13600
Epoch:0007, train_loss=1.43556, train_acc=0.81019, val_loss=1.89806, val_acc=0.68254, time=0.12701
Epoch:0008, train_loss=1.38649, train_acc=0.80961, val_loss=1.89770, val_acc=0.66138, time=0.12601
Epoch:0009, train_loss=1.37027, train_acc=0.79262, val_loss=1.89728, val_acc=0.67196, time=0.12500
Epoch:0010, train_loss=1.35346, train_acc=0.80141, val_loss=1.89643, val_acc=0.69841, time=0.10801
Epoch:0011, train_loss=1.33200, train_acc=0.83656, val_loss=1.89581, val_acc=0.71429, time=0.11300
Epoch:0012, train_loss=1.31128, train_acc=0.87053, val_loss=1.89571, val_acc=0.71429, time=0.13501
Epoch:0013, train_loss=1.29439, train_acc=0.89221, val_loss=1.89584, val_acc=0.70899, time=0.12800
Epoch:0014, train_loss=1.28056, train_acc=0.89924, val_loss=1.89583, val_acc=0.69841, time=0.12400
Epoch:0015, train_loss=1.26814, train_acc=0.91388, val_loss=1.89555, val_acc=0.71958, time=0.12399
Epoch:0016, train_loss=1.25631, train_acc=0.92209, val_loss=1.89512, val_acc=0.74074, time=0.11001
Epoch:0017, train_loss=1.24500, train_acc=0.92501, val_loss=1.89468, val_acc=0.74074, time=0.11301
Epoch:0018, train_loss=1.23412, train_acc=0.92912, val_loss=1.89432, val_acc=0.73545, time=0.12600
Epoch:0019, train_loss=1.22336, train_acc=0.94435, val_loss=1.89411, val_acc=0.73545, time=0.12499
Epoch:0020, train_loss=1.21286, train_acc=0.95079, val_loss=1.89416, val_acc=0.74603, time=0.12800
Epoch:0021, train_loss=1.20330, train_acc=0.95841, val_loss=1.89451, val_acc=0.73545, time=0.13101
Early stopping...

Optimization Finished!

Test set results: loss= 1.74986, accuracy= 0.71305, time= 0.03400

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8189    0.7429    0.7790       140
           1     0.4800    0.5333    0.5053        45
           2     0.7377    0.7438    0.7407       121
           3     0.7253    0.7174    0.7213        92
           4     0.6016    0.6638    0.6311       116
           5     0.7667    0.7077    0.7360        65
           6     0.7350    0.7382    0.7366       233

    accuracy                         0.7131       812
   macro avg     0.6950    0.6924    0.6929       812
weighted avg     0.7181    0.7131    0.7149       812


Macro average Test Precision, Recall and F1-Score...
(0.6950213118303129, 0.6924380384948787, 0.6928722620875494, None)

Micro average Test Precision, Recall and F1-Score...
(0.7130541871921182, 0.7130541871921182, 0.7130541871921183, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
