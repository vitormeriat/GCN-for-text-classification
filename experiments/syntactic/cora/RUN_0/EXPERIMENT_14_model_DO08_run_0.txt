
==========: 298084476844700
Epoch:0001, train_loss=2.23719, train_acc=0.08260, val_loss=1.94444, val_acc=0.20106, time=0.12100
Epoch:0002, train_loss=1.93235, train_acc=0.23667, val_loss=1.93342, val_acc=0.37037, time=0.12699
Epoch:0003, train_loss=1.84041, train_acc=0.36028, val_loss=1.92952, val_acc=0.40741, time=0.11500
Epoch:0004, train_loss=1.80129, train_acc=0.39074, val_loss=1.92498, val_acc=0.43915, time=0.12701
Epoch:0005, train_loss=1.75193, train_acc=0.47920, val_loss=1.92025, val_acc=0.53968, time=0.12399
Epoch:0006, train_loss=1.70164, train_acc=0.58992, val_loss=1.91610, val_acc=0.62963, time=0.12800
Epoch:0007, train_loss=1.65780, train_acc=0.68307, val_loss=1.91229, val_acc=0.66667, time=0.12800
Epoch:0008, train_loss=1.61712, train_acc=0.72525, val_loss=1.90875, val_acc=0.68783, time=0.13100
Epoch:0009, train_loss=1.57771, train_acc=0.74634, val_loss=1.90558, val_acc=0.70370, time=0.13300
Epoch:0010, train_loss=1.53990, train_acc=0.76098, val_loss=1.90282, val_acc=0.68783, time=0.11500
Epoch:0011, train_loss=1.50415, train_acc=0.76684, val_loss=1.90047, val_acc=0.68254, time=0.12700
Epoch:0012, train_loss=1.47078, train_acc=0.77856, val_loss=1.89846, val_acc=0.67725, time=0.13201
Epoch:0013, train_loss=1.43987, train_acc=0.78793, val_loss=1.89674, val_acc=0.69312, time=0.14999
Epoch:0014, train_loss=1.41150, train_acc=0.81254, val_loss=1.89530, val_acc=0.70370, time=0.11399
Epoch:0015, train_loss=1.38617, train_acc=0.82953, val_loss=1.89419, val_acc=0.71429, time=0.12901
Epoch:0016, train_loss=1.36445, train_acc=0.85296, val_loss=1.89344, val_acc=0.73016, time=0.13099
Epoch:0017, train_loss=1.34663, train_acc=0.87112, val_loss=1.89304, val_acc=0.73016, time=0.12400
Epoch:0018, train_loss=1.33251, train_acc=0.88752, val_loss=1.89291, val_acc=0.74074, time=0.12300
Epoch:0019, train_loss=1.32140, train_acc=0.89572, val_loss=1.89293, val_acc=0.74603, time=0.12301
Epoch:0020, train_loss=1.31234, train_acc=0.90217, val_loss=1.89297, val_acc=0.74603, time=0.11899
Epoch:0021, train_loss=1.30417, train_acc=0.91271, val_loss=1.89290, val_acc=0.73545, time=0.12702
Epoch:0022, train_loss=1.29585, train_acc=0.91506, val_loss=1.89267, val_acc=0.74074, time=0.12600
Epoch:0023, train_loss=1.28682, train_acc=0.92033, val_loss=1.89230, val_acc=0.74074, time=0.11499
Epoch:0024, train_loss=1.27704, train_acc=0.92384, val_loss=1.89183, val_acc=0.74603, time=0.11601
Epoch:0025, train_loss=1.26691, train_acc=0.92794, val_loss=1.89137, val_acc=0.75132, time=0.10601
Epoch:0026, train_loss=1.25701, train_acc=0.93204, val_loss=1.89099, val_acc=0.74603, time=0.12201
Epoch:0027, train_loss=1.24787, train_acc=0.93907, val_loss=1.89074, val_acc=0.74603, time=0.13299
Epoch:0028, train_loss=1.23984, train_acc=0.94318, val_loss=1.89063, val_acc=0.74603, time=0.11402
Epoch:0029, train_loss=1.23298, train_acc=0.94786, val_loss=1.89065, val_acc=0.74603, time=0.13700
Epoch:0030, train_loss=1.22716, train_acc=0.95372, val_loss=1.89075, val_acc=0.74603, time=0.13002
Epoch:0031, train_loss=1.22212, train_acc=0.95665, val_loss=1.89091, val_acc=0.74603, time=0.10699
Epoch:0032, train_loss=1.21755, train_acc=0.95841, val_loss=1.89108, val_acc=0.74603, time=0.08901
Epoch:0033, train_loss=1.21319, train_acc=0.96134, val_loss=1.89124, val_acc=0.74603, time=0.12902
Early stopping...

Optimization Finished!

Test set results: loss= 1.73290, accuracy= 0.70936, time= 0.04101

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8030    0.7571    0.7794       140
           1     0.6250    0.5556    0.5882        45
           2     0.6977    0.7438    0.7200       121
           3     0.7158    0.7391    0.7273        92
           4     0.6283    0.6121    0.6201       116
           5     0.8462    0.5077    0.6346        65
           6     0.6932    0.7854    0.7364       233

    accuracy                         0.7094       812
   macro avg     0.7156    0.6715    0.6866       812
weighted avg     0.7146    0.7094    0.7074       812


Macro average Test Precision, Recall and F1-Score...
(0.7155926348179465, 0.6715427855578601, 0.6865772882889402, None)

Micro average Test Precision, Recall and F1-Score...
(0.7093596059113301, 0.7093596059113301, 0.7093596059113301, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
