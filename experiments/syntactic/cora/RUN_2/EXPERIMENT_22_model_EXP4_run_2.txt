
==========: 299882257195300
Epoch:0001, train_loss=2.12626, train_acc=0.13650, val_loss=1.94079, val_acc=0.24339, time=0.12401
Epoch:0002, train_loss=1.90304, train_acc=0.28881, val_loss=1.93459, val_acc=0.34392, time=0.11200
Epoch:0003, train_loss=1.85832, train_acc=0.34271, val_loss=1.92929, val_acc=0.38624, time=0.11401
Epoch:0004, train_loss=1.79783, train_acc=0.39309, val_loss=1.92273, val_acc=0.45503, time=0.12401
Epoch:0005, train_loss=1.71873, train_acc=0.49209, val_loss=1.91708, val_acc=0.56614, time=0.12500
Epoch:0006, train_loss=1.64835, train_acc=0.62156, val_loss=1.91246, val_acc=0.61376, time=0.13101
Epoch:0007, train_loss=1.59018, train_acc=0.71002, val_loss=1.90878, val_acc=0.67196, time=0.10401
Epoch:0008, train_loss=1.54328, train_acc=0.76801, val_loss=1.90590, val_acc=0.68783, time=0.11800
Epoch:0009, train_loss=1.50565, train_acc=0.79672, val_loss=1.90357, val_acc=0.66667, time=0.13102
Epoch:0010, train_loss=1.47456, train_acc=0.80492, val_loss=1.90151, val_acc=0.67196, time=0.11900
Epoch:0011, train_loss=1.44739, train_acc=0.80844, val_loss=1.89956, val_acc=0.68254, time=0.11100
Epoch:0012, train_loss=1.42283, train_acc=0.81898, val_loss=1.89774, val_acc=0.69312, time=0.12200
Epoch:0013, train_loss=1.40044, train_acc=0.83597, val_loss=1.89606, val_acc=0.69312, time=0.12501
Epoch:0014, train_loss=1.37984, train_acc=0.84710, val_loss=1.89452, val_acc=0.69312, time=0.12800
Epoch:0015, train_loss=1.36074, train_acc=0.85999, val_loss=1.89318, val_acc=0.70899, time=0.12701
Epoch:0016, train_loss=1.34333, train_acc=0.86760, val_loss=1.89211, val_acc=0.73545, time=0.12501
Epoch:0017, train_loss=1.32808, train_acc=0.88225, val_loss=1.89138, val_acc=0.74074, time=0.12800
Epoch:0018, train_loss=1.31517, train_acc=0.88811, val_loss=1.89096, val_acc=0.76190, time=0.11701
Epoch:0019, train_loss=1.30421, train_acc=0.89221, val_loss=1.89076, val_acc=0.76190, time=0.12999
Epoch:0020, train_loss=1.29437, train_acc=0.89572, val_loss=1.89067, val_acc=0.76190, time=0.12800
Epoch:0021, train_loss=1.28486, train_acc=0.89982, val_loss=1.89060, val_acc=0.76720, time=0.13101
Epoch:0022, train_loss=1.27531, train_acc=0.90803, val_loss=1.89053, val_acc=0.76720, time=0.12900
Epoch:0023, train_loss=1.26589, train_acc=0.91857, val_loss=1.89047, val_acc=0.76720, time=0.12799
Epoch:0024, train_loss=1.25701, train_acc=0.92912, val_loss=1.89044, val_acc=0.75132, time=0.11501
Epoch:0025, train_loss=1.24898, train_acc=0.93556, val_loss=1.89044, val_acc=0.72487, time=0.11901
Epoch:0026, train_loss=1.24181, train_acc=0.93673, val_loss=1.89043, val_acc=0.72487, time=0.12500
Epoch:0027, train_loss=1.23532, train_acc=0.93966, val_loss=1.89040, val_acc=0.73545, time=0.12400
Epoch:0028, train_loss=1.22927, train_acc=0.94728, val_loss=1.89033, val_acc=0.73545, time=0.11201
Epoch:0029, train_loss=1.22354, train_acc=0.95196, val_loss=1.89025, val_acc=0.74074, time=0.11701
Epoch:0030, train_loss=1.21812, train_acc=0.95606, val_loss=1.89020, val_acc=0.74603, time=0.11999
Epoch:0031, train_loss=1.21303, train_acc=0.95958, val_loss=1.89020, val_acc=0.74603, time=0.13000
Epoch:0032, train_loss=1.20826, train_acc=0.96485, val_loss=1.89027, val_acc=0.75661, time=0.11600
Epoch:0033, train_loss=1.20372, train_acc=0.96778, val_loss=1.89039, val_acc=0.75661, time=0.12001
Early stopping...

Optimization Finished!

Test set results: loss= 1.72622, accuracy= 0.72167, time= 0.03701

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8295    0.7643    0.7955       140
           1     0.5778    0.5778    0.5778        45
           2     0.7395    0.7273    0.7333       121
           3     0.6800    0.7391    0.7083        92
           4     0.6167    0.6379    0.6271       116
           5     0.8200    0.6308    0.7130        65
           6     0.7309    0.7811    0.7552       233

    accuracy                         0.7217       812
   macro avg     0.7135    0.6940    0.7015       812
weighted avg     0.7257    0.7217    0.7221       812


Macro average Test Precision, Recall and F1-Score...
(0.7134744716977106, 0.6940403998855921, 0.701476046031723, None)

Micro average Test Precision, Recall and F1-Score...
(0.7216748768472906, 0.7216748768472906, 0.7216748768472906, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
