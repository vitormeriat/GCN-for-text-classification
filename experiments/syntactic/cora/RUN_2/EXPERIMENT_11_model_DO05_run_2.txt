
==========: 299774315349900
Epoch:0001, train_loss=2.21697, train_acc=0.10955, val_loss=1.94683, val_acc=0.19048, time=0.13200
Epoch:0002, train_loss=1.93009, train_acc=0.24370, val_loss=1.93421, val_acc=0.36508, time=0.12901
Epoch:0003, train_loss=1.84677, train_acc=0.32572, val_loss=1.93103, val_acc=0.40741, time=0.12600
Epoch:0004, train_loss=1.82095, train_acc=0.37786, val_loss=1.92617, val_acc=0.44974, time=0.10901
Epoch:0005, train_loss=1.76405, train_acc=0.44230, val_loss=1.92034, val_acc=0.49735, time=0.12302
Epoch:0006, train_loss=1.69285, train_acc=0.54013, val_loss=1.91516, val_acc=0.56614, time=0.10200
Epoch:0007, train_loss=1.62693, train_acc=0.61511, val_loss=1.91084, val_acc=0.58201, time=0.10402
Epoch:0008, train_loss=1.57089, train_acc=0.67663, val_loss=1.90705, val_acc=0.65079, time=0.12000
Epoch:0009, train_loss=1.52276, train_acc=0.74692, val_loss=1.90401, val_acc=0.70370, time=0.12801
Epoch:0010, train_loss=1.48406, train_acc=0.79379, val_loss=1.90186, val_acc=0.70899, time=0.13199
Epoch:0011, train_loss=1.45584, train_acc=0.82484, val_loss=1.90035, val_acc=0.74074, time=0.10501
Epoch:0012, train_loss=1.43518, train_acc=0.83773, val_loss=1.89905, val_acc=0.75132, time=0.13100
Epoch:0013, train_loss=1.41758, train_acc=0.84124, val_loss=1.89762, val_acc=0.74603, time=0.13200
Epoch:0014, train_loss=1.39973, train_acc=0.84300, val_loss=1.89601, val_acc=0.75661, time=0.12903
Epoch:0015, train_loss=1.38058, train_acc=0.85296, val_loss=1.89433, val_acc=0.75661, time=0.11500
Epoch:0016, train_loss=1.36099, train_acc=0.86292, val_loss=1.89282, val_acc=0.76190, time=0.11601
Epoch:0017, train_loss=1.34255, train_acc=0.87288, val_loss=1.89165, val_acc=0.77778, time=0.12000
Epoch:0018, train_loss=1.32656, train_acc=0.88342, val_loss=1.89089, val_acc=0.77778, time=0.12801
Epoch:0019, train_loss=1.31345, train_acc=0.89045, val_loss=1.89051, val_acc=0.77249, time=0.12201
Epoch:0020, train_loss=1.30290, train_acc=0.89397, val_loss=1.89042, val_acc=0.76190, time=0.10200
Epoch:0021, train_loss=1.29405, train_acc=0.89924, val_loss=1.89046, val_acc=0.75132, time=0.12300
Epoch:0022, train_loss=1.28598, train_acc=0.90568, val_loss=1.89049, val_acc=0.74603, time=0.13100
Epoch:0023, train_loss=1.27796, train_acc=0.90744, val_loss=1.89044, val_acc=0.74074, time=0.12500
Epoch:0024, train_loss=1.26966, train_acc=0.91154, val_loss=1.89028, val_acc=0.74074, time=0.12901
Epoch:0025, train_loss=1.26115, train_acc=0.91798, val_loss=1.89004, val_acc=0.75132, time=0.12598
Epoch:0026, train_loss=1.25278, train_acc=0.92853, val_loss=1.88978, val_acc=0.74603, time=0.13101
Epoch:0027, train_loss=1.24490, train_acc=0.93615, val_loss=1.88955, val_acc=0.74074, time=0.12401
Epoch:0028, train_loss=1.23774, train_acc=0.94259, val_loss=1.88938, val_acc=0.74603, time=0.12602
Epoch:0029, train_loss=1.23140, train_acc=0.94552, val_loss=1.88929, val_acc=0.75132, time=0.12801
Epoch:0030, train_loss=1.22581, train_acc=0.95138, val_loss=1.88930, val_acc=0.76190, time=0.14201
Epoch:0031, train_loss=1.22079, train_acc=0.95723, val_loss=1.88938, val_acc=0.75661, time=0.12500
Epoch:0032, train_loss=1.21616, train_acc=0.96075, val_loss=1.88953, val_acc=0.75661, time=0.11602
Epoch:0033, train_loss=1.21172, train_acc=0.96485, val_loss=1.88971, val_acc=0.76190, time=0.09801
Early stopping...

Optimization Finished!

Test set results: loss= 1.72984, accuracy= 0.71429, time= 0.03600

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8077    0.7500    0.7778       140
           1     0.6000    0.5333    0.5647        45
           2     0.7120    0.7355    0.7236       121
           3     0.6569    0.7283    0.6907        92
           4     0.6161    0.5948    0.6053       116
           5     0.8000    0.6769    0.7333        65
           6     0.7339    0.7811    0.7568       233

    accuracy                         0.7143       812
   macro avg     0.7038    0.6857    0.6932       812
weighted avg     0.7157    0.7143    0.7138       812


Macro average Test Precision, Recall and F1-Score...
(0.7037853498719586, 0.6857139908484993, 0.6931622561960628, None)

Micro average Test Precision, Recall and F1-Score...
(0.7142857142857143, 0.7142857142857143, 0.7142857142857143, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
