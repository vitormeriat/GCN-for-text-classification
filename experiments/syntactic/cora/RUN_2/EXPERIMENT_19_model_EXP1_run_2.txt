
==========: 299854341813100
Epoch:0001, train_loss=1.98226, train_acc=0.17985, val_loss=1.93666, val_acc=0.31217, time=0.12802
Epoch:0002, train_loss=1.90301, train_acc=0.28647, val_loss=1.93177, val_acc=0.36508, time=0.11000
Epoch:0003, train_loss=1.85199, train_acc=0.33333, val_loss=1.92805, val_acc=0.39683, time=0.12801
Epoch:0004, train_loss=1.80594, train_acc=0.38254, val_loss=1.92458, val_acc=0.44974, time=0.13000
Epoch:0005, train_loss=1.76134, train_acc=0.43527, val_loss=1.92112, val_acc=0.54497, time=0.11702
Epoch:0006, train_loss=1.71854, train_acc=0.53134, val_loss=1.91759, val_acc=0.56085, time=0.12299
Epoch:0007, train_loss=1.67766, train_acc=0.61687, val_loss=1.91407, val_acc=0.63492, time=0.12900
Epoch:0008, train_loss=1.63912, train_acc=0.66550, val_loss=1.91072, val_acc=0.66138, time=0.12601
Epoch:0009, train_loss=1.60361, train_acc=0.71295, val_loss=1.90767, val_acc=0.71429, time=0.12999
Epoch:0010, train_loss=1.57159, train_acc=0.74517, val_loss=1.90501, val_acc=0.72487, time=0.12600
Epoch:0011, train_loss=1.54300, train_acc=0.76801, val_loss=1.90272, val_acc=0.73545, time=0.12601
Epoch:0012, train_loss=1.51724, train_acc=0.78149, val_loss=1.90076, val_acc=0.74074, time=0.12400
Epoch:0013, train_loss=1.49365, train_acc=0.79613, val_loss=1.89906, val_acc=0.75132, time=0.11500
Epoch:0014, train_loss=1.47169, train_acc=0.81429, val_loss=1.89757, val_acc=0.75661, time=0.11901
Epoch:0015, train_loss=1.45111, train_acc=0.82367, val_loss=1.89626, val_acc=0.75661, time=0.13000
Epoch:0016, train_loss=1.43190, train_acc=0.83773, val_loss=1.89511, val_acc=0.75661, time=0.12703
Epoch:0017, train_loss=1.41415, train_acc=0.84886, val_loss=1.89413, val_acc=0.76190, time=0.12399
Epoch:0018, train_loss=1.39791, train_acc=0.85823, val_loss=1.89328, val_acc=0.76720, time=0.12701
Epoch:0019, train_loss=1.38314, train_acc=0.86995, val_loss=1.89254, val_acc=0.76720, time=0.11901
Epoch:0020, train_loss=1.36969, train_acc=0.87756, val_loss=1.89188, val_acc=0.76190, time=0.13001
Epoch:0021, train_loss=1.35733, train_acc=0.88284, val_loss=1.89128, val_acc=0.76190, time=0.12802
Epoch:0022, train_loss=1.34580, train_acc=0.88987, val_loss=1.89070, val_acc=0.76720, time=0.12800
Epoch:0023, train_loss=1.33489, train_acc=0.89690, val_loss=1.89016, val_acc=0.76720, time=0.12701
Epoch:0024, train_loss=1.32454, train_acc=0.89982, val_loss=1.88965, val_acc=0.76720, time=0.13000
Epoch:0025, train_loss=1.31474, train_acc=0.90217, val_loss=1.88919, val_acc=0.76190, time=0.11401
Epoch:0026, train_loss=1.30552, train_acc=0.90803, val_loss=1.88878, val_acc=0.76720, time=0.12200
Epoch:0027, train_loss=1.29692, train_acc=0.91681, val_loss=1.88844, val_acc=0.76190, time=0.10898
Epoch:0028, train_loss=1.28888, train_acc=0.92150, val_loss=1.88815, val_acc=0.77249, time=0.12202
Epoch:0029, train_loss=1.28135, train_acc=0.92560, val_loss=1.88792, val_acc=0.77778, time=0.11400
Epoch:0030, train_loss=1.27424, train_acc=0.92912, val_loss=1.88775, val_acc=0.77249, time=0.13001
Epoch:0031, train_loss=1.26749, train_acc=0.93146, val_loss=1.88762, val_acc=0.77249, time=0.12199
Epoch:0032, train_loss=1.26104, train_acc=0.93497, val_loss=1.88753, val_acc=0.77249, time=0.10903
Epoch:0033, train_loss=1.25488, train_acc=0.94083, val_loss=1.88748, val_acc=0.77778, time=0.10899
Epoch:0034, train_loss=1.24902, train_acc=0.94200, val_loss=1.88746, val_acc=0.77778, time=0.11200
Epoch:0035, train_loss=1.24345, train_acc=0.94552, val_loss=1.88747, val_acc=0.77778, time=0.13101
Epoch:0036, train_loss=1.23818, train_acc=0.95372, val_loss=1.88751, val_acc=0.77778, time=0.11700
Epoch:0037, train_loss=1.23320, train_acc=0.95606, val_loss=1.88755, val_acc=0.77778, time=0.12301
Early stopping...

Optimization Finished!

Test set results: loss= 1.72327, accuracy= 0.73030, time= 0.03701

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8333    0.7500    0.7895       140
           1     0.6512    0.6222    0.6364        45
           2     0.7323    0.7686    0.7500       121
           3     0.7174    0.7174    0.7174        92
           4     0.6577    0.6293    0.6432       116
           5     0.8036    0.6923    0.7438        65
           6     0.7121    0.7854    0.7469       233

    accuracy                         0.7303       812
   macro avg     0.7296    0.7093    0.7182       812
weighted avg     0.7328    0.7303    0.7302       812


Macro average Test Precision, Recall and F1-Score...
(0.7296374622834554, 0.7093191900499327, 0.7181629799274509, None)

Micro average Test Precision, Recall and F1-Score...
(0.7302955665024631, 0.7302955665024631, 0.7302955665024631, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
