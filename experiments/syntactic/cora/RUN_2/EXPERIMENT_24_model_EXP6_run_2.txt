
==========: 299902235287800
Epoch:0001, train_loss=2.13883, train_acc=0.13181, val_loss=1.94290, val_acc=0.20635, time=0.13399
Epoch:0002, train_loss=1.92222, train_acc=0.24780, val_loss=1.93640, val_acc=0.32804, time=0.12999
Epoch:0003, train_loss=1.86512, train_acc=0.34681, val_loss=1.93330, val_acc=0.35450, time=0.12799
Epoch:0004, train_loss=1.82574, train_acc=0.38137, val_loss=1.92859, val_acc=0.43915, time=0.12801
Epoch:0005, train_loss=1.76747, train_acc=0.46632, val_loss=1.92287, val_acc=0.51852, time=0.12100
Epoch:0006, train_loss=1.70084, train_acc=0.58289, val_loss=1.91713, val_acc=0.61905, time=0.12900
Epoch:0007, train_loss=1.63613, train_acc=0.66374, val_loss=1.91190, val_acc=0.65079, time=0.13101
Epoch:0008, train_loss=1.57844, train_acc=0.72056, val_loss=1.90726, val_acc=0.66667, time=0.12401
Epoch:0009, train_loss=1.52819, train_acc=0.75923, val_loss=1.90330, val_acc=0.68783, time=0.10499
Epoch:0010, train_loss=1.48593, train_acc=0.79379, val_loss=1.90034, val_acc=0.73016, time=0.11900
Epoch:0011, train_loss=1.45376, train_acc=0.81957, val_loss=1.89849, val_acc=0.70899, time=0.13101
Epoch:0012, train_loss=1.43178, train_acc=0.82308, val_loss=1.89735, val_acc=0.70899, time=0.12101
Epoch:0013, train_loss=1.41548, train_acc=0.81605, val_loss=1.89625, val_acc=0.71958, time=0.13099
Epoch:0014, train_loss=1.39870, train_acc=0.82191, val_loss=1.89489, val_acc=0.73016, time=0.13202
Epoch:0015, train_loss=1.37867, train_acc=0.83480, val_loss=1.89341, val_acc=0.72487, time=0.12701
Epoch:0016, train_loss=1.35703, train_acc=0.85413, val_loss=1.89215, val_acc=0.73545, time=0.12998
Epoch:0017, train_loss=1.33703, train_acc=0.87639, val_loss=1.89132, val_acc=0.75132, time=0.12901
Epoch:0018, train_loss=1.32079, train_acc=0.88928, val_loss=1.89092, val_acc=0.75132, time=0.12800
Epoch:0019, train_loss=1.30848, train_acc=0.89924, val_loss=1.89080, val_acc=0.75132, time=0.12601
Epoch:0020, train_loss=1.29898, train_acc=0.90451, val_loss=1.89076, val_acc=0.75132, time=0.11698
Epoch:0021, train_loss=1.29077, train_acc=0.90861, val_loss=1.89066, val_acc=0.75132, time=0.12603
Epoch:0022, train_loss=1.28267, train_acc=0.91037, val_loss=1.89043, val_acc=0.75132, time=0.13101
Epoch:0023, train_loss=1.27411, train_acc=0.91271, val_loss=1.89008, val_acc=0.75132, time=0.12600
Epoch:0024, train_loss=1.26513, train_acc=0.92033, val_loss=1.88969, val_acc=0.75132, time=0.10602
Epoch:0025, train_loss=1.25610, train_acc=0.92736, val_loss=1.88930, val_acc=0.73545, time=0.12200
Epoch:0026, train_loss=1.24744, train_acc=0.93673, val_loss=1.88900, val_acc=0.74603, time=0.11700
Epoch:0027, train_loss=1.23950, train_acc=0.94025, val_loss=1.88880, val_acc=0.75661, time=0.12700
Epoch:0028, train_loss=1.23246, train_acc=0.94728, val_loss=1.88872, val_acc=0.76190, time=0.12702
Epoch:0029, train_loss=1.22637, train_acc=0.95021, val_loss=1.88875, val_acc=0.76720, time=0.12101
Epoch:0030, train_loss=1.22111, train_acc=0.95489, val_loss=1.88887, val_acc=0.76720, time=0.11601
Epoch:0031, train_loss=1.21641, train_acc=0.95665, val_loss=1.88902, val_acc=0.76720, time=0.12600
Epoch:0032, train_loss=1.21198, train_acc=0.95782, val_loss=1.88918, val_acc=0.77249, time=0.13099
Epoch:0033, train_loss=1.20756, train_acc=0.96426, val_loss=1.88930, val_acc=0.76720, time=0.13100
Early stopping...

Optimization Finished!

Test set results: loss= 1.72756, accuracy= 0.71305, time= 0.03600

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8120    0.7714    0.7912       140
           1     0.5610    0.5111    0.5349        45
           2     0.7087    0.7438    0.7258       121
           3     0.7356    0.6957    0.7151        92
           4     0.5620    0.6638    0.6087       116
           5     0.8478    0.6000    0.7027        65
           6     0.7386    0.7639    0.7511       233

    accuracy                         0.7131       812
   macro avg     0.7094    0.6785    0.6899       812
weighted avg     0.7201    0.7131    0.7140       812


Macro average Test Precision, Recall and F1-Score...
(0.7093940543385949, 0.6785335872353773, 0.6899194242616999, None)

Micro average Test Precision, Recall and F1-Score...
(0.7130541871921182, 0.7130541871921182, 0.7130541871921183, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
