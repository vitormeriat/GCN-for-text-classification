
==========: 299194228789200
Epoch:0001, train_loss=2.27397, train_acc=0.09900, val_loss=1.97611, val_acc=0.37566, time=0.13101
Epoch:0002, train_loss=2.27856, train_acc=0.33040, val_loss=1.97568, val_acc=0.31746, time=0.12300
Epoch:0003, train_loss=2.19849, train_acc=0.38079, val_loss=1.94221, val_acc=0.46561, time=0.12301
Epoch:0004, train_loss=1.93710, train_acc=0.50849, val_loss=1.92165, val_acc=0.65079, time=0.11600
Epoch:0005, train_loss=1.75280, train_acc=0.68131, val_loss=1.92219, val_acc=0.55026, time=0.12701
Epoch:0006, train_loss=1.72175, train_acc=0.63386, val_loss=1.91661, val_acc=0.59259, time=0.11999
Epoch:0007, train_loss=1.62842, train_acc=0.67370, val_loss=1.90987, val_acc=0.64550, time=0.13001
Epoch:0008, train_loss=1.52365, train_acc=0.74107, val_loss=1.90570, val_acc=0.66138, time=0.11899
Epoch:0009, train_loss=1.44777, train_acc=0.78969, val_loss=1.90372, val_acc=0.68254, time=0.12700
Epoch:0010, train_loss=1.40009, train_acc=0.81898, val_loss=1.90242, val_acc=0.70899, time=0.10701
Epoch:0011, train_loss=1.36654, train_acc=0.84066, val_loss=1.90108, val_acc=0.71429, time=0.11399
Epoch:0012, train_loss=1.33946, train_acc=0.85179, val_loss=1.89969, val_acc=0.72487, time=0.13501
Epoch:0013, train_loss=1.31625, train_acc=0.86819, val_loss=1.89829, val_acc=0.72487, time=0.12599
Epoch:0014, train_loss=1.29573, train_acc=0.88049, val_loss=1.89699, val_acc=0.75661, time=0.12200
Epoch:0015, train_loss=1.27776, train_acc=0.89690, val_loss=1.89594, val_acc=0.75132, time=0.12301
Epoch:0016, train_loss=1.26244, train_acc=0.91916, val_loss=1.89526, val_acc=0.74603, time=0.10901
Epoch:0017, train_loss=1.25006, train_acc=0.92970, val_loss=1.89502, val_acc=0.75132, time=0.12300
Epoch:0018, train_loss=1.24054, train_acc=0.94142, val_loss=1.89521, val_acc=0.75661, time=0.11601
Epoch:0019, train_loss=1.23345, train_acc=0.94610, val_loss=1.89572, val_acc=0.74074, time=0.11701
Epoch:0020, train_loss=1.22795, train_acc=0.95313, val_loss=1.89641, val_acc=0.71958, time=0.11900
Epoch:0021, train_loss=1.22307, train_acc=0.95606, val_loss=1.89711, val_acc=0.71429, time=0.11900
Early stopping...

Optimization Finished!

Test set results: loss= 1.76073, accuracy= 0.68966, time= 0.03600

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7483    0.7643    0.7562       140
           1     0.3614    0.6667    0.4688        45
           2     0.7073    0.7190    0.7131       121
           3     0.8082    0.6413    0.7152        92
           4     0.6854    0.5259    0.5951       116
           5     0.8409    0.5692    0.6789        65
           6     0.6965    0.7682    0.7306       233

    accuracy                         0.6897       812
   macro avg     0.6926    0.6649    0.6654       812
weighted avg     0.7111    0.6897    0.6927       812


Macro average Test Precision, Recall and F1-Score...
(0.6925763123497096, 0.6649425963978863, 0.6654047562170275, None)

Micro average Test Precision, Recall and F1-Score...
(0.6896551724137931, 0.6896551724137931, 0.6896551724137931, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
