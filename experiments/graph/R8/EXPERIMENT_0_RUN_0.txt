
==========: 42329566166900
Epoch:0001, train_loss=5.40847, train_acc=0.07231, val_loss=2.36068, val_acc=0.13869, time=2.61517
Epoch:0002, train_loss=4.45794, train_acc=0.14645, val_loss=2.30121, val_acc=0.19343, time=2.09107
Epoch:0003, train_loss=3.66445, train_acc=0.24833, val_loss=2.25517, val_acc=0.27372, time=2.03330
Epoch:0004, train_loss=3.06059, train_acc=0.37452, val_loss=2.22269, val_acc=0.34489, time=2.01305
Epoch:0005, train_loss=2.64597, train_acc=0.49585, val_loss=2.20151, val_acc=0.41788, time=1.97805
Epoch:0006, train_loss=2.36909, train_acc=0.58619, val_loss=2.18776, val_acc=0.45073, time=2.10003
Epoch:0007, train_loss=2.17121, train_acc=0.65465, val_loss=2.17827, val_acc=0.47445, time=2.13703
Epoch:0008, train_loss=2.01759, train_acc=0.70691, val_loss=2.17172, val_acc=0.48540, time=2.05604
Epoch:0009, train_loss=1.89480, train_acc=0.76079, val_loss=2.16740, val_acc=0.48905, time=2.09204
Epoch:0010, train_loss=1.79772, train_acc=0.79947, val_loss=2.16474, val_acc=0.48905, time=1.97704
Epoch:0011, train_loss=1.71978, train_acc=0.83208, val_loss=2.16330, val_acc=0.49635, time=2.09414
Epoch:0012, train_loss=1.65575, train_acc=0.86105, val_loss=2.16268, val_acc=0.50730, time=2.11803
Epoch:0013, train_loss=1.60283, train_acc=0.88536, val_loss=2.16259, val_acc=0.50365, time=2.09103
Epoch:0014, train_loss=1.55942, train_acc=0.90865, val_loss=2.16282, val_acc=0.49818, time=2.00203
Epoch:0015, train_loss=1.52467, train_acc=0.92911, val_loss=2.16328, val_acc=0.50182, time=1.95300
Epoch:0016, train_loss=1.49770, train_acc=0.94551, val_loss=2.16387, val_acc=0.50182, time=2.04002
Epoch:0017, train_loss=1.47741, train_acc=0.95848, val_loss=2.16450, val_acc=0.49818, time=2.11002
Epoch:0018, train_loss=1.46234, train_acc=0.96820, val_loss=2.16511, val_acc=0.49453, time=2.00103
Early stopping...

Optimization Finished!

Test set results: loss= 2.42438, accuracy= 0.44861, time= 0.64399

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.4548    0.5345    0.4914       696
           1     0.6590    0.5300    0.5875      1083
           2     0.0429    0.0800    0.0558        75
           3     0.4286    0.0744    0.1268       121
           4     0.0000    0.0000    0.0000        10
           5     0.0750    0.1111    0.0896        81
           6     0.0719    0.1379    0.0945        87
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4486      2189
   macro avg     0.2165    0.1835    0.1807      2189
weighted avg     0.5014    0.4486    0.4629      2189


Macro average Test Precision, Recall and F1-Score...
(0.21650815177212165, 0.18348928788926966, 0.18069265164494908, None)

Micro average Test Precision, Recall and F1-Score...
(0.44860666971219737, 0.44860666971219737, 0.4486066697121973, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
