
==================== Torch Seed: 48117941072200
Epoch:0001, train_loss=2.13176, train_acc=0.14763, val_loss=1.94453, val_acc=0.20635, time=0.06301
Epoch:0002, train_loss=1.90551, train_acc=0.24839, val_loss=1.94006, val_acc=0.30688, time=0.06300
Epoch:0003, train_loss=1.85344, train_acc=0.34446, val_loss=1.93740, val_acc=0.33862, time=0.06301
Epoch:0004, train_loss=1.81222, train_acc=0.38723, val_loss=1.93223, val_acc=0.38624, time=0.06400
Epoch:0005, train_loss=1.75017, train_acc=0.46221, val_loss=1.92609, val_acc=0.45503, time=0.06199
Epoch:0006, train_loss=1.68212, train_acc=0.56942, val_loss=1.92040, val_acc=0.50265, time=0.06300
Epoch:0007, train_loss=1.61954, train_acc=0.64441, val_loss=1.91532, val_acc=0.53968, time=0.05901
Epoch:0008, train_loss=1.56336, train_acc=0.71060, val_loss=1.91091, val_acc=0.60317, time=0.06400
Epoch:0009, train_loss=1.51385, train_acc=0.76391, val_loss=1.90757, val_acc=0.62434, time=0.06301
Epoch:0010, train_loss=1.47403, train_acc=0.80609, val_loss=1.90563, val_acc=0.64550, time=0.06101
Epoch:0011, train_loss=1.44606, train_acc=0.82777, val_loss=1.90479, val_acc=0.65608, time=0.06200
Epoch:0012, train_loss=1.42741, train_acc=0.82835, val_loss=1.90421, val_acc=0.65608, time=0.06400
Epoch:0013, train_loss=1.41162, train_acc=0.82953, val_loss=1.90314, val_acc=0.65079, time=0.05802
Epoch:0014, train_loss=1.39355, train_acc=0.83480, val_loss=1.90149, val_acc=0.66667, time=0.06400
Epoch:0015, train_loss=1.37264, train_acc=0.85413, val_loss=1.89966, val_acc=0.67725, time=0.06000
Epoch:0016, train_loss=1.35156, train_acc=0.86702, val_loss=1.89807, val_acc=0.68254, time=0.06200
Epoch:0017, train_loss=1.33310, train_acc=0.88166, val_loss=1.89697, val_acc=0.68254, time=0.06100
Epoch:0018, train_loss=1.31840, train_acc=0.89221, val_loss=1.89633, val_acc=0.68254, time=0.05800
Epoch:0019, train_loss=1.30695, train_acc=0.90217, val_loss=1.89603, val_acc=0.67196, time=0.06100
Epoch:0020, train_loss=1.29750, train_acc=0.90568, val_loss=1.89591, val_acc=0.67196, time=0.06101
Epoch:0021, train_loss=1.28885, train_acc=0.90920, val_loss=1.89584, val_acc=0.67725, time=0.06300
Epoch:0022, train_loss=1.28026, train_acc=0.91154, val_loss=1.89578, val_acc=0.68783, time=0.06199
Epoch:0023, train_loss=1.27150, train_acc=0.91330, val_loss=1.89570, val_acc=0.68783, time=0.06401
Epoch:0024, train_loss=1.26266, train_acc=0.91681, val_loss=1.89559, val_acc=0.69841, time=0.06499
Epoch:0025, train_loss=1.25395, train_acc=0.92501, val_loss=1.89545, val_acc=0.70899, time=0.06200
Epoch:0026, train_loss=1.24561, train_acc=0.93556, val_loss=1.89530, val_acc=0.70899, time=0.06499
Epoch:0027, train_loss=1.23783, train_acc=0.94025, val_loss=1.89515, val_acc=0.71429, time=0.06300
Epoch:0028, train_loss=1.23078, train_acc=0.94610, val_loss=1.89506, val_acc=0.71958, time=0.06300
Epoch:0029, train_loss=1.22455, train_acc=0.95196, val_loss=1.89503, val_acc=0.72487, time=0.06199
Epoch:0030, train_loss=1.21906, train_acc=0.95489, val_loss=1.89507, val_acc=0.72487, time=0.06301
Epoch:0031, train_loss=1.21415, train_acc=0.96192, val_loss=1.89516, val_acc=0.72487, time=0.06100
Epoch:0032, train_loss=1.20957, train_acc=0.96251, val_loss=1.89529, val_acc=0.73016, time=0.06200
Epoch:0033, train_loss=1.20513, train_acc=0.96602, val_loss=1.89543, val_acc=0.73016, time=0.06202
Early stopping...

Optimization Finished!

Test set results: loss= 1.73097, accuracy= 0.72044, time= 0.01799

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7531    0.7725    0.7627       233
           1     0.7484    0.8286    0.7864       140
           2     0.7131    0.7190    0.7160       121
           3     0.6121    0.6121    0.6121       116
           4     0.7885    0.6308    0.7009        65
           5     0.7283    0.7283    0.7283        92
           6     0.6389    0.5111    0.5679        45

    accuracy                         0.7204       812
   macro avg     0.7118    0.6860    0.6963       812
weighted avg     0.7199    0.7204    0.7187       812


Macro average Test Precision, Recall and F1-Score...
(0.7117600269456068, 0.6860460084054629, 0.6963268136562846, None)

Micro average Test Precision, Recall and F1-Score...
(0.7204433497536946, 0.7204433497536946, 0.7204433497536946, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
