
==================== Torch Seed: 1034523075400
Epoch:0001, train_loss=2.17139, train_acc=0.10428, val_loss=1.94450, val_acc=0.34392, time=0.04100
Epoch:0002, train_loss=1.94002, train_acc=0.28061, val_loss=1.93333, val_acc=0.37566, time=0.04000
Epoch:0003, train_loss=1.84265, train_acc=0.35208, val_loss=1.92665, val_acc=0.41270, time=0.06301
Epoch:0004, train_loss=1.77382, train_acc=0.42531, val_loss=1.92251, val_acc=0.47619, time=0.04500
Epoch:0005, train_loss=1.72418, train_acc=0.52197, val_loss=1.91921, val_acc=0.49206, time=0.06501
Epoch:0006, train_loss=1.68062, train_acc=0.57352, val_loss=1.91482, val_acc=0.55026, time=0.06500
Epoch:0007, train_loss=1.62667, train_acc=0.63796, val_loss=1.91041, val_acc=0.62434, time=0.05101
Epoch:0008, train_loss=1.57248, train_acc=0.71002, val_loss=1.90696, val_acc=0.67196, time=0.04799
Epoch:0009, train_loss=1.52697, train_acc=0.74985, val_loss=1.90445, val_acc=0.66667, time=0.06299
Epoch:0010, train_loss=1.49040, train_acc=0.76743, val_loss=1.90246, val_acc=0.68783, time=0.04701
Epoch:0011, train_loss=1.45947, train_acc=0.78735, val_loss=1.90063, val_acc=0.69841, time=0.06300
Epoch:0012, train_loss=1.43161, train_acc=0.80609, val_loss=1.89889, val_acc=0.70899, time=0.06400
Epoch:0013, train_loss=1.40640, train_acc=0.83187, val_loss=1.89737, val_acc=0.72487, time=0.06499
Epoch:0014, train_loss=1.38467, train_acc=0.85120, val_loss=1.89619, val_acc=0.73016, time=0.06398
Epoch:0015, train_loss=1.36712, train_acc=0.86643, val_loss=1.89536, val_acc=0.71958, time=0.06200
Epoch:0016, train_loss=1.35329, train_acc=0.87815, val_loss=1.89472, val_acc=0.71958, time=0.06300
Epoch:0017, train_loss=1.34163, train_acc=0.88576, val_loss=1.89408, val_acc=0.73016, time=0.05701
Epoch:0018, train_loss=1.33041, train_acc=0.88576, val_loss=1.89333, val_acc=0.73016, time=0.04200
Epoch:0019, train_loss=1.31854, train_acc=0.89104, val_loss=1.89247, val_acc=0.73545, time=0.05701
Epoch:0020, train_loss=1.30597, train_acc=0.89748, val_loss=1.89162, val_acc=0.73545, time=0.06299
Epoch:0021, train_loss=1.29341, train_acc=0.90451, val_loss=1.89090, val_acc=0.74603, time=0.06101
Epoch:0022, train_loss=1.28174, train_acc=0.91271, val_loss=1.89038, val_acc=0.74074, time=0.06100
Epoch:0023, train_loss=1.27150, train_acc=0.92091, val_loss=1.89006, val_acc=0.75132, time=0.06101
Epoch:0024, train_loss=1.26283, train_acc=0.92794, val_loss=1.88989, val_acc=0.76190, time=0.04500
Epoch:0025, train_loss=1.25545, train_acc=0.93087, val_loss=1.88981, val_acc=0.75661, time=0.05101
Epoch:0026, train_loss=1.24895, train_acc=0.93907, val_loss=1.88975, val_acc=0.75132, time=0.05000
Epoch:0027, train_loss=1.24289, train_acc=0.94200, val_loss=1.88969, val_acc=0.75132, time=0.05200
Epoch:0028, train_loss=1.23699, train_acc=0.94493, val_loss=1.88961, val_acc=0.75132, time=0.06400
Epoch:0029, train_loss=1.23109, train_acc=0.95196, val_loss=1.88952, val_acc=0.74603, time=0.04800
Epoch:0030, train_loss=1.22517, train_acc=0.95489, val_loss=1.88945, val_acc=0.74603, time=0.06400
Epoch:0031, train_loss=1.21929, train_acc=0.95782, val_loss=1.88940, val_acc=0.74603, time=0.04701
Epoch:0032, train_loss=1.21359, train_acc=0.96309, val_loss=1.88940, val_acc=0.74603, time=0.05900
Epoch:0033, train_loss=1.20825, train_acc=0.96602, val_loss=1.88946, val_acc=0.74603, time=0.06201
Epoch:0034, train_loss=1.20339, train_acc=0.96719, val_loss=1.88958, val_acc=0.74074, time=0.05200
Epoch:0035, train_loss=1.19907, train_acc=0.96778, val_loss=1.88973, val_acc=0.74603, time=0.04599
Early stopping...

Optimization Finished!

Test set results: loss= 1.73710, accuracy= 0.69828, time= 0.01101

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7500    0.7500    0.7500       140
           1     0.6813    0.6739    0.6776        92
           2     0.7038    0.7854    0.7424       233
           3     0.7479    0.7355    0.7417       121
           4     0.7885    0.6308    0.7009        65
           5     0.5981    0.5517    0.5740       116
           6     0.5349    0.5111    0.5227        45

    accuracy                         0.6983       812
   macro avg     0.6864    0.6626    0.6727       812
weighted avg     0.6981    0.6983    0.6967       812


Macro average Test Precision, Recall and F1-Score...
(0.6863628707631381, 0.6626374912420243, 0.6727469727402663, None)

Micro average Test Precision, Recall and F1-Score...
(0.6982758620689655, 0.6982758620689655, 0.6982758620689655, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
