
==================== Torch Seed: 48644975774600
Epoch:0001, train_loss=2.16879, train_acc=0.08244, val_loss=2.06018, val_acc=0.59307, time=0.85203
Epoch:0002, train_loss=1.91746, train_acc=0.57322, val_loss=2.04606, val_acc=0.67701, time=0.50599
Epoch:0003, train_loss=1.78123, train_acc=0.68402, val_loss=2.03787, val_acc=0.72993, time=0.74001
Epoch:0004, train_loss=1.69981, train_acc=0.73607, val_loss=2.03216, val_acc=0.77555, time=0.66501
Epoch:0005, train_loss=1.64168, train_acc=0.78347, val_loss=2.02783, val_acc=0.81204, time=0.58200
Epoch:0006, train_loss=1.59691, train_acc=0.83269, val_loss=2.02445, val_acc=0.84672, time=0.58401
Epoch:0007, train_loss=1.56195, train_acc=0.87523, val_loss=2.02182, val_acc=0.85766, time=0.67901
Epoch:0008, train_loss=1.53441, train_acc=0.90460, val_loss=2.01979, val_acc=0.88686, time=0.64500
Epoch:0009, train_loss=1.51284, train_acc=0.92850, val_loss=2.01827, val_acc=0.90511, time=0.62701
Epoch:0010, train_loss=1.49660, train_acc=0.94268, val_loss=2.01713, val_acc=0.91241, time=0.50800
Epoch:0011, train_loss=1.48474, train_acc=0.95281, val_loss=2.01624, val_acc=0.91423, time=0.69601
Epoch:0012, train_loss=1.47603, train_acc=0.95888, val_loss=2.01548, val_acc=0.91788, time=0.71902
Epoch:0013, train_loss=1.46938, train_acc=0.96172, val_loss=2.01481, val_acc=0.91971, time=0.70900
Epoch:0014, train_loss=1.46399, train_acc=0.96496, val_loss=2.01418, val_acc=0.92153, time=0.59902
Epoch:0015, train_loss=1.45927, train_acc=0.96658, val_loss=2.01359, val_acc=0.93066, time=0.54701
Epoch:0016, train_loss=1.45488, train_acc=0.96901, val_loss=2.01304, val_acc=0.94161, time=0.67200
Epoch:0017, train_loss=1.45071, train_acc=0.97104, val_loss=2.01255, val_acc=0.95073, time=0.61302
Epoch:0018, train_loss=1.44680, train_acc=0.97428, val_loss=2.01214, val_acc=0.95073, time=0.57799
Epoch:0019, train_loss=1.44326, train_acc=0.97711, val_loss=2.01183, val_acc=0.94891, time=0.57602
Epoch:0020, train_loss=1.44020, train_acc=0.97853, val_loss=2.01159, val_acc=0.94891, time=0.53000
Epoch:0021, train_loss=1.43762, train_acc=0.98055, val_loss=2.01142, val_acc=0.95073, time=0.59501
Epoch:0022, train_loss=1.43549, train_acc=0.98197, val_loss=2.01129, val_acc=0.95438, time=0.57901
Epoch:0023, train_loss=1.43369, train_acc=0.98299, val_loss=2.01118, val_acc=0.95255, time=0.69100
Epoch:0024, train_loss=1.43213, train_acc=0.98501, val_loss=2.01108, val_acc=0.95255, time=0.70301
Epoch:0025, train_loss=1.43075, train_acc=0.98663, val_loss=2.01099, val_acc=0.95438, time=0.65901
Epoch:0026, train_loss=1.42951, train_acc=0.98724, val_loss=2.01090, val_acc=0.95620, time=0.55999
Epoch:0027, train_loss=1.42839, train_acc=0.98785, val_loss=2.01082, val_acc=0.95620, time=0.55200
Epoch:0028, train_loss=1.42738, train_acc=0.98866, val_loss=2.01075, val_acc=0.95620, time=0.57901
Epoch:0029, train_loss=1.42648, train_acc=0.98906, val_loss=2.01068, val_acc=0.95620, time=0.60701
Epoch:0030, train_loss=1.42566, train_acc=0.98947, val_loss=2.01063, val_acc=0.95803, time=0.51800
Epoch:0031, train_loss=1.42491, train_acc=0.99028, val_loss=2.01058, val_acc=0.95803, time=0.54602
Epoch:0032, train_loss=1.42420, train_acc=0.99109, val_loss=2.01054, val_acc=0.95985, time=0.69500
Epoch:0033, train_loss=1.42353, train_acc=0.99170, val_loss=2.01050, val_acc=0.95985, time=0.64800
Epoch:0034, train_loss=1.42288, train_acc=0.99230, val_loss=2.01047, val_acc=0.95985, time=0.67001
Epoch:0035, train_loss=1.42228, train_acc=0.99291, val_loss=2.01045, val_acc=0.95985, time=0.62402
Epoch:0036, train_loss=1.42172, train_acc=0.99311, val_loss=2.01044, val_acc=0.95985, time=0.57901
Epoch:0037, train_loss=1.42120, train_acc=0.99392, val_loss=2.01043, val_acc=0.96350, time=0.65800
Epoch:0038, train_loss=1.42074, train_acc=0.99413, val_loss=2.01042, val_acc=0.96350, time=0.59401
Epoch:0039, train_loss=1.42032, train_acc=0.99413, val_loss=2.01042, val_acc=0.96533, time=0.66000
Epoch:0040, train_loss=1.41993, train_acc=0.99413, val_loss=2.01041, val_acc=0.96350, time=0.62302
Epoch:0041, train_loss=1.41956, train_acc=0.99494, val_loss=2.01040, val_acc=0.96350, time=0.53901
Epoch:0042, train_loss=1.41922, train_acc=0.99615, val_loss=2.01038, val_acc=0.96350, time=0.71802
Epoch:0043, train_loss=1.41890, train_acc=0.99615, val_loss=2.01037, val_acc=0.96533, time=0.69403
Epoch:0044, train_loss=1.41859, train_acc=0.99595, val_loss=2.01036, val_acc=0.96533, time=0.62499
Epoch:0045, train_loss=1.41831, train_acc=0.99635, val_loss=2.01034, val_acc=0.96533, time=0.57301
Epoch:0046, train_loss=1.41805, train_acc=0.99635, val_loss=2.01033, val_acc=0.96533, time=0.58099
Epoch:0047, train_loss=1.41782, train_acc=0.99676, val_loss=2.01033, val_acc=0.96350, time=0.62503
Epoch:0048, train_loss=1.41759, train_acc=0.99676, val_loss=2.01032, val_acc=0.96350, time=0.55902
Epoch:0049, train_loss=1.41739, train_acc=0.99737, val_loss=2.01032, val_acc=0.96350, time=0.71998
Epoch:0050, train_loss=1.41719, train_acc=0.99737, val_loss=2.01032, val_acc=0.96350, time=0.58802
Epoch:0051, train_loss=1.41700, train_acc=0.99737, val_loss=2.01033, val_acc=0.96350, time=0.72001
Epoch:0052, train_loss=1.41682, train_acc=0.99757, val_loss=2.01033, val_acc=0.96350, time=0.58601
Epoch:0053, train_loss=1.41664, train_acc=0.99777, val_loss=2.01034, val_acc=0.96350, time=0.55002
Early stopping...

Optimization Finished!

Test set results: loss= 1.80467, accuracy= 0.95569, time= 0.19901

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9674    0.9871    0.9771      1083
           1     0.9791    0.9425    0.9605       696
           2     0.8931    0.9669    0.9286       121
           3     0.9167    0.8148    0.8627        81
           4     0.8571    0.8966    0.8764        87
           5     0.9231    0.6667    0.7742        36
           6     0.8675    0.9600    0.9114        75
           7     0.9091    1.0000    0.9524        10

    accuracy                         0.9557      2189
   macro avg     0.9141    0.9043    0.9054      2189
weighted avg     0.9563    0.9557    0.9552      2189


Macro average Test Precision, Recall and F1-Score...
(0.9141377873224217, 0.9043221294417032, 0.9054130660615789, None)

Micro average Test Precision, Recall and F1-Score...
(0.9556875285518501, 0.9556875285518501, 0.9556875285518501, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
