
==========: 253387483391600
Epoch:0001, train_loss=2.23192, train_acc=0.11991, val_loss=2.07406, val_acc=0.44343, time=1.13301
Epoch:0002, train_loss=1.99617, train_acc=0.48572, val_loss=2.06783, val_acc=0.47993, time=1.24901
Epoch:0003, train_loss=1.91456, train_acc=0.51874, val_loss=2.06622, val_acc=0.46168, time=1.22000
Epoch:0004, train_loss=1.87866, train_acc=0.51387, val_loss=2.06923, val_acc=0.36861, time=1.19601
Epoch:0005, train_loss=1.88713, train_acc=0.44541, val_loss=2.07161, val_acc=0.37409, time=1.34101
Epoch:0006, train_loss=1.89001, train_acc=0.45189, val_loss=2.07140, val_acc=0.41058, time=1.31401
Epoch:0007, train_loss=1.86920, train_acc=0.51327, val_loss=2.07118, val_acc=0.44526, time=1.23101
Epoch:0008, train_loss=1.84930, train_acc=0.55823, val_loss=2.07126, val_acc=0.45438, time=1.20901
Epoch:0009, train_loss=1.83480, train_acc=0.56917, val_loss=2.07068, val_acc=0.45985, time=1.28202
Epoch:0010, train_loss=1.81743, train_acc=0.57099, val_loss=2.06963, val_acc=0.44891, time=1.22301
Epoch:0011, train_loss=1.79843, train_acc=0.58902, val_loss=2.06887, val_acc=0.43431, time=1.20199
Epoch:0012, train_loss=1.78387, train_acc=0.61252, val_loss=2.06858, val_acc=0.41058, time=1.19401
Epoch:0013, train_loss=1.77441, train_acc=0.63500, val_loss=2.06836, val_acc=0.41606, time=1.24302
Epoch:0014, train_loss=1.76548, train_acc=0.64310, val_loss=2.06798, val_acc=0.41788, time=1.34203
Epoch:0015, train_loss=1.75438, train_acc=0.65384, val_loss=2.06755, val_acc=0.40876, time=1.30299
Epoch:0016, train_loss=1.74223, train_acc=0.67004, val_loss=2.06736, val_acc=0.41241, time=1.23101
Epoch:0017, train_loss=1.73158, train_acc=0.66781, val_loss=2.06754, val_acc=0.41971, time=1.30702
Epoch:0018, train_loss=1.72377, train_acc=0.66073, val_loss=2.06800, val_acc=0.42153, time=1.35700
Epoch:0019, train_loss=1.71833, train_acc=0.65647, val_loss=2.06856, val_acc=0.41606, time=1.16201
Early stopping...

Optimization Finished!

Test set results: loss= 2.01987, accuracy= 0.45135, time= 0.35000

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3063    0.1193    0.1717       696
           1     0.4953    0.8329    0.6212      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0000    0.0000    0.0000       121
           4     0.0513    0.0267    0.0351        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.2500    0.0278    0.0500        36

    accuracy                         0.4513      2189
   macro avg     0.1379    0.1258    0.1097      2189
weighted avg     0.3483    0.4513    0.3639      2189


Macro average Test Precision, Recall and F1-Score...
(0.13786091863104666, 0.12582112135298926, 0.10974559795417849, None)

Micro average Test Precision, Recall and F1-Score...
(0.45134764732754684, 0.45134764732754684, 0.45134764732754684, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
