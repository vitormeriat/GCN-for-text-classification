
==========: 252215064382300
Epoch:0001, train_loss=2.20090, train_acc=0.07656, val_loss=2.09026, val_acc=0.08942, time=1.42301
Epoch:0002, train_loss=2.18390, train_acc=0.09115, val_loss=2.08860, val_acc=0.11861, time=1.26501
Epoch:0003, train_loss=2.16739, train_acc=0.11606, val_loss=2.08700, val_acc=0.14234, time=1.32101
Epoch:0004, train_loss=2.15141, train_acc=0.14867, val_loss=2.08546, val_acc=0.17336, time=1.22601
Epoch:0005, train_loss=2.13598, train_acc=0.17906, val_loss=2.08398, val_acc=0.20438, time=1.34801
Epoch:0006, train_loss=2.12110, train_acc=0.21065, val_loss=2.08256, val_acc=0.23540, time=1.26201
Epoch:0007, train_loss=2.10683, train_acc=0.24002, val_loss=2.08122, val_acc=0.25912, time=1.22900
Epoch:0008, train_loss=2.09317, train_acc=0.26636, val_loss=2.07994, val_acc=0.28285, time=1.24301
Epoch:0009, train_loss=2.08015, train_acc=0.29330, val_loss=2.07873, val_acc=0.30109, time=1.22200
Epoch:0010, train_loss=2.06776, train_acc=0.31902, val_loss=2.07759, val_acc=0.32117, time=1.20402
Epoch:0011, train_loss=2.05601, train_acc=0.34150, val_loss=2.07651, val_acc=0.33212, time=1.20700
Epoch:0012, train_loss=2.04487, train_acc=0.36014, val_loss=2.07551, val_acc=0.35401, time=1.14701
Epoch:0013, train_loss=2.03433, train_acc=0.37695, val_loss=2.07456, val_acc=0.36496, time=1.16701
Epoch:0014, train_loss=2.02439, train_acc=0.39437, val_loss=2.07368, val_acc=0.38321, time=1.21001
Epoch:0015, train_loss=2.01501, train_acc=0.40672, val_loss=2.07286, val_acc=0.38504, time=1.19501
Epoch:0016, train_loss=2.00617, train_acc=0.42232, val_loss=2.07210, val_acc=0.39051, time=1.25802
Epoch:0017, train_loss=1.99783, train_acc=0.43488, val_loss=2.07139, val_acc=0.40146, time=1.29998
Epoch:0018, train_loss=1.98998, train_acc=0.44136, val_loss=2.07073, val_acc=0.41058, time=1.22999
Epoch:0019, train_loss=1.98257, train_acc=0.45088, val_loss=2.07011, val_acc=0.41423, time=1.26201
Epoch:0020, train_loss=1.97558, train_acc=0.45858, val_loss=2.06954, val_acc=0.41788, time=1.24702
Epoch:0021, train_loss=1.96897, train_acc=0.46364, val_loss=2.06900, val_acc=0.42518, time=1.20302
Epoch:0022, train_loss=1.96272, train_acc=0.46992, val_loss=2.06851, val_acc=0.42883, time=1.15202
Epoch:0023, train_loss=1.95680, train_acc=0.47438, val_loss=2.06804, val_acc=0.43431, time=1.22901
Epoch:0024, train_loss=1.95117, train_acc=0.47600, val_loss=2.06761, val_acc=0.43431, time=1.29501
Epoch:0025, train_loss=1.94584, train_acc=0.47985, val_loss=2.06721, val_acc=0.43978, time=1.23800
Epoch:0026, train_loss=1.94077, train_acc=0.48349, val_loss=2.06684, val_acc=0.43978, time=1.23400
Epoch:0027, train_loss=1.93595, train_acc=0.48491, val_loss=2.06649, val_acc=0.44343, time=1.29701
Epoch:0028, train_loss=1.93136, train_acc=0.48775, val_loss=2.06616, val_acc=0.44343, time=1.25201
Epoch:0029, train_loss=1.92699, train_acc=0.49078, val_loss=2.06586, val_acc=0.44526, time=1.17501
Epoch:0030, train_loss=1.92283, train_acc=0.49281, val_loss=2.06558, val_acc=0.44161, time=1.20001
Epoch:0031, train_loss=1.91887, train_acc=0.49605, val_loss=2.06532, val_acc=0.43796, time=1.31701
Epoch:0032, train_loss=1.91510, train_acc=0.49727, val_loss=2.06508, val_acc=0.43796, time=1.28202
Epoch:0033, train_loss=1.91151, train_acc=0.49605, val_loss=2.06486, val_acc=0.43613, time=1.21100
Epoch:0034, train_loss=1.90809, train_acc=0.49787, val_loss=2.06466, val_acc=0.43796, time=1.22400
Epoch:0035, train_loss=1.90484, train_acc=0.49949, val_loss=2.06447, val_acc=0.43978, time=1.23701
Epoch:0036, train_loss=1.90175, train_acc=0.50030, val_loss=2.06431, val_acc=0.44161, time=1.23001
Epoch:0037, train_loss=1.89882, train_acc=0.50253, val_loss=2.06415, val_acc=0.44343, time=1.24901
Epoch:0038, train_loss=1.89605, train_acc=0.50395, val_loss=2.06402, val_acc=0.44343, time=1.24202
Epoch:0039, train_loss=1.89341, train_acc=0.50638, val_loss=2.06389, val_acc=0.44526, time=1.17201
Epoch:0040, train_loss=1.89091, train_acc=0.50658, val_loss=2.06378, val_acc=0.44161, time=1.23401
Epoch:0041, train_loss=1.88853, train_acc=0.50780, val_loss=2.06368, val_acc=0.44343, time=1.24503
Epoch:0042, train_loss=1.88626, train_acc=0.50901, val_loss=2.06359, val_acc=0.44343, time=1.26401
Epoch:0043, train_loss=1.88410, train_acc=0.50719, val_loss=2.06352, val_acc=0.44343, time=1.28003
Epoch:0044, train_loss=1.88204, train_acc=0.50800, val_loss=2.06345, val_acc=0.44161, time=1.26902
Epoch:0045, train_loss=1.88005, train_acc=0.50962, val_loss=2.06338, val_acc=0.43978, time=1.23002
Epoch:0046, train_loss=1.87815, train_acc=0.51063, val_loss=2.06333, val_acc=0.43796, time=1.22301
Epoch:0047, train_loss=1.87630, train_acc=0.51266, val_loss=2.06327, val_acc=0.43978, time=1.32202
Epoch:0048, train_loss=1.87452, train_acc=0.51306, val_loss=2.06323, val_acc=0.43796, time=1.22300
Epoch:0049, train_loss=1.87278, train_acc=0.51489, val_loss=2.06318, val_acc=0.43978, time=1.33002
Epoch:0050, train_loss=1.87110, train_acc=0.51712, val_loss=2.06314, val_acc=0.43796, time=1.27400
Epoch:0051, train_loss=1.86945, train_acc=0.51833, val_loss=2.06311, val_acc=0.43796, time=1.26502
Epoch:0052, train_loss=1.86783, train_acc=0.51955, val_loss=2.06307, val_acc=0.43796, time=1.39201
Epoch:0053, train_loss=1.86625, train_acc=0.52056, val_loss=2.06304, val_acc=0.43613, time=1.31201
Epoch:0054, train_loss=1.86470, train_acc=0.52238, val_loss=2.06301, val_acc=0.43613, time=1.23600
Epoch:0055, train_loss=1.86318, train_acc=0.52319, val_loss=2.06298, val_acc=0.43431, time=1.21201
Epoch:0056, train_loss=1.86168, train_acc=0.52481, val_loss=2.06295, val_acc=0.43613, time=1.24401
Epoch:0057, train_loss=1.86021, train_acc=0.52643, val_loss=2.06293, val_acc=0.43796, time=1.24499
Epoch:0058, train_loss=1.85877, train_acc=0.52724, val_loss=2.06291, val_acc=0.43978, time=1.33800
Epoch:0059, train_loss=1.85735, train_acc=0.52805, val_loss=2.06288, val_acc=0.44343, time=1.23501
Epoch:0060, train_loss=1.85596, train_acc=0.52886, val_loss=2.06286, val_acc=0.44343, time=1.22900
Epoch:0061, train_loss=1.85460, train_acc=0.52988, val_loss=2.06285, val_acc=0.44161, time=1.30601
Epoch:0062, train_loss=1.85325, train_acc=0.53109, val_loss=2.06283, val_acc=0.44161, time=1.36301
Epoch:0063, train_loss=1.85193, train_acc=0.53251, val_loss=2.06281, val_acc=0.44343, time=1.21401
Epoch:0064, train_loss=1.85063, train_acc=0.53413, val_loss=2.06279, val_acc=0.44526, time=1.31901
Epoch:0065, train_loss=1.84935, train_acc=0.53494, val_loss=2.06278, val_acc=0.44708, time=1.27700
Epoch:0066, train_loss=1.84809, train_acc=0.53737, val_loss=2.06277, val_acc=0.44708, time=1.29800
Epoch:0067, train_loss=1.84684, train_acc=0.53879, val_loss=2.06275, val_acc=0.45073, time=1.27101
Epoch:0068, train_loss=1.84561, train_acc=0.54041, val_loss=2.06274, val_acc=0.44891, time=1.28800
Epoch:0069, train_loss=1.84440, train_acc=0.54102, val_loss=2.06273, val_acc=0.44526, time=1.23900
Epoch:0070, train_loss=1.84320, train_acc=0.54183, val_loss=2.06271, val_acc=0.44526, time=1.32200
Epoch:0071, train_loss=1.84201, train_acc=0.54304, val_loss=2.06270, val_acc=0.44526, time=1.34498
Epoch:0072, train_loss=1.84083, train_acc=0.54426, val_loss=2.06269, val_acc=0.44343, time=1.19102
Epoch:0073, train_loss=1.83967, train_acc=0.54547, val_loss=2.06268, val_acc=0.44343, time=1.28100
Epoch:0074, train_loss=1.83852, train_acc=0.54608, val_loss=2.06267, val_acc=0.44343, time=1.27801
Epoch:0075, train_loss=1.83738, train_acc=0.54790, val_loss=2.06266, val_acc=0.44343, time=1.35001
Epoch:0076, train_loss=1.83625, train_acc=0.54952, val_loss=2.06265, val_acc=0.44343, time=1.38501
Epoch:0077, train_loss=1.83514, train_acc=0.55155, val_loss=2.06264, val_acc=0.44343, time=1.30100
Epoch:0078, train_loss=1.83403, train_acc=0.55216, val_loss=2.06263, val_acc=0.43978, time=1.28701
Epoch:0079, train_loss=1.83294, train_acc=0.55337, val_loss=2.06262, val_acc=0.43978, time=1.31300
Epoch:0080, train_loss=1.83185, train_acc=0.55479, val_loss=2.06261, val_acc=0.43796, time=1.24098
Epoch:0081, train_loss=1.83078, train_acc=0.55540, val_loss=2.06260, val_acc=0.43613, time=1.32301
Epoch:0082, train_loss=1.82971, train_acc=0.55763, val_loss=2.06260, val_acc=0.43431, time=1.31901
Epoch:0083, train_loss=1.82866, train_acc=0.55823, val_loss=2.06259, val_acc=0.43613, time=1.30800
Epoch:0084, train_loss=1.82761, train_acc=0.55904, val_loss=2.06258, val_acc=0.43613, time=1.37101
Epoch:0085, train_loss=1.82658, train_acc=0.56046, val_loss=2.06258, val_acc=0.43613, time=1.24601
Epoch:0086, train_loss=1.82555, train_acc=0.56127, val_loss=2.06257, val_acc=0.43613, time=1.36202
Epoch:0087, train_loss=1.82453, train_acc=0.56168, val_loss=2.06257, val_acc=0.43613, time=1.27700
Epoch:0088, train_loss=1.82352, train_acc=0.56249, val_loss=2.06256, val_acc=0.43613, time=1.19201
Epoch:0089, train_loss=1.82252, train_acc=0.56309, val_loss=2.06256, val_acc=0.43613, time=1.20801
Epoch:0090, train_loss=1.82153, train_acc=0.56411, val_loss=2.06255, val_acc=0.43613, time=1.28300
Epoch:0091, train_loss=1.82054, train_acc=0.56451, val_loss=2.06255, val_acc=0.43613, time=1.32102
Epoch:0092, train_loss=1.81956, train_acc=0.56573, val_loss=2.06255, val_acc=0.43613, time=1.16203
Epoch:0093, train_loss=1.81859, train_acc=0.56674, val_loss=2.06254, val_acc=0.43613, time=1.30901
Epoch:0094, train_loss=1.81763, train_acc=0.56917, val_loss=2.06254, val_acc=0.43431, time=1.28900
Epoch:0095, train_loss=1.81667, train_acc=0.57099, val_loss=2.06254, val_acc=0.43248, time=1.15901
Epoch:0096, train_loss=1.81572, train_acc=0.57140, val_loss=2.06254, val_acc=0.42883, time=1.17100
Epoch:0097, train_loss=1.81477, train_acc=0.57221, val_loss=2.06254, val_acc=0.42701, time=1.27600
Epoch:0098, train_loss=1.81384, train_acc=0.57383, val_loss=2.06254, val_acc=0.42701, time=1.29201
Epoch:0099, train_loss=1.81291, train_acc=0.57444, val_loss=2.06254, val_acc=0.42701, time=1.25301
Epoch:0100, train_loss=1.81198, train_acc=0.57525, val_loss=2.06254, val_acc=0.42518, time=1.24901
Epoch:0101, train_loss=1.81107, train_acc=0.57646, val_loss=2.06254, val_acc=0.42336, time=1.31299
Early stopping...

Optimization Finished!

Test set results: loss= 1.99794, accuracy= 0.46916, time= 0.35902

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3529    0.1897    0.2467       696
           1     0.5017    0.8264    0.6243      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0000    0.0000    0.0000       121
           4     0.0000    0.0000    0.0000        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4692      2189
   macro avg     0.1068    0.1270    0.1089      2189
weighted avg     0.3604    0.4692    0.3873      2189


Macro average Test Precision, Recall and F1-Score...
(0.10682784885254551, 0.1270079122488617, 0.10888437228011955, None)

Micro average Test Precision, Recall and F1-Score...
(0.46916400182731843, 0.46916400182731843, 0.46916400182731843, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
