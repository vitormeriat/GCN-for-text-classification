
==========: 253231192719800
Epoch:0001, train_loss=2.27050, train_acc=0.12153, val_loss=2.07493, val_acc=0.36861, time=1.30002
Epoch:0002, train_loss=2.00866, train_acc=0.37330, val_loss=2.06587, val_acc=0.45438, time=1.20100
Epoch:0003, train_loss=1.90275, train_acc=0.49666, val_loss=2.06842, val_acc=0.47080, time=1.25700
Epoch:0004, train_loss=1.90484, train_acc=0.52279, val_loss=2.06946, val_acc=0.47445, time=1.20601
Epoch:0005, train_loss=1.89395, train_acc=0.53271, val_loss=2.06976, val_acc=0.45803, time=1.35202
Epoch:0006, train_loss=1.87754, train_acc=0.53818, val_loss=2.07118, val_acc=0.38139, time=1.25101
Epoch:0007, train_loss=1.87475, train_acc=0.51489, val_loss=2.07088, val_acc=0.37409, time=1.25301
Epoch:0008, train_loss=1.86021, train_acc=0.52623, val_loss=2.06918, val_acc=0.41241, time=1.20800
Epoch:0009, train_loss=1.83493, train_acc=0.58031, val_loss=2.06813, val_acc=0.44161, time=1.29902
Epoch:0010, train_loss=1.81616, train_acc=0.59672, val_loss=2.06804, val_acc=0.44343, time=1.13400
Epoch:0011, train_loss=1.80526, train_acc=0.59226, val_loss=2.06799, val_acc=0.43613, time=1.30001
Epoch:0012, train_loss=1.79348, train_acc=0.59793, val_loss=2.06765, val_acc=0.43431, time=1.19702
Epoch:0013, train_loss=1.77841, train_acc=0.60847, val_loss=2.06738, val_acc=0.42701, time=1.30601
Epoch:0014, train_loss=1.76384, train_acc=0.63095, val_loss=2.06752, val_acc=0.40328, time=1.29800
Epoch:0015, train_loss=1.75330, train_acc=0.64796, val_loss=2.06803, val_acc=0.39416, time=1.26100
Epoch:0016, train_loss=1.74636, train_acc=0.65748, val_loss=2.06857, val_acc=0.38686, time=1.31300
Epoch:0017, train_loss=1.74019, train_acc=0.66397, val_loss=2.06897, val_acc=0.38504, time=1.33302
Early stopping...

Optimization Finished!

Test set results: loss= 2.01169, accuracy= 0.42439, time= 0.44699

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3322    0.2816    0.3048       696
           1     0.4838    0.6750    0.5636      1083
           2     0.0278    0.0115    0.0163        87
           3     0.0000    0.0000    0.0000       121
           4     0.0625    0.0133    0.0220        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4244      2189
   macro avg     0.1133    0.1227    0.1133      2189
weighted avg     0.3482    0.4244    0.3772      2189


Macro average Test Precision, Recall and F1-Score...
(0.11328334250960627, 0.12267671219791765, 0.1133334577929079, None)

Micro average Test Precision, Recall and F1-Score...
(0.42439470077661035, 0.42439470077661035, 0.4243947007766103, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
