
==========: 260122006803200
Epoch:0001, train_loss=2.12751, train_acc=0.10188, val_loss=2.06605, val_acc=0.42518, time=1.35701
Epoch:0002, train_loss=1.92494, train_acc=0.48045, val_loss=2.06394, val_acc=0.44891, time=1.31500
Epoch:0003, train_loss=1.87812, train_acc=0.51631, val_loss=2.06648, val_acc=0.44891, time=1.22401
Epoch:0004, train_loss=1.87335, train_acc=0.52927, val_loss=2.06890, val_acc=0.43431, time=1.32002
Epoch:0005, train_loss=1.87017, train_acc=0.54183, val_loss=2.06996, val_acc=0.43613, time=1.32000
Epoch:0006, train_loss=1.85814, train_acc=0.56289, val_loss=2.07005, val_acc=0.44708, time=1.34902
Epoch:0007, train_loss=1.84053, train_acc=0.57889, val_loss=2.06978, val_acc=0.45255, time=1.23700
Epoch:0008, train_loss=1.82210, train_acc=0.59165, val_loss=2.06962, val_acc=0.45620, time=1.36601
Epoch:0009, train_loss=1.80684, train_acc=0.60583, val_loss=2.06961, val_acc=0.43613, time=1.29201
Epoch:0010, train_loss=1.79469, train_acc=0.62123, val_loss=2.06938, val_acc=0.43613, time=1.25702
Epoch:0011, train_loss=1.78168, train_acc=0.63541, val_loss=2.06889, val_acc=0.42701, time=1.26100
Epoch:0012, train_loss=1.76693, train_acc=0.64472, val_loss=2.06842, val_acc=0.42701, time=1.23000
Epoch:0013, train_loss=1.75255, train_acc=0.65627, val_loss=2.06817, val_acc=0.42701, time=1.23300
Epoch:0014, train_loss=1.74032, train_acc=0.66093, val_loss=2.06817, val_acc=0.42518, time=1.25402
Epoch:0015, train_loss=1.73040, train_acc=0.66498, val_loss=2.06837, val_acc=0.41788, time=1.34900
Epoch:0016, train_loss=1.72219, train_acc=0.66862, val_loss=2.06872, val_acc=0.41058, time=1.28905
Epoch:0017, train_loss=1.71514, train_acc=0.67328, val_loss=2.06918, val_acc=0.40876, time=1.34402
Early stopping...

Optimization Finished!

Test set results: loss= 2.01972, accuracy= 0.44404, time= 0.32801

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3094    0.1983    0.2417       696
           1     0.4949    0.7682    0.6020      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0000    0.0000    0.0000       121
           4     0.0800    0.0267    0.0400        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4440      2189
   macro avg     0.1105    0.1241    0.1105      2189
weighted avg     0.3460    0.4440    0.3761      2189


Macro average Test Precision, Recall and F1-Score...
(0.11054506579737129, 0.12414736364504728, 0.11046341376872018, None)

Micro average Test Precision, Recall and F1-Score...
(0.4440383736866149, 0.4440383736866149, 0.4440383736866149, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
