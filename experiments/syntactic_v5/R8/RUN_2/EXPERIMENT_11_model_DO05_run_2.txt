
==========: 259849190875600
Epoch:0001, train_loss=2.21467, train_acc=0.06340, val_loss=2.06812, val_acc=0.42518, time=1.27300
Epoch:0002, train_loss=1.96709, train_acc=0.46526, val_loss=2.06364, val_acc=0.48540, time=1.34401
Epoch:0003, train_loss=1.89679, train_acc=0.51104, val_loss=2.06458, val_acc=0.46898, time=1.36901
Epoch:0004, train_loss=1.87656, train_acc=0.52380, val_loss=2.06765, val_acc=0.41788, time=1.43602
Epoch:0005, train_loss=1.87754, train_acc=0.52076, val_loss=2.06988, val_acc=0.42153, time=1.30600
Epoch:0006, train_loss=1.87437, train_acc=0.53413, val_loss=2.07022, val_acc=0.43978, time=1.13201
Epoch:0007, train_loss=1.85768, train_acc=0.56066, val_loss=2.07034, val_acc=0.44891, time=1.21902
Epoch:0008, train_loss=1.84206, train_acc=0.57505, val_loss=2.07007, val_acc=0.45255, time=1.23701
Epoch:0009, train_loss=1.82591, train_acc=0.58315, val_loss=2.06930, val_acc=0.44708, time=1.11000
Epoch:0010, train_loss=1.80771, train_acc=0.59874, val_loss=2.06869, val_acc=0.44161, time=1.30301
Epoch:0011, train_loss=1.79273, train_acc=0.61171, val_loss=2.06841, val_acc=0.43066, time=1.17101
Epoch:0012, train_loss=1.78177, train_acc=0.62913, val_loss=2.06809, val_acc=0.42518, time=1.27201
Epoch:0013, train_loss=1.77062, train_acc=0.63966, val_loss=2.06761, val_acc=0.43066, time=1.29601
Epoch:0014, train_loss=1.75782, train_acc=0.64898, val_loss=2.06722, val_acc=0.42701, time=1.25200
Epoch:0015, train_loss=1.74561, train_acc=0.65647, val_loss=2.06713, val_acc=0.42883, time=1.30901
Epoch:0016, train_loss=1.73601, train_acc=0.65364, val_loss=2.06731, val_acc=0.43066, time=1.28901
Epoch:0017, train_loss=1.72877, train_acc=0.65708, val_loss=2.06762, val_acc=0.43066, time=1.34101
Epoch:0018, train_loss=1.72267, train_acc=0.66781, val_loss=2.06800, val_acc=0.42701, time=1.30601
Epoch:0019, train_loss=1.71706, train_acc=0.67875, val_loss=2.06846, val_acc=0.42701, time=1.27302
Early stopping...

Optimization Finished!

Test set results: loss= 2.01919, accuracy= 0.43444, time= 0.48099

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.2956    0.1839    0.2267       696
           1     0.4910    0.7535    0.5945      1083
           2     0.1429    0.0115    0.0213        87
           3     0.0000    0.0000    0.0000       121
           4     0.0851    0.0533    0.0656        75
           5     0.0000    0.0000    0.0000        10
           6     0.0435    0.0123    0.0192        81
           7     0.1667    0.0278    0.0476        36

    accuracy                         0.4344      2189
   macro avg     0.1531    0.1303    0.1219      2189
weighted avg     0.3498    0.4344    0.3708      2189


Macro average Test Precision, Recall and F1-Score...
(0.1530868989814813, 0.1302902116065185, 0.12187312973841119, None)

Micro average Test Precision, Recall and F1-Score...
(0.43444495203289174, 0.43444495203289174, 0.4344449520328917, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
