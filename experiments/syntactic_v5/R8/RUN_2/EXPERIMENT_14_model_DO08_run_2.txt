
==========: 259931284911600
Epoch:0001, train_loss=2.35451, train_acc=0.04537, val_loss=2.08010, val_acc=0.27737, time=1.35201
Epoch:0002, train_loss=2.04369, train_acc=0.30626, val_loss=2.06693, val_acc=0.42518, time=1.26900
Epoch:0003, train_loss=1.90107, train_acc=0.47721, val_loss=2.06828, val_acc=0.45803, time=1.25600
Epoch:0004, train_loss=1.89036, train_acc=0.51894, val_loss=2.07173, val_acc=0.46168, time=1.24001
Epoch:0005, train_loss=1.90003, train_acc=0.53190, val_loss=2.07344, val_acc=0.44526, time=1.23602
Epoch:0006, train_loss=1.89617, train_acc=0.54324, val_loss=2.07484, val_acc=0.42883, time=1.33801
Epoch:0007, train_loss=1.89261, train_acc=0.55378, val_loss=2.07513, val_acc=0.41971, time=1.35901
Epoch:0008, train_loss=1.88234, train_acc=0.55783, val_loss=2.07391, val_acc=0.42701, time=1.37401
Epoch:0009, train_loss=1.86072, train_acc=0.58031, val_loss=2.07233, val_acc=0.43066, time=1.25301
Epoch:0010, train_loss=1.83731, train_acc=0.59652, val_loss=2.07107, val_acc=0.44708, time=1.31300
Epoch:0011, train_loss=1.81769, train_acc=0.59753, val_loss=2.07013, val_acc=0.43796, time=1.37802
Epoch:0012, train_loss=1.80076, train_acc=0.60239, val_loss=2.06942, val_acc=0.43796, time=1.34900
Epoch:0013, train_loss=1.78496, train_acc=0.61495, val_loss=2.06901, val_acc=0.42701, time=1.36401
Epoch:0014, train_loss=1.77081, train_acc=0.63054, val_loss=2.06895, val_acc=0.41606, time=1.31202
Epoch:0015, train_loss=1.75932, train_acc=0.64513, val_loss=2.06919, val_acc=0.41058, time=1.24100
Epoch:0016, train_loss=1.75027, train_acc=0.65910, val_loss=2.06959, val_acc=0.41423, time=1.21100
Epoch:0017, train_loss=1.74261, train_acc=0.67085, val_loss=2.07006, val_acc=0.41241, time=1.34201
Epoch:0018, train_loss=1.73549, train_acc=0.67693, val_loss=2.07056, val_acc=0.41058, time=1.29801
Early stopping...

Optimization Finished!

Test set results: loss= 2.02009, accuracy= 0.42668, time= 0.57301

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3241    0.2011    0.2482       696
           1     0.4868    0.7304    0.5842      1083
           2     0.0213    0.0115    0.0149        87
           3     0.0000    0.0000    0.0000       121
           4     0.0526    0.0267    0.0354        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4267      2189
   macro avg     0.1106    0.1212    0.1103      2189
weighted avg     0.3465    0.4267    0.3698      2189


Macro average Test Precision, Recall and F1-Score...
(0.11059393494191927, 0.1212111153564492, 0.11034319142760762, None)

Micro average Test Precision, Recall and F1-Score...
(0.42667884878940154, 0.42667884878940154, 0.42667884878940154, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
