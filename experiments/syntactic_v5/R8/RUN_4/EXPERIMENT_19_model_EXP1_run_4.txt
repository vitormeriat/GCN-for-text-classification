
==========: 266643410235500
Epoch:0001, train_loss=2.24135, train_acc=0.05044, val_loss=2.08114, val_acc=0.25547, time=1.31501
Epoch:0002, train_loss=2.08358, train_acc=0.26798, val_loss=2.07052, val_acc=0.39416, time=1.36899
Epoch:0003, train_loss=1.97204, train_acc=0.42030, val_loss=2.06534, val_acc=0.44343, time=1.25200
Epoch:0004, train_loss=1.91005, train_acc=0.48086, val_loss=2.06413, val_acc=0.45620, time=1.27700
Epoch:0005, train_loss=1.88518, train_acc=0.50375, val_loss=2.06487, val_acc=0.46715, time=1.33603
Epoch:0006, train_loss=1.87891, train_acc=0.51955, val_loss=2.06603, val_acc=0.46898, time=1.16899
Epoch:0007, train_loss=1.87765, train_acc=0.52441, val_loss=2.06701, val_acc=0.45985, time=1.18799
Early stopping...

Optimization Finished!

Test set results: loss= 2.00651, accuracy= 0.47967, time= 0.38099

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3694    0.1178    0.1786       696
           1     0.4954    0.8938    0.6375      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0000    0.0000    0.0000       121
           4     0.0000    0.0000    0.0000        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4797      2189
   macro avg     0.1081    0.1265    0.1020      2189
weighted avg     0.3625    0.4797    0.3722      2189


Macro average Test Precision, Recall and F1-Score...
(0.10809542910361744, 0.1264536966281402, 0.10201505326822494, None)

Micro average Test Precision, Recall and F1-Score...
(0.47967108268615805, 0.47967108268615805, 0.47967108268615805, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
