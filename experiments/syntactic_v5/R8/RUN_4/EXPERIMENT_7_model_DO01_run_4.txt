
==========: 266353436111400
Epoch:0001, train_loss=2.30170, train_acc=0.04638, val_loss=2.07255, val_acc=0.36496, time=1.33801
Epoch:0002, train_loss=1.99995, train_acc=0.39093, val_loss=2.06326, val_acc=0.44708, time=1.32102
Epoch:0003, train_loss=1.89536, train_acc=0.49767, val_loss=2.06602, val_acc=0.45073, time=1.26301
Epoch:0004, train_loss=1.89390, train_acc=0.51712, val_loss=2.06889, val_acc=0.44526, time=1.18600
Epoch:0005, train_loss=1.89425, train_acc=0.52481, val_loss=2.07145, val_acc=0.43613, time=1.30802
Epoch:0006, train_loss=1.89418, train_acc=0.52765, val_loss=2.07312, val_acc=0.41971, time=1.33000
Epoch:0007, train_loss=1.88938, train_acc=0.53980, val_loss=2.07295, val_acc=0.42701, time=1.32001
Epoch:0008, train_loss=1.87084, train_acc=0.56289, val_loss=2.07206, val_acc=0.44161, time=1.32002
Epoch:0009, train_loss=1.84794, train_acc=0.57849, val_loss=2.07121, val_acc=0.43248, time=1.24300
Epoch:0010, train_loss=1.82725, train_acc=0.58700, val_loss=2.07040, val_acc=0.43978, time=1.32001
Epoch:0011, train_loss=1.80863, train_acc=0.59368, val_loss=2.06969, val_acc=0.43431, time=1.25600
Epoch:0012, train_loss=1.79241, train_acc=0.60361, val_loss=2.06923, val_acc=0.42701, time=1.33601
Epoch:0013, train_loss=1.77983, train_acc=0.61880, val_loss=2.06897, val_acc=0.42153, time=1.18902
Epoch:0014, train_loss=1.77008, train_acc=0.63682, val_loss=2.06874, val_acc=0.40511, time=1.21500
Epoch:0015, train_loss=1.76098, train_acc=0.64837, val_loss=2.06840, val_acc=0.40876, time=1.23801
Epoch:0016, train_loss=1.75106, train_acc=0.65748, val_loss=2.06801, val_acc=0.41423, time=1.29001
Epoch:0017, train_loss=1.74060, train_acc=0.66599, val_loss=2.06774, val_acc=0.41058, time=1.16401
Epoch:0018, train_loss=1.73091, train_acc=0.67187, val_loss=2.06770, val_acc=0.41423, time=1.28501
Epoch:0019, train_loss=1.72303, train_acc=0.67612, val_loss=2.06792, val_acc=0.41788, time=1.17500
Epoch:0020, train_loss=1.71707, train_acc=0.67733, val_loss=2.06832, val_acc=0.42153, time=1.32802
Epoch:0021, train_loss=1.71232, train_acc=0.67774, val_loss=2.06879, val_acc=0.42336, time=1.14900
Early stopping...

Optimization Finished!

Test set results: loss= 2.01825, accuracy= 0.45363, time= 0.51500

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3235    0.1724    0.2249       696
           1     0.5023    0.8033    0.6181      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0000    0.0000    0.0000       121
           4     0.0476    0.0267    0.0342        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.2000    0.0278    0.0488        36

    accuracy                         0.4536      2189
   macro avg     0.1342    0.1288    0.1158      2189
weighted avg     0.3563    0.4536    0.3793      2189


Macro average Test Precision, Recall and F1-Score...
(0.1341723314015135, 0.12877279215886056, 0.11575193257354584, None)

Micro average Test Precision, Recall and F1-Score...
(0.45363179534033804, 0.45363179534033804, 0.45363179534033804, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
