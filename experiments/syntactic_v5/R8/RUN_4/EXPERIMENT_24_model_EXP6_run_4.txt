
==========: 266747361225100
Epoch:0001, train_loss=2.24442, train_acc=0.07981, val_loss=2.07489, val_acc=0.33759, time=1.21702
Epoch:0002, train_loss=1.99938, train_acc=0.35568, val_loss=2.06484, val_acc=0.43613, time=1.28300
Epoch:0003, train_loss=1.89065, train_acc=0.49220, val_loss=2.06685, val_acc=0.47445, time=1.27900
Epoch:0004, train_loss=1.88945, train_acc=0.51570, val_loss=2.06897, val_acc=0.47993, time=1.25701
Epoch:0005, train_loss=1.89142, train_acc=0.52846, val_loss=2.06889, val_acc=0.45255, time=1.28602
Epoch:0006, train_loss=1.87610, train_acc=0.54385, val_loss=2.06911, val_acc=0.41788, time=1.42400
Epoch:0007, train_loss=1.86573, train_acc=0.54446, val_loss=2.06911, val_acc=0.37409, time=1.45402
Epoch:0008, train_loss=1.85564, train_acc=0.54304, val_loss=2.06781, val_acc=0.41788, time=1.26000
Epoch:0009, train_loss=1.83539, train_acc=0.57383, val_loss=2.06645, val_acc=0.42153, time=1.18601
Epoch:0010, train_loss=1.81523, train_acc=0.60158, val_loss=2.06594, val_acc=0.43978, time=1.31801
Epoch:0011, train_loss=1.80230, train_acc=0.60117, val_loss=2.06587, val_acc=0.43796, time=1.34601
Epoch:0012, train_loss=1.79228, train_acc=0.60381, val_loss=2.06573, val_acc=0.43796, time=1.40902
Epoch:0013, train_loss=1.78060, train_acc=0.60907, val_loss=2.06551, val_acc=0.44161, time=1.39601
Epoch:0014, train_loss=1.76749, train_acc=0.62305, val_loss=2.06546, val_acc=0.43978, time=1.32901
Epoch:0015, train_loss=1.75528, train_acc=0.63703, val_loss=2.06572, val_acc=0.43613, time=1.27401
Epoch:0016, train_loss=1.74546, train_acc=0.65202, val_loss=2.06626, val_acc=0.43066, time=1.29700
Epoch:0017, train_loss=1.73779, train_acc=0.66316, val_loss=2.06696, val_acc=0.42153, time=1.33701
Early stopping...

Optimization Finished!

Test set results: loss= 2.00918, accuracy= 0.43033, time= 0.41001

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3147    0.2586    0.2839       696
           1     0.4919    0.7018    0.5784      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0370    0.0083    0.0135       121
           4     0.0588    0.0133    0.0217        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4303      2189
   macro avg     0.1128    0.1227    0.1122      2189
weighted avg     0.3475    0.4303    0.3779      2189


Macro average Test Precision, Recall and F1-Score...
(0.11280690828092313, 0.1227466089704169, 0.11219386520705654, None)

Micro average Test Precision, Recall and F1-Score...
(0.4303334856098675, 0.4303334856098675, 0.4303334856098675, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
