
==========: 265042398979700
Epoch:0001, train_loss=2.23945, train_acc=0.07211, val_loss=2.09886, val_acc=0.49088, time=1.29101
Epoch:0002, train_loss=2.12883, train_acc=0.52684, val_loss=2.14967, val_acc=0.28650, time=1.17500
Epoch:0003, train_loss=2.49772, train_acc=0.29573, val_loss=2.10359, val_acc=0.46898, time=1.26702
Epoch:0004, train_loss=2.03950, train_acc=0.57545, val_loss=2.11077, val_acc=0.49270, time=1.16999
Epoch:0005, train_loss=2.07585, train_acc=0.54081, val_loss=2.10112, val_acc=0.47263, time=1.27101
Epoch:0006, train_loss=1.97364, train_acc=0.55601, val_loss=2.09287, val_acc=0.41971, time=1.38501
Epoch:0007, train_loss=1.89529, train_acc=0.59530, val_loss=2.08801, val_acc=0.38321, time=1.15001
Epoch:0008, train_loss=1.84810, train_acc=0.61859, val_loss=2.08485, val_acc=0.35219, time=1.34401
Epoch:0009, train_loss=1.81423, train_acc=0.55459, val_loss=2.08176, val_acc=0.35219, time=1.22899
Epoch:0010, train_loss=1.77956, train_acc=0.56208, val_loss=2.07817, val_acc=0.38504, time=1.25602
Epoch:0011, train_loss=1.73876, train_acc=0.62771, val_loss=2.07617, val_acc=0.42518, time=1.25001
Epoch:0012, train_loss=1.71071, train_acc=0.68220, val_loss=2.07656, val_acc=0.43248, time=1.27200
Epoch:0013, train_loss=1.70274, train_acc=0.67227, val_loss=2.07817, val_acc=0.43978, time=1.19802
Epoch:0014, train_loss=1.70506, train_acc=0.65485, val_loss=2.07964, val_acc=0.44343, time=1.27300
Epoch:0015, train_loss=1.70593, train_acc=0.65121, val_loss=2.08037, val_acc=0.43796, time=1.32200
Epoch:0016, train_loss=1.70019, train_acc=0.65910, val_loss=2.08049, val_acc=0.44343, time=1.25001
Epoch:0017, train_loss=1.68911, train_acc=0.67673, val_loss=2.08049, val_acc=0.43431, time=1.22402
Early stopping...

Optimization Finished!

Test set results: loss= 2.06027, accuracy= 0.43810, time= 0.37800

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.2900    0.1250    0.1747       696
           1     0.4901    0.8015    0.6083      1083
           2     0.1000    0.0115    0.0206        87
           3     0.0000    0.0000    0.0000       121
           4     0.0435    0.0267    0.0331        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.1667    0.0278    0.0476        36

    accuracy                         0.4381      2189
   macro avg     0.1363    0.1241    0.1105      2189
weighted avg     0.3429    0.4381    0.3592      2189


Macro average Test Precision, Recall and F1-Score...
(0.13628293807641634, 0.12405200937158382, 0.11053291834325965, None)

Micro average Test Precision, Recall and F1-Score...
(0.4380995888533577, 0.4380995888533577, 0.4380995888533577, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
