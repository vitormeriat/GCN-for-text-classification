
==========: 266451476122700
Epoch:0001, train_loss=2.42746, train_acc=0.02188, val_loss=2.08426, val_acc=0.24635, time=1.36201
Epoch:0002, train_loss=2.08463, train_acc=0.27466, val_loss=2.06734, val_acc=0.42883, time=1.25101
Epoch:0003, train_loss=1.91659, train_acc=0.48856, val_loss=2.06488, val_acc=0.45438, time=1.23301
Epoch:0004, train_loss=1.87972, train_acc=0.52502, val_loss=2.06650, val_acc=0.45620, time=1.23900
Epoch:0005, train_loss=1.87772, train_acc=0.52907, val_loss=2.06854, val_acc=0.43431, time=1.29601
Epoch:0006, train_loss=1.87984, train_acc=0.53879, val_loss=2.06941, val_acc=0.43796, time=1.39901
Epoch:0007, train_loss=1.87308, train_acc=0.55945, val_loss=2.06923, val_acc=0.45438, time=1.32502
Epoch:0008, train_loss=1.85844, train_acc=0.57606, val_loss=2.06852, val_acc=0.46168, time=1.22801
Epoch:0009, train_loss=1.84050, train_acc=0.58497, val_loss=2.06752, val_acc=0.45985, time=1.22003
Epoch:0010, train_loss=1.82130, train_acc=0.59571, val_loss=2.06673, val_acc=0.45803, time=1.16701
Epoch:0011, train_loss=1.80489, train_acc=0.61110, val_loss=2.06656, val_acc=0.44161, time=1.31701
Epoch:0012, train_loss=1.79446, train_acc=0.62548, val_loss=2.06683, val_acc=0.43248, time=1.26898
Epoch:0013, train_loss=1.78743, train_acc=0.63804, val_loss=2.06709, val_acc=0.43066, time=1.27902
Epoch:0014, train_loss=1.77918, train_acc=0.64513, val_loss=2.06720, val_acc=0.43796, time=1.29501
Epoch:0015, train_loss=1.76842, train_acc=0.65161, val_loss=2.06732, val_acc=0.43248, time=1.34799
Epoch:0016, train_loss=1.75685, train_acc=0.66052, val_loss=2.06764, val_acc=0.43796, time=1.24603
Epoch:0017, train_loss=1.74636, train_acc=0.66680, val_loss=2.06820, val_acc=0.43248, time=1.22100
Early stopping...

Optimization Finished!

Test set results: loss= 2.02024, accuracy= 0.45317, time= 0.39999

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3382    0.2011    0.2523       696
           1     0.5003    0.7849    0.6111      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0000    0.0000    0.0000       121
           4     0.0345    0.0133    0.0192        75
           5     0.0000    0.0000    0.0000        10
           6     0.0526    0.0123    0.0200        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4532      2189
   macro avg     0.1157    0.1265    0.1128      2189
weighted avg     0.3582    0.4532    0.3839      2189


Macro average Test Precision, Recall and F1-Score...
(0.11569660994188222, 0.12646066458409247, 0.1128192741627321, None)

Micro average Test Precision, Recall and F1-Score...
(0.4531749657377798, 0.4531749657377798, 0.4531749657377798, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
