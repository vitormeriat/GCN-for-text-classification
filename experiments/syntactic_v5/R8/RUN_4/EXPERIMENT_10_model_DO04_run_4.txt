
==========: 266425779336000
Epoch:0001, train_loss=2.35431, train_acc=0.03038, val_loss=2.08398, val_acc=0.39234, time=1.22802
Epoch:0002, train_loss=2.08397, train_acc=0.43994, val_loss=2.07319, val_acc=0.47628, time=1.28700
Epoch:0003, train_loss=1.96719, train_acc=0.50739, val_loss=2.06723, val_acc=0.47080, time=1.34201
Epoch:0004, train_loss=1.89743, train_acc=0.51631, val_loss=2.06470, val_acc=0.45073, time=1.33302
Epoch:0005, train_loss=1.86188, train_acc=0.49727, val_loss=2.06702, val_acc=0.36861, time=1.31703
Epoch:0006, train_loss=1.87191, train_acc=0.43528, val_loss=2.06852, val_acc=0.36496, time=1.28201
Epoch:0007, train_loss=1.87251, train_acc=0.44784, val_loss=2.06791, val_acc=0.41058, time=1.27099
Epoch:0008, train_loss=1.85206, train_acc=0.50476, val_loss=2.06768, val_acc=0.44343, time=1.22099
Epoch:0009, train_loss=1.83474, train_acc=0.55378, val_loss=2.06818, val_acc=0.46350, time=1.26901
Epoch:0010, train_loss=1.82567, train_acc=0.56735, val_loss=2.06817, val_acc=0.46715, time=1.21300
Epoch:0011, train_loss=1.81426, train_acc=0.57059, val_loss=2.06740, val_acc=0.45803, time=1.31001
Epoch:0012, train_loss=1.79791, train_acc=0.58031, val_loss=2.06661, val_acc=0.44708, time=1.24100
Epoch:0013, train_loss=1.78226, train_acc=0.60442, val_loss=2.06640, val_acc=0.43431, time=1.21100
Epoch:0014, train_loss=1.77207, train_acc=0.62528, val_loss=2.06669, val_acc=0.39964, time=1.20101
Epoch:0015, train_loss=1.76578, train_acc=0.62953, val_loss=2.06701, val_acc=0.38869, time=1.26202
Epoch:0016, train_loss=1.75886, train_acc=0.62447, val_loss=2.06720, val_acc=0.38869, time=1.21299
Epoch:0017, train_loss=1.74983, train_acc=0.64715, val_loss=2.06741, val_acc=0.41971, time=1.26901
Early stopping...

Optimization Finished!

Test set results: loss= 2.00944, accuracy= 0.42805, time= 0.38801

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3193    0.2730    0.2943       696
           1     0.4907    0.6851    0.5719      1083
           2     0.0400    0.0115    0.0179        87
           3     0.0455    0.0083    0.0140       121
           4     0.1053    0.0267    0.0426        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.3333    0.0278    0.0513        36

    accuracy                         0.4280      2189
   macro avg     0.1668    0.1290    0.1240      2189
weighted avg     0.3575    0.4280    0.3803      2189


Macro average Test Precision, Recall and F1-Score...
(0.16676493856447416, 0.12904069415312566, 0.12398660588111683, None)

Micro average Test Precision, Recall and F1-Score...
(0.4280493375970763, 0.4280493375970763, 0.4280493375970763, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
