
==========: 266569786536300
Epoch:0001, train_loss=2.30786, train_acc=0.03423, val_loss=2.07671, val_acc=0.35036, time=1.30100
Epoch:0002, train_loss=2.02361, train_acc=0.36439, val_loss=2.06607, val_acc=0.42701, time=1.28101
Epoch:0003, train_loss=1.90381, train_acc=0.48876, val_loss=2.06669, val_acc=0.44891, time=1.33501
Epoch:0004, train_loss=1.88621, train_acc=0.51772, val_loss=2.06875, val_acc=0.43796, time=1.24401
Epoch:0005, train_loss=1.88346, train_acc=0.52886, val_loss=2.07078, val_acc=0.43796, time=1.27501
Epoch:0006, train_loss=1.88358, train_acc=0.54669, val_loss=2.07178, val_acc=0.43978, time=1.24400
Epoch:0007, train_loss=1.87792, train_acc=0.55864, val_loss=2.07125, val_acc=0.43978, time=1.19101
Epoch:0008, train_loss=1.86085, train_acc=0.58213, val_loss=2.07022, val_acc=0.44343, time=1.28198
Epoch:0009, train_loss=1.84091, train_acc=0.59105, val_loss=2.06903, val_acc=0.44343, time=1.23202
Epoch:0010, train_loss=1.82080, train_acc=0.59368, val_loss=2.06768, val_acc=0.43978, time=1.37399
Epoch:0011, train_loss=1.80041, train_acc=0.60097, val_loss=2.06658, val_acc=0.43248, time=1.30902
Epoch:0012, train_loss=1.78272, train_acc=0.61758, val_loss=2.06605, val_acc=0.43431, time=1.18200
Epoch:0013, train_loss=1.77016, train_acc=0.63500, val_loss=2.06599, val_acc=0.42153, time=1.27401
Epoch:0014, train_loss=1.76098, train_acc=0.64452, val_loss=2.06614, val_acc=0.41788, time=1.22500
Epoch:0015, train_loss=1.75260, train_acc=0.65505, val_loss=2.06649, val_acc=0.41241, time=1.27899
Epoch:0016, train_loss=1.74469, train_acc=0.66295, val_loss=2.06708, val_acc=0.40876, time=1.19901
Epoch:0017, train_loss=1.73788, train_acc=0.66660, val_loss=2.06787, val_acc=0.41423, time=1.27302
Early stopping...

Optimization Finished!

Test set results: loss= 2.02109, accuracy= 0.43993, time= 0.33700

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3089    0.1753    0.2236       696
           1     0.4944    0.7729    0.6030      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0000    0.0000    0.0000       121
           4     0.0789    0.0400    0.0531        75
           5     0.0000    0.0000    0.0000        10
           6     0.0385    0.0123    0.0187        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4399      2189
   macro avg     0.1151    0.1251    0.1123      2189
weighted avg     0.3469    0.4399    0.3720      2189


Macro average Test Precision, Recall and F1-Score...
(0.1150822906951426, 0.1250607776162191, 0.11230786248101284, None)

Micro average Test Precision, Recall and F1-Score...
(0.4399269072635907, 0.4399269072635907, 0.4399269072635907, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
