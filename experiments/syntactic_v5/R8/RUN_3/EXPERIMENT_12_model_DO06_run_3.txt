
==========: 263279234430900
Epoch:0001, train_loss=2.34255, train_acc=0.05793, val_loss=2.07927, val_acc=0.30657, time=1.41401
Epoch:0002, train_loss=2.06006, train_acc=0.31092, val_loss=2.06565, val_acc=0.42336, time=1.33401
Epoch:0003, train_loss=1.91455, train_acc=0.46587, val_loss=2.06576, val_acc=0.45620, time=1.26399
Epoch:0004, train_loss=1.89511, train_acc=0.51063, val_loss=2.06840, val_acc=0.45985, time=1.24302
Epoch:0005, train_loss=1.90053, train_acc=0.52502, val_loss=2.06866, val_acc=0.46168, time=1.26100
Epoch:0006, train_loss=1.88662, train_acc=0.53433, val_loss=2.06848, val_acc=0.44526, time=1.21200
Epoch:0007, train_loss=1.87076, train_acc=0.54527, val_loss=2.06917, val_acc=0.43066, time=1.27901
Epoch:0008, train_loss=1.86487, train_acc=0.53636, val_loss=2.06902, val_acc=0.38504, time=1.20800
Epoch:0009, train_loss=1.85345, train_acc=0.52988, val_loss=2.06787, val_acc=0.40876, time=1.27401
Epoch:0010, train_loss=1.83418, train_acc=0.56755, val_loss=2.06700, val_acc=0.43978, time=1.22400
Epoch:0011, train_loss=1.81765, train_acc=0.59712, val_loss=2.06698, val_acc=0.44526, time=1.36603
Epoch:0012, train_loss=1.80819, train_acc=0.60178, val_loss=2.06730, val_acc=0.44343, time=1.36100
Epoch:0013, train_loss=1.80068, train_acc=0.60016, val_loss=2.06733, val_acc=0.44891, time=1.33801
Epoch:0014, train_loss=1.78990, train_acc=0.60583, val_loss=2.06700, val_acc=0.44891, time=1.27001
Epoch:0015, train_loss=1.77546, train_acc=0.61556, val_loss=2.06658, val_acc=0.43613, time=1.34500
Epoch:0016, train_loss=1.76015, train_acc=0.63156, val_loss=2.06637, val_acc=0.43431, time=1.24902
Epoch:0017, train_loss=1.74697, train_acc=0.64655, val_loss=2.06651, val_acc=0.43066, time=1.31101
Epoch:0018, train_loss=1.73711, train_acc=0.65829, val_loss=2.06689, val_acc=0.42153, time=1.25400
Epoch:0019, train_loss=1.72965, train_acc=0.66174, val_loss=2.06735, val_acc=0.41788, time=1.29700
Early stopping...

Optimization Finished!

Test set results: loss= 2.00989, accuracy= 0.44038, time= 0.32999

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3363    0.2759    0.3031       696
           1     0.4917    0.7091    0.5807      1083
           2     0.1000    0.0115    0.0206        87
           3     0.0000    0.0000    0.0000       121
           4     0.1333    0.0267    0.0444        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     1.0000    0.0278    0.0541        36

    accuracy                         0.4404      2189
   macro avg     0.2577    0.1314    0.1254      2189
weighted avg     0.3752    0.4404    0.3869      2189


Macro average Test Precision, Recall and F1-Score...
(0.2576578574028686, 0.131367755065219, 0.12536419112696778, None)

Micro average Test Precision, Recall and F1-Score...
(0.4403837368661489, 0.4403837368661489, 0.4403837368661489, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
