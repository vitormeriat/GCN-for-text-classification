
==========: 263173623121500
Epoch:0001, train_loss=2.25913, train_acc=0.02390, val_loss=2.07320, val_acc=0.37409, time=1.39501
Epoch:0002, train_loss=1.98397, train_acc=0.42880, val_loss=2.06587, val_acc=0.46168, time=1.21002
Epoch:0003, train_loss=1.89693, train_acc=0.51387, val_loss=2.06675, val_acc=0.47080, time=1.33301
Epoch:0004, train_loss=1.88382, train_acc=0.52684, val_loss=2.06844, val_acc=0.45073, time=1.30102
Epoch:0005, train_loss=1.88071, train_acc=0.53494, val_loss=2.06926, val_acc=0.44708, time=1.32100
Epoch:0006, train_loss=1.87243, train_acc=0.54649, val_loss=2.06873, val_acc=0.45438, time=1.26500
Epoch:0007, train_loss=1.85418, train_acc=0.56532, val_loss=2.06757, val_acc=0.46168, time=1.31000
Epoch:0008, train_loss=1.83214, train_acc=0.57727, val_loss=2.06647, val_acc=0.45620, time=1.31601
Epoch:0009, train_loss=1.81209, train_acc=0.58639, val_loss=2.06583, val_acc=0.45438, time=1.22100
Epoch:0010, train_loss=1.79762, train_acc=0.59611, val_loss=2.06592, val_acc=0.44891, time=1.29501
Epoch:0011, train_loss=1.79029, train_acc=0.60968, val_loss=2.06634, val_acc=0.43613, time=1.32301
Epoch:0012, train_loss=1.78552, train_acc=0.62629, val_loss=2.06655, val_acc=0.42883, time=1.27302
Epoch:0013, train_loss=1.77778, train_acc=0.64067, val_loss=2.06649, val_acc=0.44161, time=1.14701
Epoch:0014, train_loss=1.76634, train_acc=0.65060, val_loss=2.06640, val_acc=0.44526, time=1.24301
Epoch:0015, train_loss=1.75371, train_acc=0.65424, val_loss=2.06653, val_acc=0.45073, time=1.18900
Epoch:0016, train_loss=1.74255, train_acc=0.65505, val_loss=2.06694, val_acc=0.44708, time=1.27000
Early stopping...

Optimization Finished!

Test set results: loss= 2.01108, accuracy= 0.44404, time= 0.38801

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3041    0.1695    0.2177       696
           1     0.4908    0.7849    0.6039      1083
           2     0.0667    0.0115    0.0196        87
           3     0.0000    0.0000    0.0000       121
           4     0.0857    0.0400    0.0545        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4440      2189
   macro avg     0.1184    0.1257    0.1120      2189
weighted avg     0.3451    0.4440    0.3707      2189


Macro average Test Precision, Recall and F1-Score...
(0.11840834855405936, 0.12573642022479065, 0.11197163905748725, None)

Micro average Test Precision, Recall and F1-Score...
(0.4440383736866149, 0.4440383736866149, 0.4440383736866149, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
