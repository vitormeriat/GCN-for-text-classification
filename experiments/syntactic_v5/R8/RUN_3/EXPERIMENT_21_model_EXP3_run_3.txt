
==========: 263490789490300
Epoch:0001, train_loss=2.33626, train_acc=0.04598, val_loss=2.07633, val_acc=0.31752, time=1.55501
Epoch:0002, train_loss=2.00988, train_acc=0.35669, val_loss=2.06470, val_acc=0.43248, time=1.39701
Epoch:0003, train_loss=1.88780, train_acc=0.48349, val_loss=2.06595, val_acc=0.47445, time=1.38701
Epoch:0004, train_loss=1.88155, train_acc=0.51732, val_loss=2.06883, val_acc=0.47445, time=1.33701
Epoch:0005, train_loss=1.89105, train_acc=0.52522, val_loss=2.07041, val_acc=0.46168, time=1.24800
Epoch:0006, train_loss=1.89198, train_acc=0.53879, val_loss=2.07115, val_acc=0.44526, time=1.26001
Epoch:0007, train_loss=1.88795, train_acc=0.55054, val_loss=2.07070, val_acc=0.44343, time=1.24700
Epoch:0008, train_loss=1.87473, train_acc=0.56330, val_loss=2.06937, val_acc=0.45255, time=1.29401
Epoch:0009, train_loss=1.85447, train_acc=0.58193, val_loss=2.06792, val_acc=0.45255, time=1.21801
Epoch:0010, train_loss=1.83384, train_acc=0.58781, val_loss=2.06673, val_acc=0.45073, time=1.30900
Epoch:0011, train_loss=1.81605, train_acc=0.59469, val_loss=2.06591, val_acc=0.44343, time=1.42901
Epoch:0012, train_loss=1.80176, train_acc=0.60401, val_loss=2.06551, val_acc=0.43613, time=1.54601
Epoch:0013, train_loss=1.79088, train_acc=0.61799, val_loss=2.06539, val_acc=0.43431, time=1.43002
Epoch:0014, train_loss=1.78177, train_acc=0.63054, val_loss=2.06535, val_acc=0.42883, time=1.35800
Epoch:0015, train_loss=1.77242, train_acc=0.64513, val_loss=2.06533, val_acc=0.42883, time=1.35801
Epoch:0016, train_loss=1.76214, train_acc=0.65404, val_loss=2.06540, val_acc=0.42883, time=1.30300
Epoch:0017, train_loss=1.75165, train_acc=0.66295, val_loss=2.06565, val_acc=0.42518, time=1.27001
Epoch:0018, train_loss=1.74195, train_acc=0.66619, val_loss=2.06610, val_acc=0.42518, time=1.33001
Epoch:0019, train_loss=1.73354, train_acc=0.66862, val_loss=2.06668, val_acc=0.42883, time=1.26499
Early stopping...

Optimization Finished!

Test set results: loss= 2.01576, accuracy= 0.43627, time= 0.34699

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.2932    0.1681    0.2137       696
           1     0.4909    0.7710    0.5999      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0000    0.0000    0.0000       121
           4     0.0870    0.0267    0.0408        75
           5     0.0000    0.0000    0.0000        10
           6     0.0278    0.0123    0.0171        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4363      2189
   macro avg     0.1124    0.1223    0.1089      2189
weighted avg     0.3401    0.4363    0.3668      2189


Macro average Test Precision, Recall and F1-Score...
(0.1123568869167013, 0.1222652821852642, 0.10893316195008701, None)

Micro average Test Precision, Recall and F1-Score...
(0.4362722704431247, 0.4362722704431247, 0.4362722704431247, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
