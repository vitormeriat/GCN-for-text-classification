
==========: 261652715146500
Epoch:0001, train_loss=2.44583, train_acc=0.04173, val_loss=2.10575, val_acc=0.49635, time=1.47301
Epoch:0002, train_loss=2.18400, train_acc=0.52076, val_loss=2.09648, val_acc=0.29015, time=1.29702
Epoch:0003, train_loss=2.05949, train_acc=0.34616, val_loss=2.09307, val_acc=0.30474, time=1.34602
Epoch:0004, train_loss=1.98219, train_acc=0.48268, val_loss=2.09346, val_acc=0.46533, time=1.26301
Epoch:0005, train_loss=1.95066, train_acc=0.57140, val_loss=2.09309, val_acc=0.46533, time=1.25601
Epoch:0006, train_loss=1.92846, train_acc=0.57160, val_loss=2.08918, val_acc=0.43978, time=1.31100
Epoch:0007, train_loss=1.88210, train_acc=0.61697, val_loss=2.08828, val_acc=0.38869, time=1.23801
Epoch:0008, train_loss=1.85920, train_acc=0.65566, val_loss=2.08701, val_acc=0.37044, time=1.28200
Epoch:0009, train_loss=1.82960, train_acc=0.63541, val_loss=2.08501, val_acc=0.39234, time=1.36199
Epoch:0010, train_loss=1.79186, train_acc=0.65526, val_loss=2.08379, val_acc=0.41058, time=1.28202
Epoch:0011, train_loss=1.76168, train_acc=0.67977, val_loss=2.08375, val_acc=0.43613, time=1.37700
Epoch:0012, train_loss=1.74458, train_acc=0.67187, val_loss=2.08371, val_acc=0.43796, time=1.29700
Epoch:0013, train_loss=1.73044, train_acc=0.67106, val_loss=2.08302, val_acc=0.43431, time=1.33900
Epoch:0014, train_loss=1.71287, train_acc=0.67652, val_loss=2.08212, val_acc=0.42701, time=1.29601
Epoch:0015, train_loss=1.69502, train_acc=0.68989, val_loss=2.08162, val_acc=0.41423, time=1.26800
Epoch:0016, train_loss=1.68168, train_acc=0.71157, val_loss=2.08169, val_acc=0.40328, time=1.27101
Epoch:0017, train_loss=1.67320, train_acc=0.72939, val_loss=2.08209, val_acc=0.38869, time=1.29601
Epoch:0018, train_loss=1.66682, train_acc=0.73749, val_loss=2.08261, val_acc=0.38504, time=1.17301
Epoch:0019, train_loss=1.66016, train_acc=0.74418, val_loss=2.08320, val_acc=0.39599, time=1.31601
Early stopping...

Optimization Finished!

Test set results: loss= 2.05894, accuracy= 0.40932, time= 0.38700

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3034    0.2716    0.2866       696
           1     0.4852    0.6491    0.5553      1083
           2     0.0385    0.0115    0.0177        87
           3     0.0256    0.0083    0.0125       121
           4     0.0833    0.0133    0.0230        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0769    0.0278    0.0408        36

    accuracy                         0.4093      2189
   macro avg     0.1266    0.1227    0.1170      2189
weighted avg     0.3436    0.4093    0.3687      2189


Macro average Test Precision, Recall and F1-Score...
(0.12661149271127287, 0.12269304474375832, 0.11698461867410329, None)

Micro average Test Precision, Recall and F1-Score...
(0.4093193238921882, 0.4093193238921882, 0.4093193238921882, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
