
==========: 263406757478100
Epoch:0001, train_loss=2.37899, train_acc=0.06259, val_loss=2.08147, val_acc=0.27555, time=1.38101
Epoch:0002, train_loss=2.08130, train_acc=0.28884, val_loss=2.06591, val_acc=0.39599, time=1.35601
Epoch:0003, train_loss=1.92203, train_acc=0.44116, val_loss=2.06540, val_acc=0.47993, time=1.26400
Epoch:0004, train_loss=1.89498, train_acc=0.51246, val_loss=2.06946, val_acc=0.48358, time=1.30101
Epoch:0005, train_loss=1.91256, train_acc=0.52137, val_loss=2.07007, val_acc=0.48905, time=1.25601
Epoch:0006, train_loss=1.90335, train_acc=0.52907, val_loss=2.06814, val_acc=0.48358, time=1.31204
Epoch:0007, train_loss=1.87442, train_acc=0.53980, val_loss=2.06653, val_acc=0.45255, time=1.17099
Epoch:0008, train_loss=1.85092, train_acc=0.54608, val_loss=2.06651, val_acc=0.39964, time=1.31501
Epoch:0009, train_loss=1.84298, train_acc=0.51995, val_loss=2.06637, val_acc=0.39234, time=1.24501
Epoch:0010, train_loss=1.83345, train_acc=0.51367, val_loss=2.06516, val_acc=0.40328, time=1.20100
Epoch:0011, train_loss=1.81317, train_acc=0.54689, val_loss=2.06378, val_acc=0.41606, time=1.28701
Epoch:0012, train_loss=1.79063, train_acc=0.59469, val_loss=2.06320, val_acc=0.43066, time=1.29400
Epoch:0013, train_loss=1.77544, train_acc=0.61150, val_loss=2.06353, val_acc=0.44161, time=1.24701
Epoch:0014, train_loss=1.76896, train_acc=0.61090, val_loss=2.06427, val_acc=0.44526, time=1.23501
Epoch:0015, train_loss=1.76624, train_acc=0.60725, val_loss=2.06489, val_acc=0.43978, time=1.26300
Epoch:0016, train_loss=1.76247, train_acc=0.61009, val_loss=2.06522, val_acc=0.43796, time=1.18499
Epoch:0017, train_loss=1.75589, train_acc=0.62528, val_loss=2.06536, val_acc=0.42883, time=1.32200
Early stopping...

Optimization Finished!

Test set results: loss= 2.00929, accuracy= 0.45455, time= 0.40800

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3271    0.1250    0.1809       696
           1     0.4986    0.8347    0.6243      1083
           2     0.1111    0.0115    0.0208        87
           3     0.0270    0.0083    0.0127       121
           4     0.0408    0.0267    0.0323        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4545      2189
   macro avg     0.1256    0.1258    0.1089      2189
weighted avg     0.3580    0.4545    0.3690      2189


Macro average Test Precision, Recall and F1-Score...
(0.12558040048641553, 0.1257679696543409, 0.10886652485449225, None)

Micro average Test Precision, Recall and F1-Score...
(0.45454545454545453, 0.45454545454545453, 0.45454545454545453, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
