
==========: 263357695287700
Epoch:0001, train_loss=2.23479, train_acc=0.10330, val_loss=2.07342, val_acc=0.44891, time=1.31501
Epoch:0002, train_loss=1.99809, train_acc=0.48856, val_loss=2.06526, val_acc=0.49088, time=1.32601
Epoch:0003, train_loss=1.90572, train_acc=0.51550, val_loss=2.06338, val_acc=0.46533, time=1.36100
Epoch:0004, train_loss=1.87326, train_acc=0.49666, val_loss=2.06592, val_acc=0.42336, time=1.28800
Epoch:0005, train_loss=1.88069, train_acc=0.46688, val_loss=2.06695, val_acc=0.43431, time=1.21001
Epoch:0006, train_loss=1.87288, train_acc=0.50111, val_loss=2.06698, val_acc=0.44891, time=1.32601
Epoch:0007, train_loss=1.85563, train_acc=0.54304, val_loss=2.06701, val_acc=0.47263, time=1.19001
Epoch:0008, train_loss=1.84046, train_acc=0.56451, val_loss=2.06640, val_acc=0.46168, time=1.39500
Epoch:0009, train_loss=1.82295, train_acc=0.57464, val_loss=2.06536, val_acc=0.45073, time=1.38302
Epoch:0010, train_loss=1.80433, train_acc=0.59024, val_loss=2.06465, val_acc=0.45438, time=1.25000
Epoch:0011, train_loss=1.78981, train_acc=0.60543, val_loss=2.06441, val_acc=0.43613, time=1.20501
Epoch:0012, train_loss=1.77889, train_acc=0.60786, val_loss=2.06437, val_acc=0.43796, time=1.16100
Epoch:0013, train_loss=1.76808, train_acc=0.61920, val_loss=2.06447, val_acc=0.44161, time=1.42401
Epoch:0014, train_loss=1.75669, train_acc=0.64270, val_loss=2.06485, val_acc=0.43431, time=1.28101
Epoch:0015, train_loss=1.74647, train_acc=0.65485, val_loss=2.06554, val_acc=0.44161, time=1.39301
Epoch:0016, train_loss=1.73865, train_acc=0.65424, val_loss=2.06641, val_acc=0.43431, time=1.42700
Early stopping...

Optimization Finished!

Test set results: loss= 2.01726, accuracy= 0.44906, time= 0.36800

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3154    0.1351    0.1891       696
           1     0.4933    0.8163    0.6150      1083
           2     0.0606    0.0230    0.0333        87
           3     0.0000    0.0000    0.0000       121
           4     0.0606    0.0267    0.0370        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.3333    0.0278    0.0513        36

    accuracy                         0.4491      2189
   macro avg     0.1579    0.1286    0.1157      2189
weighted avg     0.3543    0.4491    0.3678      2189


Macro average Test Precision, Recall and F1-Score...
(0.15791065844809554, 0.12859269695715392, 0.11571796903058384, None)

Micro average Test Precision, Recall and F1-Score...
(0.4490634993147556, 0.4490634993147556, 0.4490634993147556, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
