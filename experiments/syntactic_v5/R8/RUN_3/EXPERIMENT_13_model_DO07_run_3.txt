
==========: 263307821771900
Epoch:0001, train_loss=2.28982, train_acc=0.09398, val_loss=2.07452, val_acc=0.31934, time=1.25301
Epoch:0002, train_loss=2.01655, train_acc=0.35102, val_loss=2.06436, val_acc=0.44891, time=1.20301
Epoch:0003, train_loss=1.89801, train_acc=0.48410, val_loss=2.06771, val_acc=0.47080, time=1.27802
Epoch:0004, train_loss=1.90351, train_acc=0.51712, val_loss=2.07081, val_acc=0.46533, time=1.22000
Epoch:0005, train_loss=1.91060, train_acc=0.52866, val_loss=2.07095, val_acc=0.46715, time=1.26601
Epoch:0006, train_loss=1.89488, train_acc=0.53778, val_loss=2.07081, val_acc=0.44891, time=1.26401
Epoch:0007, train_loss=1.88018, train_acc=0.54081, val_loss=2.07105, val_acc=0.40693, time=1.22201
Epoch:0008, train_loss=1.87215, train_acc=0.52805, val_loss=2.07004, val_acc=0.39781, time=1.21700
Epoch:0009, train_loss=1.85414, train_acc=0.53960, val_loss=2.06814, val_acc=0.43978, time=1.19201
Epoch:0010, train_loss=1.82859, train_acc=0.57970, val_loss=2.06661, val_acc=0.45073, time=1.24001
Epoch:0011, train_loss=1.80665, train_acc=0.60057, val_loss=2.06584, val_acc=0.44708, time=1.21401
Epoch:0012, train_loss=1.79182, train_acc=0.59915, val_loss=2.06549, val_acc=0.44708, time=1.32901
Epoch:0013, train_loss=1.78059, train_acc=0.60117, val_loss=2.06522, val_acc=0.43978, time=1.24701
Epoch:0014, train_loss=1.76998, train_acc=0.60766, val_loss=2.06501, val_acc=0.42701, time=1.27701
Epoch:0015, train_loss=1.75983, train_acc=0.62001, val_loss=2.06497, val_acc=0.42701, time=1.27301
Epoch:0016, train_loss=1.75108, train_acc=0.63217, val_loss=2.06517, val_acc=0.41971, time=1.28701
Epoch:0017, train_loss=1.74415, train_acc=0.64817, val_loss=2.06555, val_acc=0.42336, time=1.25301
Epoch:0018, train_loss=1.73850, train_acc=0.65910, val_loss=2.06602, val_acc=0.41606, time=1.26401
Epoch:0019, train_loss=1.73306, train_acc=0.67025, val_loss=2.06648, val_acc=0.41606, time=1.21002
Early stopping...

Optimization Finished!

Test set results: loss= 2.01545, accuracy= 0.42485, time= 0.54599

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3397    0.2572    0.2927       696
           1     0.4905    0.6907    0.5736      1083
           2     0.0169    0.0115    0.0137        87
           3     0.0000    0.0000    0.0000       121
           4     0.0217    0.0133    0.0165        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.1667    0.0278    0.0476        36

    accuracy                         0.4249      2189
   macro avg     0.1294    0.1251    0.1180      2189
weighted avg     0.3548    0.4249    0.3788      2189


Macro average Test Precision, Recall and F1-Score...
(0.12943814961816014, 0.1250579156981989, 0.11802363100415356, None)

Micro average Test Precision, Recall and F1-Score...
(0.42485153037916856, 0.42485153037916856, 0.4248515303791685, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
