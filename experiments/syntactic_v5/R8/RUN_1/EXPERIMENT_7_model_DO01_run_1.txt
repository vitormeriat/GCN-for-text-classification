
==========: 256233623595000
Epoch:0001, train_loss=2.36780, train_acc=0.01296, val_loss=2.07803, val_acc=0.29562, time=1.25802
Epoch:0002, train_loss=2.04252, train_acc=0.33806, val_loss=2.06555, val_acc=0.45438, time=1.26501
Epoch:0003, train_loss=1.90817, train_acc=0.49949, val_loss=2.06435, val_acc=0.47263, time=1.22100
Epoch:0004, train_loss=1.87744, train_acc=0.52218, val_loss=2.06494, val_acc=0.44161, time=1.25000
Epoch:0005, train_loss=1.86573, train_acc=0.53048, val_loss=2.06635, val_acc=0.42336, time=1.27000
Epoch:0006, train_loss=1.86310, train_acc=0.52724, val_loss=2.06718, val_acc=0.41423, time=1.19502
Epoch:0007, train_loss=1.85574, train_acc=0.54284, val_loss=2.06699, val_acc=0.43431, time=1.26800
Epoch:0008, train_loss=1.83975, train_acc=0.57018, val_loss=2.06671, val_acc=0.43978, time=1.24900
Epoch:0009, train_loss=1.82426, train_acc=0.58376, val_loss=2.06646, val_acc=0.44161, time=1.24700
Epoch:0010, train_loss=1.81089, train_acc=0.58720, val_loss=2.06606, val_acc=0.43796, time=1.26301
Epoch:0011, train_loss=1.79806, train_acc=0.59733, val_loss=2.06577, val_acc=0.43248, time=1.23102
Epoch:0012, train_loss=1.78769, train_acc=0.61637, val_loss=2.06579, val_acc=0.42153, time=1.29300
Epoch:0013, train_loss=1.78065, train_acc=0.63460, val_loss=2.06594, val_acc=0.41606, time=1.25202
Epoch:0014, train_loss=1.77389, train_acc=0.64452, val_loss=2.06599, val_acc=0.42336, time=1.20401
Epoch:0015, train_loss=1.76467, train_acc=0.65283, val_loss=2.06602, val_acc=0.42153, time=1.33100
Epoch:0016, train_loss=1.75392, train_acc=0.65789, val_loss=2.06626, val_acc=0.41971, time=1.29299
Epoch:0017, train_loss=1.74417, train_acc=0.66275, val_loss=2.06674, val_acc=0.42518, time=1.24399
Early stopping...

Optimization Finished!

Test set results: loss= 2.01521, accuracy= 0.45409, time= 0.36300

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3344    0.1509    0.2079       696
           1     0.4958    0.8190    0.6177      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0000    0.0000    0.0000       121
           4     0.0645    0.0267    0.0377        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4541      2189
   macro avg     0.1118    0.1246    0.1079      2189
weighted avg     0.3538    0.4541    0.3730      2189


Macro average Test Precision, Recall and F1-Score...
(0.11183984341218159, 0.1245687466169962, 0.10791808292749178, None)

Micro average Test Precision, Recall and F1-Score...
(0.4540886249428963, 0.4540886249428963, 0.4540886249428963, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
