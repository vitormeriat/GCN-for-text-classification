
==========: 255086194552000
Epoch:0001, train_loss=2.21651, train_acc=0.20883, val_loss=2.09495, val_acc=0.20073, time=1.14401
Epoch:0002, train_loss=2.20113, train_acc=0.21248, val_loss=2.09340, val_acc=0.20255, time=1.23101
Epoch:0003, train_loss=2.18596, train_acc=0.21693, val_loss=2.09187, val_acc=0.20620, time=1.28501
Epoch:0004, train_loss=2.17103, train_acc=0.21916, val_loss=2.09037, val_acc=0.20803, time=1.26401
Epoch:0005, train_loss=2.15633, train_acc=0.22463, val_loss=2.08890, val_acc=0.20803, time=1.29900
Epoch:0006, train_loss=2.14189, train_acc=0.23233, val_loss=2.08746, val_acc=0.21533, time=1.25203
Epoch:0007, train_loss=2.12773, train_acc=0.23840, val_loss=2.08605, val_acc=0.22445, time=1.38700
Epoch:0008, train_loss=2.11387, train_acc=0.24448, val_loss=2.08468, val_acc=0.23358, time=1.32001
Epoch:0009, train_loss=2.10031, train_acc=0.25481, val_loss=2.08334, val_acc=0.24270, time=1.21701
Epoch:0010, train_loss=2.08709, train_acc=0.26534, val_loss=2.08204, val_acc=0.26642, time=1.22999
Epoch:0011, train_loss=2.07422, train_acc=0.27790, val_loss=2.08079, val_acc=0.27555, time=1.28100
Epoch:0012, train_loss=2.06172, train_acc=0.29411, val_loss=2.07957, val_acc=0.27555, time=1.23701
Epoch:0013, train_loss=2.04963, train_acc=0.30707, val_loss=2.07841, val_acc=0.30292, time=1.25299
Epoch:0014, train_loss=2.03796, train_acc=0.32246, val_loss=2.07730, val_acc=0.32299, time=1.21701
Epoch:0015, train_loss=2.02673, train_acc=0.33705, val_loss=2.07623, val_acc=0.33394, time=1.31100
Epoch:0016, train_loss=2.01596, train_acc=0.35467, val_loss=2.07522, val_acc=0.34854, time=1.30701
Epoch:0017, train_loss=2.00567, train_acc=0.36378, val_loss=2.07427, val_acc=0.35036, time=1.37301
Epoch:0018, train_loss=1.99588, train_acc=0.37816, val_loss=2.07337, val_acc=0.36131, time=1.19801
Epoch:0019, train_loss=1.98661, train_acc=0.38850, val_loss=2.07252, val_acc=0.35766, time=1.19100
Epoch:0020, train_loss=1.97785, train_acc=0.40227, val_loss=2.07174, val_acc=0.37226, time=1.29000
Epoch:0021, train_loss=1.96961, train_acc=0.41179, val_loss=2.07101, val_acc=0.39234, time=1.18001
Epoch:0022, train_loss=1.96188, train_acc=0.42131, val_loss=2.07034, val_acc=0.39416, time=1.30700
Epoch:0023, train_loss=1.95466, train_acc=0.42718, val_loss=2.06972, val_acc=0.39964, time=1.27801
Epoch:0024, train_loss=1.94793, train_acc=0.43407, val_loss=2.06916, val_acc=0.40876, time=1.22701
Epoch:0025, train_loss=1.94166, train_acc=0.44258, val_loss=2.06864, val_acc=0.40693, time=1.30901
Epoch:0026, train_loss=1.93583, train_acc=0.44886, val_loss=2.06818, val_acc=0.41788, time=1.33601
Epoch:0027, train_loss=1.93043, train_acc=0.45311, val_loss=2.06775, val_acc=0.41606, time=1.25601
Epoch:0028, train_loss=1.92542, train_acc=0.46060, val_loss=2.06737, val_acc=0.41971, time=1.29403
Epoch:0029, train_loss=1.92077, train_acc=0.46486, val_loss=2.06703, val_acc=0.41788, time=1.18801
Epoch:0030, train_loss=1.91646, train_acc=0.46952, val_loss=2.06671, val_acc=0.41606, time=1.14799
Epoch:0031, train_loss=1.91245, train_acc=0.47620, val_loss=2.06643, val_acc=0.41971, time=1.34101
Epoch:0032, train_loss=1.90871, train_acc=0.48045, val_loss=2.06618, val_acc=0.41788, time=1.30801
Epoch:0033, train_loss=1.90523, train_acc=0.48167, val_loss=2.06596, val_acc=0.41606, time=1.22801
Epoch:0034, train_loss=1.90197, train_acc=0.48491, val_loss=2.06575, val_acc=0.41606, time=1.30200
Epoch:0035, train_loss=1.89891, train_acc=0.48754, val_loss=2.06557, val_acc=0.41606, time=1.21701
Epoch:0036, train_loss=1.89603, train_acc=0.48977, val_loss=2.06540, val_acc=0.41606, time=1.25299
Epoch:0037, train_loss=1.89332, train_acc=0.49220, val_loss=2.06525, val_acc=0.41788, time=1.25002
Epoch:0038, train_loss=1.89075, train_acc=0.49423, val_loss=2.06511, val_acc=0.41788, time=1.19300
Epoch:0039, train_loss=1.88830, train_acc=0.49625, val_loss=2.06499, val_acc=0.42153, time=1.33000
Epoch:0040, train_loss=1.88598, train_acc=0.49747, val_loss=2.06487, val_acc=0.42153, time=1.29301
Epoch:0041, train_loss=1.88376, train_acc=0.49970, val_loss=2.06477, val_acc=0.42153, time=1.24599
Epoch:0042, train_loss=1.88163, train_acc=0.50051, val_loss=2.06467, val_acc=0.41971, time=1.20900
Epoch:0043, train_loss=1.87960, train_acc=0.50294, val_loss=2.06458, val_acc=0.41971, time=1.28303
Epoch:0044, train_loss=1.87764, train_acc=0.50435, val_loss=2.06450, val_acc=0.42518, time=1.19601
Epoch:0045, train_loss=1.87577, train_acc=0.50496, val_loss=2.06442, val_acc=0.42518, time=1.20201
Epoch:0046, train_loss=1.87396, train_acc=0.50537, val_loss=2.06436, val_acc=0.42701, time=1.32401
Epoch:0047, train_loss=1.87222, train_acc=0.50598, val_loss=2.06429, val_acc=0.42518, time=1.38801
Epoch:0048, train_loss=1.87053, train_acc=0.50719, val_loss=2.06423, val_acc=0.42518, time=1.25500
Epoch:0049, train_loss=1.86890, train_acc=0.50760, val_loss=2.06417, val_acc=0.42518, time=1.31102
Epoch:0050, train_loss=1.86731, train_acc=0.50942, val_loss=2.06412, val_acc=0.42701, time=1.20702
Epoch:0051, train_loss=1.86577, train_acc=0.51023, val_loss=2.06407, val_acc=0.42518, time=1.22000
Epoch:0052, train_loss=1.86427, train_acc=0.51124, val_loss=2.06402, val_acc=0.42336, time=1.30201
Epoch:0053, train_loss=1.86281, train_acc=0.51246, val_loss=2.06397, val_acc=0.42336, time=1.20501
Epoch:0054, train_loss=1.86137, train_acc=0.51306, val_loss=2.06392, val_acc=0.42336, time=1.35801
Epoch:0055, train_loss=1.85997, train_acc=0.51367, val_loss=2.06388, val_acc=0.42518, time=1.32002
Epoch:0056, train_loss=1.85858, train_acc=0.51550, val_loss=2.06383, val_acc=0.42518, time=1.33301
Epoch:0057, train_loss=1.85722, train_acc=0.51610, val_loss=2.06379, val_acc=0.42518, time=1.25501
Epoch:0058, train_loss=1.85588, train_acc=0.51793, val_loss=2.06374, val_acc=0.42336, time=1.25201
Epoch:0059, train_loss=1.85456, train_acc=0.51874, val_loss=2.06370, val_acc=0.42336, time=1.25201
Epoch:0060, train_loss=1.85325, train_acc=0.51975, val_loss=2.06365, val_acc=0.42336, time=1.30500
Epoch:0061, train_loss=1.85196, train_acc=0.52137, val_loss=2.06361, val_acc=0.42336, time=1.39300
Epoch:0062, train_loss=1.85068, train_acc=0.52258, val_loss=2.06357, val_acc=0.42153, time=1.32301
Epoch:0063, train_loss=1.84942, train_acc=0.52279, val_loss=2.06353, val_acc=0.42336, time=1.30600
Epoch:0064, train_loss=1.84817, train_acc=0.52522, val_loss=2.06349, val_acc=0.42701, time=1.34902
Epoch:0065, train_loss=1.84694, train_acc=0.52562, val_loss=2.06345, val_acc=0.42518, time=1.32000
Epoch:0066, train_loss=1.84572, train_acc=0.52684, val_loss=2.06341, val_acc=0.42518, time=1.20601
Epoch:0067, train_loss=1.84452, train_acc=0.52826, val_loss=2.06337, val_acc=0.42518, time=1.33101
Epoch:0068, train_loss=1.84333, train_acc=0.52907, val_loss=2.06333, val_acc=0.42336, time=1.26302
Epoch:0069, train_loss=1.84216, train_acc=0.53048, val_loss=2.06330, val_acc=0.42153, time=1.26401
Epoch:0070, train_loss=1.84100, train_acc=0.53109, val_loss=2.06326, val_acc=0.42336, time=1.26302
Epoch:0071, train_loss=1.83986, train_acc=0.53190, val_loss=2.06323, val_acc=0.42153, time=1.19500
Epoch:0072, train_loss=1.83873, train_acc=0.53251, val_loss=2.06320, val_acc=0.42153, time=1.25799
Epoch:0073, train_loss=1.83761, train_acc=0.53332, val_loss=2.06317, val_acc=0.42153, time=1.45301
Epoch:0074, train_loss=1.83651, train_acc=0.53454, val_loss=2.06314, val_acc=0.42153, time=1.17101
Epoch:0075, train_loss=1.83542, train_acc=0.53636, val_loss=2.06312, val_acc=0.42153, time=1.27501
Epoch:0076, train_loss=1.83434, train_acc=0.53757, val_loss=2.06309, val_acc=0.42336, time=1.32199
Epoch:0077, train_loss=1.83326, train_acc=0.53818, val_loss=2.06307, val_acc=0.42336, time=1.27701
Epoch:0078, train_loss=1.83220, train_acc=0.53940, val_loss=2.06305, val_acc=0.42518, time=1.20601
Epoch:0079, train_loss=1.83115, train_acc=0.54061, val_loss=2.06303, val_acc=0.42518, time=1.37301
Epoch:0080, train_loss=1.83011, train_acc=0.54203, val_loss=2.06301, val_acc=0.42518, time=1.27701
Epoch:0081, train_loss=1.82908, train_acc=0.54284, val_loss=2.06299, val_acc=0.42518, time=1.25101
Epoch:0082, train_loss=1.82806, train_acc=0.54446, val_loss=2.06298, val_acc=0.42336, time=1.26200
Epoch:0083, train_loss=1.82705, train_acc=0.54608, val_loss=2.06296, val_acc=0.42336, time=1.29402
Epoch:0084, train_loss=1.82604, train_acc=0.54811, val_loss=2.06295, val_acc=0.41606, time=1.30499
Epoch:0085, train_loss=1.82505, train_acc=0.54932, val_loss=2.06294, val_acc=0.41606, time=1.31201
Epoch:0086, train_loss=1.82406, train_acc=0.55013, val_loss=2.06293, val_acc=0.41423, time=1.26001
Epoch:0087, train_loss=1.82308, train_acc=0.55135, val_loss=2.06292, val_acc=0.41423, time=1.19201
Epoch:0088, train_loss=1.82211, train_acc=0.55236, val_loss=2.06291, val_acc=0.41606, time=1.20600
Epoch:0089, train_loss=1.82114, train_acc=0.55317, val_loss=2.06290, val_acc=0.41606, time=1.33701
Epoch:0090, train_loss=1.82018, train_acc=0.55439, val_loss=2.06289, val_acc=0.41606, time=1.23100
Epoch:0091, train_loss=1.81923, train_acc=0.55499, val_loss=2.06288, val_acc=0.41788, time=1.28403
Epoch:0092, train_loss=1.81829, train_acc=0.55641, val_loss=2.06288, val_acc=0.41788, time=1.32400
Epoch:0093, train_loss=1.81735, train_acc=0.55783, val_loss=2.06287, val_acc=0.41788, time=1.32201
Epoch:0094, train_loss=1.81642, train_acc=0.55904, val_loss=2.06287, val_acc=0.41788, time=1.42101
Epoch:0095, train_loss=1.81550, train_acc=0.56066, val_loss=2.06287, val_acc=0.41241, time=1.36401
Epoch:0096, train_loss=1.81458, train_acc=0.56188, val_loss=2.06286, val_acc=0.41241, time=1.35800
Epoch:0097, train_loss=1.81367, train_acc=0.56309, val_loss=2.06286, val_acc=0.41241, time=1.33899
Epoch:0098, train_loss=1.81277, train_acc=0.56350, val_loss=2.06286, val_acc=0.41423, time=1.16101
Epoch:0099, train_loss=1.81187, train_acc=0.56532, val_loss=2.06286, val_acc=0.41423, time=1.27400
Epoch:0100, train_loss=1.81097, train_acc=0.56593, val_loss=2.06286, val_acc=0.41423, time=1.27301
Epoch:0101, train_loss=1.81008, train_acc=0.56674, val_loss=2.06286, val_acc=0.41423, time=1.29302
Epoch:0102, train_loss=1.80920, train_acc=0.56816, val_loss=2.06286, val_acc=0.41423, time=1.28101
Epoch:0103, train_loss=1.80832, train_acc=0.56877, val_loss=2.06286, val_acc=0.41423, time=1.26601
Epoch:0104, train_loss=1.80745, train_acc=0.57018, val_loss=2.06286, val_acc=0.41423, time=1.43201
Epoch:0105, train_loss=1.80659, train_acc=0.57120, val_loss=2.06286, val_acc=0.41241, time=1.20802
Early stopping...

Optimization Finished!

Test set results: loss= 2.00019, accuracy= 0.45135, time= 0.36398

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3286    0.2011    0.2496       696
           1     0.4939    0.7821    0.6054      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0476    0.0083    0.0141       121
           4     0.0000    0.0000    0.0000        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4513      2189
   macro avg     0.1088    0.1239    0.1086      2189
weighted avg     0.3515    0.4513    0.3797      2189


Macro average Test Precision, Recall and F1-Score...
(0.10876688703650475, 0.12393758550431064, 0.10863391574936629, None)

Micro average Test Precision, Recall and F1-Score...
(0.45134764732754684, 0.45134764732754684, 0.45134764732754684, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
