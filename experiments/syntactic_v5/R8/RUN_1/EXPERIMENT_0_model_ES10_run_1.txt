
==========: 253594222775700
Epoch:0001, train_loss=2.33820, train_acc=0.04193, val_loss=2.07660, val_acc=0.32664, time=1.36200
Epoch:0002, train_loss=2.02854, train_acc=0.35406, val_loss=2.06592, val_acc=0.45073, time=1.40601
Epoch:0003, train_loss=1.89983, train_acc=0.50152, val_loss=2.06679, val_acc=0.46898, time=1.30200
Epoch:0004, train_loss=1.88075, train_acc=0.52339, val_loss=2.06912, val_acc=0.45073, time=1.25201
Epoch:0005, train_loss=1.87927, train_acc=0.53291, val_loss=2.07254, val_acc=0.40693, time=1.25601
Epoch:0006, train_loss=1.89035, train_acc=0.53413, val_loss=2.07437, val_acc=0.39781, time=1.40899
Epoch:0007, train_loss=1.88880, train_acc=0.54790, val_loss=2.07457, val_acc=0.44526, time=1.21701
Epoch:0008, train_loss=1.87429, train_acc=0.58153, val_loss=2.07440, val_acc=0.45255, time=1.28801
Epoch:0009, train_loss=1.85897, train_acc=0.58517, val_loss=2.07357, val_acc=0.45073, time=1.34002
Epoch:0010, train_loss=1.84038, train_acc=0.59165, val_loss=2.07194, val_acc=0.45438, time=1.35000
Epoch:0011, train_loss=1.81672, train_acc=0.59955, val_loss=2.07014, val_acc=0.44708, time=1.26899
Epoch:0012, train_loss=1.79305, train_acc=0.62244, val_loss=2.06875, val_acc=0.43066, time=1.28901
Epoch:0013, train_loss=1.77395, train_acc=0.64148, val_loss=2.06788, val_acc=0.42883, time=1.29901
Epoch:0014, train_loss=1.75961, train_acc=0.64857, val_loss=2.06748, val_acc=0.42153, time=1.42201
Epoch:0015, train_loss=1.74879, train_acc=0.66133, val_loss=2.06756, val_acc=0.41971, time=1.22201
Epoch:0016, train_loss=1.74136, train_acc=0.66295, val_loss=2.06808, val_acc=0.41423, time=1.18901
Epoch:0017, train_loss=1.73692, train_acc=0.66680, val_loss=2.06884, val_acc=0.41423, time=1.22601
Epoch:0018, train_loss=1.73372, train_acc=0.66883, val_loss=2.06959, val_acc=0.42153, time=1.27203
Epoch:0019, train_loss=1.72976, train_acc=0.66721, val_loss=2.07019, val_acc=0.42883, time=1.22500
Early stopping...

Optimization Finished!

Test set results: loss= 2.02626, accuracy= 0.43764, time= 0.46599

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3302    0.1523    0.2085       696
           1     0.4907    0.7821    0.6031      1083
           2     0.0625    0.0115    0.0194        87
           3     0.0000    0.0000    0.0000       121
           4     0.0400    0.0267    0.0320        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.3333    0.0556    0.0952        36

    accuracy                         0.4376      2189
   macro avg     0.1571    0.1285    0.1198      2189
weighted avg     0.3571    0.4376    0.3681      2189


Macro average Test Precision, Recall and F1-Score...
(0.15709767668208055, 0.1285127652009637, 0.11977167532179668, None)

Micro average Test Precision, Recall and F1-Score...
(0.43764275925079943, 0.43764275925079943, 0.43764275925079943, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
