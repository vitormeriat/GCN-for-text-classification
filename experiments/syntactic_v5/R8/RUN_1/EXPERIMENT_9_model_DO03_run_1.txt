
==========: 256278308900100
Epoch:0001, train_loss=2.29451, train_acc=0.03646, val_loss=2.07379, val_acc=0.41971, time=1.27101
Epoch:0002, train_loss=2.00591, train_acc=0.43022, val_loss=2.06622, val_acc=0.46715, time=1.31601
Epoch:0003, train_loss=1.90837, train_acc=0.51165, val_loss=2.06561, val_acc=0.46898, time=1.28700
Epoch:0004, train_loss=1.88346, train_acc=0.51590, val_loss=2.06634, val_acc=0.46168, time=1.22900
Epoch:0005, train_loss=1.87670, train_acc=0.51165, val_loss=2.06818, val_acc=0.42701, time=1.21901
Epoch:0006, train_loss=1.88208, train_acc=0.48815, val_loss=2.06865, val_acc=0.42336, time=1.14500
Epoch:0007, train_loss=1.87529, train_acc=0.50395, val_loss=2.06763, val_acc=0.43796, time=1.24801
Epoch:0008, train_loss=1.85532, train_acc=0.54000, val_loss=2.06648, val_acc=0.46168, time=1.26301
Epoch:0009, train_loss=1.83514, train_acc=0.56492, val_loss=2.06567, val_acc=0.46715, time=1.24601
Epoch:0010, train_loss=1.81962, train_acc=0.56715, val_loss=2.06499, val_acc=0.46350, time=1.21801
Epoch:0011, train_loss=1.80671, train_acc=0.57261, val_loss=2.06448, val_acc=0.45803, time=1.30701
Epoch:0012, train_loss=1.79577, train_acc=0.58457, val_loss=2.06435, val_acc=0.45073, time=1.32300
Epoch:0013, train_loss=1.78716, train_acc=0.59955, val_loss=2.06458, val_acc=0.43248, time=1.26801
Epoch:0014, train_loss=1.77982, train_acc=0.61758, val_loss=2.06502, val_acc=0.42336, time=1.25202
Epoch:0015, train_loss=1.77227, train_acc=0.63318, val_loss=2.06554, val_acc=0.42336, time=1.28201
Epoch:0016, train_loss=1.76384, train_acc=0.64574, val_loss=2.06608, val_acc=0.42336, time=1.33403
Early stopping...

Optimization Finished!

Test set results: loss= 2.01033, accuracy= 0.43033, time= 0.35700

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3096    0.1753    0.2239       696
           1     0.4889    0.7544    0.5933      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0417    0.0083    0.0138       121
           4     0.0256    0.0133    0.0175        75
           5     0.0000    0.0000    0.0000        10
           6     0.0435    0.0123    0.0192        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4303      2189
   macro avg     0.1137    0.1205    0.1085      2189
weighted avg     0.3451    0.4303    0.3668      2189


Macro average Test Precision, Recall and F1-Score...
(0.11366992604832582, 0.12045209954871453, 0.10846746904280323, None)

Micro average Test Precision, Recall and F1-Score...
(0.4303334856098675, 0.4303334856098675, 0.4303334856098675, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
