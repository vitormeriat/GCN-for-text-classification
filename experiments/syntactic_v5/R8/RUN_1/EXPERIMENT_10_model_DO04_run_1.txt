
==========: 256302687915600
Epoch:0001, train_loss=2.17185, train_acc=0.10533, val_loss=2.06745, val_acc=0.39964, time=1.42800
Epoch:0002, train_loss=1.94211, train_acc=0.45432, val_loss=2.06431, val_acc=0.45985, time=1.29302
Epoch:0003, train_loss=1.88417, train_acc=0.51144, val_loss=2.06721, val_acc=0.46168, time=1.25001
Epoch:0004, train_loss=1.88005, train_acc=0.52522, val_loss=2.07036, val_acc=0.43613, time=1.21101
Epoch:0005, train_loss=1.88138, train_acc=0.53494, val_loss=2.07213, val_acc=0.43613, time=1.24901
Epoch:0006, train_loss=1.87508, train_acc=0.55560, val_loss=2.07240, val_acc=0.43613, time=1.47201
Epoch:0007, train_loss=1.85956, train_acc=0.57403, val_loss=2.07188, val_acc=0.44708, time=1.28701
Epoch:0008, train_loss=1.83996, train_acc=0.58416, val_loss=2.07094, val_acc=0.45073, time=1.26399
Epoch:0009, train_loss=1.81903, train_acc=0.59834, val_loss=2.07003, val_acc=0.44708, time=1.25102
Epoch:0010, train_loss=1.80028, train_acc=0.61556, val_loss=2.06958, val_acc=0.43613, time=1.29999
Epoch:0011, train_loss=1.78670, train_acc=0.63419, val_loss=2.06953, val_acc=0.43796, time=1.27202
Epoch:0012, train_loss=1.77684, train_acc=0.64331, val_loss=2.06957, val_acc=0.43796, time=1.25201
Epoch:0013, train_loss=1.76699, train_acc=0.65181, val_loss=2.06955, val_acc=0.43248, time=1.32701
Epoch:0014, train_loss=1.75558, train_acc=0.65627, val_loss=2.06953, val_acc=0.42883, time=1.24302
Epoch:0015, train_loss=1.74346, train_acc=0.66194, val_loss=2.06962, val_acc=0.42701, time=1.29800
Epoch:0016, train_loss=1.73201, train_acc=0.66437, val_loss=2.06989, val_acc=0.43248, time=1.25601
Epoch:0017, train_loss=1.72202, train_acc=0.67025, val_loss=2.07034, val_acc=0.42883, time=1.21902
Early stopping...

Optimization Finished!

Test set results: loss= 2.01998, accuracy= 0.45317, time= 0.37000

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3341    0.1997    0.2500       696
           1     0.4988    0.7867    0.6105      1083
           2     0.0000    0.0000    0.0000        87
           3     0.0000    0.0000    0.0000       121
           4     0.0526    0.0133    0.0213        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4532      2189
   macro avg     0.1107    0.1250    0.1102      2189
weighted avg     0.3548    0.4532    0.3823      2189


Macro average Test Precision, Recall and F1-Score...
(0.11069940426807875, 0.12496869726494093, 0.1102263068220801, None)

Micro average Test Precision, Recall and F1-Score...
(0.4531749657377798, 0.4531749657377798, 0.4531749657377798, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
