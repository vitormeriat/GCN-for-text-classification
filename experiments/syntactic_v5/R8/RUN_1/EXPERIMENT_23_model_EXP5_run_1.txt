
==========: 256620831472900
Epoch:0001, train_loss=2.16260, train_acc=0.23496, val_loss=2.06547, val_acc=0.40876, time=1.31402
Epoch:0002, train_loss=1.93870, train_acc=0.44825, val_loss=2.06504, val_acc=0.47263, time=1.37401
Epoch:0003, train_loss=1.90157, train_acc=0.51509, val_loss=2.06811, val_acc=0.48540, time=1.19600
Epoch:0004, train_loss=1.90444, train_acc=0.52441, val_loss=2.06736, val_acc=0.47445, time=1.23001
Epoch:0005, train_loss=1.87947, train_acc=0.52967, val_loss=2.06636, val_acc=0.45073, time=1.26298
Epoch:0006, train_loss=1.85651, train_acc=0.53838, val_loss=2.06714, val_acc=0.36679, time=1.27401
Epoch:0007, train_loss=1.85185, train_acc=0.51550, val_loss=2.06691, val_acc=0.35219, time=1.33801
Epoch:0008, train_loss=1.83827, train_acc=0.51691, val_loss=2.06544, val_acc=0.40146, time=1.26601
Epoch:0009, train_loss=1.81376, train_acc=0.57343, val_loss=2.06420, val_acc=0.43613, time=1.31900
Epoch:0010, train_loss=1.79264, train_acc=0.60199, val_loss=2.06388, val_acc=0.44526, time=1.29199
Epoch:0011, train_loss=1.78120, train_acc=0.59530, val_loss=2.06408, val_acc=0.45073, time=1.26502
Epoch:0012, train_loss=1.77529, train_acc=0.59733, val_loss=2.06419, val_acc=0.44891, time=1.28899
Epoch:0013, train_loss=1.76878, train_acc=0.60178, val_loss=2.06401, val_acc=0.44708, time=1.31101
Epoch:0014, train_loss=1.75955, train_acc=0.61272, val_loss=2.06373, val_acc=0.43613, time=1.30501
Epoch:0015, train_loss=1.74905, train_acc=0.62953, val_loss=2.06365, val_acc=0.42883, time=1.27102
Epoch:0016, train_loss=1.73953, train_acc=0.64796, val_loss=2.06389, val_acc=0.42153, time=1.29300
Epoch:0017, train_loss=1.73196, train_acc=0.65667, val_loss=2.06440, val_acc=0.41241, time=1.23100
Epoch:0018, train_loss=1.72569, train_acc=0.67085, val_loss=2.06502, val_acc=0.40876, time=1.29602
Early stopping...

Optimization Finished!

Test set results: loss= 2.01592, accuracy= 0.42622, time= 0.52800

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3230    0.2830    0.3017       696
           1     0.4969    0.6768    0.5731      1083
           2     0.0909    0.0115    0.0204        87
           3     0.0000    0.0000    0.0000       121
           4     0.0408    0.0267    0.0323        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4262      2189
   macro avg     0.1190    0.1248    0.1159      2189
weighted avg     0.3536    0.4262    0.3814      2189


Macro average Test Precision, Recall and F1-Score...
(0.1189531737067759, 0.12475381682427483, 0.11593184352457794, None)

Micro average Test Precision, Recall and F1-Score...
(0.4262220191868433, 0.4262220191868433, 0.4262220191868433, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
