
==========: 256563167204000
Epoch:0001, train_loss=2.26307, train_acc=0.04395, val_loss=2.07302, val_acc=0.40146, time=1.33301
Epoch:0002, train_loss=1.99403, train_acc=0.43792, val_loss=2.06547, val_acc=0.45620, time=1.18701
Epoch:0003, train_loss=1.89933, train_acc=0.51306, val_loss=2.06540, val_acc=0.45620, time=1.30400
Epoch:0004, train_loss=1.87618, train_acc=0.52400, val_loss=2.06783, val_acc=0.43613, time=1.20700
Epoch:0005, train_loss=1.87929, train_acc=0.52279, val_loss=2.07081, val_acc=0.40511, time=1.29700
Epoch:0006, train_loss=1.88741, train_acc=0.51550, val_loss=2.07168, val_acc=0.42153, time=1.33101
Epoch:0007, train_loss=1.87676, train_acc=0.55317, val_loss=2.07181, val_acc=0.43796, time=1.34702
Epoch:0008, train_loss=1.86080, train_acc=0.57687, val_loss=2.07155, val_acc=0.45073, time=1.33999
Epoch:0009, train_loss=1.84433, train_acc=0.57646, val_loss=2.07041, val_acc=0.45073, time=1.31900
Epoch:0010, train_loss=1.82301, train_acc=0.58659, val_loss=2.06873, val_acc=0.43978, time=1.34401
Epoch:0011, train_loss=1.79914, train_acc=0.60381, val_loss=2.06726, val_acc=0.43613, time=1.30200
Epoch:0012, train_loss=1.77868, train_acc=0.62427, val_loss=2.06642, val_acc=0.43796, time=1.33401
Epoch:0013, train_loss=1.76425, train_acc=0.63784, val_loss=2.06611, val_acc=0.42336, time=1.18802
Epoch:0014, train_loss=1.75448, train_acc=0.65100, val_loss=2.06618, val_acc=0.41788, time=1.37599
Epoch:0015, train_loss=1.74766, train_acc=0.65809, val_loss=2.06654, val_acc=0.42336, time=1.33801
Epoch:0016, train_loss=1.74276, train_acc=0.66417, val_loss=2.06706, val_acc=0.41788, time=1.32899
Epoch:0017, train_loss=1.73872, train_acc=0.66741, val_loss=2.06760, val_acc=0.41971, time=1.30501
Epoch:0018, train_loss=1.73433, train_acc=0.66397, val_loss=2.06805, val_acc=0.42701, time=1.23300
Early stopping...

Optimization Finished!

Test set results: loss= 2.02077, accuracy= 0.43993, time= 0.38199

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3050    0.1135    0.1654       696
           1     0.4955    0.8135    0.6159      1083
           2     0.0526    0.0115    0.0189        87
           3     0.0000    0.0000    0.0000       121
           4     0.0408    0.0267    0.0323        75
           5     0.0000    0.0000    0.0000        10
           6     0.0000    0.0000    0.0000        81
           7     0.0000    0.0000    0.0000        36

    accuracy                         0.4399      2189
   macro avg     0.1117    0.1206    0.1041      2189
weighted avg     0.3456    0.4399    0.3592      2189


Macro average Test Precision, Recall and F1-Score...
(0.11174597161587274, 0.12064346722068328, 0.10405494908036546, None)

Micro average Test Precision, Recall and F1-Score...
(0.4399269072635907, 0.4399269072635907, 0.4399269072635907, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
