
==========: 293838974359300
Epoch:0001, train_loss=1.95238, train_acc=0.11775, val_loss=2.00408, val_acc=0.34392, time=0.08600
Epoch:0002, train_loss=2.50934, train_acc=0.30463, val_loss=1.98456, val_acc=0.13757, time=0.10601
Epoch:0003, train_loss=2.25268, train_acc=0.16462, val_loss=1.95039, val_acc=0.14815, time=0.10399
Epoch:0004, train_loss=1.93904, train_acc=0.19098, val_loss=1.94642, val_acc=0.14815, time=0.12400
Epoch:0005, train_loss=1.91248, train_acc=0.24370, val_loss=1.94532, val_acc=0.18519, time=0.12900
Epoch:0006, train_loss=1.90873, train_acc=0.33509, val_loss=1.94434, val_acc=0.33862, time=0.12800
Epoch:0007, train_loss=1.90187, train_acc=0.38957, val_loss=1.94347, val_acc=0.35450, time=0.10000
Epoch:0008, train_loss=1.89280, train_acc=0.36848, val_loss=1.94270, val_acc=0.34921, time=0.11900
Epoch:0009, train_loss=1.88280, train_acc=0.35970, val_loss=1.94206, val_acc=0.35450, time=0.11701
Epoch:0010, train_loss=1.87239, train_acc=0.35501, val_loss=1.94155, val_acc=0.35450, time=0.12898
Epoch:0011, train_loss=1.86175, train_acc=0.35618, val_loss=1.94104, val_acc=0.34921, time=0.13000
Epoch:0012, train_loss=1.85034, train_acc=0.35911, val_loss=1.94047, val_acc=0.34392, time=0.12100
Epoch:0013, train_loss=1.83737, train_acc=0.36380, val_loss=1.93984, val_acc=0.33333, time=0.11802
Epoch:0014, train_loss=1.82301, train_acc=0.36555, val_loss=1.93932, val_acc=0.33862, time=0.11201
Epoch:0015, train_loss=1.80732, train_acc=0.36790, val_loss=1.93906, val_acc=0.34921, time=0.13000
Epoch:0016, train_loss=1.78988, train_acc=0.36731, val_loss=1.93940, val_acc=0.34921, time=0.12898
Epoch:0017, train_loss=1.77327, train_acc=0.37317, val_loss=1.94053, val_acc=0.33333, time=0.11500
Early stopping...

Optimization Finished!

Test set results: loss= 1.94070, accuracy= 0.27586, time= 0.02400

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.2000    0.0071    0.0138       140
           1     0.0000    0.0000    0.0000        45
           2     0.1154    0.0248    0.0408       121
           3     0.0000    0.0000    0.0000        92
           4     0.1053    0.0172    0.0296       116
           5     0.0000    0.0000    0.0000        65
           6     0.2891    0.9356    0.4417       233

    accuracy                         0.2759       812
   macro avg     0.1014    0.1407    0.0751       812
weighted avg     0.1497    0.2759    0.1394       812


Macro average Test Precision, Recall and F1-Score...
(0.10139606310205221, 0.14068570606850295, 0.07514024487387568, None)

Micro average Test Precision, Recall and F1-Score...
(0.27586206896551724, 0.27586206896551724, 0.27586206896551724, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
