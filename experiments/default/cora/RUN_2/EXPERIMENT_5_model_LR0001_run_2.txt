
==========: 294362384202700
Epoch:0001, train_loss=1.98780, train_acc=0.12478, val_loss=1.95025, val_acc=0.09524, time=0.12401
Epoch:0002, train_loss=1.98190, train_acc=0.12537, val_loss=1.94955, val_acc=0.10582, time=0.12299
Epoch:0003, train_loss=1.97619, train_acc=0.12478, val_loss=1.94887, val_acc=0.10582, time=0.12199
Epoch:0004, train_loss=1.97067, train_acc=0.12712, val_loss=1.94821, val_acc=0.10582, time=0.12099
Epoch:0005, train_loss=1.96534, train_acc=0.12771, val_loss=1.94758, val_acc=0.11640, time=0.13100
Epoch:0006, train_loss=1.96021, train_acc=0.12830, val_loss=1.94697, val_acc=0.11640, time=0.11901
Epoch:0007, train_loss=1.95529, train_acc=0.13064, val_loss=1.94638, val_acc=0.12169, time=0.11500
Epoch:0008, train_loss=1.95056, train_acc=0.13240, val_loss=1.94582, val_acc=0.14815, time=0.11701
Epoch:0009, train_loss=1.94605, train_acc=0.14236, val_loss=1.94528, val_acc=0.16402, time=0.11201
Epoch:0010, train_loss=1.94174, train_acc=0.14353, val_loss=1.94476, val_acc=0.15344, time=0.11199
Epoch:0011, train_loss=1.93765, train_acc=0.16579, val_loss=1.94427, val_acc=0.15873, time=0.14401
Epoch:0012, train_loss=1.93377, train_acc=0.17282, val_loss=1.94381, val_acc=0.19577, time=0.13101
Epoch:0013, train_loss=1.93010, train_acc=0.19098, val_loss=1.94337, val_acc=0.22751, time=0.12799
Epoch:0014, train_loss=1.92664, train_acc=0.21207, val_loss=1.94296, val_acc=0.24868, time=0.12999
Epoch:0015, train_loss=1.92340, train_acc=0.22730, val_loss=1.94257, val_acc=0.24339, time=0.13100
Epoch:0016, train_loss=1.92036, train_acc=0.24546, val_loss=1.94221, val_acc=0.27513, time=0.12802
Epoch:0017, train_loss=1.91753, train_acc=0.25659, val_loss=1.94187, val_acc=0.30159, time=0.11198
Epoch:0018, train_loss=1.91490, train_acc=0.27358, val_loss=1.94156, val_acc=0.31217, time=0.10300
Epoch:0019, train_loss=1.91246, train_acc=0.28002, val_loss=1.94127, val_acc=0.32275, time=0.11701
Epoch:0020, train_loss=1.91021, train_acc=0.28764, val_loss=1.94100, val_acc=0.32804, time=0.10500
Epoch:0021, train_loss=1.90814, train_acc=0.29233, val_loss=1.94076, val_acc=0.33333, time=0.12200
Epoch:0022, train_loss=1.90624, train_acc=0.29584, val_loss=1.94054, val_acc=0.33862, time=0.11101
Epoch:0023, train_loss=1.90450, train_acc=0.29701, val_loss=1.94034, val_acc=0.33333, time=0.12799
Epoch:0024, train_loss=1.90291, train_acc=0.29818, val_loss=1.94016, val_acc=0.33333, time=0.12700
Epoch:0025, train_loss=1.90146, train_acc=0.29877, val_loss=1.94000, val_acc=0.32275, time=0.10300
Epoch:0026, train_loss=1.90014, train_acc=0.30053, val_loss=1.93986, val_acc=0.33333, time=0.13000
Epoch:0027, train_loss=1.89892, train_acc=0.30228, val_loss=1.93974, val_acc=0.33333, time=0.11499
Epoch:0028, train_loss=1.89781, train_acc=0.30404, val_loss=1.93963, val_acc=0.32804, time=0.12300
Epoch:0029, train_loss=1.89679, train_acc=0.30404, val_loss=1.93953, val_acc=0.32804, time=0.10301
Epoch:0030, train_loss=1.89585, train_acc=0.30346, val_loss=1.93944, val_acc=0.32804, time=0.12803
Epoch:0031, train_loss=1.89497, train_acc=0.30346, val_loss=1.93937, val_acc=0.32804, time=0.12899
Epoch:0032, train_loss=1.89415, train_acc=0.30287, val_loss=1.93931, val_acc=0.32804, time=0.08900
Epoch:0033, train_loss=1.89337, train_acc=0.30287, val_loss=1.93925, val_acc=0.33333, time=0.08400
Epoch:0034, train_loss=1.89263, train_acc=0.30346, val_loss=1.93921, val_acc=0.33862, time=0.12099
Epoch:0035, train_loss=1.89192, train_acc=0.30346, val_loss=1.93917, val_acc=0.33862, time=0.08702
Epoch:0036, train_loss=1.89123, train_acc=0.30404, val_loss=1.93914, val_acc=0.33862, time=0.12699
Epoch:0037, train_loss=1.89056, train_acc=0.30463, val_loss=1.93911, val_acc=0.33862, time=0.08399
Epoch:0038, train_loss=1.88990, train_acc=0.30463, val_loss=1.93909, val_acc=0.33862, time=0.11600
Epoch:0039, train_loss=1.88924, train_acc=0.30463, val_loss=1.93907, val_acc=0.33862, time=0.09502
Epoch:0040, train_loss=1.88859, train_acc=0.30463, val_loss=1.93905, val_acc=0.33333, time=0.10401
Epoch:0041, train_loss=1.88794, train_acc=0.30463, val_loss=1.93904, val_acc=0.33333, time=0.11601
Epoch:0042, train_loss=1.88729, train_acc=0.30463, val_loss=1.93903, val_acc=0.33333, time=0.10302
Epoch:0043, train_loss=1.88664, train_acc=0.30521, val_loss=1.93902, val_acc=0.33333, time=0.09699
Epoch:0044, train_loss=1.88599, train_acc=0.30521, val_loss=1.93902, val_acc=0.32804, time=0.09201
Epoch:0045, train_loss=1.88533, train_acc=0.30521, val_loss=1.93901, val_acc=0.32804, time=0.10399
Epoch:0046, train_loss=1.88467, train_acc=0.30521, val_loss=1.93901, val_acc=0.32804, time=0.12499
Epoch:0047, train_loss=1.88400, train_acc=0.30521, val_loss=1.93901, val_acc=0.32804, time=0.10901
Epoch:0048, train_loss=1.88333, train_acc=0.30521, val_loss=1.93901, val_acc=0.32804, time=0.12699
Epoch:0049, train_loss=1.88266, train_acc=0.30521, val_loss=1.93901, val_acc=0.32804, time=0.08701
Epoch:0050, train_loss=1.88198, train_acc=0.30521, val_loss=1.93902, val_acc=0.32804, time=0.09701
Epoch:0051, train_loss=1.88130, train_acc=0.30580, val_loss=1.93902, val_acc=0.32804, time=0.09800
Epoch:0052, train_loss=1.88062, train_acc=0.30639, val_loss=1.93902, val_acc=0.32804, time=0.11101
Early stopping...

Optimization Finished!

Test set results: loss= 1.92869, accuracy= 0.28448, time= 0.02401

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000       140
           1     0.0000    0.0000    0.0000        45
           2     0.3529    0.0496    0.0870       121
           3     0.0000    0.0000    0.0000        92
           4     0.0000    0.0000    0.0000       116
           5     0.0000    0.0000    0.0000        65
           6     0.2845    0.9657    0.4395       233

    accuracy                         0.2845       812
   macro avg     0.0911    0.1450    0.0752       812
weighted avg     0.1342    0.2845    0.1391       812


Macro average Test Precision, Recall and F1-Score...
(0.09105589138310191, 0.14503600184442947, 0.07520137810559005, None)

Micro average Test Precision, Recall and F1-Score...
(0.28448275862068967, 0.28448275862068967, 0.28448275862068967, None)

Embeddings:
Word_embeddings:1343
Train_doc_embeddings:1896
Test_doc_embeddings:812
