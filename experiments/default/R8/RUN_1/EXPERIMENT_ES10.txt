
==========: 241402103301500
Epoch:0001, train_loss=2.05778, train_acc=0.25238, val_loss=2.05740, val_acc=0.71533, time=1.37600
Epoch:0002, train_loss=1.89268, train_acc=0.69253, val_loss=2.04602, val_acc=0.76825, time=1.25799
Epoch:0003, train_loss=1.79151, train_acc=0.75673, val_loss=2.03935, val_acc=0.77920, time=1.23801
Epoch:0004, train_loss=1.73229, train_acc=0.77233, val_loss=2.03477, val_acc=0.79562, time=1.24401
Epoch:0005, train_loss=1.69191, train_acc=0.78388, val_loss=2.03107, val_acc=0.80657, time=1.23601
Epoch:0006, train_loss=1.65912, train_acc=0.78833, val_loss=2.02782, val_acc=0.81204, time=1.12100
Epoch:0007, train_loss=1.62962, train_acc=0.79785, val_loss=2.02491, val_acc=0.82847, time=1.22400
Epoch:0008, train_loss=1.60221, train_acc=0.81406, val_loss=2.02239, val_acc=0.85584, time=1.23100
Epoch:0009, train_loss=1.57773, train_acc=0.84424, val_loss=2.02034, val_acc=0.89234, time=1.24002
Epoch:0010, train_loss=1.55730, train_acc=0.87827, val_loss=2.01877, val_acc=0.91423, time=1.23600
Epoch:0011, train_loss=1.54125, train_acc=0.90480, val_loss=2.01756, val_acc=0.92336, time=1.04601
Epoch:0012, train_loss=1.52880, train_acc=0.92080, val_loss=2.01659, val_acc=0.92701, time=1.17501
Epoch:0013, train_loss=1.51874, train_acc=0.93133, val_loss=2.01576, val_acc=0.93796, time=1.12000
Epoch:0014, train_loss=1.51005, train_acc=0.94085, val_loss=2.01501, val_acc=0.94526, time=1.18501
Epoch:0015, train_loss=1.50215, train_acc=0.94389, val_loss=2.01432, val_acc=0.94343, time=1.18999
Epoch:0016, train_loss=1.49483, train_acc=0.94693, val_loss=2.01371, val_acc=0.94343, time=1.17100
Epoch:0017, train_loss=1.48807, train_acc=0.95118, val_loss=2.01317, val_acc=0.95073, time=1.21101
Epoch:0018, train_loss=1.48195, train_acc=0.95625, val_loss=2.01271, val_acc=0.95255, time=1.20701
Epoch:0019, train_loss=1.47649, train_acc=0.95827, val_loss=2.01233, val_acc=0.94891, time=1.18301
Epoch:0020, train_loss=1.47167, train_acc=0.95989, val_loss=2.01202, val_acc=0.95073, time=1.17400
Epoch:0021, train_loss=1.46743, train_acc=0.96192, val_loss=2.01176, val_acc=0.95255, time=1.07300
Epoch:0022, train_loss=1.46369, train_acc=0.96395, val_loss=2.01153, val_acc=0.95438, time=1.22101
Epoch:0023, train_loss=1.46034, train_acc=0.96597, val_loss=2.01132, val_acc=0.95803, time=1.11101
Epoch:0024, train_loss=1.45730, train_acc=0.96800, val_loss=2.01111, val_acc=0.95255, time=1.21700
Epoch:0025, train_loss=1.45449, train_acc=0.97022, val_loss=2.01090, val_acc=0.95255, time=1.15601
Epoch:0026, train_loss=1.45191, train_acc=0.97205, val_loss=2.01070, val_acc=0.95620, time=1.12700
Epoch:0027, train_loss=1.44956, train_acc=0.97306, val_loss=2.01050, val_acc=0.95803, time=1.11600
Epoch:0028, train_loss=1.44741, train_acc=0.97590, val_loss=2.01031, val_acc=0.95803, time=1.26201
Epoch:0029, train_loss=1.44543, train_acc=0.97833, val_loss=2.01014, val_acc=0.95985, time=1.24000
Epoch:0030, train_loss=1.44363, train_acc=0.97995, val_loss=2.00998, val_acc=0.96350, time=1.13601
Epoch:0031, train_loss=1.44197, train_acc=0.98015, val_loss=2.00984, val_acc=0.95438, time=1.16002
Epoch:0032, train_loss=1.44046, train_acc=0.98076, val_loss=2.00972, val_acc=0.95438, time=1.17900
Epoch:0033, train_loss=1.43909, train_acc=0.98137, val_loss=2.00962, val_acc=0.95438, time=1.16101
Epoch:0034, train_loss=1.43783, train_acc=0.98197, val_loss=2.00954, val_acc=0.95255, time=1.12600
Epoch:0035, train_loss=1.43667, train_acc=0.98299, val_loss=2.00947, val_acc=0.95255, time=1.19801
Epoch:0036, train_loss=1.43560, train_acc=0.98299, val_loss=2.00942, val_acc=0.95438, time=1.28401
Epoch:0037, train_loss=1.43459, train_acc=0.98440, val_loss=2.00938, val_acc=0.95438, time=1.14001
Epoch:0038, train_loss=1.43366, train_acc=0.98521, val_loss=2.00934, val_acc=0.95438, time=1.24500
Epoch:0039, train_loss=1.43278, train_acc=0.98602, val_loss=2.00931, val_acc=0.95985, time=1.29001
Epoch:0040, train_loss=1.43193, train_acc=0.98643, val_loss=2.00927, val_acc=0.95985, time=1.19302
Epoch:0041, train_loss=1.43112, train_acc=0.98704, val_loss=2.00924, val_acc=0.95803, time=1.11202
Epoch:0042, train_loss=1.43034, train_acc=0.98764, val_loss=2.00921, val_acc=0.95620, time=1.29799
Epoch:0043, train_loss=1.42961, train_acc=0.98825, val_loss=2.00919, val_acc=0.95620, time=1.15901
Epoch:0044, train_loss=1.42895, train_acc=0.98845, val_loss=2.00917, val_acc=0.95620, time=1.23901
Epoch:0045, train_loss=1.42833, train_acc=0.98866, val_loss=2.00916, val_acc=0.95620, time=1.19901
Epoch:0046, train_loss=1.42776, train_acc=0.98926, val_loss=2.00915, val_acc=0.95620, time=1.17401
Epoch:0047, train_loss=1.42723, train_acc=0.98987, val_loss=2.00915, val_acc=0.95803, time=1.17599
Epoch:0048, train_loss=1.42672, train_acc=0.99048, val_loss=2.00915, val_acc=0.95620, time=1.19801
Epoch:0049, train_loss=1.42623, train_acc=0.99048, val_loss=2.00915, val_acc=0.95620, time=1.20000
Epoch:0050, train_loss=1.42576, train_acc=0.99089, val_loss=2.00916, val_acc=0.95803, time=1.26000
Epoch:0051, train_loss=1.42531, train_acc=0.99109, val_loss=2.00916, val_acc=0.95803, time=1.20398
Epoch:0052, train_loss=1.42488, train_acc=0.99129, val_loss=2.00915, val_acc=0.95803, time=1.19301
Epoch:0053, train_loss=1.42446, train_acc=0.99190, val_loss=2.00915, val_acc=0.95803, time=1.15501
Epoch:0054, train_loss=1.42405, train_acc=0.99230, val_loss=2.00914, val_acc=0.95985, time=1.15201
Epoch:0055, train_loss=1.42366, train_acc=0.99271, val_loss=2.00913, val_acc=0.95985, time=1.15800
Epoch:0056, train_loss=1.42329, train_acc=0.99332, val_loss=2.00913, val_acc=0.95985, time=1.15700
Epoch:0057, train_loss=1.42294, train_acc=0.99372, val_loss=2.00912, val_acc=0.95985, time=1.14400
Epoch:0058, train_loss=1.42262, train_acc=0.99413, val_loss=2.00911, val_acc=0.95985, time=1.15702
Epoch:0059, train_loss=1.42230, train_acc=0.99473, val_loss=2.00911, val_acc=0.96168, time=1.17999
Epoch:0060, train_loss=1.42200, train_acc=0.99494, val_loss=2.00911, val_acc=0.96168, time=1.19101
Epoch:0061, train_loss=1.42171, train_acc=0.99494, val_loss=2.00911, val_acc=0.96168, time=1.16501
Epoch:0062, train_loss=1.42144, train_acc=0.99494, val_loss=2.00911, val_acc=0.96350, time=1.24000
Epoch:0063, train_loss=1.42117, train_acc=0.99494, val_loss=2.00912, val_acc=0.96350, time=1.15800
Epoch:0064, train_loss=1.42092, train_acc=0.99514, val_loss=2.00912, val_acc=0.96350, time=1.32401
Epoch:0065, train_loss=1.42067, train_acc=0.99554, val_loss=2.00912, val_acc=0.96168, time=1.15199
Early stopping...

Optimization Finished!

Test set results: loss= 1.79838, accuracy= 0.96985, time= 0.34902

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8681    0.9080    0.8876        87
           1     0.9799    0.9917    0.9858      1083
           2     0.9839    0.9670    0.9754       696
           3     1.0000    1.0000    1.0000        10
           4     0.9024    0.9867    0.9427        75
           5     0.9516    0.9752    0.9633       121
           6     0.9630    0.7222    0.8254        36
           7     0.9200    0.8519    0.8846        81

    accuracy                         0.9698      2189
   macro avg     0.9461    0.9253    0.9331      2189
weighted avg     0.9701    0.9698    0.9695      2189


Macro average Test Precision, Recall and F1-Score...
(0.9461239868331404, 0.9253296378754386, 0.9330910917686674, None)

Micro average Test Precision, Recall and F1-Score...
(0.9698492462311558, 0.9698492462311558, 0.9698492462311558, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
