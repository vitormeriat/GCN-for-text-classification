
==========: 254501249188100
Epoch:0001, train_loss=2.10902, train_acc=0.03990, val_loss=2.06257, val_acc=0.57117, time=1.23901
Epoch:0002, train_loss=1.93006, train_acc=0.59125, val_loss=2.04952, val_acc=0.64599, time=1.16600
Epoch:0003, train_loss=1.81769, train_acc=0.65526, val_loss=2.04161, val_acc=0.72445, time=1.26801
Epoch:0004, train_loss=1.75018, train_acc=0.72595, val_loss=2.03662, val_acc=0.78102, time=1.18201
Epoch:0005, train_loss=1.70767, train_acc=0.76504, val_loss=2.03295, val_acc=0.79380, time=1.29601
Epoch:0006, train_loss=1.67548, train_acc=0.77760, val_loss=2.02982, val_acc=0.80657, time=1.17501
Epoch:0007, train_loss=1.64673, train_acc=0.78590, val_loss=2.02699, val_acc=0.81752, time=1.22400
Epoch:0008, train_loss=1.61984, train_acc=0.80494, val_loss=2.02454, val_acc=0.84307, time=1.28301
Epoch:0009, train_loss=1.59605, train_acc=0.83492, val_loss=2.02254, val_acc=0.87409, time=1.14701
Epoch:0010, train_loss=1.57635, train_acc=0.86064, val_loss=2.02092, val_acc=0.88321, time=1.26102
Epoch:0011, train_loss=1.56025, train_acc=0.87746, val_loss=2.01955, val_acc=0.89781, time=1.18103
Epoch:0012, train_loss=1.54649, train_acc=0.89407, val_loss=2.01835, val_acc=0.90876, time=1.22400
Epoch:0013, train_loss=1.53444, train_acc=0.90743, val_loss=2.01732, val_acc=0.92701, time=1.26701
Epoch:0014, train_loss=1.52398, train_acc=0.92263, val_loss=2.01646, val_acc=0.93248, time=1.24499
Epoch:0015, train_loss=1.51513, train_acc=0.93599, val_loss=2.01575, val_acc=0.93978, time=1.22102
Epoch:0016, train_loss=1.50769, train_acc=0.94085, val_loss=2.01515, val_acc=0.93796, time=1.30100
Epoch:0017, train_loss=1.50128, train_acc=0.94612, val_loss=2.01462, val_acc=0.93978, time=1.17000
Epoch:0018, train_loss=1.49551, train_acc=0.94835, val_loss=2.01413, val_acc=0.94526, time=1.19100
Epoch:0019, train_loss=1.49008, train_acc=0.95017, val_loss=2.01367, val_acc=0.94526, time=1.26402
Epoch:0020, train_loss=1.48482, train_acc=0.95281, val_loss=2.01324, val_acc=0.94161, time=1.23500
Epoch:0021, train_loss=1.47976, train_acc=0.95524, val_loss=2.01285, val_acc=0.94343, time=1.27101
Epoch:0022, train_loss=1.47500, train_acc=0.95605, val_loss=2.01250, val_acc=0.94526, time=1.16401
Epoch:0023, train_loss=1.47066, train_acc=0.95706, val_loss=2.01221, val_acc=0.94708, time=1.20701
Epoch:0024, train_loss=1.46678, train_acc=0.95949, val_loss=2.01195, val_acc=0.94891, time=1.30600
Epoch:0025, train_loss=1.46334, train_acc=0.96253, val_loss=2.01171, val_acc=0.94708, time=1.26101
Epoch:0026, train_loss=1.46026, train_acc=0.96435, val_loss=2.01149, val_acc=0.94526, time=1.16501
Epoch:0027, train_loss=1.45741, train_acc=0.96617, val_loss=2.01127, val_acc=0.94891, time=1.28799
Epoch:0028, train_loss=1.45471, train_acc=0.96739, val_loss=2.01105, val_acc=0.94891, time=1.16402
Epoch:0029, train_loss=1.45214, train_acc=0.96881, val_loss=2.01084, val_acc=0.95073, time=1.16099
Epoch:0030, train_loss=1.44974, train_acc=0.97043, val_loss=2.01065, val_acc=0.95255, time=1.23700
Epoch:0031, train_loss=1.44757, train_acc=0.97529, val_loss=2.01049, val_acc=0.95438, time=1.30301
Epoch:0032, train_loss=1.44568, train_acc=0.97650, val_loss=2.01037, val_acc=0.95620, time=1.19500
Epoch:0033, train_loss=1.44406, train_acc=0.97671, val_loss=2.01027, val_acc=0.95620, time=1.15601
Epoch:0034, train_loss=1.44268, train_acc=0.97954, val_loss=2.01019, val_acc=0.95803, time=1.27300
Epoch:0035, train_loss=1.44145, train_acc=0.97934, val_loss=2.01012, val_acc=0.95620, time=1.25600
Epoch:0036, train_loss=1.44031, train_acc=0.97995, val_loss=2.01006, val_acc=0.95620, time=1.21600
Epoch:0037, train_loss=1.43922, train_acc=0.98096, val_loss=2.01001, val_acc=0.95438, time=1.14701
Epoch:0038, train_loss=1.43815, train_acc=0.98177, val_loss=2.00995, val_acc=0.95438, time=1.17401
Epoch:0039, train_loss=1.43709, train_acc=0.98218, val_loss=2.00990, val_acc=0.95255, time=1.12802
Epoch:0040, train_loss=1.43608, train_acc=0.98238, val_loss=2.00985, val_acc=0.95438, time=1.21201
Epoch:0041, train_loss=1.43513, train_acc=0.98319, val_loss=2.00981, val_acc=0.95803, time=1.15800
Epoch:0042, train_loss=1.43426, train_acc=0.98400, val_loss=2.00976, val_acc=0.95620, time=1.18802
Epoch:0043, train_loss=1.43345, train_acc=0.98400, val_loss=2.00972, val_acc=0.95620, time=1.08402
Epoch:0044, train_loss=1.43270, train_acc=0.98461, val_loss=2.00968, val_acc=0.95620, time=1.22501
Epoch:0045, train_loss=1.43198, train_acc=0.98542, val_loss=2.00963, val_acc=0.95620, time=1.15600
Epoch:0046, train_loss=1.43128, train_acc=0.98643, val_loss=2.00959, val_acc=0.95803, time=1.17801
Epoch:0047, train_loss=1.43059, train_acc=0.98683, val_loss=2.00955, val_acc=0.95985, time=1.17001
Epoch:0048, train_loss=1.42994, train_acc=0.98805, val_loss=2.00951, val_acc=0.96350, time=1.12100
Epoch:0049, train_loss=1.42933, train_acc=0.98845, val_loss=2.00948, val_acc=0.96350, time=1.13201
Epoch:0050, train_loss=1.42876, train_acc=0.98886, val_loss=2.00946, val_acc=0.96533, time=1.20601
Epoch:0051, train_loss=1.42824, train_acc=0.98926, val_loss=2.00944, val_acc=0.96350, time=1.23300
Epoch:0052, train_loss=1.42776, train_acc=0.98926, val_loss=2.00943, val_acc=0.96350, time=1.26000
Epoch:0053, train_loss=1.42730, train_acc=0.98947, val_loss=2.00942, val_acc=0.96350, time=1.23601
Epoch:0054, train_loss=1.42686, train_acc=0.99048, val_loss=2.00942, val_acc=0.96350, time=1.14502
Epoch:0055, train_loss=1.42644, train_acc=0.99068, val_loss=2.00941, val_acc=0.96350, time=1.31601
Epoch:0056, train_loss=1.42602, train_acc=0.99068, val_loss=2.00941, val_acc=0.96350, time=1.23499
Epoch:0057, train_loss=1.42561, train_acc=0.99048, val_loss=2.00940, val_acc=0.96350, time=1.28101
Epoch:0058, train_loss=1.42522, train_acc=0.99068, val_loss=2.00939, val_acc=0.96533, time=1.10501
Epoch:0059, train_loss=1.42484, train_acc=0.99129, val_loss=2.00939, val_acc=0.96533, time=1.18801
Epoch:0060, train_loss=1.42448, train_acc=0.99170, val_loss=2.00938, val_acc=0.96533, time=1.23501
Epoch:0061, train_loss=1.42413, train_acc=0.99210, val_loss=2.00937, val_acc=0.96350, time=1.26701
Epoch:0062, train_loss=1.42381, train_acc=0.99251, val_loss=2.00936, val_acc=0.96350, time=1.29000
Epoch:0063, train_loss=1.42349, train_acc=0.99291, val_loss=2.00936, val_acc=0.96350, time=1.25200
Epoch:0064, train_loss=1.42318, train_acc=0.99311, val_loss=2.00935, val_acc=0.96168, time=1.11401
Epoch:0065, train_loss=1.42288, train_acc=0.99372, val_loss=2.00935, val_acc=0.96168, time=1.27301
Epoch:0066, train_loss=1.42259, train_acc=0.99413, val_loss=2.00935, val_acc=0.96168, time=1.14301
Epoch:0067, train_loss=1.42231, train_acc=0.99433, val_loss=2.00935, val_acc=0.96168, time=1.19400
Epoch:0068, train_loss=1.42204, train_acc=0.99453, val_loss=2.00936, val_acc=0.95985, time=1.17200
Epoch:0069, train_loss=1.42178, train_acc=0.99453, val_loss=2.00936, val_acc=0.95985, time=1.22401
Epoch:0070, train_loss=1.42153, train_acc=0.99453, val_loss=2.00936, val_acc=0.95985, time=1.19402
Early stopping...

Optimization Finished!

Test set results: loss= 1.79814, accuracy= 0.97076, time= 0.36900

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8681    0.9080    0.8876        87
           1     0.9817    0.9917    0.9867      1083
           2     0.9840    0.9713    0.9776       696
           3     1.0000    1.0000    1.0000        10
           4     0.9125    0.9733    0.9419        75
           5     0.9444    0.9835    0.9636       121
           6     1.0000    0.6944    0.8197        36
           7     0.9079    0.8519    0.8790        81

    accuracy                         0.9708      2189
   macro avg     0.9498    0.9218    0.9320      2189
weighted avg     0.9711    0.9708    0.9704      2189


Macro average Test Precision, Recall and F1-Score...
(0.9498347336171022, 0.9217625999412378, 0.9320069481729552, None)

Micro average Test Precision, Recall and F1-Score...
(0.9707629054362723, 0.9707629054362723, 0.9707629054362723, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
