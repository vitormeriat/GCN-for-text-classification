
==========: 242971647641100
Epoch:0001, train_loss=2.05709, train_acc=0.15252, val_loss=2.06541, val_acc=0.48540, time=1.38902
Epoch:0002, train_loss=1.96695, train_acc=0.46040, val_loss=2.05715, val_acc=0.70620, time=1.18401
Epoch:0003, train_loss=1.89381, train_acc=0.67328, val_loss=2.05057, val_acc=0.77737, time=1.16401
Epoch:0004, train_loss=1.83518, train_acc=0.73709, val_loss=2.04538, val_acc=0.80292, time=1.21101
Epoch:0005, train_loss=1.78830, train_acc=0.76544, val_loss=2.04129, val_acc=0.80109, time=1.18102
Epoch:0006, train_loss=1.75110, train_acc=0.77415, val_loss=2.03799, val_acc=0.80109, time=1.21701
Epoch:0007, train_loss=1.72101, train_acc=0.77983, val_loss=2.03523, val_acc=0.79745, time=1.14702
Epoch:0008, train_loss=1.69577, train_acc=0.78610, val_loss=2.03279, val_acc=0.80657, time=1.25102
Epoch:0009, train_loss=1.67365, train_acc=0.79036, val_loss=2.03058, val_acc=0.81387, time=1.13900
Epoch:0010, train_loss=1.65368, train_acc=0.79481, val_loss=2.02855, val_acc=0.82299, time=1.20099
Epoch:0011, train_loss=1.63541, train_acc=0.80373, val_loss=2.02670, val_acc=0.82664, time=1.20200
Epoch:0012, train_loss=1.61865, train_acc=0.81932, val_loss=2.02502, val_acc=0.84489, time=1.13599
Epoch:0013, train_loss=1.60332, train_acc=0.83289, val_loss=2.02352, val_acc=0.87044, time=1.19401
Epoch:0014, train_loss=1.58942, train_acc=0.84788, val_loss=2.02219, val_acc=0.88504, time=1.23401
Epoch:0015, train_loss=1.57693, train_acc=0.86024, val_loss=2.02103, val_acc=0.89234, time=1.19700
Epoch:0016, train_loss=1.56579, train_acc=0.87199, val_loss=2.02003, val_acc=0.90693, time=1.23801
Epoch:0017, train_loss=1.55589, train_acc=0.88596, val_loss=2.01916, val_acc=0.91788, time=1.11000
Epoch:0018, train_loss=1.54711, train_acc=0.89832, val_loss=2.01839, val_acc=0.92336, time=1.33202
Epoch:0019, train_loss=1.53928, train_acc=0.91027, val_loss=2.01773, val_acc=0.93248, time=1.17901
Epoch:0020, train_loss=1.53229, train_acc=0.91979, val_loss=2.01714, val_acc=0.93613, time=1.20099
Epoch:0021, train_loss=1.52603, train_acc=0.92830, val_loss=2.01662, val_acc=0.93796, time=1.13500
Epoch:0022, train_loss=1.52036, train_acc=0.93356, val_loss=2.01615, val_acc=0.94343, time=1.18600
Epoch:0023, train_loss=1.51517, train_acc=0.93863, val_loss=2.01571, val_acc=0.94343, time=1.17800
Epoch:0024, train_loss=1.51034, train_acc=0.94126, val_loss=2.01531, val_acc=0.94161, time=1.21401
Epoch:0025, train_loss=1.50579, train_acc=0.94592, val_loss=2.01492, val_acc=0.94161, time=1.25902
Epoch:0026, train_loss=1.50149, train_acc=0.94794, val_loss=2.01456, val_acc=0.94343, time=1.24500
Epoch:0027, train_loss=1.49742, train_acc=0.94977, val_loss=2.01423, val_acc=0.94343, time=1.23501
Epoch:0028, train_loss=1.49357, train_acc=0.95220, val_loss=2.01391, val_acc=0.94891, time=1.19600
Epoch:0029, train_loss=1.48995, train_acc=0.95402, val_loss=2.01361, val_acc=0.94526, time=1.27201
Epoch:0030, train_loss=1.48651, train_acc=0.95524, val_loss=2.01332, val_acc=0.94526, time=1.24900
Epoch:0031, train_loss=1.48323, train_acc=0.95625, val_loss=2.01305, val_acc=0.94526, time=1.25702
Epoch:0032, train_loss=1.48009, train_acc=0.95706, val_loss=2.01279, val_acc=0.94526, time=1.18301
Epoch:0033, train_loss=1.47710, train_acc=0.95888, val_loss=2.01255, val_acc=0.94526, time=1.21802
Epoch:0034, train_loss=1.47427, train_acc=0.96010, val_loss=2.01232, val_acc=0.94891, time=1.27800
Epoch:0035, train_loss=1.47162, train_acc=0.96152, val_loss=2.01212, val_acc=0.95073, time=1.18302
Epoch:0036, train_loss=1.46914, train_acc=0.96314, val_loss=2.01193, val_acc=0.95073, time=1.26301
Epoch:0037, train_loss=1.46686, train_acc=0.96374, val_loss=2.01176, val_acc=0.95073, time=1.16801
Epoch:0038, train_loss=1.46475, train_acc=0.96374, val_loss=2.01160, val_acc=0.94343, time=1.18901
Epoch:0039, train_loss=1.46281, train_acc=0.96435, val_loss=2.01145, val_acc=0.94526, time=1.25101
Epoch:0040, train_loss=1.46099, train_acc=0.96577, val_loss=2.01132, val_acc=0.94708, time=1.30800
Epoch:0041, train_loss=1.45929, train_acc=0.96759, val_loss=2.01119, val_acc=0.94891, time=1.17300
Epoch:0042, train_loss=1.45767, train_acc=0.96881, val_loss=2.01107, val_acc=0.94891, time=1.24200
Epoch:0043, train_loss=1.45612, train_acc=0.97043, val_loss=2.01095, val_acc=0.94891, time=1.17202
Epoch:0044, train_loss=1.45464, train_acc=0.97124, val_loss=2.01084, val_acc=0.94708, time=1.23401
Epoch:0045, train_loss=1.45322, train_acc=0.97367, val_loss=2.01074, val_acc=0.95073, time=1.21500
Epoch:0046, train_loss=1.45187, train_acc=0.97549, val_loss=2.01065, val_acc=0.95438, time=1.24101
Epoch:0047, train_loss=1.45059, train_acc=0.97731, val_loss=2.01056, val_acc=0.95985, time=1.22102
Epoch:0048, train_loss=1.44940, train_acc=0.97853, val_loss=2.01048, val_acc=0.96168, time=1.15601
Epoch:0049, train_loss=1.44827, train_acc=0.97954, val_loss=2.01040, val_acc=0.95985, time=1.10201
Epoch:0050, train_loss=1.44721, train_acc=0.97995, val_loss=2.01033, val_acc=0.95985, time=1.21000
Epoch:0051, train_loss=1.44621, train_acc=0.98096, val_loss=2.01027, val_acc=0.95803, time=1.22100
Epoch:0052, train_loss=1.44525, train_acc=0.98137, val_loss=2.01021, val_acc=0.95985, time=1.21800
Epoch:0053, train_loss=1.44433, train_acc=0.98218, val_loss=2.01015, val_acc=0.95803, time=1.18503
Epoch:0054, train_loss=1.44346, train_acc=0.98197, val_loss=2.01010, val_acc=0.95803, time=1.29999
Epoch:0055, train_loss=1.44262, train_acc=0.98218, val_loss=2.01005, val_acc=0.95803, time=1.26001
Epoch:0056, train_loss=1.44183, train_acc=0.98258, val_loss=2.01000, val_acc=0.95803, time=1.15801
Epoch:0057, train_loss=1.44108, train_acc=0.98339, val_loss=2.00995, val_acc=0.95620, time=1.29300
Epoch:0058, train_loss=1.44036, train_acc=0.98319, val_loss=2.00990, val_acc=0.95803, time=1.25400
Epoch:0059, train_loss=1.43967, train_acc=0.98380, val_loss=2.00986, val_acc=0.95803, time=1.10800
Epoch:0060, train_loss=1.43900, train_acc=0.98380, val_loss=2.00981, val_acc=0.95985, time=1.26199
Epoch:0061, train_loss=1.43836, train_acc=0.98440, val_loss=2.00977, val_acc=0.95985, time=1.23501
Epoch:0062, train_loss=1.43773, train_acc=0.98481, val_loss=2.00973, val_acc=0.96350, time=1.25001
Epoch:0063, train_loss=1.43713, train_acc=0.98542, val_loss=2.00969, val_acc=0.96350, time=1.32101
Epoch:0064, train_loss=1.43656, train_acc=0.98582, val_loss=2.00966, val_acc=0.96350, time=1.13301
Epoch:0065, train_loss=1.43601, train_acc=0.98582, val_loss=2.00963, val_acc=0.96350, time=1.29300
Epoch:0066, train_loss=1.43549, train_acc=0.98643, val_loss=2.00960, val_acc=0.96168, time=1.16000
Epoch:0067, train_loss=1.43498, train_acc=0.98724, val_loss=2.00958, val_acc=0.96168, time=1.25401
Epoch:0068, train_loss=1.43450, train_acc=0.98724, val_loss=2.00956, val_acc=0.96168, time=1.26801
Epoch:0069, train_loss=1.43403, train_acc=0.98744, val_loss=2.00954, val_acc=0.95985, time=1.14702
Epoch:0070, train_loss=1.43357, train_acc=0.98764, val_loss=2.00952, val_acc=0.95985, time=1.16200
Epoch:0071, train_loss=1.43312, train_acc=0.98785, val_loss=2.00951, val_acc=0.96168, time=1.23300
Epoch:0072, train_loss=1.43269, train_acc=0.98845, val_loss=2.00949, val_acc=0.96168, time=1.16200
Epoch:0073, train_loss=1.43227, train_acc=0.98866, val_loss=2.00948, val_acc=0.96168, time=1.16201
Epoch:0074, train_loss=1.43187, train_acc=0.98886, val_loss=2.00946, val_acc=0.96168, time=1.17000
Epoch:0075, train_loss=1.43148, train_acc=0.98906, val_loss=2.00945, val_acc=0.96168, time=1.17402
Epoch:0076, train_loss=1.43110, train_acc=0.98906, val_loss=2.00944, val_acc=0.96168, time=1.22702
Epoch:0077, train_loss=1.43073, train_acc=0.98926, val_loss=2.00942, val_acc=0.96168, time=1.24101
Epoch:0078, train_loss=1.43037, train_acc=0.98947, val_loss=2.00941, val_acc=0.95985, time=1.13399
Epoch:0079, train_loss=1.43002, train_acc=0.99028, val_loss=2.00940, val_acc=0.95985, time=1.16701
Epoch:0080, train_loss=1.42968, train_acc=0.99048, val_loss=2.00938, val_acc=0.95985, time=1.29901
Epoch:0081, train_loss=1.42934, train_acc=0.99089, val_loss=2.00937, val_acc=0.95985, time=1.21200
Epoch:0082, train_loss=1.42902, train_acc=0.99149, val_loss=2.00936, val_acc=0.95985, time=1.18302
Epoch:0083, train_loss=1.42871, train_acc=0.99149, val_loss=2.00935, val_acc=0.95985, time=1.19700
Epoch:0084, train_loss=1.42841, train_acc=0.99149, val_loss=2.00934, val_acc=0.95985, time=1.12700
Epoch:0085, train_loss=1.42811, train_acc=0.99149, val_loss=2.00933, val_acc=0.95985, time=1.27601
Epoch:0086, train_loss=1.42782, train_acc=0.99190, val_loss=2.00932, val_acc=0.95985, time=1.16201
Epoch:0087, train_loss=1.42754, train_acc=0.99190, val_loss=2.00932, val_acc=0.95985, time=1.21402
Epoch:0088, train_loss=1.42726, train_acc=0.99230, val_loss=2.00931, val_acc=0.95985, time=1.20001
Epoch:0089, train_loss=1.42699, train_acc=0.99291, val_loss=2.00930, val_acc=0.95985, time=1.22400
Epoch:0090, train_loss=1.42673, train_acc=0.99291, val_loss=2.00930, val_acc=0.95985, time=1.25599
Epoch:0091, train_loss=1.42647, train_acc=0.99311, val_loss=2.00929, val_acc=0.95985, time=1.17499
Epoch:0092, train_loss=1.42622, train_acc=0.99311, val_loss=2.00928, val_acc=0.95985, time=1.28702
Epoch:0093, train_loss=1.42598, train_acc=0.99332, val_loss=2.00928, val_acc=0.95985, time=1.24301
Epoch:0094, train_loss=1.42574, train_acc=0.99332, val_loss=2.00927, val_acc=0.95985, time=1.24101
Epoch:0095, train_loss=1.42551, train_acc=0.99372, val_loss=2.00926, val_acc=0.95985, time=1.20802
Epoch:0096, train_loss=1.42528, train_acc=0.99392, val_loss=2.00926, val_acc=0.95985, time=1.22902
Epoch:0097, train_loss=1.42505, train_acc=0.99392, val_loss=2.00925, val_acc=0.95985, time=1.17502
Epoch:0098, train_loss=1.42484, train_acc=0.99392, val_loss=2.00925, val_acc=0.95985, time=1.27699
Epoch:0099, train_loss=1.42462, train_acc=0.99413, val_loss=2.00924, val_acc=0.95985, time=1.20300
Epoch:0100, train_loss=1.42441, train_acc=0.99433, val_loss=2.00924, val_acc=0.95985, time=1.17001
Epoch:0101, train_loss=1.42421, train_acc=0.99473, val_loss=2.00923, val_acc=0.96168, time=1.24101
Epoch:0102, train_loss=1.42401, train_acc=0.99494, val_loss=2.00923, val_acc=0.96168, time=1.16801
Epoch:0103, train_loss=1.42381, train_acc=0.99494, val_loss=2.00923, val_acc=0.96168, time=1.30399
Epoch:0104, train_loss=1.42362, train_acc=0.99494, val_loss=2.00923, val_acc=0.96168, time=1.16602
Epoch:0105, train_loss=1.42344, train_acc=0.99554, val_loss=2.00922, val_acc=0.96168, time=1.15599
Epoch:0106, train_loss=1.42325, train_acc=0.99554, val_loss=2.00922, val_acc=0.96168, time=1.23601
Epoch:0107, train_loss=1.42307, train_acc=0.99554, val_loss=2.00922, val_acc=0.96168, time=1.19101
Epoch:0108, train_loss=1.42290, train_acc=0.99554, val_loss=2.00922, val_acc=0.96168, time=1.21800
Epoch:0109, train_loss=1.42273, train_acc=0.99554, val_loss=2.00921, val_acc=0.96168, time=1.19999
Epoch:0110, train_loss=1.42256, train_acc=0.99554, val_loss=2.00921, val_acc=0.96168, time=1.14299
Epoch:0111, train_loss=1.42239, train_acc=0.99554, val_loss=2.00921, val_acc=0.96168, time=1.25100
Epoch:0112, train_loss=1.42223, train_acc=0.99575, val_loss=2.00920, val_acc=0.96168, time=1.35601
Epoch:0113, train_loss=1.42207, train_acc=0.99575, val_loss=2.00920, val_acc=0.96168, time=1.20801
Epoch:0114, train_loss=1.42192, train_acc=0.99575, val_loss=2.00920, val_acc=0.96168, time=1.27601
Epoch:0115, train_loss=1.42176, train_acc=0.99575, val_loss=2.00920, val_acc=0.96168, time=1.25901
Epoch:0116, train_loss=1.42162, train_acc=0.99575, val_loss=2.00920, val_acc=0.96168, time=1.25401
Epoch:0117, train_loss=1.42147, train_acc=0.99575, val_loss=2.00919, val_acc=0.96168, time=1.24999
Epoch:0118, train_loss=1.42133, train_acc=0.99575, val_loss=2.00919, val_acc=0.96168, time=1.15901
Epoch:0119, train_loss=1.42119, train_acc=0.99575, val_loss=2.00919, val_acc=0.96168, time=1.23601
Epoch:0120, train_loss=1.42105, train_acc=0.99575, val_loss=2.00919, val_acc=0.96168, time=1.26700
Epoch:0121, train_loss=1.42091, train_acc=0.99575, val_loss=2.00919, val_acc=0.96168, time=1.24501
Epoch:0122, train_loss=1.42078, train_acc=0.99595, val_loss=2.00919, val_acc=0.96168, time=1.27003
Epoch:0123, train_loss=1.42065, train_acc=0.99615, val_loss=2.00919, val_acc=0.96168, time=1.19001
Epoch:0124, train_loss=1.42052, train_acc=0.99615, val_loss=2.00919, val_acc=0.96168, time=1.18201
Epoch:0125, train_loss=1.42040, train_acc=0.99635, val_loss=2.00919, val_acc=0.96168, time=1.26201
Epoch:0126, train_loss=1.42028, train_acc=0.99635, val_loss=2.00919, val_acc=0.96168, time=1.16601
Epoch:0127, train_loss=1.42016, train_acc=0.99635, val_loss=2.00919, val_acc=0.96168, time=1.24201
Epoch:0128, train_loss=1.42004, train_acc=0.99656, val_loss=2.00919, val_acc=0.96168, time=1.18401
Epoch:0129, train_loss=1.41993, train_acc=0.99656, val_loss=2.00919, val_acc=0.96168, time=1.20901
Epoch:0130, train_loss=1.41981, train_acc=0.99656, val_loss=2.00919, val_acc=0.96168, time=1.23700
Epoch:0131, train_loss=1.41970, train_acc=0.99656, val_loss=2.00918, val_acc=0.96168, time=1.15799
Epoch:0132, train_loss=1.41959, train_acc=0.99676, val_loss=2.00918, val_acc=0.96168, time=1.25100
Epoch:0133, train_loss=1.41949, train_acc=0.99676, val_loss=2.00918, val_acc=0.96168, time=1.21502
Epoch:0134, train_loss=1.41938, train_acc=0.99676, val_loss=2.00918, val_acc=0.96168, time=1.24601
Epoch:0135, train_loss=1.41928, train_acc=0.99696, val_loss=2.00918, val_acc=0.96168, time=1.17500
Epoch:0136, train_loss=1.41918, train_acc=0.99696, val_loss=2.00918, val_acc=0.96168, time=1.26600
Epoch:0137, train_loss=1.41908, train_acc=0.99696, val_loss=2.00918, val_acc=0.96168, time=1.23101
Epoch:0138, train_loss=1.41898, train_acc=0.99696, val_loss=2.00918, val_acc=0.96168, time=1.14001
Epoch:0139, train_loss=1.41889, train_acc=0.99716, val_loss=2.00918, val_acc=0.96168, time=1.23100
Epoch:0140, train_loss=1.41879, train_acc=0.99716, val_loss=2.00918, val_acc=0.96168, time=1.24303
Epoch:0141, train_loss=1.41870, train_acc=0.99716, val_loss=2.00918, val_acc=0.96168, time=1.32399
Epoch:0142, train_loss=1.41861, train_acc=0.99716, val_loss=2.00918, val_acc=0.95985, time=1.18402
Epoch:0143, train_loss=1.41852, train_acc=0.99716, val_loss=2.00918, val_acc=0.95985, time=1.29201
Epoch:0144, train_loss=1.41843, train_acc=0.99716, val_loss=2.00918, val_acc=0.95985, time=1.12899
Epoch:0145, train_loss=1.41835, train_acc=0.99716, val_loss=2.00918, val_acc=0.95985, time=1.15201
Epoch:0146, train_loss=1.41827, train_acc=0.99716, val_loss=2.00918, val_acc=0.95985, time=1.14701
Early stopping...

Optimization Finished!

Test set results: loss= 1.79866, accuracy= 0.97031, time= 0.37501

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8791    0.9195    0.8989        87
           1     0.9790    0.9917    0.9853      1083
           2     0.9839    0.9655    0.9746       696
           3     1.0000    1.0000    1.0000        10
           4     0.9024    0.9867    0.9427        75
           5     0.9516    0.9752    0.9633       121
           6     0.9630    0.7222    0.8254        36
           7     0.9333    0.8642    0.8974        81

    accuracy                         0.9703      2189
   macro avg     0.9490    0.9281    0.9359      2189
weighted avg     0.9706    0.9703    0.9700      2189


Macro average Test Precision, Recall and F1-Score...
(0.9490496767633189, 0.9281300316600278, 0.9359487478678444, None)

Micro average Test Precision, Recall and F1-Score...
(0.970306075833714, 0.970306075833714, 0.970306075833714, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
