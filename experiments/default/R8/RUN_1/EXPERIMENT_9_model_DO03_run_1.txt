
==========: 37259945740400
Epoch:0001, train_loss=2.16230, train_acc=0.01438, val_loss=2.06559, val_acc=0.68613, time=1.28900
Epoch:0002, train_loss=1.96325, train_acc=0.66376, val_loss=2.05107, val_acc=0.75365, time=1.13801
Epoch:0003, train_loss=1.83539, train_acc=0.74904, val_loss=2.04250, val_acc=0.77372, time=1.17098
Epoch:0004, train_loss=1.76032, train_acc=0.76625, val_loss=2.03722, val_acc=0.78832, time=1.17202
Epoch:0005, train_loss=1.71406, train_acc=0.77861, val_loss=2.03336, val_acc=0.79380, time=1.10300
Epoch:0006, train_loss=1.68010, train_acc=0.78732, val_loss=2.03008, val_acc=0.81022, time=1.20501
Epoch:0007, train_loss=1.65074, train_acc=0.79542, val_loss=2.02714, val_acc=0.82482, time=1.11401
Epoch:0008, train_loss=1.62378, train_acc=0.80980, val_loss=2.02457, val_acc=0.85036, time=1.17000
Epoch:0009, train_loss=1.59975, train_acc=0.83654, val_loss=2.02248, val_acc=0.87774, time=1.07001
Epoch:0010, train_loss=1.57968, train_acc=0.86064, val_loss=2.02085, val_acc=0.89599, time=1.04701
Epoch:0011, train_loss=1.56362, train_acc=0.88232, val_loss=2.01955, val_acc=0.90328, time=1.08101
Epoch:0012, train_loss=1.55057, train_acc=0.89488, val_loss=2.01847, val_acc=0.91058, time=1.06900
Epoch:0013, train_loss=1.53940, train_acc=0.90683, val_loss=2.01755, val_acc=0.92153, time=1.16001
Epoch:0014, train_loss=1.52959, train_acc=0.91756, val_loss=2.01677, val_acc=0.93248, time=1.02300
Epoch:0015, train_loss=1.52105, train_acc=0.92890, val_loss=2.01611, val_acc=0.92701, time=1.03302
Epoch:0016, train_loss=1.51370, train_acc=0.93377, val_loss=2.01554, val_acc=0.92518, time=1.05401
Epoch:0017, train_loss=1.50720, train_acc=0.93721, val_loss=2.01499, val_acc=0.92336, time=1.19000
Epoch:0018, train_loss=1.50102, train_acc=0.93964, val_loss=2.01444, val_acc=0.92336, time=1.08300
Epoch:0019, train_loss=1.49484, train_acc=0.94227, val_loss=2.01389, val_acc=0.93066, time=0.98702
Epoch:0020, train_loss=1.48874, train_acc=0.94612, val_loss=2.01338, val_acc=0.93978, time=1.19801
Epoch:0021, train_loss=1.48306, train_acc=0.95078, val_loss=2.01294, val_acc=0.94343, time=1.00601
Epoch:0022, train_loss=1.47809, train_acc=0.95341, val_loss=2.01258, val_acc=0.94526, time=1.06101
Epoch:0023, train_loss=1.47397, train_acc=0.95544, val_loss=2.01230, val_acc=0.94526, time=1.21900
Epoch:0024, train_loss=1.47061, train_acc=0.95605, val_loss=2.01207, val_acc=0.94708, time=1.04301
Epoch:0025, train_loss=1.46775, train_acc=0.95625, val_loss=2.01186, val_acc=0.94526, time=1.08601
Epoch:0026, train_loss=1.46514, train_acc=0.95686, val_loss=2.01166, val_acc=0.94526, time=1.02301
Epoch:0027, train_loss=1.46255, train_acc=0.95908, val_loss=2.01145, val_acc=0.94708, time=1.10701
Epoch:0028, train_loss=1.45987, train_acc=0.96212, val_loss=2.01122, val_acc=0.94708, time=1.13300
Epoch:0029, train_loss=1.45709, train_acc=0.96395, val_loss=2.01100, val_acc=0.94891, time=1.23501
Epoch:0030, train_loss=1.45432, train_acc=0.96577, val_loss=2.01079, val_acc=0.95073, time=0.95900
Epoch:0031, train_loss=1.45168, train_acc=0.96881, val_loss=2.01060, val_acc=0.95438, time=1.19300
Epoch:0032, train_loss=1.44927, train_acc=0.97063, val_loss=2.01044, val_acc=0.95255, time=1.14900
Epoch:0033, train_loss=1.44716, train_acc=0.97428, val_loss=2.01031, val_acc=0.95620, time=1.07402
Epoch:0034, train_loss=1.44535, train_acc=0.97549, val_loss=2.01022, val_acc=0.95620, time=1.02602
Epoch:0035, train_loss=1.44382, train_acc=0.97691, val_loss=2.01014, val_acc=0.95620, time=1.09300
Epoch:0036, train_loss=1.44250, train_acc=0.97812, val_loss=2.01007, val_acc=0.95620, time=1.04300
Epoch:0037, train_loss=1.44134, train_acc=0.97914, val_loss=2.01001, val_acc=0.95438, time=1.04202
Epoch:0038, train_loss=1.44029, train_acc=0.98015, val_loss=2.00994, val_acc=0.95620, time=1.11003
Epoch:0039, train_loss=1.43932, train_acc=0.98096, val_loss=2.00988, val_acc=0.95438, time=1.36201
Epoch:0040, train_loss=1.43839, train_acc=0.98157, val_loss=2.00981, val_acc=0.95803, time=1.12700
Epoch:0041, train_loss=1.43750, train_acc=0.98258, val_loss=2.00975, val_acc=0.95803, time=1.08301
Epoch:0042, train_loss=1.43662, train_acc=0.98278, val_loss=2.00968, val_acc=0.95803, time=1.02801
Epoch:0043, train_loss=1.43576, train_acc=0.98319, val_loss=2.00962, val_acc=0.95620, time=1.01502
Epoch:0044, train_loss=1.43491, train_acc=0.98339, val_loss=2.00957, val_acc=0.95803, time=1.18100
Epoch:0045, train_loss=1.43408, train_acc=0.98319, val_loss=2.00952, val_acc=0.95803, time=0.98100
Epoch:0046, train_loss=1.43328, train_acc=0.98400, val_loss=2.00948, val_acc=0.95803, time=1.06600
Epoch:0047, train_loss=1.43250, train_acc=0.98501, val_loss=2.00944, val_acc=0.95985, time=0.96700
Epoch:0048, train_loss=1.43175, train_acc=0.98562, val_loss=2.00942, val_acc=0.95985, time=1.14900
Epoch:0049, train_loss=1.43105, train_acc=0.98663, val_loss=2.00939, val_acc=0.95985, time=1.24201
Epoch:0050, train_loss=1.43040, train_acc=0.98744, val_loss=2.00938, val_acc=0.96168, time=1.16802
Epoch:0051, train_loss=1.42980, train_acc=0.98825, val_loss=2.00936, val_acc=0.96168, time=1.08401
Epoch:0052, train_loss=1.42925, train_acc=0.98886, val_loss=2.00935, val_acc=0.96168, time=1.12399
Epoch:0053, train_loss=1.42874, train_acc=0.98926, val_loss=2.00934, val_acc=0.96168, time=1.10901
Epoch:0054, train_loss=1.42825, train_acc=0.98967, val_loss=2.00933, val_acc=0.95985, time=1.09501
Epoch:0055, train_loss=1.42778, train_acc=0.98947, val_loss=2.00931, val_acc=0.96168, time=1.15399
Epoch:0056, train_loss=1.42732, train_acc=0.98967, val_loss=2.00930, val_acc=0.96168, time=1.12303
Epoch:0057, train_loss=1.42689, train_acc=0.98967, val_loss=2.00929, val_acc=0.96168, time=1.23100
Epoch:0058, train_loss=1.42647, train_acc=0.99028, val_loss=2.00928, val_acc=0.96350, time=1.15401
Epoch:0059, train_loss=1.42607, train_acc=0.99048, val_loss=2.00927, val_acc=0.96350, time=1.13099
Epoch:0060, train_loss=1.42568, train_acc=0.99048, val_loss=2.00926, val_acc=0.96168, time=1.10000
Epoch:0061, train_loss=1.42531, train_acc=0.99089, val_loss=2.00925, val_acc=0.96168, time=1.17301
Epoch:0062, train_loss=1.42495, train_acc=0.99149, val_loss=2.00924, val_acc=0.96168, time=1.22400
Epoch:0063, train_loss=1.42459, train_acc=0.99170, val_loss=2.00923, val_acc=0.96350, time=1.12502
Epoch:0064, train_loss=1.42425, train_acc=0.99170, val_loss=2.00922, val_acc=0.96350, time=1.17701
Epoch:0065, train_loss=1.42392, train_acc=0.99230, val_loss=2.00922, val_acc=0.96350, time=1.21300
Epoch:0066, train_loss=1.42360, train_acc=0.99230, val_loss=2.00921, val_acc=0.96350, time=1.27102
Epoch:0067, train_loss=1.42329, train_acc=0.99311, val_loss=2.00921, val_acc=0.96350, time=1.13602
Epoch:0068, train_loss=1.42299, train_acc=0.99332, val_loss=2.00921, val_acc=0.96350, time=1.02701
Epoch:0069, train_loss=1.42270, train_acc=0.99413, val_loss=2.00921, val_acc=0.96350, time=1.04903
Epoch:0070, train_loss=1.42243, train_acc=0.99392, val_loss=2.00922, val_acc=0.96350, time=1.04400
Epoch:0071, train_loss=1.42216, train_acc=0.99413, val_loss=2.00922, val_acc=0.96350, time=1.12500
Epoch:0072, train_loss=1.42191, train_acc=0.99473, val_loss=2.00922, val_acc=0.96350, time=1.06799
Early stopping...

Optimization Finished!

Test set results: loss= 1.79889, accuracy= 0.97259, time= 0.31401

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8804    0.9310    0.9050        87
           1     0.9826    0.9926    0.9876      1083
           2     0.9826    0.9713    0.9769       696
           3     1.0000    1.0000    1.0000        10
           4     0.9136    0.9867    0.9487        75
           5     0.9516    0.9752    0.9633       121
           6     1.0000    0.6944    0.8197        36
           7     0.9333    0.8642    0.8974        81

    accuracy                         0.9726      2189
   macro avg     0.9555    0.9269    0.9373      2189
weighted avg     0.9730    0.9726    0.9722      2189


Macro average Test Precision, Recall and F1-Score...
(0.9555189933437194, 0.9269284019808692, 0.9373244300616645, None)

Micro average Test Precision, Recall and F1-Score...
(0.9725902238465053, 0.9725902238465053, 0.9725902238465053, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
