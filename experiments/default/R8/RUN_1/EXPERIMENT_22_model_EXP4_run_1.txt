
==========: 38302574139400
Epoch:0001, train_loss=2.13420, train_acc=0.01620, val_loss=2.06455, val_acc=0.67701, time=1.41401
Epoch:0002, train_loss=1.95252, train_acc=0.63824, val_loss=2.05074, val_acc=0.72080, time=1.25501
Epoch:0003, train_loss=1.83200, train_acc=0.68928, val_loss=2.04211, val_acc=0.76460, time=1.16401
Epoch:0004, train_loss=1.75733, train_acc=0.74033, val_loss=2.03671, val_acc=0.79562, time=1.22402
Epoch:0005, train_loss=1.71082, train_acc=0.76929, val_loss=2.03298, val_acc=0.80292, time=1.19399
Epoch:0006, train_loss=1.67819, train_acc=0.78003, val_loss=2.02996, val_acc=0.80839, time=1.15102
Epoch:0007, train_loss=1.65077, train_acc=0.78773, val_loss=2.02725, val_acc=0.81569, time=1.42900
Epoch:0008, train_loss=1.62519, train_acc=0.79866, val_loss=2.02481, val_acc=0.82847, time=1.31701
Epoch:0009, train_loss=1.60167, train_acc=0.82155, val_loss=2.02276, val_acc=0.86496, time=1.05402
Epoch:0010, train_loss=1.58153, train_acc=0.85720, val_loss=2.02114, val_acc=0.88504, time=1.22401
Epoch:0011, train_loss=1.56524, train_acc=0.87584, val_loss=2.01982, val_acc=0.89234, time=1.05901
Epoch:0012, train_loss=1.55188, train_acc=0.89265, val_loss=2.01868, val_acc=0.90693, time=1.20001
Epoch:0013, train_loss=1.54027, train_acc=0.90460, val_loss=2.01767, val_acc=0.92153, time=1.13601
Epoch:0014, train_loss=1.52984, train_acc=0.91655, val_loss=2.01679, val_acc=0.93613, time=1.05101
Epoch:0015, train_loss=1.52055, train_acc=0.92971, val_loss=2.01604, val_acc=0.93613, time=1.36199
Epoch:0016, train_loss=1.51251, train_acc=0.93660, val_loss=2.01541, val_acc=0.93613, time=1.23801
Epoch:0017, train_loss=1.50562, train_acc=0.94004, val_loss=2.01487, val_acc=0.92883, time=1.11200
Epoch:0018, train_loss=1.49954, train_acc=0.94227, val_loss=2.01438, val_acc=0.93066, time=1.14801
Epoch:0019, train_loss=1.49391, train_acc=0.94632, val_loss=2.01392, val_acc=0.93613, time=1.06201
Epoch:0020, train_loss=1.48853, train_acc=0.95078, val_loss=2.01348, val_acc=0.93613, time=1.11501
Epoch:0021, train_loss=1.48341, train_acc=0.95463, val_loss=2.01309, val_acc=0.94161, time=1.10101
Epoch:0022, train_loss=1.47867, train_acc=0.95645, val_loss=2.01274, val_acc=0.94161, time=1.08101
Epoch:0023, train_loss=1.47437, train_acc=0.95767, val_loss=2.01243, val_acc=0.94343, time=1.11701
Epoch:0024, train_loss=1.47053, train_acc=0.95787, val_loss=2.01216, val_acc=0.94343, time=1.13401
Epoch:0025, train_loss=1.46707, train_acc=0.95969, val_loss=2.01191, val_acc=0.94526, time=1.18201
Epoch:0026, train_loss=1.46387, train_acc=0.96050, val_loss=2.01166, val_acc=0.94526, time=1.09003
Epoch:0027, train_loss=1.46084, train_acc=0.96212, val_loss=2.01142, val_acc=0.94708, time=1.05401
Epoch:0028, train_loss=1.45790, train_acc=0.96557, val_loss=2.01118, val_acc=0.94891, time=1.11800
Epoch:0029, train_loss=1.45506, train_acc=0.96739, val_loss=2.01095, val_acc=0.95073, time=1.12201
Epoch:0030, train_loss=1.45237, train_acc=0.96962, val_loss=2.01075, val_acc=0.95255, time=1.08301
Epoch:0031, train_loss=1.44988, train_acc=0.97144, val_loss=2.01057, val_acc=0.94891, time=1.24600
Epoch:0032, train_loss=1.44766, train_acc=0.97245, val_loss=2.01043, val_acc=0.94708, time=1.06300
Epoch:0033, train_loss=1.44570, train_acc=0.97428, val_loss=2.01031, val_acc=0.94891, time=1.08000
Epoch:0034, train_loss=1.44399, train_acc=0.97691, val_loss=2.01022, val_acc=0.94891, time=1.14002
Epoch:0035, train_loss=1.44248, train_acc=0.97833, val_loss=2.01015, val_acc=0.94891, time=1.25301
Epoch:0036, train_loss=1.44115, train_acc=0.97954, val_loss=2.01009, val_acc=0.95073, time=1.00001
Epoch:0037, train_loss=1.43998, train_acc=0.98116, val_loss=2.01004, val_acc=0.95073, time=1.07000
Epoch:0038, train_loss=1.43894, train_acc=0.98076, val_loss=2.00999, val_acc=0.95438, time=1.10002
Epoch:0039, train_loss=1.43798, train_acc=0.98157, val_loss=2.00995, val_acc=0.95255, time=1.23400
Epoch:0040, train_loss=1.43709, train_acc=0.98157, val_loss=2.00990, val_acc=0.95438, time=1.30500
Epoch:0041, train_loss=1.43621, train_acc=0.98218, val_loss=2.00985, val_acc=0.95438, time=1.21800
Epoch:0042, train_loss=1.43533, train_acc=0.98278, val_loss=2.00980, val_acc=0.95620, time=1.09300
Epoch:0043, train_loss=1.43447, train_acc=0.98319, val_loss=2.00975, val_acc=0.95255, time=1.17401
Epoch:0044, train_loss=1.43364, train_acc=0.98319, val_loss=2.00970, val_acc=0.95255, time=1.11302
Epoch:0045, train_loss=1.43285, train_acc=0.98420, val_loss=2.00966, val_acc=0.94891, time=1.13001
Epoch:0046, train_loss=1.43210, train_acc=0.98481, val_loss=2.00962, val_acc=0.94891, time=1.07400
Epoch:0047, train_loss=1.43137, train_acc=0.98521, val_loss=2.00958, val_acc=0.94891, time=1.02102
Epoch:0048, train_loss=1.43067, train_acc=0.98602, val_loss=2.00955, val_acc=0.95255, time=1.20801
Epoch:0049, train_loss=1.43000, train_acc=0.98643, val_loss=2.00952, val_acc=0.95620, time=1.17702
Epoch:0050, train_loss=1.42937, train_acc=0.98744, val_loss=2.00949, val_acc=0.95620, time=0.97001
Epoch:0051, train_loss=1.42878, train_acc=0.98825, val_loss=2.00947, val_acc=0.95985, time=1.04001
Epoch:0052, train_loss=1.42825, train_acc=0.98906, val_loss=2.00946, val_acc=0.96168, time=1.29400
Epoch:0053, train_loss=1.42776, train_acc=0.98906, val_loss=2.00945, val_acc=0.96168, time=1.01701
Epoch:0054, train_loss=1.42731, train_acc=0.99007, val_loss=2.00944, val_acc=0.96168, time=0.99401
Epoch:0055, train_loss=1.42687, train_acc=0.99048, val_loss=2.00943, val_acc=0.96168, time=1.08101
Epoch:0056, train_loss=1.42644, train_acc=0.99068, val_loss=2.00943, val_acc=0.96168, time=1.14401
Epoch:0057, train_loss=1.42601, train_acc=0.99068, val_loss=2.00942, val_acc=0.95985, time=1.00701
Epoch:0058, train_loss=1.42561, train_acc=0.99089, val_loss=2.00941, val_acc=0.95803, time=1.05301
Epoch:0059, train_loss=1.42522, train_acc=0.99149, val_loss=2.00941, val_acc=0.95803, time=1.07802
Epoch:0060, train_loss=1.42485, train_acc=0.99149, val_loss=2.00940, val_acc=0.95803, time=1.28700
Epoch:0061, train_loss=1.42450, train_acc=0.99210, val_loss=2.00939, val_acc=0.95803, time=1.22801
Epoch:0062, train_loss=1.42416, train_acc=0.99230, val_loss=2.00938, val_acc=0.95803, time=1.12901
Epoch:0063, train_loss=1.42383, train_acc=0.99291, val_loss=2.00937, val_acc=0.95803, time=1.18899
Epoch:0064, train_loss=1.42351, train_acc=0.99291, val_loss=2.00936, val_acc=0.95985, time=1.11999
Epoch:0065, train_loss=1.42320, train_acc=0.99291, val_loss=2.00935, val_acc=0.95985, time=1.18701
Epoch:0066, train_loss=1.42291, train_acc=0.99352, val_loss=2.00935, val_acc=0.95985, time=1.02000
Epoch:0067, train_loss=1.42262, train_acc=0.99372, val_loss=2.00934, val_acc=0.96168, time=0.99601
Epoch:0068, train_loss=1.42234, train_acc=0.99392, val_loss=2.00934, val_acc=0.96168, time=1.09102
Epoch:0069, train_loss=1.42207, train_acc=0.99413, val_loss=2.00935, val_acc=0.96168, time=1.32801
Epoch:0070, train_loss=1.42182, train_acc=0.99453, val_loss=2.00935, val_acc=0.96168, time=1.08701
Epoch:0071, train_loss=1.42157, train_acc=0.99494, val_loss=2.00936, val_acc=0.96168, time=1.14801
Epoch:0072, train_loss=1.42133, train_acc=0.99494, val_loss=2.00936, val_acc=0.96168, time=1.05199
Early stopping...

Optimization Finished!

Test set results: loss= 1.79868, accuracy= 0.97122, time= 0.29401

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8804    0.9310    0.9050        87
           1     0.9826    0.9917    0.9871      1083
           2     0.9826    0.9713    0.9769       696
           3     1.0000    1.0000    1.0000        10
           4     0.9012    0.9733    0.9359        75
           5     0.9365    0.9752    0.9555       121
           6     1.0000    0.6944    0.8197        36
           7     0.9324    0.8519    0.8903        81

    accuracy                         0.9712      2189
   macro avg     0.9520    0.9236    0.9338      2189
weighted avg     0.9717    0.9712    0.9708      2189


Macro average Test Precision, Recall and F1-Score...
(0.9519730638004122, 0.9236031053083888, 0.9337995791691882, None)

Micro average Test Precision, Recall and F1-Score...
(0.9712197350388305, 0.9712197350388305, 0.9712197350388305, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
