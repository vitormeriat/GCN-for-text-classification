
==========: 255518398988300
Epoch:0001, train_loss=2.06245, train_acc=0.13186, val_loss=2.05909, val_acc=0.71898, time=1.11700
Epoch:0002, train_loss=1.90049, train_acc=0.69982, val_loss=2.04722, val_acc=0.77007, time=1.09501
Epoch:0003, train_loss=1.79779, train_acc=0.75370, val_loss=2.03980, val_acc=0.79197, time=1.24302
Epoch:0004, train_loss=1.73362, train_acc=0.77233, val_loss=2.03479, val_acc=0.79927, time=1.19200
Epoch:0005, train_loss=1.68998, train_acc=0.78266, val_loss=2.03093, val_acc=0.80474, time=1.25300
Epoch:0006, train_loss=1.65575, train_acc=0.78671, val_loss=2.02767, val_acc=0.80839, time=1.18201
Epoch:0007, train_loss=1.62607, train_acc=0.79806, val_loss=2.02486, val_acc=0.83577, time=1.15101
Epoch:0008, train_loss=1.59999, train_acc=0.82196, val_loss=2.02254, val_acc=0.87044, time=1.15101
Epoch:0009, train_loss=1.57801, train_acc=0.85882, val_loss=2.02073, val_acc=0.89781, time=1.27401
Epoch:0010, train_loss=1.56048, train_acc=0.88434, val_loss=2.01933, val_acc=0.90511, time=1.25600
Epoch:0011, train_loss=1.54654, train_acc=0.89670, val_loss=2.01818, val_acc=0.90876, time=1.24500
Epoch:0012, train_loss=1.53491, train_acc=0.91067, val_loss=2.01721, val_acc=0.92336, time=1.15000
Epoch:0013, train_loss=1.52471, train_acc=0.92384, val_loss=2.01637, val_acc=0.93613, time=1.21001
Epoch:0014, train_loss=1.51563, train_acc=0.93417, val_loss=2.01564, val_acc=0.93978, time=1.13201
Epoch:0015, train_loss=1.50762, train_acc=0.93923, val_loss=2.01502, val_acc=0.94526, time=1.18099
Epoch:0016, train_loss=1.50054, train_acc=0.94349, val_loss=2.01447, val_acc=0.94343, time=1.17899
Epoch:0017, train_loss=1.49418, train_acc=0.94693, val_loss=2.01397, val_acc=0.93978, time=1.21701
Epoch:0018, train_loss=1.48829, train_acc=0.95037, val_loss=2.01350, val_acc=0.93978, time=1.17601
Epoch:0019, train_loss=1.48280, train_acc=0.95382, val_loss=2.01307, val_acc=0.94161, time=1.22001
Epoch:0020, train_loss=1.47771, train_acc=0.95645, val_loss=2.01268, val_acc=0.94343, time=1.22201
Epoch:0021, train_loss=1.47304, train_acc=0.95726, val_loss=2.01232, val_acc=0.94343, time=1.17600
Epoch:0022, train_loss=1.46879, train_acc=0.95787, val_loss=2.01199, val_acc=0.94526, time=1.14402
Epoch:0023, train_loss=1.46492, train_acc=0.96010, val_loss=2.01168, val_acc=0.94526, time=1.15099
Epoch:0024, train_loss=1.46134, train_acc=0.96192, val_loss=2.01139, val_acc=0.94708, time=1.24001
Epoch:0025, train_loss=1.45804, train_acc=0.96455, val_loss=2.01113, val_acc=0.94526, time=1.17000
Epoch:0026, train_loss=1.45501, train_acc=0.96638, val_loss=2.01089, val_acc=0.94708, time=1.13601
Epoch:0027, train_loss=1.45226, train_acc=0.96881, val_loss=2.01069, val_acc=0.94526, time=1.31201
Epoch:0028, train_loss=1.44981, train_acc=0.97164, val_loss=2.01053, val_acc=0.94891, time=1.18702
Epoch:0029, train_loss=1.44765, train_acc=0.97347, val_loss=2.01039, val_acc=0.95073, time=1.18902
Epoch:0030, train_loss=1.44572, train_acc=0.97529, val_loss=2.01028, val_acc=0.95073, time=1.24100
Epoch:0031, train_loss=1.44399, train_acc=0.97772, val_loss=2.01018, val_acc=0.95073, time=1.18001
Epoch:0032, train_loss=1.44241, train_acc=0.98015, val_loss=2.01010, val_acc=0.95255, time=1.21501
Epoch:0033, train_loss=1.44095, train_acc=0.98055, val_loss=2.01002, val_acc=0.95438, time=1.22301
Epoch:0034, train_loss=1.43960, train_acc=0.98157, val_loss=2.00996, val_acc=0.95438, time=1.18100
Epoch:0035, train_loss=1.43834, train_acc=0.98177, val_loss=2.00990, val_acc=0.95438, time=1.21400
Epoch:0036, train_loss=1.43717, train_acc=0.98238, val_loss=2.00984, val_acc=0.95438, time=1.24101
Epoch:0037, train_loss=1.43609, train_acc=0.98258, val_loss=2.00979, val_acc=0.95255, time=1.14502
Epoch:0038, train_loss=1.43507, train_acc=0.98258, val_loss=2.00974, val_acc=0.95073, time=1.31300
Epoch:0039, train_loss=1.43412, train_acc=0.98420, val_loss=2.00970, val_acc=0.95255, time=1.25900
Epoch:0040, train_loss=1.43322, train_acc=0.98420, val_loss=2.00965, val_acc=0.95255, time=1.17000
Epoch:0041, train_loss=1.43236, train_acc=0.98481, val_loss=2.00961, val_acc=0.95255, time=1.22102
Epoch:0042, train_loss=1.43151, train_acc=0.98542, val_loss=2.00956, val_acc=0.95438, time=1.23500
Epoch:0043, train_loss=1.43071, train_acc=0.98683, val_loss=2.00952, val_acc=0.95438, time=1.19701
Epoch:0044, train_loss=1.42994, train_acc=0.98704, val_loss=2.00949, val_acc=0.95255, time=1.25703
Epoch:0045, train_loss=1.42924, train_acc=0.98764, val_loss=2.00946, val_acc=0.95255, time=1.26901
Epoch:0046, train_loss=1.42861, train_acc=0.98724, val_loss=2.00943, val_acc=0.95438, time=1.21400
Epoch:0047, train_loss=1.42803, train_acc=0.98845, val_loss=2.00941, val_acc=0.95438, time=1.19402
Epoch:0048, train_loss=1.42749, train_acc=0.98906, val_loss=2.00939, val_acc=0.95620, time=1.19000
Epoch:0049, train_loss=1.42698, train_acc=0.98987, val_loss=2.00938, val_acc=0.95620, time=1.17500
Epoch:0050, train_loss=1.42650, train_acc=0.99048, val_loss=2.00937, val_acc=0.95803, time=1.09001
Epoch:0051, train_loss=1.42603, train_acc=0.99089, val_loss=2.00936, val_acc=0.95985, time=1.12902
Epoch:0052, train_loss=1.42558, train_acc=0.99149, val_loss=2.00935, val_acc=0.95985, time=1.24601
Epoch:0053, train_loss=1.42514, train_acc=0.99149, val_loss=2.00934, val_acc=0.95985, time=1.22100
Epoch:0054, train_loss=1.42472, train_acc=0.99190, val_loss=2.00934, val_acc=0.95985, time=1.23500
Epoch:0055, train_loss=1.42431, train_acc=0.99210, val_loss=2.00933, val_acc=0.95985, time=1.10801
Epoch:0056, train_loss=1.42392, train_acc=0.99251, val_loss=2.00933, val_acc=0.95985, time=1.22101
Epoch:0057, train_loss=1.42354, train_acc=0.99251, val_loss=2.00933, val_acc=0.95985, time=1.22501
Epoch:0058, train_loss=1.42318, train_acc=0.99332, val_loss=2.00933, val_acc=0.96168, time=1.22301
Epoch:0059, train_loss=1.42283, train_acc=0.99392, val_loss=2.00933, val_acc=0.96350, time=1.24902
Epoch:0060, train_loss=1.42251, train_acc=0.99433, val_loss=2.00934, val_acc=0.96168, time=1.23100
Epoch:0061, train_loss=1.42220, train_acc=0.99433, val_loss=2.00935, val_acc=0.96168, time=1.23600
Early stopping...

Optimization Finished!

Test set results: loss= 1.79861, accuracy= 0.97122, time= 0.35799

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8602    0.9195    0.8889        87
           1     0.9826    0.9917    0.9871      1083
           2     0.9840    0.9727    0.9783       696
           3     1.0000    1.0000    1.0000        10
           4     0.9012    0.9733    0.9359        75
           5     0.9516    0.9752    0.9633       121
           6     0.9630    0.7222    0.8254        36
           7     0.9315    0.8395    0.8831        81

    accuracy                         0.9712      2189
   macro avg     0.9468    0.9243    0.9328      2189
weighted avg     0.9716    0.9712    0.9709      2189


Macro average Test Precision, Recall and F1-Score...
(0.9467700770617007, 0.9242749337460219, 0.932752673973203, None)

Micro average Test Precision, Recall and F1-Score...
(0.9712197350388305, 0.9712197350388305, 0.9712197350388305, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
