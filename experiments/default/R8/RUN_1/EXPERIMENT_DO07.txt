
==========: 254996281780400
Epoch:0001, train_loss=2.09446, train_acc=0.06907, val_loss=2.06063, val_acc=0.72080, time=1.17700
Epoch:0002, train_loss=1.92092, train_acc=0.68301, val_loss=2.04802, val_acc=0.77190, time=1.18701
Epoch:0003, train_loss=1.81047, train_acc=0.74944, val_loss=2.04059, val_acc=0.78467, time=1.17901
Epoch:0004, train_loss=1.74457, train_acc=0.76990, val_loss=2.03586, val_acc=0.79927, time=1.26501
Epoch:0005, train_loss=1.70202, train_acc=0.77962, val_loss=2.03221, val_acc=0.80657, time=1.25200
Epoch:0006, train_loss=1.66889, train_acc=0.78671, val_loss=2.02898, val_acc=0.81204, time=1.12001
Epoch:0007, train_loss=1.63929, train_acc=0.79238, val_loss=2.02603, val_acc=0.82299, time=1.24402
Epoch:0008, train_loss=1.61180, train_acc=0.80677, val_loss=2.02344, val_acc=0.85401, time=1.23201
Epoch:0009, train_loss=1.58717, train_acc=0.83715, val_loss=2.02132, val_acc=0.88139, time=1.17100
Epoch:0010, train_loss=1.56661, train_acc=0.86611, val_loss=2.01969, val_acc=0.90876, time=1.25301
Epoch:0011, train_loss=1.55047, train_acc=0.89082, val_loss=2.01845, val_acc=0.91788, time=1.23400
Epoch:0012, train_loss=1.53803, train_acc=0.90946, val_loss=2.01748, val_acc=0.92518, time=1.18401
Epoch:0013, train_loss=1.52801, train_acc=0.92161, val_loss=2.01665, val_acc=0.93431, time=1.17201
Epoch:0014, train_loss=1.51933, train_acc=0.92971, val_loss=2.01590, val_acc=0.93978, time=1.19801
Epoch:0015, train_loss=1.51136, train_acc=0.93741, val_loss=2.01521, val_acc=0.93978, time=1.12999
Epoch:0016, train_loss=1.50386, train_acc=0.94207, val_loss=2.01458, val_acc=0.94161, time=1.17400
Epoch:0017, train_loss=1.49683, train_acc=0.94612, val_loss=2.01403, val_acc=0.94526, time=1.19000
Epoch:0018, train_loss=1.49044, train_acc=0.95078, val_loss=2.01356, val_acc=0.94526, time=1.19900
Epoch:0019, train_loss=1.48482, train_acc=0.95402, val_loss=2.01318, val_acc=0.94708, time=1.16800
Epoch:0020, train_loss=1.47996, train_acc=0.95665, val_loss=2.01286, val_acc=0.94891, time=1.23201
Epoch:0021, train_loss=1.47566, train_acc=0.95848, val_loss=2.01258, val_acc=0.94891, time=1.16701
Epoch:0022, train_loss=1.47164, train_acc=0.95827, val_loss=2.01230, val_acc=0.94891, time=1.18001
Epoch:0023, train_loss=1.46774, train_acc=0.96050, val_loss=2.01203, val_acc=0.94891, time=1.30900
Epoch:0024, train_loss=1.46392, train_acc=0.96192, val_loss=2.01176, val_acc=0.94708, time=1.22701
Epoch:0025, train_loss=1.46033, train_acc=0.96455, val_loss=2.01151, val_acc=0.94708, time=1.27100
Epoch:0026, train_loss=1.45707, train_acc=0.96779, val_loss=2.01128, val_acc=0.94708, time=1.25900
Epoch:0027, train_loss=1.45423, train_acc=0.96941, val_loss=2.01108, val_acc=0.94891, time=1.21699
Epoch:0028, train_loss=1.45178, train_acc=0.97063, val_loss=2.01089, val_acc=0.95073, time=1.25699
Epoch:0029, train_loss=1.44967, train_acc=0.97367, val_loss=2.01073, val_acc=0.94891, time=1.28803
Epoch:0030, train_loss=1.44782, train_acc=0.97529, val_loss=2.01057, val_acc=0.94891, time=1.24199
Epoch:0031, train_loss=1.44617, train_acc=0.97630, val_loss=2.01043, val_acc=0.94891, time=1.23799
Epoch:0032, train_loss=1.44465, train_acc=0.97752, val_loss=2.01030, val_acc=0.95073, time=1.26600
Epoch:0033, train_loss=1.44322, train_acc=0.97792, val_loss=2.01019, val_acc=0.95438, time=1.14901
Epoch:0034, train_loss=1.44182, train_acc=0.97934, val_loss=2.01008, val_acc=0.95803, time=1.15301
Epoch:0035, train_loss=1.44045, train_acc=0.97995, val_loss=2.00999, val_acc=0.95803, time=1.20700
Epoch:0036, train_loss=1.43911, train_acc=0.98076, val_loss=2.00991, val_acc=0.95803, time=1.20001
Epoch:0037, train_loss=1.43783, train_acc=0.98096, val_loss=2.00984, val_acc=0.95803, time=1.16301
Epoch:0038, train_loss=1.43664, train_acc=0.98197, val_loss=2.00980, val_acc=0.95985, time=1.15001
Epoch:0039, train_loss=1.43556, train_acc=0.98258, val_loss=2.00976, val_acc=0.95803, time=1.21699
Epoch:0040, train_loss=1.43459, train_acc=0.98420, val_loss=2.00973, val_acc=0.95620, time=1.11199
Epoch:0041, train_loss=1.43372, train_acc=0.98501, val_loss=2.00970, val_acc=0.95620, time=1.20500
Epoch:0042, train_loss=1.43291, train_acc=0.98542, val_loss=2.00967, val_acc=0.95620, time=1.26900
Epoch:0043, train_loss=1.43213, train_acc=0.98501, val_loss=2.00963, val_acc=0.95803, time=1.21201
Epoch:0044, train_loss=1.43138, train_acc=0.98602, val_loss=2.00958, val_acc=0.95803, time=1.18800
Epoch:0045, train_loss=1.43067, train_acc=0.98704, val_loss=2.00954, val_acc=0.96168, time=1.16701
Epoch:0046, train_loss=1.43000, train_acc=0.98744, val_loss=2.00950, val_acc=0.96168, time=1.15801
Epoch:0047, train_loss=1.42937, train_acc=0.98825, val_loss=2.00946, val_acc=0.96168, time=1.22801
Epoch:0048, train_loss=1.42879, train_acc=0.98866, val_loss=2.00943, val_acc=0.95803, time=1.18100
Epoch:0049, train_loss=1.42823, train_acc=0.98906, val_loss=2.00941, val_acc=0.95803, time=1.18300
Epoch:0050, train_loss=1.42770, train_acc=0.98947, val_loss=2.00939, val_acc=0.95803, time=1.15801
Epoch:0051, train_loss=1.42719, train_acc=0.98987, val_loss=2.00938, val_acc=0.95803, time=1.19200
Epoch:0052, train_loss=1.42670, train_acc=0.98987, val_loss=2.00937, val_acc=0.95803, time=1.13200
Epoch:0053, train_loss=1.42623, train_acc=0.99048, val_loss=2.00937, val_acc=0.95803, time=1.21101
Epoch:0054, train_loss=1.42578, train_acc=0.99068, val_loss=2.00936, val_acc=0.95803, time=1.21701
Epoch:0055, train_loss=1.42534, train_acc=0.99109, val_loss=2.00935, val_acc=0.95803, time=1.14703
Epoch:0056, train_loss=1.42492, train_acc=0.99129, val_loss=2.00935, val_acc=0.95985, time=1.14901
Epoch:0057, train_loss=1.42452, train_acc=0.99170, val_loss=2.00934, val_acc=0.95985, time=1.20902
Epoch:0058, train_loss=1.42415, train_acc=0.99251, val_loss=2.00933, val_acc=0.95803, time=1.15602
Epoch:0059, train_loss=1.42379, train_acc=0.99291, val_loss=2.00933, val_acc=0.95985, time=1.24802
Epoch:0060, train_loss=1.42345, train_acc=0.99311, val_loss=2.00933, val_acc=0.96168, time=1.13501
Epoch:0061, train_loss=1.42313, train_acc=0.99332, val_loss=2.00932, val_acc=0.96168, time=1.18600
Epoch:0062, train_loss=1.42281, train_acc=0.99413, val_loss=2.00932, val_acc=0.96168, time=1.26402
Epoch:0063, train_loss=1.42251, train_acc=0.99413, val_loss=2.00932, val_acc=0.96168, time=1.21601
Epoch:0064, train_loss=1.42222, train_acc=0.99433, val_loss=2.00933, val_acc=0.96168, time=1.23701
Epoch:0065, train_loss=1.42195, train_acc=0.99433, val_loss=2.00932, val_acc=0.96168, time=1.20400
Epoch:0066, train_loss=1.42168, train_acc=0.99473, val_loss=2.00932, val_acc=0.96168, time=1.28502
Epoch:0067, train_loss=1.42142, train_acc=0.99534, val_loss=2.00932, val_acc=0.96168, time=1.20500
Epoch:0068, train_loss=1.42116, train_acc=0.99534, val_loss=2.00932, val_acc=0.96168, time=1.19408
Epoch:0069, train_loss=1.42092, train_acc=0.99534, val_loss=2.00931, val_acc=0.96168, time=1.17307
Epoch:0070, train_loss=1.42068, train_acc=0.99554, val_loss=2.00931, val_acc=0.96168, time=1.26308
Epoch:0071, train_loss=1.42045, train_acc=0.99575, val_loss=2.00931, val_acc=0.96168, time=1.17008
Epoch:0072, train_loss=1.42024, train_acc=0.99595, val_loss=2.00931, val_acc=0.96168, time=1.22407
Epoch:0073, train_loss=1.42002, train_acc=0.99595, val_loss=2.00931, val_acc=0.96168, time=1.24508
Epoch:0074, train_loss=1.41982, train_acc=0.99615, val_loss=2.00932, val_acc=0.96168, time=1.29708
Early stopping...

Optimization Finished!

Test set results: loss= 1.79856, accuracy= 0.96985, time= 0.38802

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8696    0.9195    0.8939        87
           1     0.9799    0.9917    0.9858      1083
           2     0.9825    0.9670    0.9747       696
           3     1.0000    1.0000    1.0000        10
           4     0.8916    0.9867    0.9367        75
           5     0.9516    0.9752    0.9633       121
           6     1.0000    0.7222    0.8387        36
           7     0.9315    0.8395    0.8831        81

    accuracy                         0.9698      2189
   macro avg     0.9508    0.9252    0.9345      2189
weighted avg     0.9704    0.9698    0.9695      2189


Macro average Test Precision, Recall and F1-Score...
(0.9508324992645635, 0.9252232096080908, 0.9345106016081239, None)

Micro average Test Precision, Recall and F1-Score...
(0.9698492462311558, 0.9698492462311558, 0.9698492462311558, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
