
==========: 255839312498900
Epoch:0001, train_loss=2.07867, train_acc=0.06137, val_loss=2.05089, val_acc=0.57117, time=1.27902
Epoch:0002, train_loss=1.84081, train_acc=0.58760, val_loss=2.04415, val_acc=0.72263, time=1.27100
Epoch:0003, train_loss=1.80902, train_acc=0.69313, val_loss=2.02545, val_acc=0.81569, time=1.24600
Epoch:0004, train_loss=1.61817, train_acc=0.79340, val_loss=2.02268, val_acc=0.88686, time=1.23501
Epoch:0005, train_loss=1.57664, train_acc=0.88353, val_loss=2.02512, val_acc=0.86131, time=1.25602
Epoch:0006, train_loss=1.58634, train_acc=0.87503, val_loss=2.02343, val_acc=0.87409, time=1.29600
Epoch:0007, train_loss=1.56674, train_acc=0.89285, val_loss=2.01961, val_acc=0.89781, time=1.28401
Epoch:0008, train_loss=1.53395, train_acc=0.91797, val_loss=2.01624, val_acc=0.91788, time=1.24401
Epoch:0009, train_loss=1.50630, train_acc=0.93903, val_loss=2.01410, val_acc=0.93613, time=1.27100
Epoch:0010, train_loss=1.48885, train_acc=0.94592, val_loss=2.01299, val_acc=0.93978, time=1.23603
Epoch:0011, train_loss=1.47983, train_acc=0.94470, val_loss=2.01260, val_acc=0.94161, time=1.25101
Epoch:0012, train_loss=1.47645, train_acc=0.94004, val_loss=2.01247, val_acc=0.93613, time=1.25402
Epoch:0013, train_loss=1.47435, train_acc=0.93721, val_loss=2.01221, val_acc=0.93613, time=1.20802
Epoch:0014, train_loss=1.46983, train_acc=0.93903, val_loss=2.01175, val_acc=0.93978, time=1.25901
Epoch:0015, train_loss=1.46288, train_acc=0.94653, val_loss=2.01126, val_acc=0.93978, time=1.26701
Epoch:0016, train_loss=1.45564, train_acc=0.95382, val_loss=2.01087, val_acc=0.94891, time=1.30500
Epoch:0017, train_loss=1.44977, train_acc=0.96070, val_loss=2.01060, val_acc=0.95073, time=1.19601
Epoch:0018, train_loss=1.44562, train_acc=0.96719, val_loss=2.01043, val_acc=0.94526, time=1.16902
Epoch:0019, train_loss=1.44283, train_acc=0.97124, val_loss=2.01029, val_acc=0.94343, time=1.17701
Epoch:0020, train_loss=1.44089, train_acc=0.97266, val_loss=2.01016, val_acc=0.94891, time=1.18501
Epoch:0021, train_loss=1.43930, train_acc=0.97225, val_loss=2.00999, val_acc=0.94891, time=1.21001
Epoch:0022, train_loss=1.43764, train_acc=0.97468, val_loss=2.00980, val_acc=0.94891, time=1.20801
Epoch:0023, train_loss=1.43582, train_acc=0.97488, val_loss=2.00962, val_acc=0.95438, time=1.28001
Epoch:0024, train_loss=1.43411, train_acc=0.97873, val_loss=2.00948, val_acc=0.95620, time=1.26099
Epoch:0025, train_loss=1.43272, train_acc=0.98157, val_loss=2.00937, val_acc=0.95620, time=1.12501
Epoch:0026, train_loss=1.43148, train_acc=0.98258, val_loss=2.00927, val_acc=0.95438, time=1.22900
Epoch:0027, train_loss=1.43021, train_acc=0.98339, val_loss=2.00919, val_acc=0.96168, time=1.29601
Epoch:0028, train_loss=1.42896, train_acc=0.98481, val_loss=2.00915, val_acc=0.95985, time=1.18201
Epoch:0029, train_loss=1.42782, train_acc=0.98521, val_loss=2.00915, val_acc=0.95803, time=1.21701
Epoch:0030, train_loss=1.42671, train_acc=0.98683, val_loss=2.00918, val_acc=0.95985, time=1.26201
Epoch:0031, train_loss=1.42556, train_acc=0.98744, val_loss=2.00925, val_acc=0.96168, time=1.23900
Early stopping...

Optimization Finished!

Test set results: loss= 1.79914, accuracy= 0.96894, time= 0.40802

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8636    0.8736    0.8686        87
           1     0.9871    0.9908    0.9889      1083
           2     0.9798    0.9741    0.9769       696
           3     0.8333    1.0000    0.9091        10
           4     0.8780    0.9600    0.9172        75
           5     0.9365    0.9752    0.9555       121
           6     0.9630    0.7222    0.8254        36
           7     0.9067    0.8395    0.8718        81

    accuracy                         0.9689      2189
   macro avg     0.9185    0.9169    0.9142      2189
weighted avg     0.9693    0.9689    0.9686      2189


Macro average Test Precision, Recall and F1-Score...
(0.9185056681127035, 0.9169253182144524, 0.9141753014063174, None)

Micro average Test Precision, Recall and F1-Score...
(0.9689355870260393, 0.9689355870260393, 0.9689355870260393, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
