
==========: 78338796630800
Epoch:0001, train_loss=2.07846, train_acc=0.14199, val_loss=2.06820, val_acc=0.44891, time=1.38801
Epoch:0002, train_loss=1.99049, train_acc=0.41422, val_loss=2.05995, val_acc=0.68066, time=1.19902
Epoch:0003, train_loss=1.91773, train_acc=0.64432, val_loss=2.05326, val_acc=0.76642, time=1.14401
Epoch:0004, train_loss=1.85853, train_acc=0.72291, val_loss=2.04783, val_acc=0.78102, time=1.04100
Epoch:0005, train_loss=1.81025, train_acc=0.75653, val_loss=2.04347, val_acc=0.78650, time=1.14999
Epoch:0006, train_loss=1.77130, train_acc=0.76646, val_loss=2.03992, val_acc=0.79015, time=1.20501
Epoch:0007, train_loss=1.73943, train_acc=0.77233, val_loss=2.03695, val_acc=0.79562, time=1.09100
Epoch:0008, train_loss=1.71261, train_acc=0.78064, val_loss=2.03437, val_acc=0.80292, time=1.00801
Epoch:0009, train_loss=1.68928, train_acc=0.78590, val_loss=2.03208, val_acc=0.81204, time=1.07301
Epoch:0010, train_loss=1.66842, train_acc=0.79117, val_loss=2.03001, val_acc=0.81934, time=1.11300
Epoch:0011, train_loss=1.64946, train_acc=0.79684, val_loss=2.02813, val_acc=0.81934, time=1.17000
Epoch:0012, train_loss=1.63210, train_acc=0.80859, val_loss=2.02642, val_acc=0.83577, time=1.13800
Epoch:0013, train_loss=1.61619, train_acc=0.82155, val_loss=2.02489, val_acc=0.85584, time=1.05300
Epoch:0014, train_loss=1.60173, train_acc=0.84282, val_loss=2.02353, val_acc=0.87591, time=1.25301
Epoch:0015, train_loss=1.58873, train_acc=0.85720, val_loss=2.02234, val_acc=0.89234, time=1.14100
Epoch:0016, train_loss=1.57718, train_acc=0.86834, val_loss=2.02129, val_acc=0.89964, time=0.98101
Epoch:0017, train_loss=1.56695, train_acc=0.88009, val_loss=2.02037, val_acc=0.90693, time=1.25601
Epoch:0018, train_loss=1.55787, train_acc=0.89184, val_loss=2.01955, val_acc=0.92153, time=1.14701
Epoch:0019, train_loss=1.54974, train_acc=0.89994, val_loss=2.01880, val_acc=0.92518, time=1.05400
Epoch:0020, train_loss=1.54235, train_acc=0.90885, val_loss=2.01812, val_acc=0.92518, time=1.07701
Epoch:0021, train_loss=1.53554, train_acc=0.91614, val_loss=2.01749, val_acc=0.92883, time=1.06100
Epoch:0022, train_loss=1.52919, train_acc=0.92161, val_loss=2.01690, val_acc=0.93431, time=1.14099
Epoch:0023, train_loss=1.52323, train_acc=0.92668, val_loss=2.01636, val_acc=0.93613, time=1.08801
Epoch:0024, train_loss=1.51762, train_acc=0.93154, val_loss=2.01587, val_acc=0.93978, time=1.04401
Epoch:0025, train_loss=1.51236, train_acc=0.93498, val_loss=2.01542, val_acc=0.93978, time=0.96301
Epoch:0026, train_loss=1.50745, train_acc=0.93782, val_loss=2.01501, val_acc=0.94161, time=1.03200
Epoch:0027, train_loss=1.50289, train_acc=0.94248, val_loss=2.01465, val_acc=0.94526, time=1.08402
Epoch:0028, train_loss=1.49871, train_acc=0.94551, val_loss=2.01433, val_acc=0.94526, time=1.04801
Epoch:0029, train_loss=1.49488, train_acc=0.94956, val_loss=2.01404, val_acc=0.94526, time=1.15201
Epoch:0030, train_loss=1.49137, train_acc=0.95220, val_loss=2.01378, val_acc=0.93978, time=1.07201
Epoch:0031, train_loss=1.48811, train_acc=0.95301, val_loss=2.01354, val_acc=0.94161, time=0.99001
Epoch:0032, train_loss=1.48505, train_acc=0.95422, val_loss=2.01331, val_acc=0.93978, time=1.22500
Epoch:0033, train_loss=1.48211, train_acc=0.95706, val_loss=2.01309, val_acc=0.93978, time=1.19101
Epoch:0034, train_loss=1.47927, train_acc=0.95929, val_loss=2.01287, val_acc=0.93978, time=1.19301
Epoch:0035, train_loss=1.47650, train_acc=0.96050, val_loss=2.01266, val_acc=0.93978, time=1.06901
Epoch:0036, train_loss=1.47383, train_acc=0.96253, val_loss=2.01245, val_acc=0.94161, time=1.24101
Epoch:0037, train_loss=1.47128, train_acc=0.96212, val_loss=2.01225, val_acc=0.93978, time=1.31000
Epoch:0038, train_loss=1.46889, train_acc=0.96293, val_loss=2.01207, val_acc=0.93978, time=0.98301
Epoch:0039, train_loss=1.46666, train_acc=0.96395, val_loss=2.01189, val_acc=0.94526, time=0.97201
Epoch:0040, train_loss=1.46462, train_acc=0.96374, val_loss=2.01173, val_acc=0.94891, time=1.11201
Epoch:0041, train_loss=1.46273, train_acc=0.96496, val_loss=2.01157, val_acc=0.95255, time=0.96699
Epoch:0042, train_loss=1.46097, train_acc=0.96536, val_loss=2.01143, val_acc=0.95255, time=1.33000
Epoch:0043, train_loss=1.45932, train_acc=0.96577, val_loss=2.01129, val_acc=0.95438, time=1.03599
Epoch:0044, train_loss=1.45776, train_acc=0.96820, val_loss=2.01116, val_acc=0.95438, time=1.19900
Epoch:0045, train_loss=1.45627, train_acc=0.96982, val_loss=2.01104, val_acc=0.95438, time=1.07801
Epoch:0046, train_loss=1.45485, train_acc=0.97164, val_loss=2.01094, val_acc=0.95438, time=1.15402
Epoch:0047, train_loss=1.45349, train_acc=0.97326, val_loss=2.01084, val_acc=0.95255, time=1.29001
Epoch:0048, train_loss=1.45220, train_acc=0.97488, val_loss=2.01075, val_acc=0.95255, time=1.21101
Epoch:0049, train_loss=1.45099, train_acc=0.97671, val_loss=2.01067, val_acc=0.95073, time=1.10101
Epoch:0050, train_loss=1.44983, train_acc=0.97812, val_loss=2.01060, val_acc=0.95073, time=0.98201
Epoch:0051, train_loss=1.44874, train_acc=0.97914, val_loss=2.01053, val_acc=0.95255, time=1.03301
Epoch:0052, train_loss=1.44770, train_acc=0.98015, val_loss=2.01047, val_acc=0.95438, time=1.07999
Epoch:0053, train_loss=1.44670, train_acc=0.98137, val_loss=2.01042, val_acc=0.95438, time=0.98501
Epoch:0054, train_loss=1.44575, train_acc=0.98116, val_loss=2.01036, val_acc=0.95255, time=1.13401
Epoch:0055, train_loss=1.44484, train_acc=0.98157, val_loss=2.01031, val_acc=0.95255, time=1.14701
Epoch:0056, train_loss=1.44397, train_acc=0.98197, val_loss=2.01026, val_acc=0.95255, time=1.15500
Epoch:0057, train_loss=1.44314, train_acc=0.98238, val_loss=2.01021, val_acc=0.95255, time=1.09700
Epoch:0058, train_loss=1.44235, train_acc=0.98258, val_loss=2.01016, val_acc=0.95255, time=0.95600
Epoch:0059, train_loss=1.44160, train_acc=0.98278, val_loss=2.01011, val_acc=0.95073, time=1.17402
Epoch:0060, train_loss=1.44087, train_acc=0.98278, val_loss=2.01006, val_acc=0.95073, time=0.97801
Epoch:0061, train_loss=1.44018, train_acc=0.98299, val_loss=2.01001, val_acc=0.95255, time=1.08201
Epoch:0062, train_loss=1.43950, train_acc=0.98359, val_loss=2.00996, val_acc=0.95255, time=1.01501
Epoch:0063, train_loss=1.43885, train_acc=0.98420, val_loss=2.00991, val_acc=0.95438, time=1.03600
Epoch:0064, train_loss=1.43823, train_acc=0.98481, val_loss=2.00986, val_acc=0.95803, time=1.10102
Epoch:0065, train_loss=1.43762, train_acc=0.98461, val_loss=2.00982, val_acc=0.95620, time=1.00000
Epoch:0066, train_loss=1.43705, train_acc=0.98461, val_loss=2.00978, val_acc=0.95620, time=1.07502
Epoch:0067, train_loss=1.43650, train_acc=0.98501, val_loss=2.00974, val_acc=0.95620, time=1.07901
Epoch:0068, train_loss=1.43597, train_acc=0.98521, val_loss=2.00971, val_acc=0.95620, time=1.36900
Epoch:0069, train_loss=1.43546, train_acc=0.98542, val_loss=2.00968, val_acc=0.95803, time=1.19701
Epoch:0070, train_loss=1.43497, train_acc=0.98582, val_loss=2.00966, val_acc=0.95803, time=1.03701
Epoch:0071, train_loss=1.43450, train_acc=0.98704, val_loss=2.00963, val_acc=0.95803, time=1.11101
Epoch:0072, train_loss=1.43403, train_acc=0.98744, val_loss=2.00961, val_acc=0.95803, time=0.99400
Epoch:0073, train_loss=1.43359, train_acc=0.98724, val_loss=2.00959, val_acc=0.95620, time=1.04104
Epoch:0074, train_loss=1.43316, train_acc=0.98764, val_loss=2.00957, val_acc=0.95803, time=1.20901
Epoch:0075, train_loss=1.43273, train_acc=0.98805, val_loss=2.00956, val_acc=0.95803, time=1.02800
Epoch:0076, train_loss=1.43233, train_acc=0.98845, val_loss=2.00954, val_acc=0.95620, time=1.36000
Epoch:0077, train_loss=1.43193, train_acc=0.98906, val_loss=2.00953, val_acc=0.95620, time=1.07500
Epoch:0078, train_loss=1.43154, train_acc=0.98926, val_loss=2.00951, val_acc=0.95620, time=1.10800
Epoch:0079, train_loss=1.43117, train_acc=0.98926, val_loss=2.00950, val_acc=0.95620, time=1.12699
Epoch:0080, train_loss=1.43080, train_acc=0.99028, val_loss=2.00948, val_acc=0.95620, time=0.99202
Epoch:0081, train_loss=1.43045, train_acc=0.99028, val_loss=2.00947, val_acc=0.95620, time=1.08901
Epoch:0082, train_loss=1.43011, train_acc=0.99028, val_loss=2.00946, val_acc=0.95620, time=1.05400
Epoch:0083, train_loss=1.42977, train_acc=0.99048, val_loss=2.00945, val_acc=0.95620, time=1.14301
Epoch:0084, train_loss=1.42945, train_acc=0.99089, val_loss=2.00943, val_acc=0.95620, time=1.18902
Epoch:0085, train_loss=1.42913, train_acc=0.99149, val_loss=2.00942, val_acc=0.95803, time=1.23400
Epoch:0086, train_loss=1.42882, train_acc=0.99149, val_loss=2.00941, val_acc=0.95985, time=1.16101
Epoch:0087, train_loss=1.42852, train_acc=0.99149, val_loss=2.00940, val_acc=0.95985, time=1.07001
Epoch:0088, train_loss=1.42822, train_acc=0.99210, val_loss=2.00939, val_acc=0.95985, time=1.26901
Epoch:0089, train_loss=1.42794, train_acc=0.99230, val_loss=2.00939, val_acc=0.95985, time=1.12701
Epoch:0090, train_loss=1.42766, train_acc=0.99230, val_loss=2.00938, val_acc=0.95985, time=1.31803
Epoch:0091, train_loss=1.42738, train_acc=0.99251, val_loss=2.00937, val_acc=0.95985, time=1.10600
Epoch:0092, train_loss=1.42712, train_acc=0.99251, val_loss=2.00936, val_acc=0.95985, time=1.07800
Epoch:0093, train_loss=1.42686, train_acc=0.99271, val_loss=2.00935, val_acc=0.95985, time=1.08701
Epoch:0094, train_loss=1.42660, train_acc=0.99311, val_loss=2.00934, val_acc=0.96168, time=1.22500
Epoch:0095, train_loss=1.42636, train_acc=0.99311, val_loss=2.00933, val_acc=0.96168, time=1.10200
Epoch:0096, train_loss=1.42611, train_acc=0.99311, val_loss=2.00932, val_acc=0.96168, time=1.06702
Epoch:0097, train_loss=1.42587, train_acc=0.99311, val_loss=2.00931, val_acc=0.96168, time=1.10799
Epoch:0098, train_loss=1.42564, train_acc=0.99311, val_loss=2.00931, val_acc=0.96168, time=1.09801
Epoch:0099, train_loss=1.42542, train_acc=0.99352, val_loss=2.00930, val_acc=0.96168, time=0.97701
Epoch:0100, train_loss=1.42519, train_acc=0.99352, val_loss=2.00930, val_acc=0.96168, time=1.12300
Epoch:0101, train_loss=1.42498, train_acc=0.99392, val_loss=2.00929, val_acc=0.96168, time=1.43901
Epoch:0102, train_loss=1.42476, train_acc=0.99413, val_loss=2.00929, val_acc=0.96168, time=1.09103
Epoch:0103, train_loss=1.42456, train_acc=0.99413, val_loss=2.00928, val_acc=0.96168, time=1.18000
Epoch:0104, train_loss=1.42435, train_acc=0.99433, val_loss=2.00928, val_acc=0.96168, time=1.57201
Epoch:0105, train_loss=1.42415, train_acc=0.99473, val_loss=2.00928, val_acc=0.96168, time=1.12901
Epoch:0106, train_loss=1.42396, train_acc=0.99473, val_loss=2.00928, val_acc=0.96168, time=1.11100
Epoch:0107, train_loss=1.42377, train_acc=0.99494, val_loss=2.00927, val_acc=0.96168, time=1.07401
Epoch:0108, train_loss=1.42358, train_acc=0.99494, val_loss=2.00927, val_acc=0.96168, time=1.12700
Epoch:0109, train_loss=1.42340, train_acc=0.99494, val_loss=2.00927, val_acc=0.96168, time=1.15702
Epoch:0110, train_loss=1.42322, train_acc=0.99494, val_loss=2.00926, val_acc=0.96168, time=1.02401
Epoch:0111, train_loss=1.42304, train_acc=0.99514, val_loss=2.00926, val_acc=0.96168, time=0.99301
Epoch:0112, train_loss=1.42287, train_acc=0.99514, val_loss=2.00926, val_acc=0.96168, time=1.09500
Epoch:0113, train_loss=1.42270, train_acc=0.99514, val_loss=2.00925, val_acc=0.96168, time=1.09601
Epoch:0114, train_loss=1.42254, train_acc=0.99554, val_loss=2.00925, val_acc=0.96168, time=1.13901
Epoch:0115, train_loss=1.42237, train_acc=0.99554, val_loss=2.00925, val_acc=0.96168, time=1.02800
Epoch:0116, train_loss=1.42221, train_acc=0.99575, val_loss=2.00924, val_acc=0.96168, time=0.99903
Epoch:0117, train_loss=1.42206, train_acc=0.99575, val_loss=2.00924, val_acc=0.96168, time=1.15200
Epoch:0118, train_loss=1.42191, train_acc=0.99575, val_loss=2.00924, val_acc=0.96168, time=1.14000
Epoch:0119, train_loss=1.42176, train_acc=0.99575, val_loss=2.00924, val_acc=0.96168, time=1.30301
Epoch:0120, train_loss=1.42161, train_acc=0.99575, val_loss=2.00924, val_acc=0.96168, time=1.10800
Epoch:0121, train_loss=1.42147, train_acc=0.99595, val_loss=2.00924, val_acc=0.96168, time=1.02700
Epoch:0122, train_loss=1.42133, train_acc=0.99595, val_loss=2.00924, val_acc=0.96168, time=1.05699
Epoch:0123, train_loss=1.42119, train_acc=0.99595, val_loss=2.00923, val_acc=0.96168, time=1.04300
Epoch:0124, train_loss=1.42105, train_acc=0.99595, val_loss=2.00923, val_acc=0.96168, time=1.16001
Epoch:0125, train_loss=1.42092, train_acc=0.99615, val_loss=2.00923, val_acc=0.96168, time=1.31500
Epoch:0126, train_loss=1.42079, train_acc=0.99615, val_loss=2.00923, val_acc=0.96168, time=1.10501
Epoch:0127, train_loss=1.42066, train_acc=0.99635, val_loss=2.00923, val_acc=0.96168, time=1.06901
Epoch:0128, train_loss=1.42053, train_acc=0.99635, val_loss=2.00923, val_acc=0.96350, time=1.30800
Epoch:0129, train_loss=1.42041, train_acc=0.99656, val_loss=2.00923, val_acc=0.96350, time=1.16201
Epoch:0130, train_loss=1.42029, train_acc=0.99656, val_loss=2.00923, val_acc=0.96350, time=1.19700
Epoch:0131, train_loss=1.42017, train_acc=0.99656, val_loss=2.00923, val_acc=0.96350, time=1.16802
Epoch:0132, train_loss=1.42006, train_acc=0.99656, val_loss=2.00923, val_acc=0.96350, time=1.11400
Epoch:0133, train_loss=1.41994, train_acc=0.99656, val_loss=2.00923, val_acc=0.96350, time=1.09799
Epoch:0134, train_loss=1.41983, train_acc=0.99656, val_loss=2.00923, val_acc=0.96350, time=1.10502
Epoch:0135, train_loss=1.41972, train_acc=0.99676, val_loss=2.00923, val_acc=0.96350, time=1.03500
Epoch:0136, train_loss=1.41961, train_acc=0.99676, val_loss=2.00923, val_acc=0.96350, time=1.13500
Epoch:0137, train_loss=1.41951, train_acc=0.99676, val_loss=2.00923, val_acc=0.96350, time=1.04101
Epoch:0138, train_loss=1.41940, train_acc=0.99676, val_loss=2.00923, val_acc=0.96350, time=1.01901
Epoch:0139, train_loss=1.41930, train_acc=0.99696, val_loss=2.00923, val_acc=0.96533, time=1.15601
Epoch:0140, train_loss=1.41920, train_acc=0.99696, val_loss=2.00923, val_acc=0.96533, time=1.03800
Epoch:0141, train_loss=1.41910, train_acc=0.99696, val_loss=2.00923, val_acc=0.96533, time=0.98600
Epoch:0142, train_loss=1.41901, train_acc=0.99696, val_loss=2.00923, val_acc=0.96533, time=1.09401
Epoch:0143, train_loss=1.41891, train_acc=0.99696, val_loss=2.00923, val_acc=0.96533, time=1.12598
Epoch:0144, train_loss=1.41882, train_acc=0.99716, val_loss=2.00923, val_acc=0.96533, time=1.17901
Early stopping...

Optimization Finished!

Test set results: loss= 1.79837, accuracy= 0.97031, time= 0.29201

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8710    0.9310    0.9000        87
           1     0.9808    0.9917    0.9862      1083
           2     0.9839    0.9684    0.9761       696
           3     1.0000    1.0000    1.0000        10
           4     0.8916    0.9867    0.9367        75
           5     0.9512    0.9669    0.9590       121
           6     0.9615    0.6944    0.8065        36
           7     0.9324    0.8519    0.8903        81

    accuracy                         0.9703      2189
   macro avg     0.9466    0.9239    0.9319      2189
weighted avg     0.9707    0.9703    0.9699      2189


Macro average Test Precision, Recall and F1-Score...
(0.946560992101172, 0.923877518721517, 0.9318537019167227, None)

Micro average Test Precision, Recall and F1-Score...
(0.970306075833714, 0.970306075833714, 0.970306075833714, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
