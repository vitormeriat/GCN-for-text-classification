
==========: 51655225116300
Epoch:0001, train_loss=2.06006, train_acc=0.14199, val_loss=2.05782, val_acc=0.72628, time=1.41202
Epoch:0002, train_loss=1.89308, train_acc=0.70245, val_loss=2.04553, val_acc=0.77555, time=1.34500
Epoch:0003, train_loss=1.78682, train_acc=0.75086, val_loss=2.03830, val_acc=0.78832, time=1.10801
Epoch:0004, train_loss=1.72343, train_acc=0.76970, val_loss=2.03373, val_acc=0.79380, time=1.04400
Epoch:0005, train_loss=1.68245, train_acc=0.78246, val_loss=2.03024, val_acc=0.80657, time=1.08301
Epoch:0006, train_loss=1.65035, train_acc=0.78874, val_loss=2.02719, val_acc=0.81752, time=1.06501
Epoch:0007, train_loss=1.62167, train_acc=0.79745, val_loss=2.02445, val_acc=0.82847, time=1.13800
Epoch:0008, train_loss=1.59560, train_acc=0.82277, val_loss=2.02211, val_acc=0.86131, time=1.17201
Epoch:0009, train_loss=1.57302, train_acc=0.85254, val_loss=2.02024, val_acc=0.89051, time=1.23101
Epoch:0010, train_loss=1.55468, train_acc=0.88070, val_loss=2.01879, val_acc=0.90328, time=1.20200
Epoch:0011, train_loss=1.54033, train_acc=0.90095, val_loss=2.01766, val_acc=0.91606, time=1.06800
Epoch:0012, train_loss=1.52896, train_acc=0.91473, val_loss=2.01675, val_acc=0.92701, time=1.15001
Epoch:0013, train_loss=1.51955, train_acc=0.92911, val_loss=2.01599, val_acc=0.93978, time=1.17901
Epoch:0014, train_loss=1.51152, train_acc=0.93842, val_loss=2.01535, val_acc=0.94708, time=1.08999
Epoch:0015, train_loss=1.50450, train_acc=0.94653, val_loss=2.01479, val_acc=0.94526, time=1.05500
Epoch:0016, train_loss=1.49819, train_acc=0.94936, val_loss=2.01427, val_acc=0.94708, time=0.97501
Epoch:0017, train_loss=1.49226, train_acc=0.95382, val_loss=2.01377, val_acc=0.94708, time=1.16498
Epoch:0018, train_loss=1.48648, train_acc=0.95524, val_loss=2.01329, val_acc=0.94343, time=1.15900
Epoch:0019, train_loss=1.48088, train_acc=0.95645, val_loss=2.01285, val_acc=0.94343, time=1.04799
Epoch:0020, train_loss=1.47560, train_acc=0.95767, val_loss=2.01245, val_acc=0.94708, time=1.23300
Epoch:0021, train_loss=1.47079, train_acc=0.95969, val_loss=2.01209, val_acc=0.94708, time=1.12301
Epoch:0022, train_loss=1.46651, train_acc=0.95989, val_loss=2.01178, val_acc=0.94708, time=1.13001
Epoch:0023, train_loss=1.46272, train_acc=0.96131, val_loss=2.01149, val_acc=0.94526, time=1.16800
Epoch:0024, train_loss=1.45932, train_acc=0.96354, val_loss=2.01123, val_acc=0.94708, time=1.03201
Epoch:0025, train_loss=1.45624, train_acc=0.96557, val_loss=2.01099, val_acc=0.94708, time=1.04799
Epoch:0026, train_loss=1.45342, train_acc=0.96719, val_loss=2.01077, val_acc=0.94891, time=1.10603
Epoch:0027, train_loss=1.45084, train_acc=0.96779, val_loss=2.01058, val_acc=0.95073, time=1.21099
Epoch:0028, train_loss=1.44849, train_acc=0.97043, val_loss=2.01042, val_acc=0.95073, time=1.21701
Epoch:0029, train_loss=1.44636, train_acc=0.97428, val_loss=2.01029, val_acc=0.95620, time=1.14201
Epoch:0030, train_loss=1.44444, train_acc=0.97772, val_loss=2.01019, val_acc=0.95438, time=1.38601
Epoch:0031, train_loss=1.44274, train_acc=0.97873, val_loss=2.01010, val_acc=0.95073, time=1.40400
Epoch:0032, train_loss=1.44121, train_acc=0.97995, val_loss=2.01003, val_acc=0.95438, time=1.16103
Epoch:0033, train_loss=1.43983, train_acc=0.97995, val_loss=2.00997, val_acc=0.95438, time=1.07800
Epoch:0034, train_loss=1.43856, train_acc=0.98116, val_loss=2.00991, val_acc=0.95438, time=1.18000
Epoch:0035, train_loss=1.43738, train_acc=0.98238, val_loss=2.00985, val_acc=0.95255, time=1.10501
Epoch:0036, train_loss=1.43628, train_acc=0.98339, val_loss=2.00979, val_acc=0.95255, time=1.28001
Epoch:0037, train_loss=1.43523, train_acc=0.98420, val_loss=2.00973, val_acc=0.95620, time=1.26300
Epoch:0038, train_loss=1.43424, train_acc=0.98420, val_loss=2.00967, val_acc=0.95620, time=1.04201
Epoch:0039, train_loss=1.43331, train_acc=0.98481, val_loss=2.00961, val_acc=0.95438, time=1.05401
Epoch:0040, train_loss=1.43244, train_acc=0.98562, val_loss=2.00955, val_acc=0.95803, time=1.05301
Epoch:0041, train_loss=1.43162, train_acc=0.98643, val_loss=2.00950, val_acc=0.95803, time=1.02800
Epoch:0042, train_loss=1.43084, train_acc=0.98683, val_loss=2.00946, val_acc=0.95803, time=1.08001
Epoch:0043, train_loss=1.43009, train_acc=0.98724, val_loss=2.00942, val_acc=0.95985, time=1.06601
Epoch:0044, train_loss=1.42937, train_acc=0.98764, val_loss=2.00939, val_acc=0.96168, time=1.04000
Epoch:0045, train_loss=1.42869, train_acc=0.98866, val_loss=2.00937, val_acc=0.96168, time=1.02300
Epoch:0046, train_loss=1.42805, train_acc=0.98926, val_loss=2.00935, val_acc=0.95985, time=1.32102
Epoch:0047, train_loss=1.42746, train_acc=0.99028, val_loss=2.00934, val_acc=0.95985, time=1.11599
Epoch:0048, train_loss=1.42691, train_acc=0.99068, val_loss=2.00933, val_acc=0.95985, time=1.23401
Epoch:0049, train_loss=1.42640, train_acc=0.99089, val_loss=2.00933, val_acc=0.95985, time=1.02900
Epoch:0050, train_loss=1.42592, train_acc=0.99109, val_loss=2.00932, val_acc=0.95985, time=1.16201
Epoch:0051, train_loss=1.42547, train_acc=0.99149, val_loss=2.00932, val_acc=0.95985, time=1.15601
Epoch:0052, train_loss=1.42504, train_acc=0.99230, val_loss=2.00931, val_acc=0.95985, time=1.06901
Epoch:0053, train_loss=1.42463, train_acc=0.99251, val_loss=2.00930, val_acc=0.95985, time=1.08000
Epoch:0054, train_loss=1.42423, train_acc=0.99251, val_loss=2.00929, val_acc=0.96168, time=1.13802
Epoch:0055, train_loss=1.42385, train_acc=0.99311, val_loss=2.00929, val_acc=0.96350, time=1.01599
Epoch:0056, train_loss=1.42348, train_acc=0.99332, val_loss=2.00928, val_acc=0.96350, time=1.07202
Epoch:0057, train_loss=1.42312, train_acc=0.99372, val_loss=2.00927, val_acc=0.96350, time=1.10201
Epoch:0058, train_loss=1.42278, train_acc=0.99433, val_loss=2.00926, val_acc=0.96350, time=1.04099
Epoch:0059, train_loss=1.42246, train_acc=0.99433, val_loss=2.00925, val_acc=0.96350, time=1.19201
Epoch:0060, train_loss=1.42214, train_acc=0.99453, val_loss=2.00925, val_acc=0.96350, time=1.22502
Epoch:0061, train_loss=1.42184, train_acc=0.99453, val_loss=2.00925, val_acc=0.96350, time=1.07401
Epoch:0062, train_loss=1.42155, train_acc=0.99473, val_loss=2.00925, val_acc=0.96350, time=1.22801
Epoch:0063, train_loss=1.42127, train_acc=0.99494, val_loss=2.00925, val_acc=0.96350, time=1.06202
Epoch:0064, train_loss=1.42100, train_acc=0.99494, val_loss=2.00925, val_acc=0.96350, time=1.09000
Epoch:0065, train_loss=1.42075, train_acc=0.99494, val_loss=2.00926, val_acc=0.96350, time=1.19001
Epoch:0066, train_loss=1.42051, train_acc=0.99514, val_loss=2.00926, val_acc=0.96350, time=1.14601
Epoch:0067, train_loss=1.42027, train_acc=0.99554, val_loss=2.00927, val_acc=0.96350, time=1.15201
Epoch:0068, train_loss=1.42005, train_acc=0.99635, val_loss=2.00927, val_acc=0.96350, time=1.05501
Epoch:0069, train_loss=1.41983, train_acc=0.99635, val_loss=2.00928, val_acc=0.96350, time=1.21299
Epoch:0070, train_loss=1.41962, train_acc=0.99635, val_loss=2.00929, val_acc=0.96350, time=1.20401
Epoch:0071, train_loss=1.41942, train_acc=0.99635, val_loss=2.00929, val_acc=0.96350, time=1.08602
Epoch:0072, train_loss=1.41923, train_acc=0.99656, val_loss=2.00930, val_acc=0.96350, time=1.08800
Epoch:0073, train_loss=1.41904, train_acc=0.99656, val_loss=2.00931, val_acc=0.96168, time=0.98301
Epoch:0074, train_loss=1.41886, train_acc=0.99656, val_loss=2.00931, val_acc=0.96168, time=1.10798
Epoch:0075, train_loss=1.41868, train_acc=0.99676, val_loss=2.00932, val_acc=0.96168, time=1.12700
Epoch:0076, train_loss=1.41852, train_acc=0.99676, val_loss=2.00932, val_acc=0.96168, time=0.97800
Epoch:0077, train_loss=1.41835, train_acc=0.99676, val_loss=2.00933, val_acc=0.96168, time=1.20102
Epoch:0078, train_loss=1.41820, train_acc=0.99676, val_loss=2.00933, val_acc=0.96168, time=1.05500
Epoch:0079, train_loss=1.41804, train_acc=0.99696, val_loss=2.00933, val_acc=0.96168, time=1.29701
Epoch:0080, train_loss=1.41789, train_acc=0.99696, val_loss=2.00933, val_acc=0.95985, time=1.04701
Epoch:0081, train_loss=1.41775, train_acc=0.99696, val_loss=2.00933, val_acc=0.95985, time=1.01801
Epoch:0082, train_loss=1.41761, train_acc=0.99716, val_loss=2.00933, val_acc=0.95985, time=1.10503
Epoch:0083, train_loss=1.41748, train_acc=0.99716, val_loss=2.00933, val_acc=0.95985, time=1.08801
Epoch:0084, train_loss=1.41735, train_acc=0.99716, val_loss=2.00932, val_acc=0.95985, time=1.13201
Epoch:0085, train_loss=1.41723, train_acc=0.99737, val_loss=2.00932, val_acc=0.95985, time=1.35700
Epoch:0086, train_loss=1.41711, train_acc=0.99737, val_loss=2.00933, val_acc=0.95985, time=1.16100
Epoch:0087, train_loss=1.41699, train_acc=0.99737, val_loss=2.00933, val_acc=0.95803, time=1.11400
Epoch:0088, train_loss=1.41688, train_acc=0.99757, val_loss=2.00933, val_acc=0.95803, time=1.11200
Epoch:0089, train_loss=1.41677, train_acc=0.99757, val_loss=2.00933, val_acc=0.95803, time=1.07500
Epoch:0090, train_loss=1.41666, train_acc=0.99757, val_loss=2.00933, val_acc=0.95803, time=1.14501
Epoch:0091, train_loss=1.41656, train_acc=0.99757, val_loss=2.00934, val_acc=0.95985, time=1.07101
Epoch:0092, train_loss=1.41646, train_acc=0.99757, val_loss=2.00934, val_acc=0.95985, time=1.03600
Epoch:0093, train_loss=1.41636, train_acc=0.99777, val_loss=2.00934, val_acc=0.95985, time=1.21901
Epoch:0094, train_loss=1.41627, train_acc=0.99797, val_loss=2.00934, val_acc=0.95985, time=1.10201
Epoch:0095, train_loss=1.41618, train_acc=0.99797, val_loss=2.00935, val_acc=0.95985, time=1.14902
Epoch:0096, train_loss=1.41609, train_acc=0.99818, val_loss=2.00935, val_acc=0.95985, time=1.25001
Epoch:0097, train_loss=1.41601, train_acc=0.99818, val_loss=2.00935, val_acc=0.95985, time=1.03200
Epoch:0098, train_loss=1.41592, train_acc=0.99818, val_loss=2.00936, val_acc=0.95985, time=1.13800
Epoch:0099, train_loss=1.41584, train_acc=0.99818, val_loss=2.00936, val_acc=0.95985, time=1.19002
Epoch:0100, train_loss=1.41576, train_acc=0.99818, val_loss=2.00936, val_acc=0.95985, time=1.09400
Epoch:0101, train_loss=1.41569, train_acc=0.99818, val_loss=2.00936, val_acc=0.95985, time=1.13602
Epoch:0102, train_loss=1.41561, train_acc=0.99818, val_loss=2.00937, val_acc=0.95985, time=1.24101
Epoch:0103, train_loss=1.41554, train_acc=0.99838, val_loss=2.00937, val_acc=0.95985, time=1.22301
Epoch:0104, train_loss=1.41547, train_acc=0.99838, val_loss=2.00937, val_acc=0.96168, time=1.14401
Epoch:0105, train_loss=1.41540, train_acc=0.99838, val_loss=2.00938, val_acc=0.96168, time=1.08101
Epoch:0106, train_loss=1.41534, train_acc=0.99858, val_loss=2.00938, val_acc=0.96168, time=1.13400
Epoch:0107, train_loss=1.41527, train_acc=0.99858, val_loss=2.00938, val_acc=0.96168, time=1.02800
Epoch:0108, train_loss=1.41521, train_acc=0.99858, val_loss=2.00939, val_acc=0.96168, time=1.12101
Epoch:0109, train_loss=1.41515, train_acc=0.99858, val_loss=2.00939, val_acc=0.96168, time=1.12301
Epoch:0110, train_loss=1.41509, train_acc=0.99858, val_loss=2.00939, val_acc=0.96168, time=1.28201
Epoch:0111, train_loss=1.41503, train_acc=0.99858, val_loss=2.00940, val_acc=0.96168, time=1.19100
Epoch:0112, train_loss=1.41498, train_acc=0.99858, val_loss=2.00940, val_acc=0.96168, time=1.17901
Epoch:0113, train_loss=1.41492, train_acc=0.99858, val_loss=2.00940, val_acc=0.96168, time=1.04200
Epoch:0114, train_loss=1.41487, train_acc=0.99858, val_loss=2.00941, val_acc=0.96168, time=1.13501
Epoch:0115, train_loss=1.41482, train_acc=0.99878, val_loss=2.00941, val_acc=0.96168, time=1.11200
Epoch:0116, train_loss=1.41477, train_acc=0.99878, val_loss=2.00941, val_acc=0.96168, time=1.22301
Epoch:0117, train_loss=1.41472, train_acc=0.99878, val_loss=2.00942, val_acc=0.96168, time=1.18001
Epoch:0118, train_loss=1.41467, train_acc=0.99878, val_loss=2.00942, val_acc=0.96168, time=1.20200
Epoch:0119, train_loss=1.41462, train_acc=0.99878, val_loss=2.00942, val_acc=0.96168, time=1.16101
Epoch:0120, train_loss=1.41458, train_acc=0.99878, val_loss=2.00943, val_acc=0.96168, time=1.09200
Epoch:0121, train_loss=1.41453, train_acc=0.99878, val_loss=2.00943, val_acc=0.96168, time=1.16600
Epoch:0122, train_loss=1.41449, train_acc=0.99878, val_loss=2.00943, val_acc=0.96168, time=1.06801
Epoch:0123, train_loss=1.41445, train_acc=0.99878, val_loss=2.00944, val_acc=0.96168, time=1.13399
Epoch:0124, train_loss=1.41441, train_acc=0.99878, val_loss=2.00944, val_acc=0.96168, time=1.13100
Epoch:0125, train_loss=1.41437, train_acc=0.99899, val_loss=2.00944, val_acc=0.96168, time=1.22902
Epoch:0126, train_loss=1.41433, train_acc=0.99899, val_loss=2.00945, val_acc=0.96168, time=1.03301
Epoch:0127, train_loss=1.41429, train_acc=0.99899, val_loss=2.00945, val_acc=0.96168, time=1.10301
Early stopping...

Optimization Finished!

Test set results: loss= 1.79962, accuracy= 0.96985, time= 0.40200

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8617    0.9310    0.8950        87
           1     0.9799    0.9917    0.9858      1083
           2     0.9839    0.9670    0.9754       696
           3     1.0000    1.0000    1.0000        10
           4     0.9024    0.9867    0.9427        75
           5     0.9444    0.9835    0.9636       121
           6     1.0000    0.6944    0.8197        36
           7     0.9306    0.8272    0.8758        81

    accuracy                         0.9698      2189
   macro avg     0.9504    0.9227    0.9322      2189
weighted avg     0.9705    0.9698    0.9694      2189


Macro average Test Precision, Recall and F1-Score...
(0.9503732860005074, 0.9226776169697606, 0.9322362838167376, None)

Micro average Test Precision, Recall and F1-Score...
(0.9698492462311558, 0.9698492462311558, 0.9698492462311558, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
