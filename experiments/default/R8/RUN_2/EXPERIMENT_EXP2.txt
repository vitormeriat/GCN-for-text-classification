
==========: 270730530655000
Epoch:0001, train_loss=2.11532, train_acc=0.03261, val_loss=2.04637, val_acc=0.78102, time=1.25901
Epoch:0002, train_loss=1.80372, train_acc=0.76544, val_loss=2.03305, val_acc=0.80839, time=1.12200
Epoch:0003, train_loss=1.68794, train_acc=0.77719, val_loss=2.02297, val_acc=0.86131, time=1.15001
Epoch:0004, train_loss=1.58305, train_acc=0.85193, val_loss=2.01940, val_acc=0.90511, time=1.26501
Epoch:0005, train_loss=1.54770, train_acc=0.89305, val_loss=2.01698, val_acc=0.91971, time=1.22901
Epoch:0006, train_loss=1.52437, train_acc=0.91695, val_loss=2.01532, val_acc=0.93431, time=1.21001
Epoch:0007, train_loss=1.50802, train_acc=0.93113, val_loss=2.01417, val_acc=0.93978, time=1.19901
Epoch:0008, train_loss=1.49577, train_acc=0.93802, val_loss=2.01325, val_acc=0.93796, time=1.24201
Epoch:0009, train_loss=1.48441, train_acc=0.94673, val_loss=2.01260, val_acc=0.93613, time=1.32702
Epoch:0010, train_loss=1.47497, train_acc=0.95382, val_loss=2.01220, val_acc=0.93978, time=1.17501
Epoch:0011, train_loss=1.46783, train_acc=0.95665, val_loss=2.01194, val_acc=0.94343, time=1.19601
Epoch:0012, train_loss=1.46260, train_acc=0.95888, val_loss=2.01161, val_acc=0.94526, time=1.19700
Epoch:0013, train_loss=1.45780, train_acc=0.95949, val_loss=2.01114, val_acc=0.94343, time=1.17400
Epoch:0014, train_loss=1.45272, train_acc=0.96152, val_loss=2.01060, val_acc=0.94526, time=1.15500
Epoch:0015, train_loss=1.44783, train_acc=0.96536, val_loss=2.01013, val_acc=0.94891, time=1.24300
Epoch:0016, train_loss=1.44377, train_acc=0.96881, val_loss=2.00977, val_acc=0.94708, time=1.24501
Epoch:0017, train_loss=1.44045, train_acc=0.97164, val_loss=2.00948, val_acc=0.94708, time=1.22301
Epoch:0018, train_loss=1.43739, train_acc=0.97488, val_loss=2.00925, val_acc=0.95073, time=1.20700
Epoch:0019, train_loss=1.43455, train_acc=0.97772, val_loss=2.00912, val_acc=0.95438, time=1.17701
Epoch:0020, train_loss=1.43234, train_acc=0.98076, val_loss=2.00912, val_acc=0.95803, time=1.18200
Epoch:0021, train_loss=1.43089, train_acc=0.98319, val_loss=2.00919, val_acc=0.96168, time=1.24601
Epoch:0022, train_loss=1.42988, train_acc=0.98339, val_loss=2.00928, val_acc=0.96533, time=1.22301
Early stopping...

Optimization Finished!

Test set results: loss= 1.80206, accuracy= 0.96757, time= 0.50599

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8989    0.9195    0.9091        87
           1     0.9808    0.9908    0.9858      1083
           2     0.9838    0.9598    0.9716       696
           3     0.8333    1.0000    0.9091        10
           4     0.9114    0.9600    0.9351        75
           5     0.9023    0.9917    0.9449       121
           6     1.0000    0.6389    0.7797        36
           7     0.9000    0.8889    0.8944        81

    accuracy                         0.9676      2189
   macro avg     0.9263    0.9187    0.9162      2189
weighted avg     0.9684    0.9676    0.9671      2189


Macro average Test Precision, Recall and F1-Score...
(0.9263077343758122, 0.9186987561817254, 0.9161995227463946, None)

Micro average Test Precision, Recall and F1-Score...
(0.9675650982183646, 0.9675650982183646, 0.9675650982183646, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
