
==========: 269618290907700
Epoch:0001, train_loss=2.07497, train_acc=0.14098, val_loss=2.05835, val_acc=0.57117, time=1.17601
Epoch:0002, train_loss=1.89988, train_acc=0.56937, val_loss=2.04598, val_acc=0.70255, time=1.16401
Epoch:0003, train_loss=1.79376, train_acc=0.70124, val_loss=2.03881, val_acc=0.77920, time=1.20101
Epoch:0004, train_loss=1.73282, train_acc=0.74904, val_loss=2.03445, val_acc=0.79745, time=1.17701
Epoch:0005, train_loss=1.69465, train_acc=0.76767, val_loss=2.03115, val_acc=0.80292, time=1.22001
Epoch:0006, train_loss=1.66392, train_acc=0.77760, val_loss=2.02820, val_acc=0.80839, time=1.29601
Epoch:0007, train_loss=1.63519, train_acc=0.78793, val_loss=2.02551, val_acc=0.81752, time=1.29402
Epoch:0008, train_loss=1.60844, train_acc=0.80251, val_loss=2.02317, val_acc=0.85401, time=1.21200
Epoch:0009, train_loss=1.58490, train_acc=0.83188, val_loss=2.02124, val_acc=0.87591, time=1.11001
Epoch:0010, train_loss=1.56547, train_acc=0.86895, val_loss=2.01970, val_acc=0.90876, time=1.12901
Epoch:0011, train_loss=1.55011, train_acc=0.89650, val_loss=2.01849, val_acc=0.92336, time=1.09303
Epoch:0012, train_loss=1.53807, train_acc=0.91432, val_loss=2.01751, val_acc=0.92883, time=1.16200
Epoch:0013, train_loss=1.52832, train_acc=0.92323, val_loss=2.01668, val_acc=0.93431, time=1.28201
Epoch:0014, train_loss=1.51998, train_acc=0.93113, val_loss=2.01595, val_acc=0.94161, time=1.29103
Epoch:0015, train_loss=1.51247, train_acc=0.93559, val_loss=2.01529, val_acc=0.94526, time=1.19100
Epoch:0016, train_loss=1.50549, train_acc=0.94146, val_loss=2.01470, val_acc=0.94526, time=1.30501
Epoch:0017, train_loss=1.49891, train_acc=0.94531, val_loss=2.01416, val_acc=0.94891, time=1.33301
Epoch:0018, train_loss=1.49272, train_acc=0.94936, val_loss=2.01367, val_acc=0.94708, time=1.30401
Epoch:0019, train_loss=1.48690, train_acc=0.95118, val_loss=2.01324, val_acc=0.94708, time=1.13202
Epoch:0020, train_loss=1.48147, train_acc=0.95402, val_loss=2.01286, val_acc=0.94708, time=1.27601
Epoch:0021, train_loss=1.47651, train_acc=0.95665, val_loss=2.01253, val_acc=0.94708, time=1.33800
Epoch:0022, train_loss=1.47209, train_acc=0.95767, val_loss=2.01225, val_acc=0.94526, time=1.20801
Epoch:0023, train_loss=1.46820, train_acc=0.95929, val_loss=2.01200, val_acc=0.94708, time=1.23501
Epoch:0024, train_loss=1.46472, train_acc=0.96091, val_loss=2.01176, val_acc=0.94891, time=1.26400
Epoch:0025, train_loss=1.46150, train_acc=0.96192, val_loss=2.01152, val_acc=0.95073, time=1.32801
Epoch:0026, train_loss=1.45843, train_acc=0.96334, val_loss=2.01128, val_acc=0.95073, time=1.21501
Epoch:0027, train_loss=1.45549, train_acc=0.96455, val_loss=2.01104, val_acc=0.95255, time=1.30899
Epoch:0028, train_loss=1.45274, train_acc=0.96779, val_loss=2.01082, val_acc=0.94891, time=1.21501
Epoch:0029, train_loss=1.45024, train_acc=0.97022, val_loss=2.01062, val_acc=0.95073, time=1.16600
Epoch:0030, train_loss=1.44803, train_acc=0.97286, val_loss=2.01046, val_acc=0.95255, time=1.24901
Epoch:0031, train_loss=1.44608, train_acc=0.97529, val_loss=2.01032, val_acc=0.95255, time=1.28100
Epoch:0032, train_loss=1.44435, train_acc=0.97711, val_loss=2.01021, val_acc=0.95073, time=1.19001
Epoch:0033, train_loss=1.44278, train_acc=0.97833, val_loss=2.01011, val_acc=0.94891, time=1.22502
Epoch:0034, train_loss=1.44135, train_acc=0.97893, val_loss=2.01004, val_acc=0.94891, time=1.10501
Epoch:0035, train_loss=1.44003, train_acc=0.98015, val_loss=2.00998, val_acc=0.95073, time=1.14601
Epoch:0036, train_loss=1.43882, train_acc=0.98218, val_loss=2.00994, val_acc=0.95438, time=1.17401
Epoch:0037, train_loss=1.43771, train_acc=0.98238, val_loss=2.00990, val_acc=0.95255, time=1.19100
Epoch:0038, train_loss=1.43666, train_acc=0.98278, val_loss=2.00985, val_acc=0.95073, time=1.23302
Epoch:0039, train_loss=1.43566, train_acc=0.98278, val_loss=2.00981, val_acc=0.95073, time=1.24799
Epoch:0040, train_loss=1.43469, train_acc=0.98299, val_loss=2.00976, val_acc=0.94891, time=1.20301
Epoch:0041, train_loss=1.43374, train_acc=0.98400, val_loss=2.00971, val_acc=0.95255, time=1.22501
Epoch:0042, train_loss=1.43284, train_acc=0.98400, val_loss=2.00966, val_acc=0.95255, time=1.24401
Epoch:0043, train_loss=1.43199, train_acc=0.98501, val_loss=2.00961, val_acc=0.95438, time=1.25201
Epoch:0044, train_loss=1.43120, train_acc=0.98582, val_loss=2.00956, val_acc=0.95620, time=1.15801
Epoch:0045, train_loss=1.43047, train_acc=0.98683, val_loss=2.00953, val_acc=0.95438, time=1.26501
Epoch:0046, train_loss=1.42978, train_acc=0.98724, val_loss=2.00950, val_acc=0.95803, time=1.27701
Epoch:0047, train_loss=1.42915, train_acc=0.98744, val_loss=2.00948, val_acc=0.95803, time=1.26300
Epoch:0048, train_loss=1.42857, train_acc=0.98845, val_loss=2.00947, val_acc=0.95803, time=1.30703
Epoch:0049, train_loss=1.42803, train_acc=0.98906, val_loss=2.00946, val_acc=0.95803, time=1.27800
Epoch:0050, train_loss=1.42752, train_acc=0.98926, val_loss=2.00946, val_acc=0.95803, time=1.19401
Epoch:0051, train_loss=1.42704, train_acc=0.98987, val_loss=2.00946, val_acc=0.95803, time=1.27000
Epoch:0052, train_loss=1.42657, train_acc=0.98987, val_loss=2.00946, val_acc=0.95803, time=1.32205
Epoch:0053, train_loss=1.42611, train_acc=0.99028, val_loss=2.00946, val_acc=0.96168, time=1.53700
Epoch:0054, train_loss=1.42568, train_acc=0.99089, val_loss=2.00946, val_acc=0.96168, time=1.34702
Epoch:0055, train_loss=1.42526, train_acc=0.99129, val_loss=2.00946, val_acc=0.96168, time=1.11916
Epoch:0056, train_loss=1.42485, train_acc=0.99190, val_loss=2.00945, val_acc=0.95985, time=1.45401
Epoch:0057, train_loss=1.42446, train_acc=0.99230, val_loss=2.00945, val_acc=0.95985, time=1.37801
Epoch:0058, train_loss=1.42408, train_acc=0.99251, val_loss=2.00944, val_acc=0.95985, time=1.18601
Epoch:0059, train_loss=1.42372, train_acc=0.99291, val_loss=2.00944, val_acc=0.95985, time=1.19702
Epoch:0060, train_loss=1.42337, train_acc=0.99332, val_loss=2.00943, val_acc=0.95985, time=1.21102
Epoch:0061, train_loss=1.42305, train_acc=0.99352, val_loss=2.00943, val_acc=0.95985, time=1.19701
Epoch:0062, train_loss=1.42273, train_acc=0.99413, val_loss=2.00942, val_acc=0.95985, time=1.24700
Epoch:0063, train_loss=1.42243, train_acc=0.99433, val_loss=2.00942, val_acc=0.95985, time=1.32801
Epoch:0064, train_loss=1.42215, train_acc=0.99433, val_loss=2.00941, val_acc=0.95985, time=1.27500
Epoch:0065, train_loss=1.42187, train_acc=0.99433, val_loss=2.00941, val_acc=0.95985, time=1.24301
Epoch:0066, train_loss=1.42161, train_acc=0.99453, val_loss=2.00940, val_acc=0.95985, time=1.13200
Epoch:0067, train_loss=1.42136, train_acc=0.99453, val_loss=2.00940, val_acc=0.95985, time=1.20700
Epoch:0068, train_loss=1.42111, train_acc=0.99494, val_loss=2.00940, val_acc=0.95985, time=1.29001
Epoch:0069, train_loss=1.42088, train_acc=0.99514, val_loss=2.00941, val_acc=0.95985, time=1.22001
Epoch:0070, train_loss=1.42065, train_acc=0.99534, val_loss=2.00941, val_acc=0.95985, time=1.39501
Epoch:0071, train_loss=1.42043, train_acc=0.99554, val_loss=2.00941, val_acc=0.95985, time=1.41202
Early stopping...

Optimization Finished!

Test set results: loss= 1.79879, accuracy= 0.97213, time= 0.43001

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8696    0.9195    0.8939        87
           1     0.9826    0.9917    0.9871      1083
           2     0.9840    0.9713    0.9776       696
           3     1.0000    1.0000    1.0000        10
           4     0.9024    0.9867    0.9427        75
           5     0.9520    0.9835    0.9675       121
           6     1.0000    0.7222    0.8387        36
           7     0.9324    0.8519    0.8903        81

    accuracy                         0.9721      2189
   macro avg     0.9529    0.9283    0.9372      2189
weighted avg     0.9726    0.9721    0.9718      2189


Macro average Test Precision, Recall and F1-Score...
(0.9528802100999363, 0.928338270439322, 0.9372198942341052, None)

Micro average Test Precision, Recall and F1-Score...
(0.972133394243947, 0.972133394243947, 0.972133394243947, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
