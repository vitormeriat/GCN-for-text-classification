
==========: 257840081711800
Epoch:0001, train_loss=2.09478, train_acc=0.05185, val_loss=2.04450, val_acc=0.77372, time=1.19101
Epoch:0002, train_loss=1.79297, train_acc=0.76605, val_loss=2.03158, val_acc=0.81387, time=1.16300
Epoch:0003, train_loss=1.68033, train_acc=0.78570, val_loss=2.02268, val_acc=0.87591, time=1.22701
Epoch:0004, train_loss=1.58900, train_acc=0.86368, val_loss=2.01954, val_acc=0.89599, time=1.19501
Epoch:0005, train_loss=1.55500, train_acc=0.88394, val_loss=2.01659, val_acc=0.91241, time=1.21201
Epoch:0006, train_loss=1.52315, train_acc=0.90642, val_loss=2.01451, val_acc=0.92518, time=1.16001
Epoch:0007, train_loss=1.49963, train_acc=0.92607, val_loss=2.01372, val_acc=0.92883, time=1.24301
Epoch:0008, train_loss=1.48846, train_acc=0.93660, val_loss=2.01336, val_acc=0.92518, time=1.22300
Epoch:0009, train_loss=1.48112, train_acc=0.94268, val_loss=2.01288, val_acc=0.92883, time=1.14200
Epoch:0010, train_loss=1.47266, train_acc=0.94916, val_loss=2.01232, val_acc=0.93248, time=1.28701
Epoch:0011, train_loss=1.46413, train_acc=0.95665, val_loss=2.01178, val_acc=0.94526, time=1.22002
Epoch:0012, train_loss=1.45712, train_acc=0.96212, val_loss=2.01127, val_acc=0.94343, time=1.26000
Epoch:0013, train_loss=1.45165, train_acc=0.96779, val_loss=2.01076, val_acc=0.94708, time=1.20300
Epoch:0014, train_loss=1.44723, train_acc=0.97144, val_loss=2.01032, val_acc=0.95073, time=1.23400
Epoch:0015, train_loss=1.44355, train_acc=0.97407, val_loss=2.01000, val_acc=0.95255, time=1.17699
Epoch:0016, train_loss=1.44055, train_acc=0.97569, val_loss=2.00980, val_acc=0.95620, time=1.11803
Epoch:0017, train_loss=1.43808, train_acc=0.97914, val_loss=2.00968, val_acc=0.95255, time=1.28300
Epoch:0018, train_loss=1.43579, train_acc=0.98035, val_loss=2.00962, val_acc=0.95620, time=1.13701
Epoch:0019, train_loss=1.43340, train_acc=0.98177, val_loss=2.00962, val_acc=0.95985, time=1.24401
Epoch:0020, train_loss=1.43124, train_acc=0.98400, val_loss=2.00967, val_acc=0.96168, time=1.31201
Epoch:0021, train_loss=1.42954, train_acc=0.98602, val_loss=2.00976, val_acc=0.95985, time=1.18601
Epoch:0022, train_loss=1.42816, train_acc=0.98704, val_loss=2.00980, val_acc=0.95803, time=1.14200
Epoch:0023, train_loss=1.42687, train_acc=0.98704, val_loss=2.00979, val_acc=0.95803, time=1.23001
Epoch:0024, train_loss=1.42563, train_acc=0.98805, val_loss=2.00974, val_acc=0.95438, time=1.35701
Epoch:0025, train_loss=1.42453, train_acc=0.98845, val_loss=2.00970, val_acc=0.95438, time=1.17401
Epoch:0026, train_loss=1.42359, train_acc=0.98886, val_loss=2.00966, val_acc=0.95620, time=1.20801
Epoch:0027, train_loss=1.42275, train_acc=0.98967, val_loss=2.00963, val_acc=0.95803, time=1.25401
Epoch:0028, train_loss=1.42193, train_acc=0.98987, val_loss=2.00962, val_acc=0.95985, time=1.24899
Epoch:0029, train_loss=1.42112, train_acc=0.99089, val_loss=2.00963, val_acc=0.96168, time=1.16902
Epoch:0030, train_loss=1.42035, train_acc=0.99291, val_loss=2.00965, val_acc=0.95985, time=1.22001
Epoch:0031, train_loss=1.41967, train_acc=0.99352, val_loss=2.00969, val_acc=0.95985, time=1.22600
Epoch:0032, train_loss=1.41908, train_acc=0.99453, val_loss=2.00974, val_acc=0.95985, time=1.14500
Early stopping...

Optimization Finished!

Test set results: loss= 1.80090, accuracy= 0.96939, time= 0.33099

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8571    0.8966    0.8764        87
           1     0.9826    0.9917    0.9871      1083
           2     0.9868    0.9641    0.9753       696
           3     0.8182    0.9000    0.8571        10
           4     0.9359    0.9733    0.9542        75
           5     0.9225    0.9835    0.9520       121
           6     0.9375    0.8333    0.8824        36
           7     0.9067    0.8395    0.8718        81

    accuracy                         0.9694      2189
   macro avg     0.9184    0.9227    0.9195      2189
weighted avg     0.9697    0.9694    0.9693      2189


Macro average Test Precision, Recall and F1-Score...
(0.9184063444180357, 0.9227457310608631, 0.9195458226406111, None)

Micro average Test Precision, Recall and F1-Score...
(0.9693924166285975, 0.9693924166285975, 0.9693924166285975, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
