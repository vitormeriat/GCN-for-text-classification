
==========: 270235885095700
Epoch:0001, train_loss=2.06069, train_acc=0.19627, val_loss=2.05949, val_acc=0.56022, time=1.19200
Epoch:0002, train_loss=1.90251, train_acc=0.56127, val_loss=2.04744, val_acc=0.68613, time=1.21101
Epoch:0003, train_loss=1.79928, train_acc=0.68118, val_loss=2.03980, val_acc=0.76095, time=1.31204
Epoch:0004, train_loss=1.73454, train_acc=0.74823, val_loss=2.03481, val_acc=0.79380, time=1.43595
Epoch:0005, train_loss=1.69166, train_acc=0.76666, val_loss=2.03104, val_acc=0.80657, time=1.28601
Epoch:0006, train_loss=1.65788, train_acc=0.77740, val_loss=2.02783, val_acc=0.81569, time=1.25800
Epoch:0007, train_loss=1.62801, train_acc=0.79380, val_loss=2.02507, val_acc=0.82847, time=1.30800
Epoch:0008, train_loss=1.60153, train_acc=0.81791, val_loss=2.02280, val_acc=0.86679, time=1.32101
Epoch:0009, train_loss=1.57941, train_acc=0.85274, val_loss=2.02102, val_acc=0.89964, time=1.34201
Epoch:0010, train_loss=1.56198, train_acc=0.88455, val_loss=2.01963, val_acc=0.90876, time=1.37601
Epoch:0011, train_loss=1.54839, train_acc=0.90014, val_loss=2.01851, val_acc=0.91788, time=1.31701
Epoch:0012, train_loss=1.53728, train_acc=0.91209, val_loss=2.01753, val_acc=0.91971, time=1.22601
Epoch:0013, train_loss=1.52752, train_acc=0.92121, val_loss=2.01664, val_acc=0.92153, time=1.29801
Epoch:0014, train_loss=1.51852, train_acc=0.92931, val_loss=2.01582, val_acc=0.92701, time=1.22002
Epoch:0015, train_loss=1.51002, train_acc=0.93275, val_loss=2.01507, val_acc=0.93431, time=1.27702
Epoch:0016, train_loss=1.50203, train_acc=0.93863, val_loss=2.01439, val_acc=0.94343, time=1.27501
Epoch:0017, train_loss=1.49468, train_acc=0.94288, val_loss=2.01380, val_acc=0.94343, time=1.26000
Epoch:0018, train_loss=1.48810, train_acc=0.94734, val_loss=2.01330, val_acc=0.93978, time=1.28701
Epoch:0019, train_loss=1.48231, train_acc=0.95118, val_loss=2.01288, val_acc=0.93796, time=1.26800
Epoch:0020, train_loss=1.47722, train_acc=0.95321, val_loss=2.01253, val_acc=0.93978, time=1.21202
Epoch:0021, train_loss=1.47268, train_acc=0.95605, val_loss=2.01223, val_acc=0.94343, time=1.27600
Epoch:0022, train_loss=1.46859, train_acc=0.95767, val_loss=2.01197, val_acc=0.94526, time=1.24801
Epoch:0023, train_loss=1.46488, train_acc=0.95929, val_loss=2.01174, val_acc=0.94891, time=1.26399
Epoch:0024, train_loss=1.46148, train_acc=0.96152, val_loss=2.01151, val_acc=0.94891, time=1.37401
Epoch:0025, train_loss=1.45832, train_acc=0.96435, val_loss=2.01128, val_acc=0.94891, time=1.25500
Epoch:0026, train_loss=1.45535, train_acc=0.96557, val_loss=2.01105, val_acc=0.95073, time=1.23701
Epoch:0027, train_loss=1.45257, train_acc=0.96962, val_loss=2.01084, val_acc=0.95255, time=1.27100
Epoch:0028, train_loss=1.45000, train_acc=0.97306, val_loss=2.01064, val_acc=0.95438, time=1.20500
Epoch:0029, train_loss=1.44769, train_acc=0.97529, val_loss=2.01046, val_acc=0.95438, time=1.29700
Epoch:0030, train_loss=1.44566, train_acc=0.97731, val_loss=2.01032, val_acc=0.95803, time=1.22202
Epoch:0031, train_loss=1.44391, train_acc=0.97833, val_loss=2.01021, val_acc=0.95803, time=1.29699
Epoch:0032, train_loss=1.44241, train_acc=0.97934, val_loss=2.01012, val_acc=0.95803, time=1.23000
Epoch:0033, train_loss=1.44111, train_acc=0.97934, val_loss=2.01005, val_acc=0.95803, time=1.24100
Epoch:0034, train_loss=1.43992, train_acc=0.98015, val_loss=2.00999, val_acc=0.95803, time=1.23400
Epoch:0035, train_loss=1.43879, train_acc=0.98076, val_loss=2.00994, val_acc=0.95438, time=1.20200
Epoch:0036, train_loss=1.43767, train_acc=0.98157, val_loss=2.00989, val_acc=0.95438, time=1.23202
Epoch:0037, train_loss=1.43657, train_acc=0.98197, val_loss=2.00983, val_acc=0.95438, time=1.26001
Epoch:0038, train_loss=1.43549, train_acc=0.98238, val_loss=2.00978, val_acc=0.95438, time=1.30600
Epoch:0039, train_loss=1.43445, train_acc=0.98319, val_loss=2.00972, val_acc=0.95073, time=1.27101
Epoch:0040, train_loss=1.43345, train_acc=0.98339, val_loss=2.00966, val_acc=0.95073, time=1.28000
Epoch:0041, train_loss=1.43252, train_acc=0.98420, val_loss=2.00960, val_acc=0.95255, time=1.21901
Epoch:0042, train_loss=1.43164, train_acc=0.98542, val_loss=2.00955, val_acc=0.95438, time=1.27700
Epoch:0043, train_loss=1.43084, train_acc=0.98643, val_loss=2.00950, val_acc=0.95803, time=1.24502
Epoch:0044, train_loss=1.43011, train_acc=0.98683, val_loss=2.00946, val_acc=0.95985, time=1.26002
Epoch:0045, train_loss=1.42947, train_acc=0.98764, val_loss=2.00943, val_acc=0.95985, time=1.29400
Epoch:0046, train_loss=1.42888, train_acc=0.98825, val_loss=2.00940, val_acc=0.95985, time=1.22400
Epoch:0047, train_loss=1.42834, train_acc=0.98886, val_loss=2.00939, val_acc=0.96168, time=1.27401
Epoch:0048, train_loss=1.42782, train_acc=0.98906, val_loss=2.00938, val_acc=0.96168, time=1.23199
Epoch:0049, train_loss=1.42732, train_acc=0.98906, val_loss=2.00937, val_acc=0.96168, time=1.18499
Epoch:0050, train_loss=1.42683, train_acc=0.98926, val_loss=2.00937, val_acc=0.96168, time=1.26300
Epoch:0051, train_loss=1.42636, train_acc=0.98987, val_loss=2.00937, val_acc=0.96168, time=1.24101
Epoch:0052, train_loss=1.42590, train_acc=0.98987, val_loss=2.00936, val_acc=0.96168, time=1.26601
Epoch:0053, train_loss=1.42545, train_acc=0.99068, val_loss=2.00936, val_acc=0.96168, time=1.29400
Epoch:0054, train_loss=1.42501, train_acc=0.99109, val_loss=2.00935, val_acc=0.95985, time=1.19901
Epoch:0055, train_loss=1.42458, train_acc=0.99149, val_loss=2.00934, val_acc=0.95985, time=1.18801
Epoch:0056, train_loss=1.42417, train_acc=0.99210, val_loss=2.00933, val_acc=0.95985, time=1.22101
Epoch:0057, train_loss=1.42379, train_acc=0.99271, val_loss=2.00933, val_acc=0.95985, time=1.28001
Epoch:0058, train_loss=1.42342, train_acc=0.99271, val_loss=2.00932, val_acc=0.95803, time=1.33202
Epoch:0059, train_loss=1.42308, train_acc=0.99332, val_loss=2.00932, val_acc=0.95803, time=1.29501
Epoch:0060, train_loss=1.42275, train_acc=0.99352, val_loss=2.00933, val_acc=0.95803, time=1.34502
Epoch:0061, train_loss=1.42244, train_acc=0.99372, val_loss=2.00933, val_acc=0.95803, time=1.32000
Epoch:0062, train_loss=1.42213, train_acc=0.99392, val_loss=2.00933, val_acc=0.95803, time=1.22500
Epoch:0063, train_loss=1.42185, train_acc=0.99413, val_loss=2.00934, val_acc=0.95803, time=1.29701
Early stopping...

Optimization Finished!

Test set results: loss= 1.79847, accuracy= 0.96939, time= 0.42501

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8511    0.9195    0.8840        87
           1     0.9817    0.9917    0.9867      1083
           2     0.9825    0.9698    0.9761       696
           3     1.0000    1.0000    1.0000        10
           4     0.9024    0.9867    0.9427        75
           5     0.9508    0.9587    0.9547       121
           6     0.9286    0.7222    0.8125        36
           7     0.9306    0.8272    0.8758        81

    accuracy                         0.9694      2189
   macro avg     0.9410    0.9220    0.9291      2189
weighted avg     0.9697    0.9694    0.9691      2189


Macro average Test Precision, Recall and F1-Score...
(0.9409625907347898, 0.9219730794313672, 0.9290650385141306, None)

Micro average Test Precision, Recall and F1-Score...
(0.9693924166285975, 0.9693924166285975, 0.9693924166285975, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
