
==========: 240632630904700
Epoch:0001, train_loss=2.14330, train_acc=0.02633, val_loss=2.06446, val_acc=0.63504, time=1.27603
Epoch:0002, train_loss=1.95082, train_acc=0.62710, val_loss=2.05101, val_acc=0.68978, time=1.17200
Epoch:0003, train_loss=1.83313, train_acc=0.68888, val_loss=2.04305, val_acc=0.74270, time=1.20202
Epoch:0004, train_loss=1.76423, train_acc=0.73769, val_loss=2.03800, val_acc=0.78285, time=1.24400
Epoch:0005, train_loss=1.72105, train_acc=0.76362, val_loss=2.03429, val_acc=0.79745, time=1.15602
Epoch:0006, train_loss=1.68912, train_acc=0.77942, val_loss=2.03115, val_acc=0.79745, time=1.11600
Epoch:0007, train_loss=1.66130, train_acc=0.78570, val_loss=2.02829, val_acc=0.81022, time=1.24201
Epoch:0008, train_loss=1.63505, train_acc=0.79380, val_loss=2.02572, val_acc=0.82664, time=1.16201
Epoch:0009, train_loss=1.61073, train_acc=0.81689, val_loss=2.02357, val_acc=0.85584, time=1.09701
Epoch:0010, train_loss=1.58984, train_acc=0.84485, val_loss=2.02187, val_acc=0.88686, time=1.18600
Epoch:0011, train_loss=1.57308, train_acc=0.86510, val_loss=2.02053, val_acc=0.89051, time=1.28400
Epoch:0012, train_loss=1.55970, train_acc=0.88090, val_loss=2.01940, val_acc=0.90146, time=1.34300
Epoch:0013, train_loss=1.54836, train_acc=0.89366, val_loss=2.01840, val_acc=0.91058, time=1.14400
Epoch:0014, train_loss=1.53825, train_acc=0.90419, val_loss=2.01753, val_acc=0.91606, time=1.31001
Epoch:0015, train_loss=1.52915, train_acc=0.91574, val_loss=2.01677, val_acc=0.92701, time=1.15000
Epoch:0016, train_loss=1.52109, train_acc=0.92445, val_loss=2.01613, val_acc=0.93066, time=1.28200
Epoch:0017, train_loss=1.51394, train_acc=0.92931, val_loss=2.01555, val_acc=0.93431, time=1.18401
Epoch:0018, train_loss=1.50736, train_acc=0.93417, val_loss=2.01501, val_acc=0.93248, time=1.29002
Epoch:0019, train_loss=1.50106, train_acc=0.93640, val_loss=2.01450, val_acc=0.93431, time=1.25901
Epoch:0020, train_loss=1.49497, train_acc=0.94126, val_loss=2.01402, val_acc=0.93431, time=1.20301
Epoch:0021, train_loss=1.48924, train_acc=0.94612, val_loss=2.01359, val_acc=0.93978, time=1.25301
Epoch:0022, train_loss=1.48409, train_acc=0.95260, val_loss=2.01323, val_acc=0.93978, time=1.28901
Epoch:0023, train_loss=1.47961, train_acc=0.95443, val_loss=2.01291, val_acc=0.94526, time=1.19201
Epoch:0024, train_loss=1.47571, train_acc=0.95605, val_loss=2.01262, val_acc=0.94161, time=1.19400
Epoch:0025, train_loss=1.47219, train_acc=0.95787, val_loss=2.01235, val_acc=0.94161, time=1.22301
Epoch:0026, train_loss=1.46889, train_acc=0.96070, val_loss=2.01208, val_acc=0.94526, time=1.18000
Epoch:0027, train_loss=1.46571, train_acc=0.96131, val_loss=2.01181, val_acc=0.94708, time=1.16902
Epoch:0028, train_loss=1.46264, train_acc=0.96273, val_loss=2.01155, val_acc=0.94708, time=1.12301
Epoch:0029, train_loss=1.45970, train_acc=0.96455, val_loss=2.01130, val_acc=0.94891, time=1.21300
Epoch:0030, train_loss=1.45694, train_acc=0.96617, val_loss=2.01108, val_acc=0.94891, time=1.17900
Epoch:0031, train_loss=1.45440, train_acc=0.96881, val_loss=2.01088, val_acc=0.95073, time=1.26302
Epoch:0032, train_loss=1.45212, train_acc=0.97063, val_loss=2.01072, val_acc=0.95438, time=1.12900
Epoch:0033, train_loss=1.45010, train_acc=0.97164, val_loss=2.01059, val_acc=0.95255, time=1.22602
Epoch:0034, train_loss=1.44829, train_acc=0.97428, val_loss=2.01048, val_acc=0.95803, time=1.27899
Epoch:0035, train_loss=1.44664, train_acc=0.97488, val_loss=2.01038, val_acc=0.95438, time=1.15101
Epoch:0036, train_loss=1.44511, train_acc=0.97711, val_loss=2.01030, val_acc=0.95620, time=1.19701
Epoch:0037, train_loss=1.44368, train_acc=0.97914, val_loss=2.01022, val_acc=0.95438, time=1.16402
Epoch:0038, train_loss=1.44235, train_acc=0.98015, val_loss=2.01014, val_acc=0.95620, time=1.16201
Epoch:0039, train_loss=1.44114, train_acc=0.98096, val_loss=2.01008, val_acc=0.95620, time=1.18302
Epoch:0040, train_loss=1.44005, train_acc=0.98218, val_loss=2.01002, val_acc=0.95255, time=1.20002
Epoch:0041, train_loss=1.43906, train_acc=0.98197, val_loss=2.00997, val_acc=0.95255, time=1.26002
Epoch:0042, train_loss=1.43813, train_acc=0.98238, val_loss=2.00991, val_acc=0.95073, time=1.34001
Epoch:0043, train_loss=1.43721, train_acc=0.98218, val_loss=2.00985, val_acc=0.95073, time=1.19202
Epoch:0044, train_loss=1.43627, train_acc=0.98258, val_loss=2.00978, val_acc=0.95255, time=1.19301
Epoch:0045, train_loss=1.43533, train_acc=0.98380, val_loss=2.00972, val_acc=0.95620, time=1.21503
Epoch:0046, train_loss=1.43442, train_acc=0.98440, val_loss=2.00967, val_acc=0.95985, time=1.23301
Epoch:0047, train_loss=1.43356, train_acc=0.98400, val_loss=2.00962, val_acc=0.96168, time=1.14502
Epoch:0048, train_loss=1.43278, train_acc=0.98521, val_loss=2.00958, val_acc=0.96168, time=1.22998
Epoch:0049, train_loss=1.43207, train_acc=0.98582, val_loss=2.00954, val_acc=0.96168, time=1.18102
Epoch:0050, train_loss=1.43142, train_acc=0.98602, val_loss=2.00951, val_acc=0.96168, time=1.21700
Epoch:0051, train_loss=1.43079, train_acc=0.98683, val_loss=2.00947, val_acc=0.96168, time=1.17599
Epoch:0052, train_loss=1.43020, train_acc=0.98764, val_loss=2.00944, val_acc=0.96168, time=1.29601
Epoch:0053, train_loss=1.42963, train_acc=0.98764, val_loss=2.00941, val_acc=0.96168, time=1.18200
Epoch:0054, train_loss=1.42910, train_acc=0.98805, val_loss=2.00938, val_acc=0.96168, time=1.18702
Epoch:0055, train_loss=1.42861, train_acc=0.98886, val_loss=2.00936, val_acc=0.96168, time=1.10900
Epoch:0056, train_loss=1.42815, train_acc=0.98947, val_loss=2.00934, val_acc=0.96350, time=1.21301
Epoch:0057, train_loss=1.42771, train_acc=0.98947, val_loss=2.00932, val_acc=0.96350, time=1.18401
Epoch:0058, train_loss=1.42728, train_acc=0.98967, val_loss=2.00931, val_acc=0.96350, time=1.17700
Epoch:0059, train_loss=1.42685, train_acc=0.99007, val_loss=2.00931, val_acc=0.96533, time=1.22901
Epoch:0060, train_loss=1.42642, train_acc=0.99068, val_loss=2.00930, val_acc=0.96533, time=1.22101
Epoch:0061, train_loss=1.42600, train_acc=0.99068, val_loss=2.00930, val_acc=0.96350, time=1.24200
Epoch:0062, train_loss=1.42560, train_acc=0.99170, val_loss=2.00930, val_acc=0.96168, time=1.20199
Epoch:0063, train_loss=1.42522, train_acc=0.99190, val_loss=2.00931, val_acc=0.95985, time=1.31402
Epoch:0064, train_loss=1.42486, train_acc=0.99230, val_loss=2.00931, val_acc=0.95985, time=1.19501
Epoch:0065, train_loss=1.42451, train_acc=0.99271, val_loss=2.00931, val_acc=0.96350, time=1.17502
Epoch:0066, train_loss=1.42418, train_acc=0.99271, val_loss=2.00931, val_acc=0.96350, time=1.19201
Epoch:0067, train_loss=1.42386, train_acc=0.99311, val_loss=2.00930, val_acc=0.96350, time=1.15501
Epoch:0068, train_loss=1.42354, train_acc=0.99332, val_loss=2.00929, val_acc=0.96350, time=1.20700
Epoch:0069, train_loss=1.42324, train_acc=0.99352, val_loss=2.00929, val_acc=0.96350, time=1.22801
Epoch:0070, train_loss=1.42296, train_acc=0.99392, val_loss=2.00928, val_acc=0.96350, time=1.16502
Epoch:0071, train_loss=1.42268, train_acc=0.99433, val_loss=2.00928, val_acc=0.96350, time=1.32499
Epoch:0072, train_loss=1.42242, train_acc=0.99433, val_loss=2.00927, val_acc=0.96350, time=1.32200
Epoch:0073, train_loss=1.42216, train_acc=0.99473, val_loss=2.00927, val_acc=0.96350, time=1.30603
Epoch:0074, train_loss=1.42191, train_acc=0.99494, val_loss=2.00927, val_acc=0.96350, time=1.23901
Epoch:0075, train_loss=1.42166, train_acc=0.99514, val_loss=2.00927, val_acc=0.96350, time=1.23101
Epoch:0076, train_loss=1.42143, train_acc=0.99514, val_loss=2.00927, val_acc=0.96350, time=1.19203
Epoch:0077, train_loss=1.42120, train_acc=0.99554, val_loss=2.00928, val_acc=0.96350, time=1.14300
Epoch:0078, train_loss=1.42098, train_acc=0.99575, val_loss=2.00928, val_acc=0.96350, time=1.27300
Early stopping...

Optimization Finished!

Test set results: loss= 1.79874, accuracy= 0.97076, time= 0.39000

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8804    0.9310    0.9050        87
           1     0.9808    0.9917    0.9862      1083
           2     0.9825    0.9684    0.9754       696
           3     1.0000    1.0000    1.0000        10
           4     0.8916    0.9867    0.9367        75
           5     0.9440    0.9752    0.9593       121
           6     1.0000    0.6944    0.8197        36
           7     0.9452    0.8519    0.8961        81

    accuracy                         0.9708      2189
   macro avg     0.9531    0.9249    0.9348      2189
weighted avg     0.9714    0.9708    0.9704      2189


Macro average Test Precision, Recall and F1-Score...
(0.9530669666948686, 0.9249105765727567, 0.93481078546692, None)

Micro average Test Precision, Recall and F1-Score...
(0.9707629054362723, 0.9707629054362723, 0.9707629054362723, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
