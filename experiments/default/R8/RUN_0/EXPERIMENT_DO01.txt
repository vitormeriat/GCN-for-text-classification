
==========: 239542292549800
Epoch:0001, train_loss=2.07309, train_acc=0.41138, val_loss=2.05956, val_acc=0.51825, time=1.31201
Epoch:0002, train_loss=1.89903, train_acc=0.53312, val_loss=2.04648, val_acc=0.66971, time=1.07801
Epoch:0003, train_loss=1.78948, train_acc=0.67187, val_loss=2.03896, val_acc=0.75912, time=1.16801
Epoch:0004, train_loss=1.72744, train_acc=0.74519, val_loss=2.03428, val_acc=0.78467, time=1.17299
Epoch:0005, train_loss=1.68784, train_acc=0.76261, val_loss=2.03066, val_acc=0.79380, time=1.16000
Epoch:0006, train_loss=1.65530, train_acc=0.77557, val_loss=2.02752, val_acc=0.80839, time=1.17801
Epoch:0007, train_loss=1.62590, train_acc=0.79218, val_loss=2.02486, val_acc=0.83577, time=1.19801
Epoch:0008, train_loss=1.60027, train_acc=0.82034, val_loss=2.02273, val_acc=0.87226, time=1.22901
Epoch:0009, train_loss=1.57945, train_acc=0.85193, val_loss=2.02107, val_acc=0.89416, time=1.16600
Epoch:0010, train_loss=1.56296, train_acc=0.87989, val_loss=2.01970, val_acc=0.90328, time=1.15099
Epoch:0011, train_loss=1.54931, train_acc=0.89326, val_loss=2.01851, val_acc=0.91058, time=1.14600
Epoch:0012, train_loss=1.53717, train_acc=0.90359, val_loss=2.01742, val_acc=0.91971, time=1.25701
Epoch:0013, train_loss=1.52596, train_acc=0.91533, val_loss=2.01647, val_acc=0.93066, time=1.21001
Epoch:0014, train_loss=1.51581, train_acc=0.92809, val_loss=2.01566, val_acc=0.93613, time=1.09603
Epoch:0015, train_loss=1.50704, train_acc=0.93620, val_loss=2.01501, val_acc=0.93978, time=1.11300
Epoch:0016, train_loss=1.49975, train_acc=0.94004, val_loss=2.01448, val_acc=0.93796, time=1.16202
Epoch:0017, train_loss=1.49366, train_acc=0.94389, val_loss=2.01403, val_acc=0.93796, time=1.17800
Epoch:0018, train_loss=1.48831, train_acc=0.94693, val_loss=2.01361, val_acc=0.94526, time=1.11701
Epoch:0019, train_loss=1.48334, train_acc=0.95058, val_loss=2.01322, val_acc=0.94526, time=1.12500
Epoch:0020, train_loss=1.47863, train_acc=0.95281, val_loss=2.01284, val_acc=0.94343, time=1.16602
Epoch:0021, train_loss=1.47420, train_acc=0.95524, val_loss=2.01250, val_acc=0.94526, time=1.15200
Epoch:0022, train_loss=1.47013, train_acc=0.95807, val_loss=2.01219, val_acc=0.94526, time=1.14901
Epoch:0023, train_loss=1.46644, train_acc=0.96111, val_loss=2.01191, val_acc=0.94708, time=1.14800
Epoch:0024, train_loss=1.46308, train_acc=0.96212, val_loss=2.01164, val_acc=0.94891, time=1.13299
Epoch:0025, train_loss=1.45998, train_acc=0.96314, val_loss=2.01138, val_acc=0.95073, time=1.11701
Epoch:0026, train_loss=1.45707, train_acc=0.96516, val_loss=2.01114, val_acc=0.95073, time=1.21600
Epoch:0027, train_loss=1.45435, train_acc=0.96800, val_loss=2.01091, val_acc=0.94891, time=1.12301
Epoch:0028, train_loss=1.45188, train_acc=0.97043, val_loss=2.01072, val_acc=0.95255, time=1.20901
Epoch:0029, train_loss=1.44967, train_acc=0.97104, val_loss=2.01055, val_acc=0.95255, time=1.26200
Epoch:0030, train_loss=1.44771, train_acc=0.97205, val_loss=2.01042, val_acc=0.95073, time=1.21801
Epoch:0031, train_loss=1.44596, train_acc=0.97306, val_loss=2.01030, val_acc=0.95073, time=1.17300
Epoch:0032, train_loss=1.44436, train_acc=0.97610, val_loss=2.01020, val_acc=0.95073, time=1.19101
Epoch:0033, train_loss=1.44286, train_acc=0.97752, val_loss=2.01012, val_acc=0.95438, time=1.17701
Epoch:0034, train_loss=1.44146, train_acc=0.97914, val_loss=2.01004, val_acc=0.95255, time=1.19301
Epoch:0035, train_loss=1.44017, train_acc=0.97974, val_loss=2.00998, val_acc=0.95438, time=1.21301
Epoch:0036, train_loss=1.43900, train_acc=0.98076, val_loss=2.00993, val_acc=0.95438, time=1.13201
Epoch:0037, train_loss=1.43792, train_acc=0.98096, val_loss=2.00989, val_acc=0.95620, time=1.20101
Epoch:0038, train_loss=1.43692, train_acc=0.98157, val_loss=2.00985, val_acc=0.95803, time=1.19000
Epoch:0039, train_loss=1.43595, train_acc=0.98197, val_loss=2.00981, val_acc=0.95803, time=1.23401
Epoch:0040, train_loss=1.43501, train_acc=0.98258, val_loss=2.00976, val_acc=0.95620, time=1.14801
Epoch:0041, train_loss=1.43409, train_acc=0.98197, val_loss=2.00972, val_acc=0.95803, time=1.15201
Epoch:0042, train_loss=1.43323, train_acc=0.98339, val_loss=2.00967, val_acc=0.95620, time=1.19802
Epoch:0043, train_loss=1.43243, train_acc=0.98380, val_loss=2.00962, val_acc=0.95620, time=1.31102
Epoch:0044, train_loss=1.43168, train_acc=0.98420, val_loss=2.00958, val_acc=0.95255, time=1.19901
Epoch:0045, train_loss=1.43098, train_acc=0.98542, val_loss=2.00953, val_acc=0.95255, time=1.17801
Epoch:0046, train_loss=1.43031, train_acc=0.98602, val_loss=2.00948, val_acc=0.95620, time=1.32001
Epoch:0047, train_loss=1.42968, train_acc=0.98704, val_loss=2.00944, val_acc=0.95803, time=1.09900
Epoch:0048, train_loss=1.42909, train_acc=0.98785, val_loss=2.00941, val_acc=0.96168, time=1.19501
Epoch:0049, train_loss=1.42856, train_acc=0.98785, val_loss=2.00938, val_acc=0.96168, time=1.17802
Epoch:0050, train_loss=1.42806, train_acc=0.98805, val_loss=2.00937, val_acc=0.96168, time=1.18000
Epoch:0051, train_loss=1.42759, train_acc=0.98866, val_loss=2.00936, val_acc=0.95985, time=1.26902
Epoch:0052, train_loss=1.42713, train_acc=0.98926, val_loss=2.00935, val_acc=0.95985, time=1.21700
Epoch:0053, train_loss=1.42668, train_acc=0.98987, val_loss=2.00935, val_acc=0.95985, time=1.16801
Epoch:0054, train_loss=1.42622, train_acc=0.99089, val_loss=2.00936, val_acc=0.95985, time=1.17801
Epoch:0055, train_loss=1.42578, train_acc=0.99129, val_loss=2.00936, val_acc=0.95985, time=1.16500
Epoch:0056, train_loss=1.42536, train_acc=0.99210, val_loss=2.00936, val_acc=0.95985, time=1.21599
Epoch:0057, train_loss=1.42496, train_acc=0.99190, val_loss=2.00936, val_acc=0.95803, time=1.22701
Epoch:0058, train_loss=1.42457, train_acc=0.99210, val_loss=2.00936, val_acc=0.95803, time=1.20301
Epoch:0059, train_loss=1.42420, train_acc=0.99230, val_loss=2.00936, val_acc=0.95803, time=1.26001
Epoch:0060, train_loss=1.42385, train_acc=0.99271, val_loss=2.00935, val_acc=0.95803, time=1.22400
Epoch:0061, train_loss=1.42351, train_acc=0.99291, val_loss=2.00934, val_acc=0.95803, time=1.19501
Epoch:0062, train_loss=1.42319, train_acc=0.99332, val_loss=2.00933, val_acc=0.95803, time=1.15901
Epoch:0063, train_loss=1.42289, train_acc=0.99392, val_loss=2.00933, val_acc=0.95803, time=1.27400
Epoch:0064, train_loss=1.42259, train_acc=0.99392, val_loss=2.00933, val_acc=0.95985, time=1.12902
Epoch:0065, train_loss=1.42231, train_acc=0.99413, val_loss=2.00933, val_acc=0.95985, time=1.17798
Epoch:0066, train_loss=1.42203, train_acc=0.99453, val_loss=2.00933, val_acc=0.95985, time=1.19300
Epoch:0067, train_loss=1.42176, train_acc=0.99473, val_loss=2.00934, val_acc=0.95985, time=1.19601
Epoch:0068, train_loss=1.42151, train_acc=0.99494, val_loss=2.00934, val_acc=0.95985, time=1.18199
Early stopping...

Optimization Finished!

Test set results: loss= 1.79835, accuracy= 0.97031, time= 0.36900

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8876    0.9080    0.8977        87
           1     0.9799    0.9917    0.9858      1083
           2     0.9825    0.9670    0.9747       696
           3     1.0000    1.0000    1.0000        10
           4     0.9024    0.9867    0.9427        75
           5     0.9512    0.9669    0.9590       121
           6     0.9630    0.7222    0.8254        36
           7     0.9221    0.8765    0.8987        81

    accuracy                         0.9703      2189
   macro avg     0.9486    0.9274    0.9355      2189
weighted avg     0.9705    0.9703    0.9700      2189


Macro average Test Precision, Recall and F1-Score...
(0.9485935787735675, 0.9273829997772854, 0.9354973956076298, None)

Micro average Test Precision, Recall and F1-Score...
(0.970306075833714, 0.970306075833714, 0.970306075833714, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
