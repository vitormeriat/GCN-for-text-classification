
==========: 225948567060300
Epoch:0001, train_loss=2.06322, train_acc=0.22949, val_loss=2.05998, val_acc=0.62226, time=1.26500
Epoch:0002, train_loss=1.90494, train_acc=0.64776, val_loss=2.04742, val_acc=0.73358, time=1.29800
Epoch:0003, train_loss=1.79839, train_acc=0.73445, val_loss=2.03965, val_acc=0.78102, time=1.25501
Epoch:0004, train_loss=1.73256, train_acc=0.76342, val_loss=2.03466, val_acc=0.79380, time=1.21300
Epoch:0005, train_loss=1.68916, train_acc=0.77740, val_loss=2.03092, val_acc=0.80292, time=1.25700
Epoch:0006, train_loss=1.65530, train_acc=0.78610, val_loss=2.02778, val_acc=0.81204, time=1.19400
Epoch:0007, train_loss=1.62602, train_acc=0.80859, val_loss=2.02512, val_acc=0.84307, time=1.27402
Epoch:0008, train_loss=1.60080, train_acc=0.83674, val_loss=2.02294, val_acc=0.86314, time=1.32400
Epoch:0009, train_loss=1.57997, train_acc=0.85457, val_loss=2.02117, val_acc=0.88139, time=1.31201
Epoch:0010, train_loss=1.56289, train_acc=0.87361, val_loss=2.01969, val_acc=0.89599, time=1.28302
Epoch:0011, train_loss=1.54847, train_acc=0.89022, val_loss=2.01843, val_acc=0.90328, time=1.32500
Epoch:0012, train_loss=1.53593, train_acc=0.90662, val_loss=2.01738, val_acc=0.91423, time=1.27500
Epoch:0013, train_loss=1.52494, train_acc=0.91878, val_loss=2.01649, val_acc=0.92518, time=1.23802
Epoch:0014, train_loss=1.51538, train_acc=0.92870, val_loss=2.01577, val_acc=0.93613, time=1.20500
Epoch:0015, train_loss=1.50723, train_acc=0.93923, val_loss=2.01518, val_acc=0.93796, time=1.20901
Epoch:0016, train_loss=1.50041, train_acc=0.94369, val_loss=2.01470, val_acc=0.93248, time=1.41402
Epoch:0017, train_loss=1.49460, train_acc=0.94612, val_loss=2.01428, val_acc=0.92701, time=1.18800
Epoch:0018, train_loss=1.48934, train_acc=0.94713, val_loss=2.01386, val_acc=0.92518, time=1.30901
Epoch:0019, train_loss=1.48429, train_acc=0.95017, val_loss=2.01344, val_acc=0.93066, time=1.18000
Epoch:0020, train_loss=1.47935, train_acc=0.95260, val_loss=2.01304, val_acc=0.93796, time=1.35200
Epoch:0021, train_loss=1.47469, train_acc=0.95483, val_loss=2.01267, val_acc=0.94343, time=1.19001
Epoch:0022, train_loss=1.47042, train_acc=0.95827, val_loss=2.01233, val_acc=0.94526, time=1.34500
Epoch:0023, train_loss=1.46659, train_acc=0.96050, val_loss=2.01202, val_acc=0.94526, time=1.20501
Epoch:0024, train_loss=1.46313, train_acc=0.96131, val_loss=2.01172, val_acc=0.94891, time=1.21700
Epoch:0025, train_loss=1.45991, train_acc=0.96314, val_loss=2.01145, val_acc=0.94891, time=1.16701
Epoch:0026, train_loss=1.45684, train_acc=0.96597, val_loss=2.01119, val_acc=0.94891, time=1.34299
Epoch:0027, train_loss=1.45389, train_acc=0.96840, val_loss=2.01096, val_acc=0.95255, time=1.25501
Epoch:0028, train_loss=1.45112, train_acc=0.97063, val_loss=2.01077, val_acc=0.95803, time=1.24602
Epoch:0029, train_loss=1.44860, train_acc=0.97306, val_loss=2.01062, val_acc=0.95803, time=1.24999
Epoch:0030, train_loss=1.44639, train_acc=0.97509, val_loss=2.01051, val_acc=0.95620, time=1.32801
Epoch:0031, train_loss=1.44453, train_acc=0.97691, val_loss=2.01044, val_acc=0.95438, time=1.22102
Epoch:0032, train_loss=1.44298, train_acc=0.97853, val_loss=2.01038, val_acc=0.95255, time=1.21602
Epoch:0033, train_loss=1.44166, train_acc=0.97853, val_loss=2.01032, val_acc=0.95073, time=1.33400
Epoch:0034, train_loss=1.44047, train_acc=0.97893, val_loss=2.01027, val_acc=0.94891, time=1.20700
Epoch:0035, train_loss=1.43935, train_acc=0.98035, val_loss=2.01020, val_acc=0.94891, time=1.24801
Epoch:0036, train_loss=1.43826, train_acc=0.98177, val_loss=2.01012, val_acc=0.94708, time=1.33201
Epoch:0037, train_loss=1.43721, train_acc=0.98238, val_loss=2.01005, val_acc=0.95073, time=1.37901
Epoch:0038, train_loss=1.43622, train_acc=0.98238, val_loss=2.00997, val_acc=0.95438, time=1.34800
Epoch:0039, train_loss=1.43528, train_acc=0.98258, val_loss=2.00990, val_acc=0.95620, time=1.16601
Epoch:0040, train_loss=1.43436, train_acc=0.98359, val_loss=2.00982, val_acc=0.95620, time=1.17001
Epoch:0041, train_loss=1.43346, train_acc=0.98440, val_loss=2.00976, val_acc=0.95803, time=1.14799
Epoch:0042, train_loss=1.43256, train_acc=0.98501, val_loss=2.00970, val_acc=0.95620, time=1.21401
Epoch:0043, train_loss=1.43170, train_acc=0.98562, val_loss=2.00965, val_acc=0.95803, time=1.20300
Epoch:0044, train_loss=1.43091, train_acc=0.98582, val_loss=2.00961, val_acc=0.95803, time=1.17802
Epoch:0045, train_loss=1.43019, train_acc=0.98724, val_loss=2.00958, val_acc=0.95803, time=1.24800
Epoch:0046, train_loss=1.42955, train_acc=0.98744, val_loss=2.00956, val_acc=0.95803, time=1.23802
Epoch:0047, train_loss=1.42896, train_acc=0.98845, val_loss=2.00953, val_acc=0.95803, time=1.18600
Epoch:0048, train_loss=1.42841, train_acc=0.98866, val_loss=2.00951, val_acc=0.95620, time=1.19801
Epoch:0049, train_loss=1.42789, train_acc=0.98967, val_loss=2.00949, val_acc=0.95620, time=1.23801
Epoch:0050, train_loss=1.42739, train_acc=0.98967, val_loss=2.00947, val_acc=0.95620, time=1.24701
Epoch:0051, train_loss=1.42691, train_acc=0.98987, val_loss=2.00945, val_acc=0.95803, time=1.20701
Epoch:0052, train_loss=1.42645, train_acc=0.99007, val_loss=2.00944, val_acc=0.96168, time=1.18900
Epoch:0053, train_loss=1.42600, train_acc=0.99028, val_loss=2.00943, val_acc=0.96168, time=1.12101
Epoch:0054, train_loss=1.42556, train_acc=0.99109, val_loss=2.00942, val_acc=0.95985, time=1.26700
Epoch:0055, train_loss=1.42515, train_acc=0.99170, val_loss=2.00942, val_acc=0.95803, time=1.14599
Epoch:0056, train_loss=1.42475, train_acc=0.99190, val_loss=2.00942, val_acc=0.95803, time=1.17001
Epoch:0057, train_loss=1.42437, train_acc=0.99251, val_loss=2.00942, val_acc=0.95985, time=1.18801
Epoch:0058, train_loss=1.42401, train_acc=0.99230, val_loss=2.00942, val_acc=0.96168, time=1.26702
Epoch:0059, train_loss=1.42366, train_acc=0.99311, val_loss=2.00942, val_acc=0.96168, time=1.32199
Epoch:0060, train_loss=1.42332, train_acc=0.99311, val_loss=2.00941, val_acc=0.95985, time=1.24301
Epoch:0061, train_loss=1.42298, train_acc=0.99352, val_loss=2.00940, val_acc=0.95985, time=1.21601
Epoch:0062, train_loss=1.42266, train_acc=0.99413, val_loss=2.00939, val_acc=0.95985, time=1.30301
Epoch:0063, train_loss=1.42235, train_acc=0.99413, val_loss=2.00938, val_acc=0.95985, time=1.22701
Epoch:0064, train_loss=1.42206, train_acc=0.99413, val_loss=2.00938, val_acc=0.95985, time=1.34101
Epoch:0065, train_loss=1.42179, train_acc=0.99413, val_loss=2.00938, val_acc=0.95985, time=1.38900
Epoch:0066, train_loss=1.42152, train_acc=0.99433, val_loss=2.00938, val_acc=0.95985, time=1.21001
Epoch:0067, train_loss=1.42126, train_acc=0.99453, val_loss=2.00938, val_acc=0.95985, time=1.19201
Epoch:0068, train_loss=1.42101, train_acc=0.99494, val_loss=2.00939, val_acc=0.95985, time=1.09899
Epoch:0069, train_loss=1.42077, train_acc=0.99514, val_loss=2.00940, val_acc=0.95985, time=1.29201
Early stopping...

Optimization Finished!

Test set results: loss= 1.79851, accuracy= 0.97350, time= 0.41293

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8804    0.9310    0.9050        87
           1     0.9835    0.9917    0.9876      1083
           2     0.9840    0.9727    0.9783       696
           3     1.0000    1.0000    1.0000        10
           4     0.9136    0.9867    0.9487        75
           5     0.9520    0.9835    0.9675       121
           6     1.0000    0.7222    0.8387        36
           7     0.9333    0.8642    0.8974        81

    accuracy                         0.9735      2189
   macro avg     0.9559    0.9315    0.9404      2189
weighted avg     0.9739    0.9735    0.9732      2189


Macro average Test Precision, Recall and F1-Score...
(0.9558595592848836, 0.93149785962621, 0.94041012970617, None)

Micro average Test Precision, Recall and F1-Score...
(0.9735038830516217, 0.9735038830516217, 0.9735038830516217, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
