
==========: 227535562993000
Epoch:0001, train_loss=2.12251, train_acc=0.05044, val_loss=2.07345, val_acc=0.47628, time=1.12200
Epoch:0002, train_loss=2.02220, train_acc=0.50091, val_loss=2.06363, val_acc=0.52737, time=1.28501
Epoch:0003, train_loss=1.93753, train_acc=0.54790, val_loss=2.05555, val_acc=0.58394, time=1.23503
Epoch:0004, train_loss=1.86826, train_acc=0.60117, val_loss=2.04912, val_acc=0.65876, time=1.13400
Epoch:0005, train_loss=1.81367, train_acc=0.65566, val_loss=2.04418, val_acc=0.71715, time=1.17901
Epoch:0006, train_loss=1.77201, train_acc=0.70286, val_loss=2.04040, val_acc=0.75182, time=1.16700
Epoch:0007, train_loss=1.74030, train_acc=0.73324, val_loss=2.03748, val_acc=0.77372, time=1.16001
Epoch:0008, train_loss=1.71562, train_acc=0.75005, val_loss=2.03513, val_acc=0.78650, time=1.19699
Epoch:0009, train_loss=1.69537, train_acc=0.76160, val_loss=2.03312, val_acc=0.79927, time=1.22502
Epoch:0010, train_loss=1.67760, train_acc=0.77112, val_loss=2.03132, val_acc=0.80292, time=1.16999
Epoch:0011, train_loss=1.66113, train_acc=0.77821, val_loss=2.02964, val_acc=0.80839, time=1.21400
Epoch:0012, train_loss=1.64545, train_acc=0.78752, val_loss=2.02805, val_acc=0.81204, time=1.17201
Epoch:0013, train_loss=1.63043, train_acc=0.79887, val_loss=2.02657, val_acc=0.81934, time=1.25803
Epoch:0014, train_loss=1.61620, train_acc=0.81203, val_loss=2.02520, val_acc=0.83212, time=1.14299
Epoch:0015, train_loss=1.60293, train_acc=0.82905, val_loss=2.02395, val_acc=0.85219, time=1.16400
Epoch:0016, train_loss=1.59076, train_acc=0.84403, val_loss=2.02282, val_acc=0.87044, time=1.19500
Epoch:0017, train_loss=1.57971, train_acc=0.86226, val_loss=2.02181, val_acc=0.88686, time=1.21401
Epoch:0018, train_loss=1.56974, train_acc=0.87685, val_loss=2.02090, val_acc=0.89416, time=1.21502
Epoch:0019, train_loss=1.56074, train_acc=0.88698, val_loss=2.02008, val_acc=0.90328, time=1.10902
Epoch:0020, train_loss=1.55259, train_acc=0.89710, val_loss=2.01936, val_acc=0.90876, time=1.25301
Epoch:0021, train_loss=1.54522, train_acc=0.90500, val_loss=2.01870, val_acc=0.91971, time=1.11801
Epoch:0022, train_loss=1.53851, train_acc=0.91371, val_loss=2.01811, val_acc=0.92701, time=1.20299
Epoch:0023, train_loss=1.53237, train_acc=0.92181, val_loss=2.01758, val_acc=0.93248, time=1.22301
Epoch:0024, train_loss=1.52672, train_acc=0.92627, val_loss=2.01709, val_acc=0.93431, time=1.27499
Epoch:0025, train_loss=1.52148, train_acc=0.93194, val_loss=2.01665, val_acc=0.93613, time=1.23500
Epoch:0026, train_loss=1.51658, train_acc=0.93640, val_loss=2.01623, val_acc=0.94343, time=1.13003
Epoch:0027, train_loss=1.51194, train_acc=0.93923, val_loss=2.01583, val_acc=0.93978, time=1.23999
Epoch:0028, train_loss=1.50752, train_acc=0.94207, val_loss=2.01545, val_acc=0.93796, time=1.15402
Epoch:0029, train_loss=1.50331, train_acc=0.94511, val_loss=2.01510, val_acc=0.93796, time=1.18300
Epoch:0030, train_loss=1.49929, train_acc=0.94673, val_loss=2.01476, val_acc=0.94526, time=1.19101
Epoch:0031, train_loss=1.49549, train_acc=0.94997, val_loss=2.01444, val_acc=0.94708, time=1.26100
Epoch:0032, train_loss=1.49192, train_acc=0.95078, val_loss=2.01414, val_acc=0.94708, time=1.16001
Epoch:0033, train_loss=1.48859, train_acc=0.95341, val_loss=2.01387, val_acc=0.94708, time=1.18002
Epoch:0034, train_loss=1.48550, train_acc=0.95443, val_loss=2.01361, val_acc=0.94708, time=1.11601
Epoch:0035, train_loss=1.48261, train_acc=0.95544, val_loss=2.01337, val_acc=0.94708, time=1.20500
Epoch:0036, train_loss=1.47991, train_acc=0.95686, val_loss=2.01314, val_acc=0.94891, time=1.22500
Epoch:0037, train_loss=1.47735, train_acc=0.95767, val_loss=2.01292, val_acc=0.94891, time=1.25302
Epoch:0038, train_loss=1.47489, train_acc=0.95908, val_loss=2.01271, val_acc=0.95073, time=1.17202
Epoch:0039, train_loss=1.47252, train_acc=0.96010, val_loss=2.01250, val_acc=0.95073, time=1.15802
Epoch:0040, train_loss=1.47023, train_acc=0.96152, val_loss=2.01230, val_acc=0.95255, time=1.25000
Epoch:0041, train_loss=1.46803, train_acc=0.96314, val_loss=2.01211, val_acc=0.95073, time=1.16001
Epoch:0042, train_loss=1.46591, train_acc=0.96435, val_loss=2.01193, val_acc=0.95073, time=1.19600
Epoch:0043, train_loss=1.46391, train_acc=0.96617, val_loss=2.01176, val_acc=0.95073, time=1.23601
Epoch:0044, train_loss=1.46201, train_acc=0.96759, val_loss=2.01161, val_acc=0.95620, time=1.25503
Epoch:0045, train_loss=1.46024, train_acc=0.96941, val_loss=2.01147, val_acc=0.95620, time=1.15500
Epoch:0046, train_loss=1.45859, train_acc=0.97043, val_loss=2.01135, val_acc=0.95438, time=1.23701
Epoch:0047, train_loss=1.45705, train_acc=0.97286, val_loss=2.01124, val_acc=0.95438, time=1.20200
Epoch:0048, train_loss=1.45561, train_acc=0.97468, val_loss=2.01114, val_acc=0.95438, time=1.23901
Epoch:0049, train_loss=1.45426, train_acc=0.97529, val_loss=2.01104, val_acc=0.95438, time=1.19802
Epoch:0050, train_loss=1.45300, train_acc=0.97671, val_loss=2.01096, val_acc=0.95438, time=1.17602
Epoch:0051, train_loss=1.45180, train_acc=0.97731, val_loss=2.01088, val_acc=0.95438, time=1.18901
Epoch:0052, train_loss=1.45068, train_acc=0.97792, val_loss=2.01080, val_acc=0.95438, time=1.25401
Epoch:0053, train_loss=1.44961, train_acc=0.97893, val_loss=2.01073, val_acc=0.95438, time=1.27202
Epoch:0054, train_loss=1.44860, train_acc=0.97934, val_loss=2.01066, val_acc=0.95438, time=1.13000
Epoch:0055, train_loss=1.44763, train_acc=0.97934, val_loss=2.01059, val_acc=0.95438, time=1.14901
Epoch:0056, train_loss=1.44670, train_acc=0.98035, val_loss=2.01053, val_acc=0.95255, time=1.16000
Epoch:0057, train_loss=1.44581, train_acc=0.98096, val_loss=2.01047, val_acc=0.95255, time=1.15601
Epoch:0058, train_loss=1.44494, train_acc=0.98116, val_loss=2.01040, val_acc=0.95255, time=1.16800
Epoch:0059, train_loss=1.44411, train_acc=0.98177, val_loss=2.01035, val_acc=0.95255, time=1.16200
Epoch:0060, train_loss=1.44331, train_acc=0.98258, val_loss=2.01029, val_acc=0.95438, time=1.23300
Epoch:0061, train_loss=1.44254, train_acc=0.98278, val_loss=2.01024, val_acc=0.95438, time=1.13900
Epoch:0062, train_loss=1.44179, train_acc=0.98380, val_loss=2.01019, val_acc=0.95438, time=1.17202
Epoch:0063, train_loss=1.44109, train_acc=0.98380, val_loss=2.01014, val_acc=0.95620, time=1.19599
Epoch:0064, train_loss=1.44041, train_acc=0.98380, val_loss=2.01010, val_acc=0.95620, time=1.15498
Epoch:0065, train_loss=1.43976, train_acc=0.98440, val_loss=2.01006, val_acc=0.95803, time=1.24601
Epoch:0066, train_loss=1.43914, train_acc=0.98461, val_loss=2.01002, val_acc=0.95803, time=1.29601
Epoch:0067, train_loss=1.43855, train_acc=0.98461, val_loss=2.00998, val_acc=0.95803, time=1.17600
Epoch:0068, train_loss=1.43798, train_acc=0.98481, val_loss=2.00995, val_acc=0.95803, time=1.21802
Epoch:0069, train_loss=1.43744, train_acc=0.98562, val_loss=2.00992, val_acc=0.95985, time=1.24401
Epoch:0070, train_loss=1.43691, train_acc=0.98562, val_loss=2.00989, val_acc=0.96168, time=1.34800
Epoch:0071, train_loss=1.43641, train_acc=0.98602, val_loss=2.00986, val_acc=0.96168, time=1.17601
Epoch:0072, train_loss=1.43592, train_acc=0.98623, val_loss=2.00983, val_acc=0.96168, time=1.22801
Epoch:0073, train_loss=1.43545, train_acc=0.98623, val_loss=2.00981, val_acc=0.96168, time=1.23000
Epoch:0074, train_loss=1.43499, train_acc=0.98683, val_loss=2.00978, val_acc=0.96168, time=1.23502
Epoch:0075, train_loss=1.43455, train_acc=0.98704, val_loss=2.00976, val_acc=0.96168, time=1.22500
Epoch:0076, train_loss=1.43412, train_acc=0.98744, val_loss=2.00973, val_acc=0.95985, time=1.14500
Epoch:0077, train_loss=1.43370, train_acc=0.98825, val_loss=2.00971, val_acc=0.95985, time=1.12501
Epoch:0078, train_loss=1.43329, train_acc=0.98906, val_loss=2.00969, val_acc=0.95985, time=1.23500
Epoch:0079, train_loss=1.43289, train_acc=0.98926, val_loss=2.00968, val_acc=0.95985, time=1.22102
Epoch:0080, train_loss=1.43251, train_acc=0.98967, val_loss=2.00966, val_acc=0.95985, time=1.15701
Epoch:0081, train_loss=1.43214, train_acc=0.98947, val_loss=2.00964, val_acc=0.95985, time=1.28201
Epoch:0082, train_loss=1.43177, train_acc=0.98967, val_loss=2.00963, val_acc=0.95985, time=1.18401
Epoch:0083, train_loss=1.43142, train_acc=0.99028, val_loss=2.00961, val_acc=0.95985, time=1.25100
Epoch:0084, train_loss=1.43108, train_acc=0.99028, val_loss=2.00960, val_acc=0.96168, time=1.11101
Epoch:0085, train_loss=1.43075, train_acc=0.99048, val_loss=2.00959, val_acc=0.96168, time=1.24302
Epoch:0086, train_loss=1.43042, train_acc=0.99048, val_loss=2.00958, val_acc=0.96168, time=1.21601
Epoch:0087, train_loss=1.43011, train_acc=0.99048, val_loss=2.00956, val_acc=0.96168, time=1.18800
Epoch:0088, train_loss=1.42980, train_acc=0.99089, val_loss=2.00955, val_acc=0.96168, time=1.20301
Epoch:0089, train_loss=1.42950, train_acc=0.99089, val_loss=2.00954, val_acc=0.96168, time=1.20100
Epoch:0090, train_loss=1.42921, train_acc=0.99109, val_loss=2.00953, val_acc=0.96168, time=1.18702
Epoch:0091, train_loss=1.42893, train_acc=0.99149, val_loss=2.00952, val_acc=0.96168, time=1.23200
Epoch:0092, train_loss=1.42865, train_acc=0.99170, val_loss=2.00951, val_acc=0.96168, time=1.22000
Epoch:0093, train_loss=1.42838, train_acc=0.99170, val_loss=2.00950, val_acc=0.96168, time=1.21900
Epoch:0094, train_loss=1.42811, train_acc=0.99170, val_loss=2.00949, val_acc=0.96168, time=1.32699
Epoch:0095, train_loss=1.42786, train_acc=0.99190, val_loss=2.00948, val_acc=0.96168, time=1.27800
Epoch:0096, train_loss=1.42760, train_acc=0.99210, val_loss=2.00947, val_acc=0.96168, time=1.17900
Epoch:0097, train_loss=1.42736, train_acc=0.99210, val_loss=2.00946, val_acc=0.96168, time=1.23201
Epoch:0098, train_loss=1.42712, train_acc=0.99271, val_loss=2.00946, val_acc=0.96168, time=1.11000
Epoch:0099, train_loss=1.42688, train_acc=0.99271, val_loss=2.00945, val_acc=0.96168, time=1.18702
Epoch:0100, train_loss=1.42665, train_acc=0.99311, val_loss=2.00944, val_acc=0.96168, time=1.26502
Epoch:0101, train_loss=1.42642, train_acc=0.99311, val_loss=2.00943, val_acc=0.96168, time=1.20598
Epoch:0102, train_loss=1.42620, train_acc=0.99332, val_loss=2.00943, val_acc=0.96168, time=1.20599
Epoch:0103, train_loss=1.42599, train_acc=0.99332, val_loss=2.00942, val_acc=0.96168, time=1.16102
Epoch:0104, train_loss=1.42578, train_acc=0.99332, val_loss=2.00941, val_acc=0.96168, time=1.14402
Epoch:0105, train_loss=1.42557, train_acc=0.99352, val_loss=2.00941, val_acc=0.96168, time=1.19601
Epoch:0106, train_loss=1.42537, train_acc=0.99372, val_loss=2.00940, val_acc=0.96168, time=1.29401
Epoch:0107, train_loss=1.42517, train_acc=0.99433, val_loss=2.00940, val_acc=0.95985, time=1.21501
Epoch:0108, train_loss=1.42497, train_acc=0.99453, val_loss=2.00939, val_acc=0.95985, time=1.26500
Epoch:0109, train_loss=1.42478, train_acc=0.99453, val_loss=2.00939, val_acc=0.95803, time=1.17102
Epoch:0110, train_loss=1.42459, train_acc=0.99453, val_loss=2.00938, val_acc=0.95803, time=1.20701
Epoch:0111, train_loss=1.42441, train_acc=0.99453, val_loss=2.00938, val_acc=0.95803, time=1.22999
Epoch:0112, train_loss=1.42423, train_acc=0.99453, val_loss=2.00937, val_acc=0.95803, time=1.19600
Epoch:0113, train_loss=1.42406, train_acc=0.99494, val_loss=2.00937, val_acc=0.95803, time=1.27901
Epoch:0114, train_loss=1.42388, train_acc=0.99494, val_loss=2.00937, val_acc=0.95803, time=1.15200
Epoch:0115, train_loss=1.42371, train_acc=0.99514, val_loss=2.00936, val_acc=0.95803, time=1.18303
Epoch:0116, train_loss=1.42355, train_acc=0.99514, val_loss=2.00936, val_acc=0.95803, time=1.14800
Epoch:0117, train_loss=1.42338, train_acc=0.99534, val_loss=2.00935, val_acc=0.95803, time=1.15100
Epoch:0118, train_loss=1.42322, train_acc=0.99534, val_loss=2.00935, val_acc=0.95803, time=1.20201
Epoch:0119, train_loss=1.42307, train_acc=0.99534, val_loss=2.00935, val_acc=0.95803, time=1.16300
Epoch:0120, train_loss=1.42291, train_acc=0.99554, val_loss=2.00934, val_acc=0.95803, time=1.18101
Epoch:0121, train_loss=1.42276, train_acc=0.99554, val_loss=2.00934, val_acc=0.95803, time=1.22502
Epoch:0122, train_loss=1.42261, train_acc=0.99575, val_loss=2.00934, val_acc=0.95803, time=1.36001
Epoch:0123, train_loss=1.42247, train_acc=0.99575, val_loss=2.00933, val_acc=0.95803, time=1.12699
Epoch:0124, train_loss=1.42232, train_acc=0.99575, val_loss=2.00933, val_acc=0.95803, time=1.22801
Epoch:0125, train_loss=1.42218, train_acc=0.99575, val_loss=2.00933, val_acc=0.95803, time=1.25900
Epoch:0126, train_loss=1.42205, train_acc=0.99575, val_loss=2.00933, val_acc=0.95985, time=1.15001
Epoch:0127, train_loss=1.42191, train_acc=0.99595, val_loss=2.00932, val_acc=0.95985, time=1.20400
Epoch:0128, train_loss=1.42178, train_acc=0.99595, val_loss=2.00932, val_acc=0.95985, time=1.16201
Epoch:0129, train_loss=1.42165, train_acc=0.99595, val_loss=2.00932, val_acc=0.95985, time=1.18799
Epoch:0130, train_loss=1.42152, train_acc=0.99595, val_loss=2.00932, val_acc=0.95985, time=1.25602
Epoch:0131, train_loss=1.42139, train_acc=0.99595, val_loss=2.00932, val_acc=0.95985, time=1.15601
Epoch:0132, train_loss=1.42127, train_acc=0.99595, val_loss=2.00931, val_acc=0.95985, time=1.23599
Epoch:0133, train_loss=1.42115, train_acc=0.99595, val_loss=2.00931, val_acc=0.95985, time=1.22301
Epoch:0134, train_loss=1.42103, train_acc=0.99595, val_loss=2.00931, val_acc=0.95985, time=1.19801
Epoch:0135, train_loss=1.42091, train_acc=0.99595, val_loss=2.00931, val_acc=0.95985, time=1.20401
Epoch:0136, train_loss=1.42079, train_acc=0.99595, val_loss=2.00931, val_acc=0.95985, time=1.16400
Epoch:0137, train_loss=1.42068, train_acc=0.99615, val_loss=2.00931, val_acc=0.95985, time=1.18601
Epoch:0138, train_loss=1.42057, train_acc=0.99635, val_loss=2.00930, val_acc=0.95985, time=1.26100
Epoch:0139, train_loss=1.42046, train_acc=0.99635, val_loss=2.00930, val_acc=0.95985, time=1.21301
Epoch:0140, train_loss=1.42035, train_acc=0.99656, val_loss=2.00930, val_acc=0.95985, time=1.19601
Epoch:0141, train_loss=1.42024, train_acc=0.99656, val_loss=2.00930, val_acc=0.95985, time=1.20301
Epoch:0142, train_loss=1.42014, train_acc=0.99656, val_loss=2.00930, val_acc=0.95985, time=1.18599
Epoch:0143, train_loss=1.42004, train_acc=0.99656, val_loss=2.00930, val_acc=0.95985, time=1.30402
Epoch:0144, train_loss=1.41993, train_acc=0.99656, val_loss=2.00930, val_acc=0.95985, time=1.21600
Epoch:0145, train_loss=1.41983, train_acc=0.99656, val_loss=2.00930, val_acc=0.95985, time=1.11800
Epoch:0146, train_loss=1.41974, train_acc=0.99676, val_loss=2.00930, val_acc=0.95985, time=1.21399
Epoch:0147, train_loss=1.41964, train_acc=0.99676, val_loss=2.00930, val_acc=0.95985, time=1.25900
Epoch:0148, train_loss=1.41955, train_acc=0.99676, val_loss=2.00930, val_acc=0.95985, time=1.22500
Epoch:0149, train_loss=1.41945, train_acc=0.99676, val_loss=2.00930, val_acc=0.95985, time=1.22001
Epoch:0150, train_loss=1.41936, train_acc=0.99676, val_loss=2.00929, val_acc=0.95985, time=1.31701
Epoch:0151, train_loss=1.41927, train_acc=0.99676, val_loss=2.00929, val_acc=0.95985, time=1.16401
Epoch:0152, train_loss=1.41918, train_acc=0.99676, val_loss=2.00929, val_acc=0.95985, time=1.23901
Epoch:0153, train_loss=1.41909, train_acc=0.99716, val_loss=2.00929, val_acc=0.95985, time=1.23399
Epoch:0154, train_loss=1.41901, train_acc=0.99716, val_loss=2.00929, val_acc=0.95985, time=1.13602
Epoch:0155, train_loss=1.41892, train_acc=0.99737, val_loss=2.00929, val_acc=0.95985, time=1.11799
Epoch:0156, train_loss=1.41884, train_acc=0.99737, val_loss=2.00929, val_acc=0.95985, time=1.22201
Epoch:0157, train_loss=1.41876, train_acc=0.99737, val_loss=2.00929, val_acc=0.95985, time=1.28300
Epoch:0158, train_loss=1.41868, train_acc=0.99757, val_loss=2.00929, val_acc=0.95985, time=1.19401
Epoch:0159, train_loss=1.41860, train_acc=0.99757, val_loss=2.00929, val_acc=0.95985, time=1.13901
Epoch:0160, train_loss=1.41852, train_acc=0.99757, val_loss=2.00929, val_acc=0.95985, time=1.18501
Epoch:0161, train_loss=1.41844, train_acc=0.99757, val_loss=2.00929, val_acc=0.95985, time=1.29000
Epoch:0162, train_loss=1.41837, train_acc=0.99757, val_loss=2.00929, val_acc=0.95985, time=1.15400
Epoch:0163, train_loss=1.41829, train_acc=0.99757, val_loss=2.00929, val_acc=0.95985, time=1.23302
Epoch:0164, train_loss=1.41822, train_acc=0.99757, val_loss=2.00929, val_acc=0.95985, time=1.19700
Early stopping...

Optimization Finished!

Test set results: loss= 1.79882, accuracy= 0.97168, time= 0.39201

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8511    0.9195    0.8840        87
           1     0.9826    0.9926    0.9876      1083
           2     0.9840    0.9713    0.9776       696
           3     1.0000    1.0000    1.0000        10
           4     0.9136    0.9867    0.9487        75
           5     0.9597    0.9835    0.9714       121
           6     1.0000    0.7222    0.8387        36
           7     0.9178    0.8272    0.8701        81

    accuracy                         0.9717      2189
   macro avg     0.9511    0.9254    0.9348      2189
weighted avg     0.9722    0.9717    0.9713      2189


Macro average Test Precision, Recall and F1-Score...
(0.9510938264418232, 0.9253672708155062, 0.9347683174839294, None)

Micro average Test Precision, Recall and F1-Score...
(0.9716765646413887, 0.9716765646413887, 0.9716765646413887, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
