
==========: 240744867272800
Epoch:0001, train_loss=2.11674, train_acc=0.03727, val_loss=2.07200, val_acc=0.48723, time=1.19501
Epoch:0002, train_loss=2.01198, train_acc=0.50334, val_loss=2.06219, val_acc=0.58029, time=1.26201
Epoch:0003, train_loss=1.92741, train_acc=0.59814, val_loss=2.05454, val_acc=0.64234, time=1.21301
Epoch:0004, train_loss=1.86190, train_acc=0.64837, val_loss=2.04870, val_acc=0.67518, time=1.25201
Epoch:0005, train_loss=1.81199, train_acc=0.69313, val_loss=2.04422, val_acc=0.71715, time=1.18900
Epoch:0006, train_loss=1.77380, train_acc=0.72959, val_loss=2.04070, val_acc=0.75000, time=1.13202
Epoch:0007, train_loss=1.74371, train_acc=0.75511, val_loss=2.03784, val_acc=0.77737, time=1.17801
Epoch:0008, train_loss=1.71902, train_acc=0.76788, val_loss=2.03542, val_acc=0.78832, time=1.26501
Epoch:0009, train_loss=1.69775, train_acc=0.77557, val_loss=2.03329, val_acc=0.78832, time=1.24001
Epoch:0010, train_loss=1.67860, train_acc=0.78003, val_loss=2.03135, val_acc=0.80839, time=1.17202
Epoch:0011, train_loss=1.66077, train_acc=0.78509, val_loss=2.02955, val_acc=0.81204, time=1.31100
Epoch:0012, train_loss=1.64386, train_acc=0.79461, val_loss=2.02789, val_acc=0.82482, time=1.20502
Epoch:0013, train_loss=1.62785, train_acc=0.80717, val_loss=2.02636, val_acc=0.83577, time=1.24600
Epoch:0014, train_loss=1.61299, train_acc=0.82317, val_loss=2.02499, val_acc=0.85036, time=1.19202
Epoch:0015, train_loss=1.59953, train_acc=0.83735, val_loss=2.02378, val_acc=0.87226, time=1.22600
Epoch:0016, train_loss=1.58759, train_acc=0.85497, val_loss=2.02273, val_acc=0.88321, time=1.20401
Epoch:0017, train_loss=1.57709, train_acc=0.86834, val_loss=2.02181, val_acc=0.88869, time=1.13100
Epoch:0018, train_loss=1.56785, train_acc=0.87968, val_loss=2.02099, val_acc=0.89964, time=1.25001
Epoch:0019, train_loss=1.55962, train_acc=0.88981, val_loss=2.02024, val_acc=0.90146, time=1.20499
Epoch:0020, train_loss=1.55214, train_acc=0.89913, val_loss=2.01955, val_acc=0.90876, time=1.20801
Epoch:0021, train_loss=1.54521, train_acc=0.90500, val_loss=2.01891, val_acc=0.91423, time=1.12500
Epoch:0022, train_loss=1.53873, train_acc=0.91331, val_loss=2.01830, val_acc=0.91971, time=1.16401
Epoch:0023, train_loss=1.53263, train_acc=0.92060, val_loss=2.01773, val_acc=0.92518, time=1.23101
Epoch:0024, train_loss=1.52684, train_acc=0.92728, val_loss=2.01720, val_acc=0.92518, time=1.30702
Epoch:0025, train_loss=1.52134, train_acc=0.93255, val_loss=2.01669, val_acc=0.93248, time=1.20000
Epoch:0026, train_loss=1.51610, train_acc=0.93620, val_loss=2.01622, val_acc=0.93613, time=1.20200
Epoch:0027, train_loss=1.51111, train_acc=0.93883, val_loss=2.01577, val_acc=0.93978, time=1.20600
Epoch:0028, train_loss=1.50636, train_acc=0.94227, val_loss=2.01535, val_acc=0.93978, time=1.18601
Epoch:0029, train_loss=1.50188, train_acc=0.94491, val_loss=2.01497, val_acc=0.93796, time=1.19900
Epoch:0030, train_loss=1.49766, train_acc=0.94774, val_loss=2.01461, val_acc=0.94161, time=1.10000
Epoch:0031, train_loss=1.49372, train_acc=0.95037, val_loss=2.01428, val_acc=0.94161, time=1.19201
Epoch:0032, train_loss=1.49006, train_acc=0.95301, val_loss=2.01399, val_acc=0.94343, time=1.26201
Epoch:0033, train_loss=1.48668, train_acc=0.95503, val_loss=2.01372, val_acc=0.94161, time=1.21099
Epoch:0034, train_loss=1.48357, train_acc=0.95503, val_loss=2.01347, val_acc=0.94526, time=1.24301
Epoch:0035, train_loss=1.48068, train_acc=0.95706, val_loss=2.01325, val_acc=0.94526, time=1.10300
Epoch:0036, train_loss=1.47800, train_acc=0.95827, val_loss=2.01303, val_acc=0.94343, time=1.05600
Epoch:0037, train_loss=1.47549, train_acc=0.95949, val_loss=2.01283, val_acc=0.94526, time=1.25900
Epoch:0038, train_loss=1.47310, train_acc=0.96192, val_loss=2.01263, val_acc=0.94891, time=1.32001
Epoch:0039, train_loss=1.47082, train_acc=0.96395, val_loss=2.01243, val_acc=0.95073, time=1.10400
Epoch:0040, train_loss=1.46863, train_acc=0.96597, val_loss=2.01224, val_acc=0.95255, time=1.27701
Epoch:0041, train_loss=1.46654, train_acc=0.96759, val_loss=2.01206, val_acc=0.95255, time=1.17402
Epoch:0042, train_loss=1.46454, train_acc=0.96840, val_loss=2.01189, val_acc=0.95255, time=1.22903
Epoch:0043, train_loss=1.46264, train_acc=0.96962, val_loss=2.01173, val_acc=0.95255, time=1.29199
Epoch:0044, train_loss=1.46085, train_acc=0.97144, val_loss=2.01158, val_acc=0.95255, time=1.14201
Epoch:0045, train_loss=1.45917, train_acc=0.97266, val_loss=2.01144, val_acc=0.95255, time=1.17301
Epoch:0046, train_loss=1.45760, train_acc=0.97407, val_loss=2.01132, val_acc=0.95438, time=1.25501
Epoch:0047, train_loss=1.45613, train_acc=0.97428, val_loss=2.01120, val_acc=0.95438, time=1.20902
Epoch:0048, train_loss=1.45476, train_acc=0.97569, val_loss=2.01110, val_acc=0.95620, time=1.24000
Epoch:0049, train_loss=1.45347, train_acc=0.97590, val_loss=2.01101, val_acc=0.95620, time=1.15301
Epoch:0050, train_loss=1.45226, train_acc=0.97792, val_loss=2.01092, val_acc=0.95438, time=1.27902
Epoch:0051, train_loss=1.45112, train_acc=0.97893, val_loss=2.01084, val_acc=0.95438, time=1.21001
Epoch:0052, train_loss=1.45003, train_acc=0.97893, val_loss=2.01077, val_acc=0.95438, time=1.38001
Epoch:0053, train_loss=1.44899, train_acc=0.97974, val_loss=2.01070, val_acc=0.95438, time=1.16701
Epoch:0054, train_loss=1.44799, train_acc=0.98015, val_loss=2.01063, val_acc=0.95438, time=1.21900
Epoch:0055, train_loss=1.44702, train_acc=0.98055, val_loss=2.01056, val_acc=0.95438, time=1.19501
Epoch:0056, train_loss=1.44609, train_acc=0.98096, val_loss=2.01049, val_acc=0.95438, time=1.23600
Epoch:0057, train_loss=1.44520, train_acc=0.98116, val_loss=2.01043, val_acc=0.95438, time=1.15100
Epoch:0058, train_loss=1.44434, train_acc=0.98137, val_loss=2.01037, val_acc=0.95255, time=1.13602
Epoch:0059, train_loss=1.44353, train_acc=0.98177, val_loss=2.01031, val_acc=0.95255, time=1.22799
Epoch:0060, train_loss=1.44275, train_acc=0.98218, val_loss=2.01025, val_acc=0.95255, time=1.26602
Epoch:0061, train_loss=1.44201, train_acc=0.98258, val_loss=2.01020, val_acc=0.95255, time=1.23601
Epoch:0062, train_loss=1.44130, train_acc=0.98319, val_loss=2.01015, val_acc=0.95438, time=1.21901
Epoch:0063, train_loss=1.44062, train_acc=0.98339, val_loss=2.01010, val_acc=0.95438, time=1.17000
Epoch:0064, train_loss=1.43996, train_acc=0.98400, val_loss=2.01006, val_acc=0.95803, time=1.14802
Epoch:0065, train_loss=1.43934, train_acc=0.98440, val_loss=2.01002, val_acc=0.95803, time=1.22199
Epoch:0066, train_loss=1.43874, train_acc=0.98501, val_loss=2.00998, val_acc=0.95985, time=1.24701
Epoch:0067, train_loss=1.43816, train_acc=0.98501, val_loss=2.00994, val_acc=0.95985, time=1.23702
Epoch:0068, train_loss=1.43761, train_acc=0.98501, val_loss=2.00991, val_acc=0.95985, time=1.24800
Epoch:0069, train_loss=1.43708, train_acc=0.98521, val_loss=2.00988, val_acc=0.96350, time=1.20200
Epoch:0070, train_loss=1.43656, train_acc=0.98542, val_loss=2.00985, val_acc=0.96350, time=1.13001
Epoch:0071, train_loss=1.43606, train_acc=0.98582, val_loss=2.00982, val_acc=0.96350, time=1.18001
Epoch:0072, train_loss=1.43558, train_acc=0.98602, val_loss=2.00979, val_acc=0.96350, time=1.28700
Epoch:0073, train_loss=1.43511, train_acc=0.98643, val_loss=2.00977, val_acc=0.96715, time=1.17001
Epoch:0074, train_loss=1.43465, train_acc=0.98704, val_loss=2.00974, val_acc=0.96715, time=1.19801
Epoch:0075, train_loss=1.43420, train_acc=0.98724, val_loss=2.00972, val_acc=0.96715, time=1.20099
Epoch:0076, train_loss=1.43377, train_acc=0.98785, val_loss=2.00970, val_acc=0.96715, time=1.26400
Epoch:0077, train_loss=1.43336, train_acc=0.98845, val_loss=2.00968, val_acc=0.96715, time=1.22101
Epoch:0078, train_loss=1.43295, train_acc=0.98906, val_loss=2.00966, val_acc=0.96715, time=1.26701
Epoch:0079, train_loss=1.43256, train_acc=0.98926, val_loss=2.00964, val_acc=0.96533, time=1.20699
Epoch:0080, train_loss=1.43218, train_acc=0.98967, val_loss=2.00962, val_acc=0.96533, time=1.24100
Epoch:0081, train_loss=1.43181, train_acc=0.98987, val_loss=2.00961, val_acc=0.96533, time=1.15802
Epoch:0082, train_loss=1.43145, train_acc=0.99028, val_loss=2.00959, val_acc=0.96533, time=1.18801
Epoch:0083, train_loss=1.43110, train_acc=0.99028, val_loss=2.00957, val_acc=0.96533, time=1.18302
Epoch:0084, train_loss=1.43076, train_acc=0.99048, val_loss=2.00956, val_acc=0.96533, time=1.24401
Epoch:0085, train_loss=1.43043, train_acc=0.99089, val_loss=2.00955, val_acc=0.96533, time=1.19601
Epoch:0086, train_loss=1.43010, train_acc=0.99109, val_loss=2.00954, val_acc=0.96533, time=1.35301
Epoch:0087, train_loss=1.42979, train_acc=0.99129, val_loss=2.00952, val_acc=0.96533, time=1.23702
Epoch:0088, train_loss=1.42948, train_acc=0.99129, val_loss=2.00951, val_acc=0.96533, time=1.19300
Epoch:0089, train_loss=1.42918, train_acc=0.99170, val_loss=2.00950, val_acc=0.96533, time=1.18000
Epoch:0090, train_loss=1.42889, train_acc=0.99271, val_loss=2.00949, val_acc=0.96533, time=1.18801
Epoch:0091, train_loss=1.42860, train_acc=0.99271, val_loss=2.00948, val_acc=0.96533, time=1.27400
Epoch:0092, train_loss=1.42832, train_acc=0.99271, val_loss=2.00947, val_acc=0.96533, time=1.25001
Epoch:0093, train_loss=1.42805, train_acc=0.99271, val_loss=2.00946, val_acc=0.96533, time=1.22200
Epoch:0094, train_loss=1.42779, train_acc=0.99271, val_loss=2.00945, val_acc=0.96533, time=1.22101
Epoch:0095, train_loss=1.42753, train_acc=0.99271, val_loss=2.00945, val_acc=0.96533, time=1.25800
Epoch:0096, train_loss=1.42727, train_acc=0.99271, val_loss=2.00944, val_acc=0.96533, time=1.22499
Epoch:0097, train_loss=1.42703, train_acc=0.99291, val_loss=2.00943, val_acc=0.96533, time=1.25001
Epoch:0098, train_loss=1.42678, train_acc=0.99291, val_loss=2.00942, val_acc=0.96533, time=1.15001
Epoch:0099, train_loss=1.42655, train_acc=0.99291, val_loss=2.00941, val_acc=0.96533, time=1.19700
Epoch:0100, train_loss=1.42632, train_acc=0.99291, val_loss=2.00940, val_acc=0.96533, time=1.12700
Epoch:0101, train_loss=1.42609, train_acc=0.99332, val_loss=2.00939, val_acc=0.96533, time=1.19001
Epoch:0102, train_loss=1.42587, train_acc=0.99392, val_loss=2.00939, val_acc=0.96533, time=1.20901
Epoch:0103, train_loss=1.42565, train_acc=0.99392, val_loss=2.00938, val_acc=0.96533, time=1.18401
Epoch:0104, train_loss=1.42544, train_acc=0.99392, val_loss=2.00938, val_acc=0.96533, time=1.16402
Epoch:0105, train_loss=1.42523, train_acc=0.99392, val_loss=2.00937, val_acc=0.96533, time=1.28100
Epoch:0106, train_loss=1.42503, train_acc=0.99392, val_loss=2.00936, val_acc=0.96533, time=1.15000
Epoch:0107, train_loss=1.42483, train_acc=0.99453, val_loss=2.00936, val_acc=0.96533, time=1.17300
Epoch:0108, train_loss=1.42464, train_acc=0.99473, val_loss=2.00936, val_acc=0.96533, time=1.19601
Epoch:0109, train_loss=1.42445, train_acc=0.99473, val_loss=2.00935, val_acc=0.96533, time=1.18000
Epoch:0110, train_loss=1.42426, train_acc=0.99473, val_loss=2.00935, val_acc=0.96533, time=1.14901
Epoch:0111, train_loss=1.42408, train_acc=0.99494, val_loss=2.00934, val_acc=0.96533, time=1.30202
Epoch:0112, train_loss=1.42390, train_acc=0.99494, val_loss=2.00934, val_acc=0.96533, time=1.22900
Epoch:0113, train_loss=1.42372, train_acc=0.99494, val_loss=2.00933, val_acc=0.96533, time=1.25103
Epoch:0114, train_loss=1.42355, train_acc=0.99514, val_loss=2.00933, val_acc=0.96533, time=1.24500
Epoch:0115, train_loss=1.42338, train_acc=0.99514, val_loss=2.00932, val_acc=0.96533, time=1.16901
Epoch:0116, train_loss=1.42322, train_acc=0.99514, val_loss=2.00932, val_acc=0.96533, time=1.17201
Epoch:0117, train_loss=1.42305, train_acc=0.99514, val_loss=2.00932, val_acc=0.96533, time=1.19601
Epoch:0118, train_loss=1.42289, train_acc=0.99514, val_loss=2.00931, val_acc=0.96533, time=1.29901
Epoch:0119, train_loss=1.42274, train_acc=0.99514, val_loss=2.00931, val_acc=0.96533, time=1.20702
Epoch:0120, train_loss=1.42258, train_acc=0.99514, val_loss=2.00931, val_acc=0.96533, time=1.22601
Epoch:0121, train_loss=1.42243, train_acc=0.99514, val_loss=2.00930, val_acc=0.96533, time=1.20502
Epoch:0122, train_loss=1.42229, train_acc=0.99534, val_loss=2.00930, val_acc=0.96533, time=1.15401
Epoch:0123, train_loss=1.42214, train_acc=0.99575, val_loss=2.00930, val_acc=0.96533, time=1.16601
Epoch:0124, train_loss=1.42200, train_acc=0.99575, val_loss=2.00930, val_acc=0.96533, time=1.16500
Epoch:0125, train_loss=1.42186, train_acc=0.99575, val_loss=2.00929, val_acc=0.96533, time=1.15101
Epoch:0126, train_loss=1.42172, train_acc=0.99595, val_loss=2.00929, val_acc=0.96533, time=1.10400
Epoch:0127, train_loss=1.42159, train_acc=0.99595, val_loss=2.00929, val_acc=0.96533, time=1.16202
Epoch:0128, train_loss=1.42146, train_acc=0.99595, val_loss=2.00929, val_acc=0.96533, time=1.20999
Epoch:0129, train_loss=1.42133, train_acc=0.99595, val_loss=2.00929, val_acc=0.96533, time=1.13002
Epoch:0130, train_loss=1.42120, train_acc=0.99595, val_loss=2.00928, val_acc=0.96533, time=1.31199
Epoch:0131, train_loss=1.42108, train_acc=0.99595, val_loss=2.00928, val_acc=0.96533, time=1.26302
Epoch:0132, train_loss=1.42095, train_acc=0.99595, val_loss=2.00928, val_acc=0.96533, time=1.20101
Epoch:0133, train_loss=1.42083, train_acc=0.99615, val_loss=2.00928, val_acc=0.96533, time=1.19801
Epoch:0134, train_loss=1.42071, train_acc=0.99635, val_loss=2.00928, val_acc=0.96533, time=1.14701
Epoch:0135, train_loss=1.42060, train_acc=0.99656, val_loss=2.00928, val_acc=0.96533, time=1.14200
Epoch:0136, train_loss=1.42048, train_acc=0.99656, val_loss=2.00928, val_acc=0.96533, time=1.21601
Epoch:0137, train_loss=1.42037, train_acc=0.99656, val_loss=2.00927, val_acc=0.96533, time=1.20101
Epoch:0138, train_loss=1.42026, train_acc=0.99656, val_loss=2.00927, val_acc=0.96350, time=1.19101
Epoch:0139, train_loss=1.42015, train_acc=0.99656, val_loss=2.00927, val_acc=0.96350, time=1.23902
Epoch:0140, train_loss=1.42005, train_acc=0.99656, val_loss=2.00927, val_acc=0.96350, time=1.15000
Epoch:0141, train_loss=1.41994, train_acc=0.99656, val_loss=2.00927, val_acc=0.96350, time=1.33902
Epoch:0142, train_loss=1.41984, train_acc=0.99676, val_loss=2.00927, val_acc=0.96350, time=1.25201
Epoch:0143, train_loss=1.41974, train_acc=0.99676, val_loss=2.00927, val_acc=0.96350, time=1.16200
Epoch:0144, train_loss=1.41964, train_acc=0.99676, val_loss=2.00927, val_acc=0.96350, time=1.26602
Epoch:0145, train_loss=1.41954, train_acc=0.99676, val_loss=2.00927, val_acc=0.96350, time=1.24201
Epoch:0146, train_loss=1.41944, train_acc=0.99676, val_loss=2.00927, val_acc=0.96350, time=1.26401
Epoch:0147, train_loss=1.41935, train_acc=0.99676, val_loss=2.00926, val_acc=0.96350, time=1.14299
Epoch:0148, train_loss=1.41926, train_acc=0.99696, val_loss=2.00926, val_acc=0.96350, time=1.16402
Epoch:0149, train_loss=1.41916, train_acc=0.99716, val_loss=2.00926, val_acc=0.96350, time=1.18100
Epoch:0150, train_loss=1.41907, train_acc=0.99716, val_loss=2.00926, val_acc=0.96350, time=1.23101
Epoch:0151, train_loss=1.41899, train_acc=0.99737, val_loss=2.00926, val_acc=0.96350, time=1.21000
Epoch:0152, train_loss=1.41890, train_acc=0.99737, val_loss=2.00926, val_acc=0.96350, time=1.13301
Epoch:0153, train_loss=1.41881, train_acc=0.99737, val_loss=2.00926, val_acc=0.96350, time=1.18100
Epoch:0154, train_loss=1.41873, train_acc=0.99737, val_loss=2.00926, val_acc=0.96350, time=1.12901
Epoch:0155, train_loss=1.41865, train_acc=0.99737, val_loss=2.00926, val_acc=0.96168, time=1.15401
Epoch:0156, train_loss=1.41856, train_acc=0.99737, val_loss=2.00926, val_acc=0.96168, time=1.25102
Epoch:0157, train_loss=1.41848, train_acc=0.99737, val_loss=2.00926, val_acc=0.96168, time=1.21601
Epoch:0158, train_loss=1.41840, train_acc=0.99737, val_loss=2.00926, val_acc=0.96168, time=1.10501
Epoch:0159, train_loss=1.41833, train_acc=0.99737, val_loss=2.00926, val_acc=0.96168, time=1.17299
Epoch:0160, train_loss=1.41825, train_acc=0.99737, val_loss=2.00926, val_acc=0.96168, time=1.04501
Epoch:0161, train_loss=1.41817, train_acc=0.99737, val_loss=2.00926, val_acc=0.96168, time=1.15100
Early stopping...

Optimization Finished!

Test set results: loss= 1.79916, accuracy= 0.96939, time= 0.36299

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8438    0.9310    0.8852        87
           1     0.9808    0.9926    0.9867      1083
           2     0.9825    0.9670    0.9747       696
           3     1.0000    1.0000    1.0000        10
           4     0.9136    0.9867    0.9487        75
           5     0.9512    0.9669    0.9590       121
           6     0.9630    0.7222    0.8254        36
           7     0.9296    0.8148    0.8684        81

    accuracy                         0.9694      2189
   macro avg     0.9456    0.9227    0.9310      2189
weighted avg     0.9699    0.9694    0.9690      2189


Macro average Test Precision, Recall and F1-Score...
(0.9455514193429512, 0.9226559337422306, 0.9310181638621964, None)

Micro average Test Precision, Recall and F1-Score...
(0.9693924166285975, 0.9693924166285975, 0.9693924166285975, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
