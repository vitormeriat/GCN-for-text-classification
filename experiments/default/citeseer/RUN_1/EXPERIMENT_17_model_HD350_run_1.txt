
==========: 304957158340100
Epoch:0001, train_loss=1.81561, train_acc=0.11782, val_loss=1.79162, val_acc=0.19048, time=0.28599
Epoch:0002, train_loss=1.78051, train_acc=0.21695, val_loss=1.79301, val_acc=0.20346, time=0.28401
Epoch:0003, train_loss=1.77635, train_acc=0.23611, val_loss=1.79412, val_acc=0.21212, time=0.33402
Epoch:0004, train_loss=1.77353, train_acc=0.26628, val_loss=1.79452, val_acc=0.19048, time=0.29899
Epoch:0005, train_loss=1.76851, train_acc=0.33046, val_loss=1.79451, val_acc=0.19913, time=0.30800
Epoch:0006, train_loss=1.76297, train_acc=0.37883, val_loss=1.79423, val_acc=0.18615, time=0.26203
Epoch:0007, train_loss=1.75680, train_acc=0.41427, val_loss=1.79376, val_acc=0.18615, time=0.27400
Epoch:0008, train_loss=1.74964, train_acc=0.43774, val_loss=1.79325, val_acc=0.19913, time=0.30801
Epoch:0009, train_loss=1.74210, train_acc=0.43966, val_loss=1.79281, val_acc=0.19481, time=0.27500
Epoch:0010, train_loss=1.73510, train_acc=0.43008, val_loss=1.79253, val_acc=0.17749, time=0.28200
Epoch:0011, train_loss=1.72895, train_acc=0.43918, val_loss=1.79239, val_acc=0.18615, time=0.32201
Epoch:0012, train_loss=1.72341, train_acc=0.45833, val_loss=1.79235, val_acc=0.19913, time=0.28099
Epoch:0013, train_loss=1.71803, train_acc=0.47989, val_loss=1.79238, val_acc=0.19913, time=0.32102
Epoch:0014, train_loss=1.71234, train_acc=0.49761, val_loss=1.79243, val_acc=0.18182, time=0.26101
Epoch:0015, train_loss=1.70609, train_acc=0.51676, val_loss=1.79252, val_acc=0.18182, time=0.30900
Epoch:0016, train_loss=1.69939, train_acc=0.54310, val_loss=1.79269, val_acc=0.18182, time=0.29300
Epoch:0017, train_loss=1.69260, train_acc=0.55268, val_loss=1.79297, val_acc=0.17749, time=0.32002
Early stopping...

Optimization Finished!

Test set results: loss= 1.79168, accuracy= 0.19537, time= 0.10100

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.1368    0.0847    0.1046       189
           1     0.1250    0.0800    0.0976       150
           2     0.1870    0.2255    0.2044       204
           3     0.2150    0.3317    0.2609       208
           4     0.2394    0.2948    0.2642       173
           5     0.0000    0.0000    0.0000        69

    accuracy                         0.1954       993
   macro avg     0.1505    0.1694    0.1553       993
weighted avg     0.1701    0.1954    0.1773       993


Macro average Test Precision, Recall and F1-Score...
(0.1505223162361972, 0.1694457896377595, 0.1552831422222495, None)

Micro average Test Precision, Recall and F1-Score...
(0.19536757301107754, 0.19536757301107754, 0.19536757301107754, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
