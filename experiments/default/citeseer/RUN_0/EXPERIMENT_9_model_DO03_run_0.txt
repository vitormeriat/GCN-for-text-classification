
==========: 304234472592700
Epoch:0001, train_loss=1.82012, train_acc=0.07280, val_loss=1.79147, val_acc=0.17749, time=0.25900
Epoch:0002, train_loss=1.78007, train_acc=0.21408, val_loss=1.79266, val_acc=0.22944, time=0.28700
Epoch:0003, train_loss=1.77447, train_acc=0.22701, val_loss=1.79415, val_acc=0.20779, time=0.29400
Epoch:0004, train_loss=1.77375, train_acc=0.25958, val_loss=1.79503, val_acc=0.20346, time=0.31301
Epoch:0005, train_loss=1.77109, train_acc=0.31178, val_loss=1.79522, val_acc=0.17316, time=0.29602
Epoch:0006, train_loss=1.76613, train_acc=0.36303, val_loss=1.79489, val_acc=0.18182, time=0.30600
Epoch:0007, train_loss=1.75926, train_acc=0.39559, val_loss=1.79431, val_acc=0.19048, time=0.28700
Epoch:0008, train_loss=1.75147, train_acc=0.40517, val_loss=1.79368, val_acc=0.20346, time=0.30901
Epoch:0009, train_loss=1.74364, train_acc=0.41667, val_loss=1.79314, val_acc=0.20779, time=0.25703
Epoch:0010, train_loss=1.73627, train_acc=0.42720, val_loss=1.79274, val_acc=0.21212, time=0.32097
Epoch:0011, train_loss=1.72956, train_acc=0.43918, val_loss=1.79249, val_acc=0.20346, time=0.31401
Epoch:0012, train_loss=1.72341, train_acc=0.46264, val_loss=1.79237, val_acc=0.20346, time=0.29501
Epoch:0013, train_loss=1.71761, train_acc=0.49090, val_loss=1.79233, val_acc=0.19481, time=0.30600
Epoch:0014, train_loss=1.71187, train_acc=0.50862, val_loss=1.79236, val_acc=0.18182, time=0.34200
Epoch:0015, train_loss=1.70593, train_acc=0.52586, val_loss=1.79246, val_acc=0.17316, time=0.28400
Epoch:0016, train_loss=1.69965, train_acc=0.53831, val_loss=1.79263, val_acc=0.17749, time=0.26700
Epoch:0017, train_loss=1.69295, train_acc=0.54406, val_loss=1.79289, val_acc=0.18182, time=0.28601
Early stopping...

Optimization Finished!

Test set results: loss= 1.79193, accuracy= 0.19335, time= 0.06200

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.1892    0.1481    0.1662       189
           1     0.1493    0.0667    0.0922       150
           2     0.1769    0.2402    0.2037       204
           3     0.2012    0.3125    0.2448       208
           4     0.2247    0.2312    0.2279       173
           5     0.0000    0.0000    0.0000        69

    accuracy                         0.1934       993
   macro avg     0.1569    0.1665    0.1558       993
weighted avg     0.1762    0.1934    0.1784       993


Macro average Test Precision, Recall and F1-Score...
(0.15688261976802556, 0.16645412767975956, 0.15580358823059806, None)

Micro average Test Precision, Recall and F1-Score...
(0.1933534743202417, 0.1933534743202417, 0.19335347432024166, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
