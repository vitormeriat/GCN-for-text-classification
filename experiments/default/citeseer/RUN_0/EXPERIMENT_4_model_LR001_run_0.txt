
==========: 304157953027200
Epoch:0001, train_loss=1.79353, train_acc=0.17193, val_loss=1.79179, val_acc=0.20779, time=0.38402
Epoch:0002, train_loss=1.77948, train_acc=0.21839, val_loss=1.79257, val_acc=0.22511, time=0.30001
Epoch:0003, train_loss=1.77616, train_acc=0.24138, val_loss=1.79329, val_acc=0.21645, time=0.31500
Epoch:0004, train_loss=1.77447, train_acc=0.26389, val_loss=1.79354, val_acc=0.22078, time=0.26201
Epoch:0005, train_loss=1.77099, train_acc=0.28544, val_loss=1.79342, val_acc=0.21645, time=0.31100
Epoch:0006, train_loss=1.76607, train_acc=0.30843, val_loss=1.79315, val_acc=0.20779, time=0.32901
Epoch:0007, train_loss=1.76083, train_acc=0.32854, val_loss=1.79286, val_acc=0.18182, time=0.30400
Epoch:0008, train_loss=1.75607, train_acc=0.34770, val_loss=1.79263, val_acc=0.18182, time=0.31602
Epoch:0009, train_loss=1.75195, train_acc=0.37692, val_loss=1.79247, val_acc=0.17316, time=0.33600
Epoch:0010, train_loss=1.74821, train_acc=0.39224, val_loss=1.79236, val_acc=0.16017, time=0.30599
Epoch:0011, train_loss=1.74448, train_acc=0.40661, val_loss=1.79229, val_acc=0.17749, time=0.30902
Epoch:0012, train_loss=1.74056, train_acc=0.41906, val_loss=1.79227, val_acc=0.16883, time=0.33699
Epoch:0013, train_loss=1.73643, train_acc=0.43103, val_loss=1.79232, val_acc=0.17749, time=0.30600
Epoch:0014, train_loss=1.73216, train_acc=0.43918, val_loss=1.79243, val_acc=0.18182, time=0.30400
Epoch:0015, train_loss=1.72784, train_acc=0.44253, val_loss=1.79260, val_acc=0.19048, time=0.26300
Epoch:0016, train_loss=1.72353, train_acc=0.44780, val_loss=1.79282, val_acc=0.18182, time=0.21200
Early stopping...

Optimization Finished!

Test set results: loss= 1.78792, accuracy= 0.20242, time= 0.06600

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.2121    0.0370    0.0631       189
           1     0.1795    0.0467    0.0741       150
           2     0.2050    0.2794    0.2365       204
           3     0.2025    0.3942    0.2675       208
           4     0.2017    0.2775    0.2336       173
           5     0.0000    0.0000    0.0000        69

    accuracy                         0.2024       993
   macro avg     0.1668    0.1725    0.1458       993
weighted avg     0.1872    0.2024    0.1685       993


Macro average Test Precision, Recall and F1-Score...
(0.16679902848379832, 0.17246714750653322, 0.14579416783755206, None)

Micro average Test Precision, Recall and F1-Score...
(0.20241691842900303, 0.20241691842900303, 0.20241691842900306, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
