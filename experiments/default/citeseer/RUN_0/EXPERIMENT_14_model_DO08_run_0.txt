
==========: 304296846384200
Epoch:0001, train_loss=1.80350, train_acc=0.20307, val_loss=1.79218, val_acc=0.15584, time=0.30800
Epoch:0002, train_loss=1.77676, train_acc=0.22126, val_loss=1.79400, val_acc=0.15152, time=0.33400
Epoch:0003, train_loss=1.77521, train_acc=0.21791, val_loss=1.79466, val_acc=0.18615, time=0.31101
Epoch:0004, train_loss=1.77067, train_acc=0.31753, val_loss=1.79468, val_acc=0.20779, time=0.27801
Epoch:0005, train_loss=1.76451, train_acc=0.32519, val_loss=1.79419, val_acc=0.21645, time=0.28602
Epoch:0006, train_loss=1.75607, train_acc=0.34674, val_loss=1.79350, val_acc=0.22511, time=0.28399
Epoch:0007, train_loss=1.74681, train_acc=0.40757, val_loss=1.79292, val_acc=0.20779, time=0.30000
Epoch:0008, train_loss=1.73861, train_acc=0.44971, val_loss=1.79252, val_acc=0.19481, time=0.30800
Epoch:0009, train_loss=1.73170, train_acc=0.46648, val_loss=1.79227, val_acc=0.18182, time=0.31601
Epoch:0010, train_loss=1.72537, train_acc=0.49425, val_loss=1.79216, val_acc=0.17749, time=0.32199
Epoch:0011, train_loss=1.71912, train_acc=0.51006, val_loss=1.79217, val_acc=0.17749, time=0.28900
Epoch:0012, train_loss=1.71268, train_acc=0.51437, val_loss=1.79230, val_acc=0.19048, time=0.31101
Epoch:0013, train_loss=1.70571, train_acc=0.51389, val_loss=1.79252, val_acc=0.19048, time=0.32300
Epoch:0014, train_loss=1.69799, train_acc=0.51964, val_loss=1.79284, val_acc=0.16883, time=0.24200
Epoch:0015, train_loss=1.68972, train_acc=0.54023, val_loss=1.79330, val_acc=0.16883, time=0.30500
Early stopping...

Optimization Finished!

Test set results: loss= 1.79094, accuracy= 0.20141, time= 0.06600

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.1880    0.1323    0.1553       189
           1     0.1220    0.0667    0.0862       150
           2     0.2083    0.2696    0.2350       204
           3     0.2090    0.3125    0.2505       208
           4     0.2217    0.2601    0.2394       173
           5     0.0000    0.0000    0.0000        69

    accuracy                         0.2014       993
   macro avg     0.1582    0.1735    0.1611       993
weighted avg     0.1794    0.2014    0.1850       993


Macro average Test Precision, Recall and F1-Score...
(0.15815542832315546, 0.17352754150257832, 0.1610620887326849, None)

Micro average Test Precision, Recall and F1-Score...
(0.2014098690835851, 0.2014098690835851, 0.2014098690835851, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
