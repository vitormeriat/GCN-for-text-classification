
==========: 305420308773500
Epoch:0001, train_loss=1.79527, train_acc=0.17241, val_loss=1.79181, val_acc=0.17749, time=0.31101
Epoch:0002, train_loss=1.79504, train_acc=0.17241, val_loss=1.79180, val_acc=0.17316, time=0.29001
Epoch:0003, train_loss=1.79482, train_acc=0.17289, val_loss=1.79179, val_acc=0.17749, time=0.28000
Epoch:0004, train_loss=1.79459, train_acc=0.17337, val_loss=1.79178, val_acc=0.17749, time=0.29299
Epoch:0005, train_loss=1.79437, train_acc=0.17146, val_loss=1.79176, val_acc=0.17749, time=0.29400
Epoch:0006, train_loss=1.79415, train_acc=0.17146, val_loss=1.79175, val_acc=0.17749, time=0.32001
Epoch:0007, train_loss=1.79393, train_acc=0.17241, val_loss=1.79174, val_acc=0.17749, time=0.27099
Epoch:0008, train_loss=1.79371, train_acc=0.17289, val_loss=1.79173, val_acc=0.17749, time=0.27500
Epoch:0009, train_loss=1.79350, train_acc=0.17385, val_loss=1.79172, val_acc=0.17749, time=0.32300
Epoch:0010, train_loss=1.79328, train_acc=0.17433, val_loss=1.79171, val_acc=0.17749, time=0.30901
Epoch:0011, train_loss=1.79307, train_acc=0.17481, val_loss=1.79170, val_acc=0.17316, time=0.31900
Epoch:0012, train_loss=1.79286, train_acc=0.17481, val_loss=1.79169, val_acc=0.17316, time=0.31501
Epoch:0013, train_loss=1.79265, train_acc=0.17529, val_loss=1.79168, val_acc=0.16883, time=0.28400
Epoch:0014, train_loss=1.79244, train_acc=0.17529, val_loss=1.79167, val_acc=0.16883, time=0.29201
Epoch:0015, train_loss=1.79223, train_acc=0.17625, val_loss=1.79166, val_acc=0.16883, time=0.32201
Epoch:0016, train_loss=1.79202, train_acc=0.17625, val_loss=1.79166, val_acc=0.16883, time=0.30900
Epoch:0017, train_loss=1.79182, train_acc=0.17625, val_loss=1.79165, val_acc=0.16883, time=0.25201
Epoch:0018, train_loss=1.79162, train_acc=0.17672, val_loss=1.79164, val_acc=0.16883, time=0.25500
Epoch:0019, train_loss=1.79142, train_acc=0.17672, val_loss=1.79163, val_acc=0.16883, time=0.25701
Epoch:0020, train_loss=1.79122, train_acc=0.17672, val_loss=1.79162, val_acc=0.16883, time=0.27499
Epoch:0021, train_loss=1.79102, train_acc=0.17720, val_loss=1.79161, val_acc=0.16883, time=0.25801
Epoch:0022, train_loss=1.79083, train_acc=0.17816, val_loss=1.79161, val_acc=0.16883, time=0.29200
Epoch:0023, train_loss=1.79063, train_acc=0.17768, val_loss=1.79160, val_acc=0.16883, time=0.24101
Epoch:0024, train_loss=1.79044, train_acc=0.17816, val_loss=1.79159, val_acc=0.16883, time=0.32901
Epoch:0025, train_loss=1.79025, train_acc=0.17816, val_loss=1.79158, val_acc=0.16883, time=0.31601
Epoch:0026, train_loss=1.79006, train_acc=0.17864, val_loss=1.79157, val_acc=0.16883, time=0.24400
Epoch:0027, train_loss=1.78987, train_acc=0.17912, val_loss=1.79157, val_acc=0.16883, time=0.24699
Epoch:0028, train_loss=1.78969, train_acc=0.17960, val_loss=1.79156, val_acc=0.16450, time=0.31400
Epoch:0029, train_loss=1.78950, train_acc=0.17912, val_loss=1.79155, val_acc=0.16450, time=0.32701
Epoch:0030, train_loss=1.78932, train_acc=0.17912, val_loss=1.79155, val_acc=0.16450, time=0.33100
Epoch:0031, train_loss=1.78914, train_acc=0.17864, val_loss=1.79154, val_acc=0.16450, time=0.21204
Epoch:0032, train_loss=1.78896, train_acc=0.17816, val_loss=1.79153, val_acc=0.16450, time=0.21602
Epoch:0033, train_loss=1.78878, train_acc=0.17864, val_loss=1.79153, val_acc=0.16450, time=0.24599
Epoch:0034, train_loss=1.78861, train_acc=0.17960, val_loss=1.79152, val_acc=0.16450, time=0.24101
Epoch:0035, train_loss=1.78843, train_acc=0.18056, val_loss=1.79152, val_acc=0.16450, time=0.22300
Epoch:0036, train_loss=1.78826, train_acc=0.18056, val_loss=1.79151, val_acc=0.16017, time=0.28400
Epoch:0037, train_loss=1.78809, train_acc=0.18008, val_loss=1.79150, val_acc=0.16017, time=0.27301
Epoch:0038, train_loss=1.78792, train_acc=0.17864, val_loss=1.79150, val_acc=0.16450, time=0.21899
Epoch:0039, train_loss=1.78775, train_acc=0.17816, val_loss=1.79149, val_acc=0.16450, time=0.24902
Epoch:0040, train_loss=1.78758, train_acc=0.17960, val_loss=1.79149, val_acc=0.16450, time=0.24602
Epoch:0041, train_loss=1.78742, train_acc=0.18056, val_loss=1.79148, val_acc=0.16450, time=0.27799
Epoch:0042, train_loss=1.78726, train_acc=0.18008, val_loss=1.79148, val_acc=0.16450, time=0.33802
Epoch:0043, train_loss=1.78709, train_acc=0.17960, val_loss=1.79147, val_acc=0.16450, time=0.27500
Epoch:0044, train_loss=1.78693, train_acc=0.18151, val_loss=1.79147, val_acc=0.16017, time=0.25300
Epoch:0045, train_loss=1.78677, train_acc=0.18103, val_loss=1.79147, val_acc=0.16017, time=0.22400
Epoch:0046, train_loss=1.78662, train_acc=0.18295, val_loss=1.79146, val_acc=0.16017, time=0.21901
Epoch:0047, train_loss=1.78646, train_acc=0.18391, val_loss=1.79146, val_acc=0.16017, time=0.31700
Epoch:0048, train_loss=1.78631, train_acc=0.18534, val_loss=1.79145, val_acc=0.15584, time=0.21499
Epoch:0049, train_loss=1.78615, train_acc=0.18582, val_loss=1.79145, val_acc=0.16017, time=0.29400
Epoch:0050, train_loss=1.78600, train_acc=0.18534, val_loss=1.79145, val_acc=0.16017, time=0.26201
Epoch:0051, train_loss=1.78585, train_acc=0.18487, val_loss=1.79144, val_acc=0.16450, time=0.30701
Epoch:0052, train_loss=1.78570, train_acc=0.18678, val_loss=1.79144, val_acc=0.16450, time=0.28400
Epoch:0053, train_loss=1.78555, train_acc=0.18726, val_loss=1.79144, val_acc=0.16883, time=0.24298
Epoch:0054, train_loss=1.78541, train_acc=0.18822, val_loss=1.79143, val_acc=0.16883, time=0.28500
Epoch:0055, train_loss=1.78526, train_acc=0.18918, val_loss=1.79143, val_acc=0.17316, time=0.30300
Epoch:0056, train_loss=1.78512, train_acc=0.18918, val_loss=1.79143, val_acc=0.17749, time=0.28803
Epoch:0057, train_loss=1.78498, train_acc=0.19061, val_loss=1.79142, val_acc=0.17749, time=0.42504
Epoch:0058, train_loss=1.78484, train_acc=0.19061, val_loss=1.79142, val_acc=0.18182, time=0.37497
Epoch:0059, train_loss=1.78470, train_acc=0.19253, val_loss=1.79142, val_acc=0.18182, time=0.25300
Epoch:0060, train_loss=1.78456, train_acc=0.19444, val_loss=1.79142, val_acc=0.18182, time=0.24100
Epoch:0061, train_loss=1.78442, train_acc=0.19540, val_loss=1.79141, val_acc=0.17749, time=0.28701
Epoch:0062, train_loss=1.78429, train_acc=0.19636, val_loss=1.79141, val_acc=0.18182, time=0.21799
Epoch:0063, train_loss=1.78415, train_acc=0.19828, val_loss=1.79141, val_acc=0.18182, time=0.25002
Epoch:0064, train_loss=1.78402, train_acc=0.20019, val_loss=1.79141, val_acc=0.18615, time=0.23600
Epoch:0065, train_loss=1.78388, train_acc=0.20163, val_loss=1.79140, val_acc=0.19048, time=0.26200
Epoch:0066, train_loss=1.78375, train_acc=0.20307, val_loss=1.79140, val_acc=0.19481, time=0.32403
Epoch:0067, train_loss=1.78362, train_acc=0.20259, val_loss=1.79140, val_acc=0.19048, time=0.26700
Epoch:0068, train_loss=1.78349, train_acc=0.20211, val_loss=1.79140, val_acc=0.19913, time=0.26198
Epoch:0069, train_loss=1.78337, train_acc=0.20402, val_loss=1.79140, val_acc=0.19913, time=0.30901
Epoch:0070, train_loss=1.78324, train_acc=0.20546, val_loss=1.79140, val_acc=0.19913, time=0.31802
Epoch:0071, train_loss=1.78311, train_acc=0.20642, val_loss=1.79139, val_acc=0.19913, time=0.28200
Epoch:0072, train_loss=1.78299, train_acc=0.20546, val_loss=1.79139, val_acc=0.19913, time=0.27500
Epoch:0073, train_loss=1.78287, train_acc=0.20594, val_loss=1.79139, val_acc=0.19913, time=0.28001
Epoch:0074, train_loss=1.78275, train_acc=0.20881, val_loss=1.79139, val_acc=0.19913, time=0.26099
Epoch:0075, train_loss=1.78262, train_acc=0.21073, val_loss=1.79139, val_acc=0.20346, time=0.22401
Epoch:0076, train_loss=1.78250, train_acc=0.21121, val_loss=1.79139, val_acc=0.20779, time=0.22302
Epoch:0077, train_loss=1.78238, train_acc=0.21073, val_loss=1.79139, val_acc=0.20779, time=0.21300
Epoch:0078, train_loss=1.78227, train_acc=0.21312, val_loss=1.79139, val_acc=0.20779, time=0.29900
Epoch:0079, train_loss=1.78215, train_acc=0.21121, val_loss=1.79139, val_acc=0.20779, time=0.24300
Epoch:0080, train_loss=1.78203, train_acc=0.21216, val_loss=1.79139, val_acc=0.19913, time=0.30002
Epoch:0081, train_loss=1.78192, train_acc=0.21216, val_loss=1.79139, val_acc=0.19481, time=0.27299
Epoch:0082, train_loss=1.78181, train_acc=0.21073, val_loss=1.79139, val_acc=0.19048, time=0.21800
Epoch:0083, train_loss=1.78169, train_acc=0.21121, val_loss=1.79139, val_acc=0.19048, time=0.22000
Epoch:0084, train_loss=1.78158, train_acc=0.21073, val_loss=1.79138, val_acc=0.19048, time=0.30301
Epoch:0085, train_loss=1.78147, train_acc=0.21169, val_loss=1.79138, val_acc=0.19481, time=0.24000
Epoch:0086, train_loss=1.78136, train_acc=0.21312, val_loss=1.79138, val_acc=0.19481, time=0.24101
Epoch:0087, train_loss=1.78125, train_acc=0.21648, val_loss=1.79138, val_acc=0.19913, time=0.28500
Epoch:0088, train_loss=1.78114, train_acc=0.21648, val_loss=1.79138, val_acc=0.19913, time=0.27699
Epoch:0089, train_loss=1.78103, train_acc=0.21648, val_loss=1.79138, val_acc=0.20346, time=0.21402
Epoch:0090, train_loss=1.78093, train_acc=0.21600, val_loss=1.79138, val_acc=0.20346, time=0.22900
Epoch:0091, train_loss=1.78082, train_acc=0.21695, val_loss=1.79138, val_acc=0.19481, time=0.27399
Epoch:0092, train_loss=1.78072, train_acc=0.21552, val_loss=1.79138, val_acc=0.19481, time=0.33100
Early stopping...

Optimization Finished!

Test set results: loss= 1.78681, accuracy= 0.19335, time= 0.09500

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.2075    0.4709    0.2880       189
           1     0.1084    0.0600    0.0773       150
           2     0.2300    0.1127    0.1513       204
           3     0.1821    0.3221    0.2326       208
           4     0.3077    0.0231    0.0430       173
           5     0.0000    0.0000    0.0000        69

    accuracy                         0.1934       993
   macro avg     0.1726    0.1648    0.1320       993
weighted avg     0.1949    0.1934    0.1538       993


Macro average Test Precision, Recall and F1-Score...
(0.1726084112470964, 0.16481355680621804, 0.13204075665041712, None)

Micro average Test Precision, Recall and F1-Score...
(0.1933534743202417, 0.1933534743202417, 0.19335347432024166, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
