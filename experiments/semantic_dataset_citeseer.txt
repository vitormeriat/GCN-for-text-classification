
==================== Torch Seed: 2597002743400
Epoch:0001, train_loss=1.93037, train_acc=0.18103, val_loss=1.79404, val_acc=0.24675, time=0.13402
Epoch:0002, train_loss=1.78970, train_acc=0.25144, val_loss=1.79370, val_acc=0.25974, time=0.13800
Epoch:0003, train_loss=1.75449, train_acc=0.32040, val_loss=1.78948, val_acc=0.29437, time=0.13402
Epoch:0004, train_loss=1.70489, train_acc=0.39033, val_loss=1.78217, val_acc=0.37662, time=0.16200
Epoch:0005, train_loss=1.63602, train_acc=0.51485, val_loss=1.77599, val_acc=0.53680, time=0.18900
Epoch:0006, train_loss=1.57879, train_acc=0.68391, val_loss=1.77234, val_acc=0.60173, time=0.19000
Epoch:0007, train_loss=1.54111, train_acc=0.73946, val_loss=1.77052, val_acc=0.61905, time=0.13401
Epoch:0008, train_loss=1.51551, train_acc=0.76006, val_loss=1.76954, val_acc=0.60606, time=0.12901
Epoch:0009, train_loss=1.49441, train_acc=0.77682, val_loss=1.76853, val_acc=0.60606, time=0.13000
Epoch:0010, train_loss=1.47298, train_acc=0.78640, val_loss=1.76723, val_acc=0.64935, time=0.16700
Epoch:0011, train_loss=1.45080, train_acc=0.81466, val_loss=1.76587, val_acc=0.67100, time=0.18400
Epoch:0012, train_loss=1.43048, train_acc=0.83956, val_loss=1.76475, val_acc=0.67965, time=0.20001
Epoch:0013, train_loss=1.41419, train_acc=0.85584, val_loss=1.76397, val_acc=0.68831, time=0.14002
Epoch:0014, train_loss=1.40197, train_acc=0.86782, val_loss=1.76346, val_acc=0.69697, time=0.13100
Epoch:0015, train_loss=1.39241, train_acc=0.87213, val_loss=1.76307, val_acc=0.69697, time=0.13901
Epoch:0016, train_loss=1.38392, train_acc=0.87452, val_loss=1.76272, val_acc=0.71429, time=0.15800
Epoch:0017, train_loss=1.37555, train_acc=0.88123, val_loss=1.76240, val_acc=0.71429, time=0.14302
Epoch:0018, train_loss=1.36698, train_acc=0.89176, val_loss=1.76215, val_acc=0.70996, time=0.18398
Epoch:0019, train_loss=1.35838, train_acc=0.90469, val_loss=1.76202, val_acc=0.71429, time=0.13900
Epoch:0020, train_loss=1.35014, train_acc=0.91619, val_loss=1.76204, val_acc=0.71429, time=0.14101
Epoch:0021, train_loss=1.34266, train_acc=0.91954, val_loss=1.76222, val_acc=0.71861, time=0.13100
Epoch:0022, train_loss=1.33615, train_acc=0.92625, val_loss=1.76251, val_acc=0.71429, time=0.12900
Epoch:0023, train_loss=1.33057, train_acc=0.93391, val_loss=1.76284, val_acc=0.70996, time=0.14901
Early stopping...

Optimization Finished!

Test set results: loss= 1.66023, accuracy= 0.71098, time= 0.04100

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.6804    0.6471    0.6633       204
           1     0.7756    0.7644    0.7700       208
           2     0.6872    0.7090    0.6979       189
           3     0.7273    0.7861    0.7556       173
           4     0.7785    0.7733    0.7759       150
           5     0.4603    0.4203    0.4394        69

    accuracy                         0.7110       993
   macro avg     0.6849    0.6834    0.6837       993
weighted avg     0.7093    0.7110    0.7098       993


Macro average Test Precision, Recall and F1-Score...
(0.6848858819890239, 0.6833711609138421, 0.6836797106495242, None)

Micro average Test Precision, Recall and F1-Score...
(0.7109768378650554, 0.7109768378650554, 0.7109768378650553, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993

Elapsed time is 4.005007 seconds.
