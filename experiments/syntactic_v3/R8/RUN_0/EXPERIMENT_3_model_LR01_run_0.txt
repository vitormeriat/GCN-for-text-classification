
==========: 223057969629600
Epoch:0001, train_loss=2.30304, train_acc=0.03342, val_loss=2.05050, val_acc=0.75182, time=1.10803
Epoch:0002, train_loss=1.79952, train_acc=0.73790, val_loss=2.04499, val_acc=0.76642, time=1.05900
Epoch:0003, train_loss=1.73140, train_acc=0.77132, val_loss=2.03063, val_acc=0.87044, time=1.09001
Epoch:0004, train_loss=1.60632, train_acc=0.87685, val_loss=2.02536, val_acc=0.88139, time=1.03501
Epoch:0005, train_loss=1.55521, train_acc=0.91432, val_loss=2.02215, val_acc=0.90693, time=1.11102
Epoch:0006, train_loss=1.52412, train_acc=0.93701, val_loss=2.02125, val_acc=0.89964, time=1.07200
Epoch:0007, train_loss=1.51231, train_acc=0.93579, val_loss=2.02006, val_acc=0.89599, time=1.11899
Epoch:0008, train_loss=1.49886, train_acc=0.94065, val_loss=2.01810, val_acc=0.90511, time=1.16101
Epoch:0009, train_loss=1.48105, train_acc=0.94997, val_loss=2.01637, val_acc=0.90511, time=1.04901
Epoch:0010, train_loss=1.46547, train_acc=0.95848, val_loss=2.01494, val_acc=0.91788, time=1.03099
Epoch:0011, train_loss=1.45238, train_acc=0.96455, val_loss=2.01373, val_acc=0.92518, time=1.10002
Epoch:0012, train_loss=1.44188, train_acc=0.97347, val_loss=2.01291, val_acc=0.93431, time=0.97200
Epoch:0013, train_loss=1.43478, train_acc=0.98096, val_loss=2.01250, val_acc=0.94343, time=1.07599
Epoch:0014, train_loss=1.43073, train_acc=0.98359, val_loss=2.01235, val_acc=0.94708, time=1.10101
Epoch:0015, train_loss=1.42860, train_acc=0.98542, val_loss=2.01233, val_acc=0.94343, time=1.16000
Epoch:0016, train_loss=1.42729, train_acc=0.98420, val_loss=2.01236, val_acc=0.94708, time=1.10600
Epoch:0017, train_loss=1.42622, train_acc=0.98542, val_loss=2.01240, val_acc=0.94161, time=1.14501
Epoch:0018, train_loss=1.42509, train_acc=0.98602, val_loss=2.01244, val_acc=0.93978, time=1.28300
Epoch:0019, train_loss=1.42386, train_acc=0.98704, val_loss=2.01250, val_acc=0.93978, time=1.22502
Epoch:0020, train_loss=1.42264, train_acc=0.98947, val_loss=2.01258, val_acc=0.93613, time=1.12200
Epoch:0021, train_loss=1.42160, train_acc=0.98967, val_loss=2.01267, val_acc=0.94161, time=1.24601
Early stopping...

Optimization Finished!

Test set results: loss= 1.81178, accuracy= 0.94290, time= 0.37900

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9702    0.9353    0.9525       696
           1     0.9579    0.9880    0.9727      1083
           2     0.9310    0.8926    0.9114       121
           3     0.7527    0.9333    0.8333        75
           4     0.8462    0.6111    0.7097        36
           5     0.8409    0.8506    0.8457        87
           6     0.9365    0.7284    0.8194        81
           7     0.6667    1.0000    0.8000        10

    accuracy                         0.9429      2189
   macro avg     0.8628    0.8674    0.8556      2189
weighted avg     0.9447    0.9429    0.9423      2189


Macro average Test Precision, Recall and F1-Score...
(0.8627596179727515, 0.8674146670537077, 0.8555924728046284, None)

Micro average Test Precision, Recall and F1-Score...
(0.9428962996802193, 0.9428962996802193, 0.9428962996802193, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
