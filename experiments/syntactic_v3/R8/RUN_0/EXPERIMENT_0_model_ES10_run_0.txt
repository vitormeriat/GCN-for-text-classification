
==========: 221609654901100
Epoch:0001, train_loss=2.29888, train_acc=0.04294, val_loss=2.06736, val_acc=0.50912, time=1.28101
Epoch:0002, train_loss=1.96539, train_acc=0.51408, val_loss=2.04853, val_acc=0.67701, time=1.24900
Epoch:0003, train_loss=1.79435, train_acc=0.68139, val_loss=2.04000, val_acc=0.74088, time=1.12301
Epoch:0004, train_loss=1.71610, train_acc=0.73263, val_loss=2.03504, val_acc=0.77555, time=1.20402
Epoch:0005, train_loss=1.66936, train_acc=0.76727, val_loss=2.03113, val_acc=0.79927, time=1.00401
Epoch:0006, train_loss=1.63171, train_acc=0.80130, val_loss=2.02781, val_acc=0.83577, time=1.09401
Epoch:0007, train_loss=1.59929, train_acc=0.84059, val_loss=2.02507, val_acc=0.86496, time=1.12800
Epoch:0008, train_loss=1.57236, train_acc=0.86875, val_loss=2.02284, val_acc=0.88869, time=1.17201
Epoch:0009, train_loss=1.55019, train_acc=0.88981, val_loss=2.02101, val_acc=0.89781, time=1.18501
Epoch:0010, train_loss=1.53177, train_acc=0.90440, val_loss=2.01950, val_acc=0.90511, time=1.13101
Epoch:0011, train_loss=1.51619, train_acc=0.91918, val_loss=2.01819, val_acc=0.91058, time=1.27101
Epoch:0012, train_loss=1.50246, train_acc=0.93093, val_loss=2.01699, val_acc=0.91606, time=1.16502
Epoch:0013, train_loss=1.49000, train_acc=0.94166, val_loss=2.01590, val_acc=0.91788, time=1.28000
Epoch:0014, train_loss=1.47890, train_acc=0.94977, val_loss=2.01496, val_acc=0.91788, time=1.15401
Epoch:0015, train_loss=1.46951, train_acc=0.95888, val_loss=2.01418, val_acc=0.92518, time=1.07999
Epoch:0016, train_loss=1.46209, train_acc=0.96455, val_loss=2.01360, val_acc=0.93431, time=1.19101
Epoch:0017, train_loss=1.45653, train_acc=0.96759, val_loss=2.01318, val_acc=0.93978, time=1.20001
Epoch:0018, train_loss=1.45241, train_acc=0.97205, val_loss=2.01287, val_acc=0.94161, time=1.20301
Epoch:0019, train_loss=1.44927, train_acc=0.97529, val_loss=2.01263, val_acc=0.93978, time=1.25401
Epoch:0020, train_loss=1.44676, train_acc=0.97752, val_loss=2.01243, val_acc=0.94343, time=1.21301
Epoch:0021, train_loss=1.44464, train_acc=0.97812, val_loss=2.01227, val_acc=0.94343, time=1.38200
Epoch:0022, train_loss=1.44279, train_acc=0.97893, val_loss=2.01212, val_acc=0.94526, time=1.30101
Epoch:0023, train_loss=1.44108, train_acc=0.98035, val_loss=2.01198, val_acc=0.94343, time=1.21700
Epoch:0024, train_loss=1.43947, train_acc=0.98137, val_loss=2.01185, val_acc=0.94526, time=1.26801
Epoch:0025, train_loss=1.43791, train_acc=0.98116, val_loss=2.01171, val_acc=0.94526, time=1.14600
Epoch:0026, train_loss=1.43636, train_acc=0.98319, val_loss=2.01158, val_acc=0.94708, time=1.37702
Epoch:0027, train_loss=1.43484, train_acc=0.98420, val_loss=2.01144, val_acc=0.94891, time=1.36200
Epoch:0028, train_loss=1.43335, train_acc=0.98542, val_loss=2.01130, val_acc=0.94708, time=1.24201
Epoch:0029, train_loss=1.43193, train_acc=0.98623, val_loss=2.01117, val_acc=0.94891, time=1.12399
Epoch:0030, train_loss=1.43061, train_acc=0.98704, val_loss=2.01105, val_acc=0.94891, time=1.15001
Epoch:0031, train_loss=1.42939, train_acc=0.98845, val_loss=2.01095, val_acc=0.94891, time=1.18301
Epoch:0032, train_loss=1.42829, train_acc=0.98947, val_loss=2.01086, val_acc=0.94891, time=1.26400
Epoch:0033, train_loss=1.42732, train_acc=0.99028, val_loss=2.01078, val_acc=0.94891, time=1.31302
Epoch:0034, train_loss=1.42647, train_acc=0.99109, val_loss=2.01072, val_acc=0.95255, time=1.26300
Epoch:0035, train_loss=1.42572, train_acc=0.99149, val_loss=2.01067, val_acc=0.95255, time=1.16201
Epoch:0036, train_loss=1.42505, train_acc=0.99230, val_loss=2.01063, val_acc=0.95255, time=1.19701
Epoch:0037, train_loss=1.42446, train_acc=0.99271, val_loss=2.01059, val_acc=0.95073, time=1.24501
Epoch:0038, train_loss=1.42393, train_acc=0.99311, val_loss=2.01056, val_acc=0.95073, time=1.20702
Epoch:0039, train_loss=1.42343, train_acc=0.99332, val_loss=2.01054, val_acc=0.95255, time=1.22999
Epoch:0040, train_loss=1.42297, train_acc=0.99352, val_loss=2.01052, val_acc=0.95073, time=1.20901
Epoch:0041, train_loss=1.42254, train_acc=0.99352, val_loss=2.01051, val_acc=0.95255, time=1.19000
Epoch:0042, train_loss=1.42213, train_acc=0.99392, val_loss=2.01050, val_acc=0.95255, time=1.28500
Epoch:0043, train_loss=1.42174, train_acc=0.99433, val_loss=2.01049, val_acc=0.95073, time=1.18601
Epoch:0044, train_loss=1.42137, train_acc=0.99433, val_loss=2.01049, val_acc=0.95255, time=1.44801
Epoch:0045, train_loss=1.42102, train_acc=0.99453, val_loss=2.01048, val_acc=0.95255, time=1.28001
Epoch:0046, train_loss=1.42068, train_acc=0.99494, val_loss=2.01048, val_acc=0.95255, time=1.24602
Epoch:0047, train_loss=1.42035, train_acc=0.99575, val_loss=2.01047, val_acc=0.95255, time=1.22100
Epoch:0048, train_loss=1.42004, train_acc=0.99595, val_loss=2.01047, val_acc=0.95255, time=1.14801
Epoch:0049, train_loss=1.41974, train_acc=0.99615, val_loss=2.01046, val_acc=0.95255, time=1.31201
Epoch:0050, train_loss=1.41946, train_acc=0.99615, val_loss=2.01046, val_acc=0.95255, time=1.37702
Epoch:0051, train_loss=1.41919, train_acc=0.99635, val_loss=2.01045, val_acc=0.95255, time=1.30101
Epoch:0052, train_loss=1.41893, train_acc=0.99635, val_loss=2.01044, val_acc=0.95255, time=1.17800
Epoch:0053, train_loss=1.41869, train_acc=0.99656, val_loss=2.01044, val_acc=0.95255, time=1.20302
Epoch:0054, train_loss=1.41846, train_acc=0.99676, val_loss=2.01043, val_acc=0.95255, time=1.25801
Epoch:0055, train_loss=1.41825, train_acc=0.99696, val_loss=2.01043, val_acc=0.95255, time=1.12600
Epoch:0056, train_loss=1.41805, train_acc=0.99716, val_loss=2.01042, val_acc=0.95255, time=1.16700
Epoch:0057, train_loss=1.41787, train_acc=0.99696, val_loss=2.01042, val_acc=0.95438, time=1.21601
Epoch:0058, train_loss=1.41769, train_acc=0.99696, val_loss=2.01041, val_acc=0.95255, time=1.25501
Epoch:0059, train_loss=1.41752, train_acc=0.99696, val_loss=2.01040, val_acc=0.95438, time=1.16101
Epoch:0060, train_loss=1.41737, train_acc=0.99737, val_loss=2.01040, val_acc=0.95438, time=1.14200
Epoch:0061, train_loss=1.41722, train_acc=0.99737, val_loss=2.01039, val_acc=0.95438, time=1.26901
Epoch:0062, train_loss=1.41707, train_acc=0.99737, val_loss=2.01039, val_acc=0.95438, time=1.13602
Epoch:0063, train_loss=1.41693, train_acc=0.99737, val_loss=2.01038, val_acc=0.95438, time=1.29101
Epoch:0064, train_loss=1.41680, train_acc=0.99737, val_loss=2.01037, val_acc=0.95438, time=1.36002
Epoch:0065, train_loss=1.41668, train_acc=0.99757, val_loss=2.01037, val_acc=0.95438, time=1.25401
Epoch:0066, train_loss=1.41656, train_acc=0.99777, val_loss=2.01036, val_acc=0.95438, time=1.26700
Epoch:0067, train_loss=1.41645, train_acc=0.99777, val_loss=2.01036, val_acc=0.95438, time=1.17001
Epoch:0068, train_loss=1.41634, train_acc=0.99777, val_loss=2.01035, val_acc=0.95438, time=1.27701
Epoch:0069, train_loss=1.41624, train_acc=0.99797, val_loss=2.01035, val_acc=0.95438, time=1.20601
Epoch:0070, train_loss=1.41614, train_acc=0.99838, val_loss=2.01034, val_acc=0.95438, time=1.27203
Epoch:0071, train_loss=1.41604, train_acc=0.99838, val_loss=2.01034, val_acc=0.95438, time=1.35600
Epoch:0072, train_loss=1.41595, train_acc=0.99838, val_loss=2.01033, val_acc=0.95620, time=1.25702
Epoch:0073, train_loss=1.41586, train_acc=0.99858, val_loss=2.01033, val_acc=0.95620, time=1.25999
Epoch:0074, train_loss=1.41578, train_acc=0.99838, val_loss=2.01032, val_acc=0.95620, time=1.29202
Epoch:0075, train_loss=1.41569, train_acc=0.99838, val_loss=2.01032, val_acc=0.95620, time=1.27500
Epoch:0076, train_loss=1.41561, train_acc=0.99858, val_loss=2.01031, val_acc=0.95620, time=1.29801
Epoch:0077, train_loss=1.41554, train_acc=0.99878, val_loss=2.01031, val_acc=0.95620, time=1.26601
Epoch:0078, train_loss=1.41546, train_acc=0.99878, val_loss=2.01031, val_acc=0.95620, time=1.21601
Epoch:0079, train_loss=1.41539, train_acc=0.99878, val_loss=2.01030, val_acc=0.95620, time=1.25901
Epoch:0080, train_loss=1.41533, train_acc=0.99878, val_loss=2.01030, val_acc=0.95620, time=1.11201
Epoch:0081, train_loss=1.41526, train_acc=0.99878, val_loss=2.01029, val_acc=0.95620, time=1.31900
Epoch:0082, train_loss=1.41519, train_acc=0.99878, val_loss=2.01029, val_acc=0.95620, time=1.19601
Epoch:0083, train_loss=1.41513, train_acc=0.99878, val_loss=2.01029, val_acc=0.95620, time=1.25401
Epoch:0084, train_loss=1.41507, train_acc=0.99878, val_loss=2.01028, val_acc=0.95620, time=1.36600
Epoch:0085, train_loss=1.41502, train_acc=0.99878, val_loss=2.01028, val_acc=0.95620, time=1.15403
Epoch:0086, train_loss=1.41496, train_acc=0.99878, val_loss=2.01028, val_acc=0.95620, time=1.18800
Epoch:0087, train_loss=1.41490, train_acc=0.99878, val_loss=2.01028, val_acc=0.95620, time=1.29502
Epoch:0088, train_loss=1.41485, train_acc=0.99878, val_loss=2.01028, val_acc=0.95620, time=1.24301
Epoch:0089, train_loss=1.41480, train_acc=0.99878, val_loss=2.01028, val_acc=0.95620, time=1.21001
Epoch:0090, train_loss=1.41475, train_acc=0.99878, val_loss=2.01027, val_acc=0.95620, time=1.26401
Epoch:0091, train_loss=1.41470, train_acc=0.99878, val_loss=2.01027, val_acc=0.95620, time=1.22500
Epoch:0092, train_loss=1.41466, train_acc=0.99878, val_loss=2.01027, val_acc=0.95620, time=1.27501
Epoch:0093, train_loss=1.41461, train_acc=0.99878, val_loss=2.01027, val_acc=0.95620, time=1.31900
Epoch:0094, train_loss=1.41457, train_acc=0.99878, val_loss=2.01027, val_acc=0.95803, time=1.30200
Epoch:0095, train_loss=1.41452, train_acc=0.99878, val_loss=2.01027, val_acc=0.95803, time=1.32201
Epoch:0096, train_loss=1.41448, train_acc=0.99878, val_loss=2.01027, val_acc=0.95803, time=1.14701
Epoch:0097, train_loss=1.41444, train_acc=0.99878, val_loss=2.01027, val_acc=0.95803, time=1.13600
Epoch:0098, train_loss=1.41440, train_acc=0.99878, val_loss=2.01027, val_acc=0.95803, time=1.25401
Epoch:0099, train_loss=1.41436, train_acc=0.99878, val_loss=2.01027, val_acc=0.95803, time=1.33501
Early stopping...

Optimization Finished!

Test set results: loss= 1.80573, accuracy= 0.95340, time= 0.41600

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9849    0.9368    0.9602       696
           1     0.9649    0.9898    0.9772      1083
           2     0.8846    0.9504    0.9163       121
           3     0.8353    0.9467    0.8875        75
           4     0.9200    0.6389    0.7541        36
           5     0.8571    0.8966    0.8764        87
           6     0.8919    0.8148    0.8516        81
           7     0.9091    1.0000    0.9524        10

    accuracy                         0.9534      2189
   macro avg     0.9060    0.8967    0.8970      2189
weighted avg     0.9544    0.9534    0.9529      2189


Macro average Test Precision, Recall and F1-Score...
(0.9059782387319747, 0.8967449944335489, 0.89697219836758, None)

Micro average Test Precision, Recall and F1-Score...
(0.9534033805390589, 0.9534033805390589, 0.9534033805390589, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
