
==========: 155715295868900
Epoch:0001, train_loss=2.27167, train_acc=0.03747, val_loss=2.09687, val_acc=0.04927, time=1.29901
Epoch:0002, train_loss=2.25410, train_acc=0.04355, val_loss=2.09502, val_acc=0.05657, time=1.36700
Epoch:0003, train_loss=2.23691, train_acc=0.05064, val_loss=2.09322, val_acc=0.07482, time=1.17001
Epoch:0004, train_loss=2.22012, train_acc=0.05793, val_loss=2.09146, val_acc=0.09124, time=1.13599
Epoch:0005, train_loss=2.20373, train_acc=0.06765, val_loss=2.08975, val_acc=0.10036, time=1.24700
Epoch:0006, train_loss=2.18776, train_acc=0.07981, val_loss=2.08809, val_acc=0.11496, time=1.01500
Epoch:0007, train_loss=2.17224, train_acc=0.09479, val_loss=2.08647, val_acc=0.12591, time=1.19101
Epoch:0008, train_loss=2.15714, train_acc=0.11424, val_loss=2.08491, val_acc=0.14416, time=1.06901
Epoch:0009, train_loss=2.14250, train_acc=0.13247, val_loss=2.08339, val_acc=0.16971, time=1.36401
Epoch:0010, train_loss=2.12831, train_acc=0.15353, val_loss=2.08193, val_acc=0.19526, time=1.21300
Epoch:0011, train_loss=2.11458, train_acc=0.17014, val_loss=2.08052, val_acc=0.21533, time=1.16301
Epoch:0012, train_loss=2.10132, train_acc=0.19283, val_loss=2.07916, val_acc=0.21715, time=1.27900
Epoch:0013, train_loss=2.08852, train_acc=0.21511, val_loss=2.07786, val_acc=0.23175, time=1.32998
Epoch:0014, train_loss=2.07618, train_acc=0.23375, val_loss=2.07661, val_acc=0.24818, time=1.29100
Epoch:0015, train_loss=2.06432, train_acc=0.25137, val_loss=2.07541, val_acc=0.27737, time=1.26800
Epoch:0016, train_loss=2.05294, train_acc=0.27020, val_loss=2.07427, val_acc=0.29745, time=1.16602
Epoch:0017, train_loss=2.04204, train_acc=0.29188, val_loss=2.07318, val_acc=0.31204, time=1.08200
Epoch:0018, train_loss=2.03162, train_acc=0.31153, val_loss=2.07215, val_acc=0.33577, time=1.12701
Epoch:0019, train_loss=2.02168, train_acc=0.32834, val_loss=2.07117, val_acc=0.34854, time=1.33900
Epoch:0020, train_loss=2.01221, train_acc=0.34373, val_loss=2.07024, val_acc=0.36314, time=1.13100
Epoch:0021, train_loss=2.00320, train_acc=0.36034, val_loss=2.06937, val_acc=0.37409, time=1.16501
Epoch:0022, train_loss=1.99466, train_acc=0.37087, val_loss=2.06854, val_acc=0.37956, time=1.30501
Epoch:0023, train_loss=1.98655, train_acc=0.38141, val_loss=2.06777, val_acc=0.38321, time=1.21000
Epoch:0024, train_loss=1.97888, train_acc=0.39174, val_loss=2.06704, val_acc=0.39051, time=1.08000
Epoch:0025, train_loss=1.97163, train_acc=0.40126, val_loss=2.06636, val_acc=0.39781, time=1.29400
Epoch:0026, train_loss=1.96479, train_acc=0.41078, val_loss=2.06573, val_acc=0.40876, time=1.09801
Epoch:0027, train_loss=1.95834, train_acc=0.42030, val_loss=2.06514, val_acc=0.41971, time=1.25400
Epoch:0028, train_loss=1.95226, train_acc=0.43083, val_loss=2.06458, val_acc=0.42336, time=1.11100
Epoch:0029, train_loss=1.94654, train_acc=0.43650, val_loss=2.06407, val_acc=0.43066, time=1.10000
Epoch:0030, train_loss=1.94115, train_acc=0.44237, val_loss=2.06360, val_acc=0.42701, time=1.12600
Epoch:0031, train_loss=1.93609, train_acc=0.44967, val_loss=2.06315, val_acc=0.43248, time=1.09402
Epoch:0032, train_loss=1.93134, train_acc=0.45250, val_loss=2.06275, val_acc=0.43613, time=1.11099
Epoch:0033, train_loss=1.92687, train_acc=0.45655, val_loss=2.06237, val_acc=0.44526, time=1.11102
Epoch:0034, train_loss=1.92268, train_acc=0.46121, val_loss=2.06202, val_acc=0.44891, time=1.08300
Epoch:0035, train_loss=1.91874, train_acc=0.46405, val_loss=2.06170, val_acc=0.45438, time=1.12401
Epoch:0036, train_loss=1.91503, train_acc=0.46891, val_loss=2.06140, val_acc=0.45620, time=1.19200
Epoch:0037, train_loss=1.91154, train_acc=0.47235, val_loss=2.06113, val_acc=0.46168, time=1.18901
Epoch:0038, train_loss=1.90826, train_acc=0.47681, val_loss=2.06087, val_acc=0.45985, time=1.11301
Epoch:0039, train_loss=1.90516, train_acc=0.48025, val_loss=2.06064, val_acc=0.46350, time=1.12101
Epoch:0040, train_loss=1.90223, train_acc=0.48531, val_loss=2.06042, val_acc=0.46350, time=1.29899
Epoch:0041, train_loss=1.89946, train_acc=0.48714, val_loss=2.06022, val_acc=0.46533, time=1.32501
Epoch:0042, train_loss=1.89684, train_acc=0.49119, val_loss=2.06003, val_acc=0.46715, time=1.44101
Epoch:0043, train_loss=1.89435, train_acc=0.49342, val_loss=2.05986, val_acc=0.46350, time=1.43601
Epoch:0044, train_loss=1.89198, train_acc=0.49605, val_loss=2.05970, val_acc=0.46533, time=1.16801
Epoch:0045, train_loss=1.88973, train_acc=0.49706, val_loss=2.05955, val_acc=0.46350, time=1.20901
Epoch:0046, train_loss=1.88757, train_acc=0.49970, val_loss=2.05941, val_acc=0.46350, time=1.22401
Epoch:0047, train_loss=1.88551, train_acc=0.50132, val_loss=2.05928, val_acc=0.46350, time=1.00900
Epoch:0048, train_loss=1.88353, train_acc=0.50375, val_loss=2.05916, val_acc=0.46533, time=1.20701
Epoch:0049, train_loss=1.88163, train_acc=0.50638, val_loss=2.05904, val_acc=0.46533, time=1.11299
Epoch:0050, train_loss=1.87980, train_acc=0.50820, val_loss=2.05893, val_acc=0.46898, time=1.05803
Epoch:0051, train_loss=1.87804, train_acc=0.51084, val_loss=2.05883, val_acc=0.47263, time=1.11202
Epoch:0052, train_loss=1.87633, train_acc=0.51165, val_loss=2.05874, val_acc=0.47263, time=1.08501
Epoch:0053, train_loss=1.87468, train_acc=0.51205, val_loss=2.05865, val_acc=0.47263, time=1.15101
Epoch:0054, train_loss=1.87308, train_acc=0.51428, val_loss=2.05857, val_acc=0.47263, time=1.02301
Epoch:0055, train_loss=1.87153, train_acc=0.51529, val_loss=2.05849, val_acc=0.47445, time=1.16900
Epoch:0056, train_loss=1.87002, train_acc=0.51610, val_loss=2.05842, val_acc=0.47445, time=1.14200
Epoch:0057, train_loss=1.86855, train_acc=0.51853, val_loss=2.05835, val_acc=0.47445, time=1.16101
Epoch:0058, train_loss=1.86712, train_acc=0.51874, val_loss=2.05828, val_acc=0.47628, time=1.09701
Epoch:0059, train_loss=1.86572, train_acc=0.51955, val_loss=2.05822, val_acc=0.47810, time=1.21001
Epoch:0060, train_loss=1.86436, train_acc=0.52076, val_loss=2.05817, val_acc=0.47810, time=1.17200
Epoch:0061, train_loss=1.86302, train_acc=0.52198, val_loss=2.05811, val_acc=0.47993, time=0.96800
Epoch:0062, train_loss=1.86172, train_acc=0.52279, val_loss=2.05807, val_acc=0.48175, time=1.13003
Epoch:0063, train_loss=1.86044, train_acc=0.52400, val_loss=2.05802, val_acc=0.48358, time=1.11999
Epoch:0064, train_loss=1.85918, train_acc=0.52562, val_loss=2.05798, val_acc=0.48175, time=1.05701
Epoch:0065, train_loss=1.85795, train_acc=0.52603, val_loss=2.05794, val_acc=0.48358, time=1.15901
Epoch:0066, train_loss=1.85674, train_acc=0.52684, val_loss=2.05790, val_acc=0.48540, time=1.15701
Epoch:0067, train_loss=1.85555, train_acc=0.52785, val_loss=2.05787, val_acc=0.48540, time=1.14801
Epoch:0068, train_loss=1.85437, train_acc=0.52886, val_loss=2.05784, val_acc=0.48358, time=1.32302
Epoch:0069, train_loss=1.85322, train_acc=0.52927, val_loss=2.05781, val_acc=0.47993, time=1.10600
Epoch:0070, train_loss=1.85208, train_acc=0.53028, val_loss=2.05779, val_acc=0.48175, time=1.01400
Epoch:0071, train_loss=1.85096, train_acc=0.53089, val_loss=2.05776, val_acc=0.47628, time=1.08500
Epoch:0072, train_loss=1.84985, train_acc=0.53170, val_loss=2.05774, val_acc=0.47628, time=1.06101
Epoch:0073, train_loss=1.84875, train_acc=0.53312, val_loss=2.05772, val_acc=0.47263, time=1.12700
Epoch:0074, train_loss=1.84767, train_acc=0.53393, val_loss=2.05770, val_acc=0.47080, time=1.25699
Epoch:0075, train_loss=1.84661, train_acc=0.53575, val_loss=2.05768, val_acc=0.47080, time=1.11500
Epoch:0076, train_loss=1.84555, train_acc=0.53697, val_loss=2.05767, val_acc=0.46898, time=0.96201
Epoch:0077, train_loss=1.84451, train_acc=0.53838, val_loss=2.05765, val_acc=0.46898, time=1.02202
Epoch:0078, train_loss=1.84348, train_acc=0.53919, val_loss=2.05764, val_acc=0.46898, time=1.11499
Epoch:0079, train_loss=1.84247, train_acc=0.54041, val_loss=2.05763, val_acc=0.46898, time=1.00302
Epoch:0080, train_loss=1.84146, train_acc=0.54142, val_loss=2.05762, val_acc=0.47080, time=1.14700
Epoch:0081, train_loss=1.84046, train_acc=0.54243, val_loss=2.05761, val_acc=0.47263, time=1.10302
Epoch:0082, train_loss=1.83948, train_acc=0.54304, val_loss=2.05760, val_acc=0.47263, time=0.98600
Epoch:0083, train_loss=1.83850, train_acc=0.54304, val_loss=2.05759, val_acc=0.47263, time=1.05001
Epoch:0084, train_loss=1.83754, train_acc=0.54426, val_loss=2.05758, val_acc=0.47263, time=1.12200
Epoch:0085, train_loss=1.83658, train_acc=0.54588, val_loss=2.05757, val_acc=0.47263, time=1.10000
Epoch:0086, train_loss=1.83563, train_acc=0.54689, val_loss=2.05757, val_acc=0.47263, time=1.12201
Epoch:0087, train_loss=1.83469, train_acc=0.54790, val_loss=2.05756, val_acc=0.47080, time=1.26603
Epoch:0088, train_loss=1.83376, train_acc=0.54871, val_loss=2.05756, val_acc=0.47445, time=1.40699
Epoch:0089, train_loss=1.83284, train_acc=0.54993, val_loss=2.05755, val_acc=0.47445, time=1.11100
Epoch:0090, train_loss=1.83193, train_acc=0.55114, val_loss=2.05755, val_acc=0.47628, time=1.18702
Epoch:0091, train_loss=1.83102, train_acc=0.55297, val_loss=2.05754, val_acc=0.47810, time=1.15202
Epoch:0092, train_loss=1.83012, train_acc=0.55418, val_loss=2.05754, val_acc=0.47810, time=1.08100
Epoch:0093, train_loss=1.82923, train_acc=0.55439, val_loss=2.05753, val_acc=0.47810, time=0.98101
Epoch:0094, train_loss=1.82835, train_acc=0.55580, val_loss=2.05753, val_acc=0.47810, time=0.98599
Epoch:0095, train_loss=1.82747, train_acc=0.55702, val_loss=2.05753, val_acc=0.47993, time=1.11401
Epoch:0096, train_loss=1.82660, train_acc=0.55864, val_loss=2.05753, val_acc=0.48175, time=1.02901
Epoch:0097, train_loss=1.82574, train_acc=0.55945, val_loss=2.05753, val_acc=0.47993, time=1.03402
Epoch:0098, train_loss=1.82488, train_acc=0.56107, val_loss=2.05752, val_acc=0.47993, time=1.11702
Epoch:0099, train_loss=1.82403, train_acc=0.56289, val_loss=2.05752, val_acc=0.47993, time=1.25000
Epoch:0100, train_loss=1.82318, train_acc=0.56391, val_loss=2.05752, val_acc=0.48175, time=1.20599
Epoch:0101, train_loss=1.82235, train_acc=0.56472, val_loss=2.05752, val_acc=0.48358, time=1.10400
Epoch:0102, train_loss=1.82151, train_acc=0.56492, val_loss=2.05752, val_acc=0.48540, time=1.04801
Epoch:0103, train_loss=1.82069, train_acc=0.56613, val_loss=2.05753, val_acc=0.48358, time=1.04601
Epoch:0104, train_loss=1.81986, train_acc=0.56735, val_loss=2.05753, val_acc=0.47993, time=1.25300
Early stopping...

Optimization Finished!

Test set results: loss= 2.00131, accuracy= 0.45683, time= 0.38899

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        87
           1     0.4950    0.8301    0.6202      1083
           2     0.3146    0.1451    0.1986       696
           3     0.0000    0.0000    0.0000        10
           4     0.0000    0.0000    0.0000        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.0000    0.0000    0.0000        81

    accuracy                         0.4568      2189
   macro avg     0.1012    0.1219    0.1024      2189
weighted avg     0.3450    0.4568    0.3700      2189


Macro average Test Precision, Recall and F1-Score...
(0.10121072467646533, 0.1219020640303117, 0.1023546586267329, None)

Micro average Test Precision, Recall and F1-Score...
(0.4568296025582458, 0.4568296025582458, 0.4568296025582458, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
