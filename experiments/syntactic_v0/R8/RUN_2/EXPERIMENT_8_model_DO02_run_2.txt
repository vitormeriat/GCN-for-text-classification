
==========: 156837658426900
Epoch:0001, train_loss=2.24432, train_acc=0.22038, val_loss=2.08035, val_acc=0.48723, time=1.20502
Epoch:0002, train_loss=2.05604, train_acc=0.50638, val_loss=2.06893, val_acc=0.50000, time=1.23800
Epoch:0003, train_loss=1.95143, train_acc=0.51590, val_loss=2.06180, val_acc=0.45803, time=1.17901
Epoch:0004, train_loss=1.88537, train_acc=0.49058, val_loss=2.06224, val_acc=0.37409, time=1.07900
Epoch:0005, train_loss=1.88642, train_acc=0.41381, val_loss=2.06363, val_acc=0.36496, time=1.04701
Epoch:0006, train_loss=1.88887, train_acc=0.41240, val_loss=2.06282, val_acc=0.39234, time=1.20401
Epoch:0007, train_loss=1.86383, train_acc=0.47357, val_loss=2.06236, val_acc=0.44161, time=1.11800
Epoch:0008, train_loss=1.83856, train_acc=0.52481, val_loss=2.06319, val_acc=0.46898, time=0.97400
Epoch:0009, train_loss=1.82696, train_acc=0.55864, val_loss=2.06407, val_acc=0.49088, time=1.21602
Epoch:0010, train_loss=1.82032, train_acc=0.56269, val_loss=2.06415, val_acc=0.48905, time=1.18201
Epoch:0011, train_loss=1.81059, train_acc=0.56694, val_loss=2.06361, val_acc=0.47993, time=1.05501
Epoch:0012, train_loss=1.79831, train_acc=0.57910, val_loss=2.06296, val_acc=0.46350, time=1.05000
Epoch:0013, train_loss=1.78660, train_acc=0.59814, val_loss=2.06257, val_acc=0.44526, time=0.99100
Epoch:0014, train_loss=1.77716, train_acc=0.61839, val_loss=2.06243, val_acc=0.39964, time=1.02701
Epoch:0015, train_loss=1.76928, train_acc=0.61515, val_loss=2.06241, val_acc=0.39599, time=1.00101
Epoch:0016, train_loss=1.76128, train_acc=0.61333, val_loss=2.06244, val_acc=0.39416, time=1.01401
Epoch:0017, train_loss=1.75257, train_acc=0.62082, val_loss=2.06259, val_acc=0.42336, time=1.08900
Epoch:0018, train_loss=1.74399, train_acc=0.63905, val_loss=2.06295, val_acc=0.43978, time=1.19900
Epoch:0019, train_loss=1.73672, train_acc=0.64432, val_loss=2.06350, val_acc=0.45073, time=1.03799
Early stopping...

Optimization Finished!

Test set results: loss= 2.01577, accuracy= 0.46277, time= 0.37200

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.2500    0.0115    0.0220        87
           1     0.4970    0.8430    0.6253      1083
           2     0.3151    0.1408    0.1946       696
           3     0.0000    0.0000    0.0000        10
           4     0.0000    0.0000    0.0000        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.0588    0.0123    0.0204        81

    accuracy                         0.4628      2189
   macro avg     0.1401    0.1260    0.1078      2189
weighted avg     0.3582    0.4628    0.3729      2189


Macro average Test Precision, Recall and F1-Score...
(0.14011775720358036, 0.12595914422238969, 0.1077957735295097, None)

Micro average Test Precision, Recall and F1-Score...
(0.46276838739150294, 0.46276838739150294, 0.46276838739150294, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
