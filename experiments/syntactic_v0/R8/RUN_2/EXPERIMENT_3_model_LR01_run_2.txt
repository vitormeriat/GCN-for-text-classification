
==========: 155666147549100
Epoch:0001, train_loss=2.19890, train_acc=0.15556, val_loss=2.08741, val_acc=0.50182, time=1.42401
Epoch:0002, train_loss=2.12146, train_acc=0.52056, val_loss=2.12802, val_acc=0.32299, time=1.34702
Epoch:0003, train_loss=2.54087, train_acc=0.29856, val_loss=2.08179, val_acc=0.34124, time=1.19500
Epoch:0004, train_loss=2.03538, train_acc=0.40348, val_loss=2.09017, val_acc=0.49453, time=1.14000
Epoch:0005, train_loss=2.02451, train_acc=0.53595, val_loss=2.10004, val_acc=0.49635, time=1.29800
Epoch:0006, train_loss=2.06214, train_acc=0.53616, val_loss=2.09361, val_acc=0.49088, time=1.27401
Epoch:0007, train_loss=1.97889, train_acc=0.54649, val_loss=2.08258, val_acc=0.46168, time=1.09901
Epoch:0008, train_loss=1.86924, train_acc=0.56391, val_loss=2.07394, val_acc=0.45073, time=1.13800
Epoch:0009, train_loss=1.79104, train_acc=0.62123, val_loss=2.07190, val_acc=0.38686, time=1.10502
Epoch:0010, train_loss=1.77303, train_acc=0.64938, val_loss=2.07337, val_acc=0.35036, time=1.14902
Epoch:0011, train_loss=1.78083, train_acc=0.56775, val_loss=2.07428, val_acc=0.35584, time=1.24801
Epoch:0012, train_loss=1.77783, train_acc=0.54831, val_loss=2.07385, val_acc=0.35036, time=1.11501
Epoch:0013, train_loss=1.75786, train_acc=0.57302, val_loss=2.07291, val_acc=0.37044, time=1.23300
Epoch:0014, train_loss=1.73085, train_acc=0.63136, val_loss=2.07252, val_acc=0.43248, time=1.14202
Epoch:0015, train_loss=1.70806, train_acc=0.68989, val_loss=2.07321, val_acc=0.44161, time=1.09900
Epoch:0016, train_loss=1.69552, train_acc=0.68868, val_loss=2.07477, val_acc=0.46350, time=1.02700
Epoch:0017, train_loss=1.69199, train_acc=0.67713, val_loss=2.07648, val_acc=0.46533, time=1.19500
Early stopping...

Optimization Finished!

Test set results: loss= 2.06417, accuracy= 0.46642, time= 0.35000

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.0476    0.0115    0.0185        87
           1     0.5011    0.8569    0.6324      1083
           2     0.3383    0.1293    0.1871       696
           3     0.0000    0.0000    0.0000        10
           4     0.0455    0.0133    0.0206        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.0833    0.0123    0.0215        81

    accuracy                         0.4664      2189
   macro avg     0.1270    0.1279    0.1100      2189
weighted avg     0.3620    0.4664    0.3746      2189


Macro average Test Precision, Recall and F1-Score...
(0.12697908808443648, 0.1279203312189191, 0.11001507642707278, None)

Micro average Test Precision, Recall and F1-Score...
(0.46642302421196896, 0.46642302421196896, 0.46642302421196896, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
