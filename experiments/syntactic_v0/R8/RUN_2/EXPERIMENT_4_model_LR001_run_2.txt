
==========: 155690441751600
Epoch:0001, train_loss=2.29336, train_acc=0.06198, val_loss=2.08425, val_acc=0.18613, time=1.38100
Epoch:0002, train_loss=2.12964, train_acc=0.19567, val_loss=2.07189, val_acc=0.36131, time=1.29000
Epoch:0003, train_loss=2.00831, train_acc=0.35224, val_loss=2.06457, val_acc=0.41058, time=1.20302
Epoch:0004, train_loss=1.93275, train_acc=0.43873, val_loss=2.06196, val_acc=0.45620, time=1.13100
Epoch:0005, train_loss=1.90029, train_acc=0.49099, val_loss=2.06215, val_acc=0.48905, time=1.13001
Epoch:0006, train_loss=1.89460, train_acc=0.50820, val_loss=2.06281, val_acc=0.49088, time=1.13600
Epoch:0007, train_loss=1.89515, train_acc=0.51610, val_loss=2.06288, val_acc=0.48723, time=1.15501
Epoch:0008, train_loss=1.89204, train_acc=0.52157, val_loss=2.06242, val_acc=0.47810, time=1.10399
Epoch:0009, train_loss=1.88501, train_acc=0.52785, val_loss=2.06192, val_acc=0.46898, time=1.12400
Epoch:0010, train_loss=1.87759, train_acc=0.53433, val_loss=2.06172, val_acc=0.43978, time=1.12102
Epoch:0011, train_loss=1.87170, train_acc=0.53433, val_loss=2.06167, val_acc=0.41058, time=1.12700
Epoch:0012, train_loss=1.86545, train_acc=0.53919, val_loss=2.06152, val_acc=0.41241, time=1.23301
Epoch:0013, train_loss=1.85660, train_acc=0.54324, val_loss=2.06124, val_acc=0.41058, time=1.00902
Epoch:0014, train_loss=1.84541, train_acc=0.55560, val_loss=2.06098, val_acc=0.43066, time=1.18100
Epoch:0015, train_loss=1.83381, train_acc=0.56654, val_loss=2.06089, val_acc=0.43796, time=1.07902
Epoch:0016, train_loss=1.82357, train_acc=0.57180, val_loss=2.06101, val_acc=0.43431, time=1.03101
Epoch:0017, train_loss=1.81537, train_acc=0.57646, val_loss=2.06126, val_acc=0.44161, time=1.04501
Epoch:0018, train_loss=1.80865, train_acc=0.57910, val_loss=2.06149, val_acc=0.44708, time=1.02301
Early stopping...

Optimization Finished!

Test set results: loss= 2.01043, accuracy= 0.46505, time= 0.43000

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3333    0.0115    0.0222        87
           1     0.4923    0.8550    0.6248      1083
           2     0.3408    0.1307    0.1890       696
           3     0.0000    0.0000    0.0000        10
           4     0.0000    0.0000    0.0000        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.0000    0.0000    0.0000        81

    accuracy                         0.4651      2189
   macro avg     0.1458    0.1247    0.1045      2189
weighted avg     0.3652    0.4651    0.3701      2189


Macro average Test Precision, Recall and F1-Score...
(0.145806079720923, 0.12465921211831757, 0.10450578278910794, None)

Micro average Test Precision, Recall and F1-Score...
(0.4650525354042942, 0.4650525354042942, 0.4650525354042942, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
