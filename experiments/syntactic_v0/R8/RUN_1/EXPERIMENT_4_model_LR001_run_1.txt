
==========: 152373082120500
Epoch:0001, train_loss=2.31491, train_acc=0.02046, val_loss=2.08677, val_acc=0.21168, time=1.48701
Epoch:0002, train_loss=2.12533, train_acc=0.20296, val_loss=2.07336, val_acc=0.40146, time=1.26101
Epoch:0003, train_loss=2.00012, train_acc=0.42090, val_loss=2.06644, val_acc=0.47993, time=1.38700
Epoch:0004, train_loss=1.93560, train_acc=0.48714, val_loss=2.06329, val_acc=0.49270, time=1.17401
Epoch:0005, train_loss=1.90570, train_acc=0.50577, val_loss=2.06168, val_acc=0.48905, time=0.97002
Epoch:0006, train_loss=1.88976, train_acc=0.51387, val_loss=2.06074, val_acc=0.47080, time=0.98900
Epoch:0007, train_loss=1.87965, train_acc=0.51469, val_loss=2.06039, val_acc=0.46715, time=1.02002
Epoch:0008, train_loss=1.87418, train_acc=0.51651, val_loss=2.06052, val_acc=0.45255, time=1.09702
Epoch:0009, train_loss=1.87172, train_acc=0.51306, val_loss=2.06072, val_acc=0.43796, time=1.04900
Epoch:0010, train_loss=1.86815, train_acc=0.50922, val_loss=2.06068, val_acc=0.43796, time=1.15801
Epoch:0011, train_loss=1.86079, train_acc=0.51874, val_loss=2.06044, val_acc=0.44161, time=1.20501
Epoch:0012, train_loss=1.85045, train_acc=0.53960, val_loss=2.06022, val_acc=0.46898, time=1.04300
Epoch:0013, train_loss=1.83953, train_acc=0.55520, val_loss=2.06014, val_acc=0.46898, time=1.16900
Epoch:0014, train_loss=1.82970, train_acc=0.56472, val_loss=2.06018, val_acc=0.47993, time=1.00801
Epoch:0015, train_loss=1.82114, train_acc=0.56998, val_loss=2.06023, val_acc=0.47993, time=1.02701
Epoch:0016, train_loss=1.81321, train_acc=0.57099, val_loss=2.06025, val_acc=0.48175, time=1.07799
Epoch:0017, train_loss=1.80555, train_acc=0.57869, val_loss=2.06025, val_acc=0.47628, time=0.99201
Epoch:0018, train_loss=1.79836, train_acc=0.58538, val_loss=2.06030, val_acc=0.46898, time=1.04103
Epoch:0019, train_loss=1.79202, train_acc=0.59226, val_loss=2.06042, val_acc=0.45438, time=1.13401
Early stopping...

Optimization Finished!

Test set results: loss= 2.00478, accuracy= 0.44358, time= 0.36202

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        87
           1     0.4938    0.8061    0.6124      1083
           2     0.2672    0.1394    0.1832       696
           3     0.0000    0.0000    0.0000        10
           4     0.0333    0.0133    0.0190        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.0000    0.0000    0.0000        81

    accuracy                         0.4436      2189
   macro avg     0.0993    0.1198    0.1018      2189
weighted avg     0.3304    0.4436    0.3619      2189


Macro average Test Precision, Recall and F1-Score...
(0.09929115559128927, 0.11984941653134651, 0.1018320006522049, None)

Micro average Test Precision, Recall and F1-Score...
(0.44358154408405664, 0.44358154408405664, 0.44358154408405664, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
