
==========: 154144059252000
Epoch:0001, train_loss=2.52651, train_acc=0.02188, val_loss=2.09218, val_acc=0.22263, time=1.47502
Epoch:0002, train_loss=2.18164, train_acc=0.21592, val_loss=2.07027, val_acc=0.44891, time=1.21501
Epoch:0003, train_loss=1.97349, train_acc=0.46546, val_loss=2.06316, val_acc=0.48905, time=1.19201
Epoch:0004, train_loss=1.90531, train_acc=0.51246, val_loss=2.06127, val_acc=0.49818, time=1.18401
Epoch:0005, train_loss=1.88746, train_acc=0.52157, val_loss=2.06108, val_acc=0.47993, time=1.15700
Epoch:0006, train_loss=1.88487, train_acc=0.53089, val_loss=2.06255, val_acc=0.44343, time=1.15502
Epoch:0007, train_loss=1.89396, train_acc=0.51043, val_loss=2.06371, val_acc=0.44161, time=0.97198
Epoch:0008, train_loss=1.89475, train_acc=0.49747, val_loss=2.06356, val_acc=0.46168, time=1.31602
Epoch:0009, train_loss=1.87932, train_acc=0.53616, val_loss=2.06297, val_acc=0.47080, time=1.19100
Epoch:0010, train_loss=1.85753, train_acc=0.57059, val_loss=2.06266, val_acc=0.48175, time=0.99201
Epoch:0011, train_loss=1.83790, train_acc=0.58092, val_loss=2.06253, val_acc=0.49088, time=1.05700
Epoch:0012, train_loss=1.82111, train_acc=0.57849, val_loss=2.06228, val_acc=0.49088, time=1.10400
Epoch:0013, train_loss=1.80546, train_acc=0.58416, val_loss=2.06201, val_acc=0.48175, time=1.01300
Epoch:0014, train_loss=1.79184, train_acc=0.59348, val_loss=2.06202, val_acc=0.47445, time=1.24300
Epoch:0015, train_loss=1.78229, train_acc=0.60867, val_loss=2.06240, val_acc=0.46533, time=1.15199
Epoch:0016, train_loss=1.77694, train_acc=0.62690, val_loss=2.06296, val_acc=0.45803, time=1.05299
Early stopping...

Optimization Finished!

Test set results: loss= 2.01030, accuracy= 0.45637, time= 0.29300

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.0882    0.0345    0.0496        87
           1     0.5032    0.7959    0.6166      1083
           2     0.3560    0.1882    0.2462       696
           3     0.0000    0.0000    0.0000        10
           4     0.0000    0.0000    0.0000        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.1304    0.0370    0.0577        81

    accuracy                         0.4564      2189
   macro avg     0.1347    0.1320    0.1213      2189
weighted avg     0.3705    0.4564    0.3875      2189


Macro average Test Precision, Recall and F1-Score...
(0.13473238487316042, 0.13195942473900013, 0.12126435274550147, None)

Micro average Test Precision, Recall and F1-Score...
(0.4563727729556875, 0.4563727729556875, 0.4563727729556875, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
