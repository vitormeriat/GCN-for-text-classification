
==========: 160039186090200
Epoch:0001, train_loss=2.40964, train_acc=0.02572, val_loss=2.08015, val_acc=0.31204, time=1.38600
Epoch:0002, train_loss=2.07838, train_acc=0.28175, val_loss=2.06277, val_acc=0.43613, time=1.30802
Epoch:0003, train_loss=1.91172, train_acc=0.45919, val_loss=2.06141, val_acc=0.47263, time=1.21502
Epoch:0004, train_loss=1.88747, train_acc=0.51246, val_loss=2.06407, val_acc=0.49270, time=1.01700
Epoch:0005, train_loss=1.90335, train_acc=0.52927, val_loss=2.06419, val_acc=0.48723, time=0.96801
Epoch:0006, train_loss=1.90039, train_acc=0.53454, val_loss=2.06310, val_acc=0.48905, time=1.10500
Epoch:0007, train_loss=1.88759, train_acc=0.54203, val_loss=2.06280, val_acc=0.45620, time=1.04001
Epoch:0008, train_loss=1.87953, train_acc=0.53717, val_loss=2.06264, val_acc=0.43613, time=1.05099
Epoch:0009, train_loss=1.86806, train_acc=0.53535, val_loss=2.06188, val_acc=0.45255, time=1.12001
Epoch:0010, train_loss=1.84730, train_acc=0.55925, val_loss=2.06112, val_acc=0.45255, time=1.05302
Epoch:0011, train_loss=1.82478, train_acc=0.59145, val_loss=2.06098, val_acc=0.46898, time=1.07601
Epoch:0012, train_loss=1.80765, train_acc=0.59591, val_loss=2.06135, val_acc=0.47810, time=1.34200
Epoch:0013, train_loss=1.79595, train_acc=0.59591, val_loss=2.06178, val_acc=0.47263, time=1.15602
Epoch:0014, train_loss=1.78606, train_acc=0.60077, val_loss=2.06200, val_acc=0.46533, time=0.99600
Epoch:0015, train_loss=1.77581, train_acc=0.61313, val_loss=2.06203, val_acc=0.45985, time=0.95800
Epoch:0016, train_loss=1.76539, train_acc=0.62467, val_loss=2.06206, val_acc=0.45255, time=1.05101
Early stopping...

Optimization Finished!

Test set results: loss= 2.01004, accuracy= 0.44312, time= 0.29301

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.2222    0.0230    0.0417        87
           1     0.4928    0.7904    0.6071      1083
           2     0.2984    0.1595    0.2079       696
           3     0.0000    0.0000    0.0000        10
           4     0.0000    0.0000    0.0000        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.0769    0.0123    0.0213        81

    accuracy                         0.4431      2189
   macro avg     0.1363    0.1232    0.1097      2189
weighted avg     0.3504    0.4431    0.3689      2189


Macro average Test Precision, Recall and F1-Score...
(0.13629201005412772, 0.12315174857810657, 0.10973757869152921, None)

Micro average Test Precision, Recall and F1-Score...
(0.4431247144814984, 0.4431247144814984, 0.4431247144814984, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
