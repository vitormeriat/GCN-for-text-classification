
==========: 161405020887500
Epoch:0001, train_loss=2.32979, train_acc=0.04800, val_loss=2.10241, val_acc=0.05292, time=1.40600
Epoch:0002, train_loss=2.31160, train_acc=0.04902, val_loss=2.10056, val_acc=0.05292, time=1.19101
Epoch:0003, train_loss=2.29371, train_acc=0.05104, val_loss=2.09874, val_acc=0.05657, time=1.25201
Epoch:0004, train_loss=2.27613, train_acc=0.05145, val_loss=2.09695, val_acc=0.06022, time=0.94201
Epoch:0005, train_loss=2.25888, train_acc=0.05611, val_loss=2.09521, val_acc=0.06387, time=1.15101
Epoch:0006, train_loss=2.24198, train_acc=0.06218, val_loss=2.09350, val_acc=0.06752, time=0.99801
Epoch:0007, train_loss=2.22542, train_acc=0.06948, val_loss=2.09183, val_acc=0.07117, time=1.09201
Epoch:0008, train_loss=2.20921, train_acc=0.08284, val_loss=2.09019, val_acc=0.09124, time=1.13799
Epoch:0009, train_loss=2.19337, train_acc=0.09601, val_loss=2.08860, val_acc=0.12409, time=1.16998
Epoch:0010, train_loss=2.17791, train_acc=0.11120, val_loss=2.08705, val_acc=0.14781, time=1.14302
Epoch:0011, train_loss=2.16282, train_acc=0.12700, val_loss=2.08554, val_acc=0.16241, time=0.99801
Epoch:0012, train_loss=2.14812, train_acc=0.14260, val_loss=2.08407, val_acc=0.17336, time=1.08500
Epoch:0013, train_loss=2.13383, train_acc=0.15941, val_loss=2.08265, val_acc=0.18431, time=1.07500
Epoch:0014, train_loss=2.11996, train_acc=0.17237, val_loss=2.08128, val_acc=0.19708, time=1.08400
Epoch:0015, train_loss=2.10650, train_acc=0.18716, val_loss=2.07995, val_acc=0.22263, time=1.07301
Epoch:0016, train_loss=2.09345, train_acc=0.20741, val_loss=2.07867, val_acc=0.24635, time=1.07901
Epoch:0017, train_loss=2.08083, train_acc=0.21997, val_loss=2.07743, val_acc=0.26825, time=1.12700
Epoch:0018, train_loss=2.06864, train_acc=0.23476, val_loss=2.07624, val_acc=0.27920, time=0.99800
Epoch:0019, train_loss=2.05688, train_acc=0.24914, val_loss=2.07510, val_acc=0.29380, time=1.12900
Epoch:0020, train_loss=2.04556, train_acc=0.26595, val_loss=2.07401, val_acc=0.31022, time=0.99500
Epoch:0021, train_loss=2.03468, train_acc=0.28053, val_loss=2.07297, val_acc=0.33759, time=0.99601
Epoch:0022, train_loss=2.02425, train_acc=0.29795, val_loss=2.07197, val_acc=0.34672, time=0.98302
Epoch:0023, train_loss=2.01427, train_acc=0.31375, val_loss=2.07103, val_acc=0.35949, time=0.94503
Epoch:0024, train_loss=2.00473, train_acc=0.32955, val_loss=2.07013, val_acc=0.37226, time=1.20100
Epoch:0025, train_loss=1.99564, train_acc=0.34252, val_loss=2.06928, val_acc=0.37409, time=1.35401
Epoch:0026, train_loss=1.98699, train_acc=0.35528, val_loss=2.06848, val_acc=0.38504, time=1.19201
Epoch:0027, train_loss=1.97878, train_acc=0.37027, val_loss=2.06773, val_acc=0.38504, time=1.15801
Epoch:0028, train_loss=1.97100, train_acc=0.38161, val_loss=2.06703, val_acc=0.38504, time=1.07602
Epoch:0029, train_loss=1.96365, train_acc=0.39477, val_loss=2.06637, val_acc=0.38686, time=1.06799
Epoch:0030, train_loss=1.95672, train_acc=0.40369, val_loss=2.06575, val_acc=0.39234, time=0.99800
Epoch:0031, train_loss=1.95021, train_acc=0.41483, val_loss=2.06518, val_acc=0.39599, time=0.95301
Epoch:0032, train_loss=1.94410, train_acc=0.42313, val_loss=2.06466, val_acc=0.39964, time=0.95500
Epoch:0033, train_loss=1.93838, train_acc=0.42941, val_loss=2.06417, val_acc=0.40511, time=1.06602
Epoch:0034, train_loss=1.93304, train_acc=0.43751, val_loss=2.06372, val_acc=0.41058, time=1.02301
Epoch:0035, train_loss=1.92805, train_acc=0.44399, val_loss=2.06331, val_acc=0.41788, time=1.17801
Epoch:0036, train_loss=1.92340, train_acc=0.44967, val_loss=2.06293, val_acc=0.41971, time=1.01403
Epoch:0037, train_loss=1.91905, train_acc=0.45554, val_loss=2.06258, val_acc=0.42518, time=1.02901
Epoch:0038, train_loss=1.91500, train_acc=0.46222, val_loss=2.06226, val_acc=0.43248, time=0.97602
Epoch:0039, train_loss=1.91122, train_acc=0.46648, val_loss=2.06196, val_acc=0.43613, time=1.11000
Epoch:0040, train_loss=1.90768, train_acc=0.47012, val_loss=2.06169, val_acc=0.43796, time=1.07701
Epoch:0041, train_loss=1.90437, train_acc=0.47438, val_loss=2.06144, val_acc=0.43796, time=1.16100
Epoch:0042, train_loss=1.90126, train_acc=0.47742, val_loss=2.06120, val_acc=0.44161, time=1.01100
Epoch:0043, train_loss=1.89834, train_acc=0.48126, val_loss=2.06099, val_acc=0.44526, time=1.01900
Epoch:0044, train_loss=1.89558, train_acc=0.48511, val_loss=2.06078, val_acc=0.45073, time=1.15501
Epoch:0045, train_loss=1.89297, train_acc=0.48775, val_loss=2.06059, val_acc=0.44891, time=1.05300
Epoch:0046, train_loss=1.89049, train_acc=0.48997, val_loss=2.06041, val_acc=0.44891, time=1.01902
Epoch:0047, train_loss=1.88813, train_acc=0.49281, val_loss=2.06025, val_acc=0.44891, time=1.11100
Epoch:0048, train_loss=1.88588, train_acc=0.49706, val_loss=2.06009, val_acc=0.45073, time=1.10302
Epoch:0049, train_loss=1.88373, train_acc=0.49828, val_loss=2.05994, val_acc=0.45073, time=1.07801
Epoch:0050, train_loss=1.88167, train_acc=0.49909, val_loss=2.05979, val_acc=0.45255, time=0.98700
Epoch:0051, train_loss=1.87969, train_acc=0.50172, val_loss=2.05966, val_acc=0.45438, time=0.97800
Epoch:0052, train_loss=1.87779, train_acc=0.50354, val_loss=2.05953, val_acc=0.45803, time=1.09702
Epoch:0053, train_loss=1.87596, train_acc=0.50517, val_loss=2.05941, val_acc=0.45803, time=1.04000
Epoch:0054, train_loss=1.87419, train_acc=0.50679, val_loss=2.05930, val_acc=0.45620, time=1.03602
Epoch:0055, train_loss=1.87249, train_acc=0.50861, val_loss=2.05919, val_acc=0.45620, time=0.94900
Epoch:0056, train_loss=1.87084, train_acc=0.50922, val_loss=2.05909, val_acc=0.45620, time=1.14302
Epoch:0057, train_loss=1.86925, train_acc=0.51043, val_loss=2.05899, val_acc=0.45620, time=0.93701
Epoch:0058, train_loss=1.86771, train_acc=0.51286, val_loss=2.05890, val_acc=0.45620, time=0.95600
Epoch:0059, train_loss=1.86622, train_acc=0.51469, val_loss=2.05882, val_acc=0.45620, time=1.20901
Epoch:0060, train_loss=1.86477, train_acc=0.51570, val_loss=2.05874, val_acc=0.45620, time=1.04501
Epoch:0061, train_loss=1.86337, train_acc=0.51631, val_loss=2.05867, val_acc=0.45620, time=1.00101
Epoch:0062, train_loss=1.86201, train_acc=0.51894, val_loss=2.05861, val_acc=0.45620, time=0.98000
Epoch:0063, train_loss=1.86068, train_acc=0.52137, val_loss=2.05855, val_acc=0.45438, time=1.08101
Epoch:0064, train_loss=1.85938, train_acc=0.52157, val_loss=2.05849, val_acc=0.45620, time=0.99100
Epoch:0065, train_loss=1.85812, train_acc=0.52279, val_loss=2.05844, val_acc=0.45620, time=1.01401
Epoch:0066, train_loss=1.85688, train_acc=0.52360, val_loss=2.05839, val_acc=0.45620, time=0.93701
Epoch:0067, train_loss=1.85566, train_acc=0.52441, val_loss=2.05835, val_acc=0.45620, time=1.03600
Epoch:0068, train_loss=1.85447, train_acc=0.52623, val_loss=2.05832, val_acc=0.45803, time=1.00902
Epoch:0069, train_loss=1.85330, train_acc=0.52785, val_loss=2.05828, val_acc=0.45803, time=0.98200
Epoch:0070, train_loss=1.85215, train_acc=0.52846, val_loss=2.05825, val_acc=0.45803, time=1.02401
Epoch:0071, train_loss=1.85102, train_acc=0.53069, val_loss=2.05822, val_acc=0.45803, time=1.04601
Epoch:0072, train_loss=1.84990, train_acc=0.53109, val_loss=2.05820, val_acc=0.45803, time=1.08900
Epoch:0073, train_loss=1.84879, train_acc=0.53251, val_loss=2.05818, val_acc=0.45803, time=1.10101
Epoch:0074, train_loss=1.84770, train_acc=0.53393, val_loss=2.05816, val_acc=0.45985, time=1.24102
Epoch:0075, train_loss=1.84663, train_acc=0.53474, val_loss=2.05814, val_acc=0.45985, time=0.96601
Epoch:0076, train_loss=1.84557, train_acc=0.53616, val_loss=2.05812, val_acc=0.45985, time=1.01100
Epoch:0077, train_loss=1.84452, train_acc=0.53737, val_loss=2.05811, val_acc=0.45985, time=1.07600
Epoch:0078, train_loss=1.84348, train_acc=0.53940, val_loss=2.05810, val_acc=0.46168, time=0.99100
Epoch:0079, train_loss=1.84246, train_acc=0.53980, val_loss=2.05809, val_acc=0.46168, time=1.16200
Epoch:0080, train_loss=1.84144, train_acc=0.54041, val_loss=2.05808, val_acc=0.46168, time=1.08199
Epoch:0081, train_loss=1.84044, train_acc=0.54203, val_loss=2.05807, val_acc=0.46168, time=1.22601
Epoch:0082, train_loss=1.83945, train_acc=0.54284, val_loss=2.05806, val_acc=0.46350, time=1.32001
Epoch:0083, train_loss=1.83847, train_acc=0.54466, val_loss=2.05805, val_acc=0.46350, time=1.14701
Epoch:0084, train_loss=1.83750, train_acc=0.54568, val_loss=2.05805, val_acc=0.46350, time=1.06900
Epoch:0085, train_loss=1.83654, train_acc=0.54689, val_loss=2.05804, val_acc=0.46350, time=0.96002
Epoch:0086, train_loss=1.83559, train_acc=0.54790, val_loss=2.05804, val_acc=0.46350, time=1.16500
Epoch:0087, train_loss=1.83465, train_acc=0.54811, val_loss=2.05803, val_acc=0.46168, time=0.96498
Epoch:0088, train_loss=1.83372, train_acc=0.54851, val_loss=2.05803, val_acc=0.45985, time=0.98600
Epoch:0089, train_loss=1.83280, train_acc=0.54892, val_loss=2.05802, val_acc=0.45985, time=0.95600
Epoch:0090, train_loss=1.83188, train_acc=0.54993, val_loss=2.05802, val_acc=0.45985, time=1.03401
Epoch:0091, train_loss=1.83097, train_acc=0.55094, val_loss=2.05801, val_acc=0.45985, time=0.98202
Epoch:0092, train_loss=1.83007, train_acc=0.55195, val_loss=2.05801, val_acc=0.45985, time=0.95499
Epoch:0093, train_loss=1.82917, train_acc=0.55378, val_loss=2.05800, val_acc=0.45985, time=1.07101
Epoch:0094, train_loss=1.82829, train_acc=0.55459, val_loss=2.05800, val_acc=0.46350, time=0.98802
Epoch:0095, train_loss=1.82741, train_acc=0.55520, val_loss=2.05799, val_acc=0.46350, time=0.95701
Epoch:0096, train_loss=1.82653, train_acc=0.55540, val_loss=2.05799, val_acc=0.46350, time=1.11302
Epoch:0097, train_loss=1.82566, train_acc=0.55702, val_loss=2.05799, val_acc=0.46533, time=1.00300
Epoch:0098, train_loss=1.82480, train_acc=0.55783, val_loss=2.05798, val_acc=0.46533, time=1.00200
Epoch:0099, train_loss=1.82395, train_acc=0.55925, val_loss=2.05798, val_acc=0.46715, time=1.02901
Epoch:0100, train_loss=1.82310, train_acc=0.55985, val_loss=2.05798, val_acc=0.46898, time=0.97599
Epoch:0101, train_loss=1.82226, train_acc=0.56147, val_loss=2.05798, val_acc=0.46898, time=0.95301
Epoch:0102, train_loss=1.82142, train_acc=0.56289, val_loss=2.05797, val_acc=0.46898, time=1.09503
Epoch:0103, train_loss=1.82059, train_acc=0.56391, val_loss=2.05797, val_acc=0.46898, time=0.99301
Epoch:0104, train_loss=1.81976, train_acc=0.56492, val_loss=2.05797, val_acc=0.46898, time=0.96499
Epoch:0105, train_loss=1.81894, train_acc=0.56573, val_loss=2.05797, val_acc=0.47080, time=1.16502
Epoch:0106, train_loss=1.81813, train_acc=0.56674, val_loss=2.05797, val_acc=0.47080, time=1.03400
Epoch:0107, train_loss=1.81732, train_acc=0.56775, val_loss=2.05797, val_acc=0.47080, time=1.08202
Epoch:0108, train_loss=1.81651, train_acc=0.56978, val_loss=2.05797, val_acc=0.46898, time=1.17902
Epoch:0109, train_loss=1.81571, train_acc=0.57099, val_loss=2.05798, val_acc=0.47080, time=1.05201
Early stopping...

Optimization Finished!

Test set results: loss= 1.99834, accuracy= 0.45226, time= 0.33100

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        87
           1     0.4922    0.8190    0.6149      1083
           2     0.3091    0.1466    0.1988       696
           3     0.0000    0.0000    0.0000        10
           4     0.0000    0.0000    0.0000        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.0714    0.0123    0.0211        81

    accuracy                         0.4523      2189
   macro avg     0.1091    0.1222    0.1043      2189
weighted avg     0.3444    0.4523    0.3682      2189


Macro average Test Precision, Recall and F1-Score...
(0.10909379189068423, 0.12223983005675781, 0.10434846503896947, None)

Micro average Test Precision, Recall and F1-Score...
(0.45226130653266333, 0.45226130653266333, 0.45226130653266333, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
