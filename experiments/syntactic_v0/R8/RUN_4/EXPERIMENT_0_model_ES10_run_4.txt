
==========: 160123722784100
Epoch:0001, train_loss=2.45378, train_acc=0.03848, val_loss=2.08272, val_acc=0.26460, time=1.32201
Epoch:0002, train_loss=2.09018, train_acc=0.25400, val_loss=2.06365, val_acc=0.44891, time=1.42001
Epoch:0003, train_loss=1.91221, train_acc=0.47681, val_loss=2.06162, val_acc=0.47263, time=1.20701
Epoch:0004, train_loss=1.89287, train_acc=0.51550, val_loss=2.06321, val_acc=0.48358, time=0.99303
Epoch:0005, train_loss=1.90555, train_acc=0.52643, val_loss=2.06408, val_acc=0.48723, time=1.00100
Epoch:0006, train_loss=1.90999, train_acc=0.53413, val_loss=2.06498, val_acc=0.47628, time=1.05500
Epoch:0007, train_loss=1.91192, train_acc=0.54102, val_loss=2.06548, val_acc=0.46168, time=1.04801
Epoch:0008, train_loss=1.90659, train_acc=0.54122, val_loss=2.06500, val_acc=0.45438, time=0.95001
Epoch:0009, train_loss=1.88934, train_acc=0.56127, val_loss=2.06415, val_acc=0.47263, time=1.18600
Epoch:0010, train_loss=1.86675, train_acc=0.57788, val_loss=2.06349, val_acc=0.48540, time=1.01601
Epoch:0011, train_loss=1.84512, train_acc=0.58619, val_loss=2.06311, val_acc=0.47993, time=1.10200
Epoch:0012, train_loss=1.82623, train_acc=0.59064, val_loss=2.06294, val_acc=0.47993, time=1.03801
Epoch:0013, train_loss=1.81036, train_acc=0.59652, val_loss=2.06299, val_acc=0.47263, time=1.07800
Epoch:0014, train_loss=1.79802, train_acc=0.60725, val_loss=2.06319, val_acc=0.47080, time=1.11300
Epoch:0015, train_loss=1.78878, train_acc=0.61940, val_loss=2.06341, val_acc=0.45438, time=0.99900
Epoch:0016, train_loss=1.78094, train_acc=0.63196, val_loss=2.06351, val_acc=0.45073, time=0.96201
Epoch:0017, train_loss=1.77284, train_acc=0.63925, val_loss=2.06345, val_acc=0.44708, time=0.96898
Epoch:0018, train_loss=1.76381, train_acc=0.64715, val_loss=2.06330, val_acc=0.44891, time=1.00002
Epoch:0019, train_loss=1.75416, train_acc=0.65424, val_loss=2.06317, val_acc=0.44526, time=1.05703
Epoch:0020, train_loss=1.74478, train_acc=0.65931, val_loss=2.06314, val_acc=0.45073, time=1.00800
Epoch:0021, train_loss=1.73650, train_acc=0.65809, val_loss=2.06326, val_acc=0.45255, time=1.03800
Early stopping...

Optimization Finished!

Test set results: loss= 2.01366, accuracy= 0.45226, time= 0.29301

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.1176    0.0230    0.0385        87
           1     0.5049    0.8107    0.6223      1083
           2     0.3191    0.1509    0.2049       696
           3     0.0000    0.0000    0.0000        10
           4     0.0870    0.0533    0.0661        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.0909    0.0123    0.0217        81

    accuracy                         0.4523      2189
   macro avg     0.1399    0.1313    0.1192      2189
weighted avg     0.3623    0.4523    0.3776      2189


Macro average Test Precision, Recall and F1-Score...
(0.13994368427899473, 0.13128007188182866, 0.11918101761519528, None)

Micro average Test Precision, Recall and F1-Score...
(0.45226130653266333, 0.45226130653266333, 0.45226130653266333, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
