
==========: 163197933488000
Epoch:0001, train_loss=2.47190, train_acc=0.04578, val_loss=2.08470, val_acc=0.21898, time=1.41902
Epoch:0002, train_loss=2.12952, train_acc=0.22382, val_loss=2.06431, val_acc=0.40146, time=1.34500
Epoch:0003, train_loss=1.93363, train_acc=0.44156, val_loss=2.06132, val_acc=0.46533, time=1.28602
Epoch:0004, train_loss=1.89758, train_acc=0.50091, val_loss=2.06328, val_acc=0.48723, time=1.08800
Epoch:0005, train_loss=1.90977, train_acc=0.51934, val_loss=2.06338, val_acc=0.47263, time=1.17801
Epoch:0006, train_loss=1.90734, train_acc=0.52866, val_loss=2.06281, val_acc=0.48540, time=1.26600
Epoch:0007, train_loss=1.89866, train_acc=0.53595, val_loss=2.06310, val_acc=0.43978, time=1.10601
Epoch:0008, train_loss=1.89499, train_acc=0.54021, val_loss=2.06308, val_acc=0.41788, time=1.24801
Epoch:0009, train_loss=1.88434, train_acc=0.53859, val_loss=2.06230, val_acc=0.42701, time=1.14100
Epoch:0010, train_loss=1.86413, train_acc=0.56674, val_loss=2.06163, val_acc=0.46715, time=1.00901
Epoch:0011, train_loss=1.84380, train_acc=0.58396, val_loss=2.06161, val_acc=0.47810, time=1.18801
Epoch:0012, train_loss=1.82923, train_acc=0.59449, val_loss=2.06204, val_acc=0.47993, time=1.16102
Epoch:0013, train_loss=1.81900, train_acc=0.59409, val_loss=2.06240, val_acc=0.47810, time=1.25300
Epoch:0014, train_loss=1.80918, train_acc=0.59712, val_loss=2.06243, val_acc=0.46350, time=1.09300
Epoch:0015, train_loss=1.79747, train_acc=0.60867, val_loss=2.06215, val_acc=0.45255, time=1.09401
Epoch:0016, train_loss=1.78404, train_acc=0.62285, val_loss=2.06174, val_acc=0.45803, time=1.05901
Epoch:0017, train_loss=1.77029, train_acc=0.63460, val_loss=2.06138, val_acc=0.45073, time=1.14299
Epoch:0018, train_loss=1.75756, train_acc=0.64553, val_loss=2.06117, val_acc=0.44161, time=1.20900
Epoch:0019, train_loss=1.74648, train_acc=0.65262, val_loss=2.06114, val_acc=0.44526, time=1.50138
Epoch:0020, train_loss=1.73713, train_acc=0.65870, val_loss=2.06129, val_acc=0.45073, time=1.00902
Epoch:0021, train_loss=1.72948, train_acc=0.66336, val_loss=2.06160, val_acc=0.45255, time=1.09700
Epoch:0022, train_loss=1.72346, train_acc=0.66619, val_loss=2.06205, val_acc=0.45620, time=1.08802
Early stopping...

Optimization Finished!

Test set results: loss= 2.01651, accuracy= 0.44861, time= 0.41301

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.0588    0.0115    0.0192        87
           1     0.4961    0.7645    0.6017      1083
           2     0.3319    0.2184    0.2634       696
           3     0.0000    0.0000    0.0000        10
           4     0.0000    0.0000    0.0000        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.0625    0.0123    0.0206        81

    accuracy                         0.4486      2189
   macro avg     0.1187    0.1258    0.1131      2189
weighted avg     0.3556    0.4486    0.3830      2189


Macro average Test Precision, Recall and F1-Score...
(0.11866333887951165, 0.12584670909646234, 0.11312813180491464, None)

Micro average Test Precision, Recall and F1-Score...
(0.44860666971219737, 0.44860666971219737, 0.4486066697121973, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
