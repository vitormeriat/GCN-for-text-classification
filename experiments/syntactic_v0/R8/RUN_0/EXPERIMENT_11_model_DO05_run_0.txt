
==========: 150800304744100
Epoch:0001, train_loss=2.39492, train_acc=0.10796, val_loss=2.08021, val_acc=0.29562, time=1.43500
Epoch:0002, train_loss=2.11117, train_acc=0.28499, val_loss=2.06302, val_acc=0.41423, time=1.28900
Epoch:0003, train_loss=1.93297, train_acc=0.41280, val_loss=2.06139, val_acc=0.47628, time=1.13700
Epoch:0004, train_loss=1.89628, train_acc=0.50982, val_loss=2.06652, val_acc=0.49088, time=1.02900
Epoch:0005, train_loss=1.92986, train_acc=0.52299, val_loss=2.06779, val_acc=0.49088, time=1.07300
Epoch:0006, train_loss=1.93505, train_acc=0.52785, val_loss=2.06539, val_acc=0.49088, time=1.15802
Epoch:0007, train_loss=1.90952, train_acc=0.53372, val_loss=2.06213, val_acc=0.48540, time=1.25400
Epoch:0008, train_loss=1.87644, train_acc=0.54588, val_loss=2.06051, val_acc=0.46350, time=1.10600
Epoch:0009, train_loss=1.85648, train_acc=0.53190, val_loss=2.06075, val_acc=0.40693, time=1.12602
Epoch:0010, train_loss=1.85109, train_acc=0.50273, val_loss=2.06130, val_acc=0.39964, time=1.25100
Epoch:0011, train_loss=1.84615, train_acc=0.49058, val_loss=2.06120, val_acc=0.40146, time=1.15401
Epoch:0012, train_loss=1.83329, train_acc=0.51003, val_loss=2.06063, val_acc=0.42336, time=1.05898
Epoch:0013, train_loss=1.81471, train_acc=0.55763, val_loss=2.06016, val_acc=0.44526, time=1.15101
Epoch:0014, train_loss=1.79637, train_acc=0.60219, val_loss=2.06017, val_acc=0.45438, time=1.01502
Epoch:0015, train_loss=1.78242, train_acc=0.60543, val_loss=2.06064, val_acc=0.46350, time=1.17501
Epoch:0016, train_loss=1.77328, train_acc=0.60381, val_loss=2.06126, val_acc=0.47263, time=1.04601
Epoch:0017, train_loss=1.76684, train_acc=0.60340, val_loss=2.06177, val_acc=0.46715, time=1.08599
Early stopping...

Optimization Finished!

Test set results: loss= 2.01186, accuracy= 0.45637, time= 0.32401

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.1500    0.0345    0.0561        87
           1     0.4919    0.8735    0.6294      1083
           2     0.2500    0.0704    0.1099       696
           3     0.0000    0.0000    0.0000        10
           4     0.0000    0.0000    0.0000        75
           5     0.0000    0.0000    0.0000       121
           6     0.0000    0.0000    0.0000        36
           7     0.2000    0.0123    0.0233        81

    accuracy                         0.4564      2189
   macro avg     0.1365    0.1238    0.1023      2189
weighted avg     0.3362    0.4564    0.3494      2189


Macro average Test Precision, Recall and F1-Score...
(0.13649245969838794, 0.1238412843503866, 0.10232548776567296, None)

Micro average Test Precision, Recall and F1-Score...
(0.4563727729556875, 0.4563727729556875, 0.4563727729556875, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
