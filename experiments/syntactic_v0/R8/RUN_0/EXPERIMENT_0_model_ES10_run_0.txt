
==========: 147996120387400
Epoch:0001, train_loss=2.41395, train_acc=0.03342, val_loss=2.08139, val_acc=0.26460, time=1.12601
Epoch:0002, train_loss=2.08464, train_acc=0.27304, val_loss=2.06266, val_acc=0.44708, time=1.28499
Epoch:0003, train_loss=1.91213, train_acc=0.47721, val_loss=2.05956, val_acc=0.47628, time=1.31401
Epoch:0004, train_loss=1.88157, train_acc=0.51225, val_loss=2.06075, val_acc=0.48540, time=1.24701
Epoch:0005, train_loss=1.89031, train_acc=0.52502, val_loss=2.06197, val_acc=0.47810, time=1.26500
Epoch:0006, train_loss=1.89800, train_acc=0.54021, val_loss=2.06320, val_acc=0.48540, time=1.06500
Epoch:0007, train_loss=1.90254, train_acc=0.54385, val_loss=2.06377, val_acc=0.46350, time=1.18200
Epoch:0008, train_loss=1.89709, train_acc=0.55520, val_loss=2.06341, val_acc=0.47993, time=1.06201
Epoch:0009, train_loss=1.88047, train_acc=0.57180, val_loss=2.06267, val_acc=0.48175, time=1.12901
Epoch:0010, train_loss=1.85887, train_acc=0.58153, val_loss=2.06189, val_acc=0.48175, time=1.04001
Epoch:0011, train_loss=1.83642, train_acc=0.58841, val_loss=2.06113, val_acc=0.48723, time=1.11700
Epoch:0012, train_loss=1.81424, train_acc=0.59307, val_loss=2.06047, val_acc=0.47993, time=1.07200
Epoch:0013, train_loss=1.79369, train_acc=0.60016, val_loss=2.06016, val_acc=0.47993, time=1.02400
Epoch:0014, train_loss=1.77724, train_acc=0.61049, val_loss=2.06037, val_acc=0.47810, time=1.07901
Epoch:0015, train_loss=1.76644, train_acc=0.62427, val_loss=2.06100, val_acc=0.47445, time=1.12400
Epoch:0016, train_loss=1.76025, train_acc=0.63662, val_loss=2.06176, val_acc=0.45803, time=1.13800
Epoch:0017, train_loss=1.75610, train_acc=0.64796, val_loss=2.06247, val_acc=0.45803, time=1.14602
Early stopping...

Optimization Finished!

Test set results: loss= 2.01441, accuracy= 0.44815, time= 0.33301

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.0857    0.0345    0.0492        87
           1     0.5042    0.7812    0.6128      1083
           2     0.3457    0.1868    0.2425       696
           3     0.0000    0.0000    0.0000        10
           4     0.0000    0.0000    0.0000        75
           5     0.0286    0.0083    0.0128       121
           6     0.0000    0.0000    0.0000        36
           7     0.0278    0.0123    0.0171        81

    accuracy                         0.4481      2189
   macro avg     0.1240    0.1279    0.1168      2189
weighted avg     0.3654    0.4481    0.3836      2189


Macro average Test Precision, Recall and F1-Score...
(0.12399747572635764, 0.12787974306767524, 0.11680670159036483, None)

Micro average Test Precision, Recall and F1-Score...
(0.4481498401096391, 0.4481498401096391, 0.4481498401096391, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
