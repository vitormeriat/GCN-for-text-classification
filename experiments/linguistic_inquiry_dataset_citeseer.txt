
==================== Torch Seed: 48120870692300
Epoch:0001, train_loss=1.89424, train_acc=0.13745, val_loss=1.78937, val_acc=0.23377, time=0.15500
Epoch:0002, train_loss=1.77144, train_acc=0.29406, val_loss=1.78495, val_acc=0.32035, time=0.14899
Epoch:0003, train_loss=1.71472, train_acc=0.38314, val_loss=1.78009, val_acc=0.45455, time=0.16200
Epoch:0004, train_loss=1.65727, train_acc=0.52921, val_loss=1.77528, val_acc=0.57143, time=0.12500
Epoch:0005, train_loss=1.60335, train_acc=0.66379, val_loss=1.77179, val_acc=0.60173, time=0.11299
Epoch:0006, train_loss=1.56143, train_acc=0.73228, val_loss=1.76909, val_acc=0.61905, time=0.14900
Epoch:0007, train_loss=1.52502, train_acc=0.76006, val_loss=1.76682, val_acc=0.64935, time=0.15899
Epoch:0008, train_loss=1.49148, train_acc=0.78784, val_loss=1.76517, val_acc=0.65368, time=0.15700
Epoch:0009, train_loss=1.46372, train_acc=0.81657, val_loss=1.76433, val_acc=0.64935, time=0.14900
Epoch:0010, train_loss=1.44423, train_acc=0.83573, val_loss=1.76401, val_acc=0.64935, time=0.14400
Epoch:0011, train_loss=1.43073, train_acc=0.85345, val_loss=1.76360, val_acc=0.64935, time=0.16001
Epoch:0012, train_loss=1.41799, train_acc=0.86063, val_loss=1.76284, val_acc=0.65801, time=0.11898
Epoch:0013, train_loss=1.40377, train_acc=0.87069, val_loss=1.76201, val_acc=0.68831, time=0.16699
Epoch:0014, train_loss=1.38991, train_acc=0.87883, val_loss=1.76146, val_acc=0.69697, time=0.12000
Epoch:0015, train_loss=1.37858, train_acc=0.88554, val_loss=1.76126, val_acc=0.69697, time=0.14399
Epoch:0016, train_loss=1.36984, train_acc=0.88506, val_loss=1.76124, val_acc=0.70130, time=0.15900
Epoch:0017, train_loss=1.36232, train_acc=0.88506, val_loss=1.76127, val_acc=0.70130, time=0.12000
Epoch:0018, train_loss=1.35483, train_acc=0.89224, val_loss=1.76130, val_acc=0.70130, time=0.15800
Epoch:0019, train_loss=1.34719, train_acc=0.90182, val_loss=1.76137, val_acc=0.70563, time=0.13100
Epoch:0020, train_loss=1.33985, train_acc=0.91188, val_loss=1.76150, val_acc=0.69264, time=0.15399
Epoch:0021, train_loss=1.33319, train_acc=0.92193, val_loss=1.76169, val_acc=0.68831, time=0.16000
Epoch:0022, train_loss=1.32723, train_acc=0.92864, val_loss=1.76189, val_acc=0.69264, time=0.14800
Early stopping...

Optimization Finished!

Test set results: loss= 1.66198, accuracy= 0.71601, time= 0.05100

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7391    0.7861    0.7619       173
           1     0.5091    0.4058    0.4516        69
           2     0.7158    0.6931    0.7043       189
           3     0.7606    0.7788    0.7696       208
           4     0.6516    0.7059    0.6776       204
           5     0.8029    0.7333    0.7666       150

    accuracy                         0.7160       993
   macro avg     0.6965    0.6839    0.6886       993
weighted avg     0.7149    0.7160    0.7144       993


Macro average Test Precision, Recall and F1-Score...
(0.6965225228545272, 0.6838513003869483, 0.6886020868993232, None)

Micro average Test Precision, Recall and F1-Score...
(0.716012084592145, 0.716012084592145, 0.716012084592145, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
