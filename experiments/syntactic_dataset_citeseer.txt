
==================== Torch Seed: 49165049188400
Epoch:0001, train_loss=1.98889, train_acc=0.12931, val_loss=1.79392, val_acc=0.25541, time=0.16801
Epoch:0002, train_loss=1.80050, train_acc=0.26197, val_loss=1.78773, val_acc=0.32900, time=0.17400
Epoch:0003, train_loss=1.73342, train_acc=0.37452, val_loss=1.78504, val_acc=0.39827, time=0.17501
Epoch:0004, train_loss=1.69572, train_acc=0.45929, val_loss=1.78217, val_acc=0.40693, time=0.18401
Epoch:0005, train_loss=1.65815, train_acc=0.51102, val_loss=1.77793, val_acc=0.47619, time=0.18900
Epoch:0006, train_loss=1.61100, train_acc=0.60776, val_loss=1.77390, val_acc=0.55411, time=0.18102
Epoch:0007, train_loss=1.56676, train_acc=0.70067, val_loss=1.77118, val_acc=0.62338, time=0.16199
Epoch:0008, train_loss=1.53396, train_acc=0.75048, val_loss=1.76964, val_acc=0.62338, time=0.18100
Epoch:0009, train_loss=1.51084, train_acc=0.76868, val_loss=1.76827, val_acc=0.62338, time=0.14799
Epoch:0010, train_loss=1.48952, train_acc=0.77682, val_loss=1.76656, val_acc=0.63203, time=0.15499
Epoch:0011, train_loss=1.46633, train_acc=0.79837, val_loss=1.76478, val_acc=0.65368, time=0.17200
Epoch:0012, train_loss=1.44399, train_acc=0.82423, val_loss=1.76349, val_acc=0.67965, time=0.14301
Epoch:0013, train_loss=1.42676, train_acc=0.84914, val_loss=1.76294, val_acc=0.68831, time=0.14701
Epoch:0014, train_loss=1.41611, train_acc=0.86015, val_loss=1.76292, val_acc=0.68398, time=0.17898
Epoch:0015, train_loss=1.40967, train_acc=0.86303, val_loss=1.76294, val_acc=0.67532, time=0.15300
Epoch:0016, train_loss=1.40332, train_acc=0.86494, val_loss=1.76267, val_acc=0.67532, time=0.12500
Epoch:0017, train_loss=1.39448, train_acc=0.87021, val_loss=1.76213, val_acc=0.68398, time=0.16500
Epoch:0018, train_loss=1.38354, train_acc=0.88602, val_loss=1.76160, val_acc=0.69264, time=0.18602
Epoch:0019, train_loss=1.37253, train_acc=0.89320, val_loss=1.76133, val_acc=0.69697, time=0.18402
Epoch:0020, train_loss=1.36328, train_acc=0.89799, val_loss=1.76138, val_acc=0.69697, time=0.12099
Epoch:0021, train_loss=1.35640, train_acc=0.90326, val_loss=1.76167, val_acc=0.69697, time=0.12601
Epoch:0022, train_loss=1.35135, train_acc=0.90661, val_loss=1.76202, val_acc=0.70130, time=0.11200
Epoch:0023, train_loss=1.34702, train_acc=0.90805, val_loss=1.76228, val_acc=0.70996, time=0.11200
Early stopping...

Optimization Finished!

Test set results: loss= 1.66366, accuracy= 0.70493, time= 0.04199

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7421    0.7885    0.7646       208
           1     0.7065    0.6373    0.6701       204
           2     0.7330    0.7457    0.7393       173
           3     0.6337    0.8148    0.7130       189
           4     0.7365    0.7267    0.7315       150
           5     0.6667    0.2029    0.3111        69

    accuracy                         0.7049       993
   macro avg     0.7031    0.6526    0.6549       993
weighted avg     0.7065    0.7049    0.6944       993


Macro average Test Precision, Recall and F1-Score...
(0.7030759569448355, 0.6526268687521392, 0.6549240949856775, None)

Micro average Test Precision, Recall and F1-Score...
(0.7049345417925479, 0.7049345417925479, 0.7049345417925479, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
