
==================== Torch Seed: 13666989231500
Epoch:0001, train_loss=1.98821, train_acc=0.18966, val_loss=1.79627, val_acc=0.23377, time=0.16801
Epoch:0002, train_loss=1.81246, train_acc=0.23611, val_loss=1.78549, val_acc=0.37662, time=0.15802
Epoch:0003, train_loss=1.73732, train_acc=0.35105, val_loss=1.78127, val_acc=0.39827, time=0.18800
Epoch:0004, train_loss=1.70000, train_acc=0.40038, val_loss=1.77768, val_acc=0.45887, time=0.17699
Epoch:0005, train_loss=1.65198, train_acc=0.46312, val_loss=1.77354, val_acc=0.56710, time=0.18001
Epoch:0006, train_loss=1.59391, train_acc=0.60536, val_loss=1.77124, val_acc=0.62338, time=0.18500
Epoch:0007, train_loss=1.55357, train_acc=0.71073, val_loss=1.77045, val_acc=0.62338, time=0.17599
Epoch:0008, train_loss=1.53026, train_acc=0.73563, val_loss=1.76939, val_acc=0.59740, time=0.14501
Epoch:0009, train_loss=1.50970, train_acc=0.74665, val_loss=1.76743, val_acc=0.63636, time=0.14103
Epoch:0010, train_loss=1.48607, train_acc=0.77107, val_loss=1.76504, val_acc=0.67100, time=0.15999
Epoch:0011, train_loss=1.46194, train_acc=0.79167, val_loss=1.76292, val_acc=0.71429, time=0.15501
Epoch:0012, train_loss=1.44137, train_acc=0.81370, val_loss=1.76147, val_acc=0.70563, time=0.14500
Epoch:0013, train_loss=1.42646, train_acc=0.83812, val_loss=1.76074, val_acc=0.70563, time=0.16302
Epoch:0014, train_loss=1.41651, train_acc=0.85632, val_loss=1.76042, val_acc=0.70996, time=0.18201
Epoch:0015, train_loss=1.40875, train_acc=0.86111, val_loss=1.76018, val_acc=0.73160, time=0.15200
Epoch:0016, train_loss=1.40040, train_acc=0.86830, val_loss=1.75987, val_acc=0.74026, time=0.15799
Epoch:0017, train_loss=1.39050, train_acc=0.87308, val_loss=1.75956, val_acc=0.72727, time=0.17500
Epoch:0018, train_loss=1.37996, train_acc=0.88123, val_loss=1.75937, val_acc=0.72727, time=0.17701
Epoch:0019, train_loss=1.37023, train_acc=0.89176, val_loss=1.75940, val_acc=0.72294, time=0.14900
Epoch:0020, train_loss=1.36227, train_acc=0.89368, val_loss=1.75962, val_acc=0.71429, time=0.14501
Epoch:0021, train_loss=1.35610, train_acc=0.89511, val_loss=1.75993, val_acc=0.70563, time=0.16700
Epoch:0022, train_loss=1.35108, train_acc=0.89703, val_loss=1.76022, val_acc=0.69697, time=0.17500
Early stopping...

Optimization Finished!

Test set results: loss= 1.66177, accuracy= 0.71098, time= 0.05600

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.6854    0.7725    0.7264       189
           1     0.7643    0.7133    0.7379       150
           2     0.5357    0.2174    0.3093        69
           3     0.7105    0.7803    0.7438       173
           4     0.6594    0.7402    0.6975       204
           5     0.7876    0.7308    0.7581       208

    accuracy                         0.7110       993
   macro avg     0.6905    0.6591    0.6622       993
weighted avg     0.7074    0.7110    0.7029       993


Macro average Test Precision, Recall and F1-Score...
(0.6904876230511222, 0.6590872566962974, 0.6621572532574983, None)

Micro average Test Precision, Recall and F1-Score...
(0.7109768378650554, 0.7109768378650554, 0.7109768378650553, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
