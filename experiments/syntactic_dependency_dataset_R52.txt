
==================== Torch Seed: 56876203775500
Epoch:0001, train_loss=3.99966, train_acc=0.03691, val_loss=3.92469, val_acc=0.39051, time=0.76100
Epoch:0002, train_loss=3.68215, train_acc=0.39854, val_loss=3.89731, val_acc=0.47779, time=0.71899
Epoch:0003, train_loss=3.43548, train_acc=0.50383, val_loss=3.87967, val_acc=0.54824, time=0.81499
Epoch:0004, train_loss=3.27472, train_acc=0.57782, val_loss=3.86989, val_acc=0.61256, time=0.93799
Epoch:0005, train_loss=3.18318, train_acc=0.63480, val_loss=3.86438, val_acc=0.64625, time=0.85400
Epoch:0006, train_loss=3.12996, train_acc=0.66083, val_loss=3.86014, val_acc=0.66156, time=0.74600
Epoch:0007, train_loss=3.08772, train_acc=0.68328, val_loss=3.85595, val_acc=0.69678, time=0.80199
Epoch:0008, train_loss=3.04527, train_acc=0.71101, val_loss=3.85187, val_acc=0.71822, time=0.76899
Epoch:0009, train_loss=3.00377, train_acc=0.74519, val_loss=3.84830, val_acc=0.76417, time=0.79700
Epoch:0010, train_loss=2.96748, train_acc=0.78551, val_loss=3.84545, val_acc=0.78101, time=1.07798
Epoch:0011, train_loss=2.93788, train_acc=0.81493, val_loss=3.84313, val_acc=0.80092, time=0.73200
Epoch:0012, train_loss=2.91325, train_acc=0.83450, val_loss=3.84110, val_acc=0.81776, time=0.81599
Epoch:0013, train_loss=2.89153, train_acc=0.85287, val_loss=3.83922, val_acc=0.82542, time=0.80699
Epoch:0014, train_loss=2.87175, train_acc=0.86766, val_loss=3.83745, val_acc=0.83461, time=0.85900
Epoch:0015, train_loss=2.85387, train_acc=0.88672, val_loss=3.83584, val_acc=0.84074, time=0.78697
Epoch:0016, train_loss=2.83818, train_acc=0.90151, val_loss=3.83442, val_acc=0.84992, time=0.76599
Epoch:0017, train_loss=2.82481, train_acc=0.91444, val_loss=3.83318, val_acc=0.85299, time=0.67600
Epoch:0018, train_loss=2.81354, train_acc=0.91903, val_loss=3.83208, val_acc=0.85911, time=0.85600
Epoch:0019, train_loss=2.80384, train_acc=0.92261, val_loss=3.83107, val_acc=0.86524, time=0.92799
Epoch:0020, train_loss=2.79513, train_acc=0.92771, val_loss=3.83011, val_acc=0.86983, time=0.76798
Epoch:0021, train_loss=2.78694, train_acc=0.93162, val_loss=3.82919, val_acc=0.86983, time=0.80200
Epoch:0022, train_loss=2.77904, train_acc=0.93638, val_loss=3.82829, val_acc=0.88055, time=0.72500
Epoch:0023, train_loss=2.77137, train_acc=0.94047, val_loss=3.82744, val_acc=0.88208, time=0.70998
Epoch:0024, train_loss=2.76406, train_acc=0.94489, val_loss=3.82665, val_acc=0.88055, time=0.82800
Epoch:0025, train_loss=2.75725, train_acc=0.94880, val_loss=3.82594, val_acc=0.88055, time=0.72898
Epoch:0026, train_loss=2.75105, train_acc=0.95152, val_loss=3.82532, val_acc=0.88821, time=0.77700
Epoch:0027, train_loss=2.74548, train_acc=0.95629, val_loss=3.82477, val_acc=0.89587, time=0.79998
Epoch:0028, train_loss=2.74048, train_acc=0.96071, val_loss=3.82428, val_acc=0.89280, time=0.93499
Epoch:0029, train_loss=2.73592, train_acc=0.96275, val_loss=3.82383, val_acc=0.89740, time=0.86600
Epoch:0030, train_loss=2.73168, train_acc=0.96479, val_loss=3.82341, val_acc=0.89893, time=0.91899
Epoch:0031, train_loss=2.72767, train_acc=0.96734, val_loss=3.82300, val_acc=0.90199, time=0.91698
Epoch:0032, train_loss=2.72386, train_acc=0.96904, val_loss=3.82262, val_acc=0.90199, time=0.82100
Epoch:0033, train_loss=2.72025, train_acc=0.97176, val_loss=3.82224, val_acc=0.90199, time=0.88998
Epoch:0034, train_loss=2.71685, train_acc=0.97398, val_loss=3.82189, val_acc=0.90352, time=0.78802
Epoch:0035, train_loss=2.71368, train_acc=0.97636, val_loss=3.82157, val_acc=0.90505, time=0.76400
Epoch:0036, train_loss=2.71076, train_acc=0.97806, val_loss=3.82127, val_acc=0.90658, time=0.79600
Epoch:0037, train_loss=2.70808, train_acc=0.97908, val_loss=3.82100, val_acc=0.90965, time=0.90798
Epoch:0038, train_loss=2.70560, train_acc=0.98061, val_loss=3.82076, val_acc=0.90965, time=0.78800
Epoch:0039, train_loss=2.70331, train_acc=0.98095, val_loss=3.82054, val_acc=0.90965, time=0.74600
Epoch:0040, train_loss=2.70116, train_acc=0.98231, val_loss=3.82034, val_acc=0.91118, time=0.81199
Epoch:0041, train_loss=2.69913, train_acc=0.98282, val_loss=3.82016, val_acc=0.91271, time=0.75600
Epoch:0042, train_loss=2.69721, train_acc=0.98384, val_loss=3.82001, val_acc=0.91271, time=0.79399
Epoch:0043, train_loss=2.69540, train_acc=0.98469, val_loss=3.81987, val_acc=0.91271, time=0.83098
Epoch:0044, train_loss=2.69369, train_acc=0.98537, val_loss=3.81976, val_acc=0.91271, time=0.76398
Epoch:0045, train_loss=2.69208, train_acc=0.98605, val_loss=3.81966, val_acc=0.91271, time=0.73801
Epoch:0046, train_loss=2.69059, train_acc=0.98724, val_loss=3.81958, val_acc=0.91118, time=0.83100
Epoch:0047, train_loss=2.68919, train_acc=0.98809, val_loss=3.81950, val_acc=0.91118, time=0.81899
Epoch:0048, train_loss=2.68788, train_acc=0.98843, val_loss=3.81943, val_acc=0.91118, time=0.89299
Epoch:0049, train_loss=2.68665, train_acc=0.98877, val_loss=3.81936, val_acc=0.91271, time=0.85899
Epoch:0050, train_loss=2.68549, train_acc=0.98911, val_loss=3.81929, val_acc=0.91118, time=0.84802
Epoch:0051, train_loss=2.68439, train_acc=0.98928, val_loss=3.81921, val_acc=0.91118, time=0.85798
Epoch:0052, train_loss=2.68334, train_acc=0.99030, val_loss=3.81913, val_acc=0.91118, time=0.81599
Epoch:0053, train_loss=2.68235, train_acc=0.99098, val_loss=3.81905, val_acc=0.91118, time=0.73800
Epoch:0054, train_loss=2.68142, train_acc=0.99098, val_loss=3.81897, val_acc=0.91118, time=0.75798
Epoch:0055, train_loss=2.68055, train_acc=0.99115, val_loss=3.81888, val_acc=0.91424, time=0.74500
Epoch:0056, train_loss=2.67973, train_acc=0.99133, val_loss=3.81881, val_acc=0.91730, time=0.71099
Epoch:0057, train_loss=2.67897, train_acc=0.99184, val_loss=3.81873, val_acc=0.92037, time=0.90497
Epoch:0058, train_loss=2.67825, train_acc=0.99252, val_loss=3.81866, val_acc=0.92037, time=0.71301
Epoch:0059, train_loss=2.67758, train_acc=0.99269, val_loss=3.81860, val_acc=0.92037, time=0.80999
Epoch:0060, train_loss=2.67694, train_acc=0.99286, val_loss=3.81854, val_acc=0.92190, time=0.75498
Epoch:0061, train_loss=2.67634, train_acc=0.99303, val_loss=3.81848, val_acc=0.92190, time=0.74301
Epoch:0062, train_loss=2.67578, train_acc=0.99354, val_loss=3.81843, val_acc=0.92190, time=0.78598
Epoch:0063, train_loss=2.67525, train_acc=0.99354, val_loss=3.81838, val_acc=0.92190, time=0.76300
Epoch:0064, train_loss=2.67475, train_acc=0.99405, val_loss=3.81833, val_acc=0.92190, time=0.71699
Epoch:0065, train_loss=2.67428, train_acc=0.99439, val_loss=3.81829, val_acc=0.92190, time=0.72000
Epoch:0066, train_loss=2.67383, train_acc=0.99473, val_loss=3.81824, val_acc=0.92190, time=0.72999
Epoch:0067, train_loss=2.67341, train_acc=0.99490, val_loss=3.81819, val_acc=0.92343, time=0.80300
Epoch:0068, train_loss=2.67301, train_acc=0.99524, val_loss=3.81814, val_acc=0.92343, time=0.91300
Epoch:0069, train_loss=2.67262, train_acc=0.99541, val_loss=3.81809, val_acc=0.92190, time=0.84098
Epoch:0070, train_loss=2.67225, train_acc=0.99575, val_loss=3.81804, val_acc=0.92343, time=0.77191
Epoch:0071, train_loss=2.67190, train_acc=0.99575, val_loss=3.81799, val_acc=0.92496, time=0.69700
Epoch:0072, train_loss=2.67156, train_acc=0.99592, val_loss=3.81793, val_acc=0.92496, time=0.78400
Epoch:0073, train_loss=2.67124, train_acc=0.99592, val_loss=3.81788, val_acc=0.92649, time=0.74801
Epoch:0074, train_loss=2.67093, train_acc=0.99592, val_loss=3.81784, val_acc=0.92802, time=0.79898
Epoch:0075, train_loss=2.67064, train_acc=0.99592, val_loss=3.81779, val_acc=0.92802, time=0.71900
Epoch:0076, train_loss=2.67037, train_acc=0.99592, val_loss=3.81775, val_acc=0.92802, time=0.84600
Epoch:0077, train_loss=2.67011, train_acc=0.99609, val_loss=3.81772, val_acc=0.92802, time=0.73999
Epoch:0078, train_loss=2.66986, train_acc=0.99643, val_loss=3.81769, val_acc=0.92802, time=0.70699
Epoch:0079, train_loss=2.66962, train_acc=0.99677, val_loss=3.81766, val_acc=0.92802, time=0.79100
Epoch:0080, train_loss=2.66940, train_acc=0.99694, val_loss=3.81764, val_acc=0.92649, time=0.75800
Epoch:0081, train_loss=2.66918, train_acc=0.99694, val_loss=3.81761, val_acc=0.92649, time=0.85199
Epoch:0082, train_loss=2.66898, train_acc=0.99711, val_loss=3.81760, val_acc=0.92649, time=0.76698
Epoch:0083, train_loss=2.66879, train_acc=0.99711, val_loss=3.81758, val_acc=0.92649, time=0.78699
Epoch:0084, train_loss=2.66860, train_acc=0.99762, val_loss=3.81756, val_acc=0.92649, time=0.80800
Epoch:0085, train_loss=2.66842, train_acc=0.99762, val_loss=3.81755, val_acc=0.92649, time=0.80299
Epoch:0086, train_loss=2.66825, train_acc=0.99762, val_loss=3.81753, val_acc=0.92649, time=0.82299
Epoch:0087, train_loss=2.66809, train_acc=0.99762, val_loss=3.81752, val_acc=0.92649, time=0.80200
Epoch:0088, train_loss=2.66793, train_acc=0.99762, val_loss=3.81750, val_acc=0.92649, time=0.74600
Epoch:0089, train_loss=2.66778, train_acc=0.99762, val_loss=3.81749, val_acc=0.92649, time=0.73199
Epoch:0090, train_loss=2.66763, train_acc=0.99762, val_loss=3.81748, val_acc=0.92649, time=0.81199
Epoch:0091, train_loss=2.66749, train_acc=0.99762, val_loss=3.81746, val_acc=0.92649, time=0.88998
Epoch:0092, train_loss=2.66735, train_acc=0.99762, val_loss=3.81745, val_acc=0.92649, time=0.72101
Epoch:0093, train_loss=2.66722, train_acc=0.99779, val_loss=3.81744, val_acc=0.92649, time=0.70498
Epoch:0094, train_loss=2.66710, train_acc=0.99779, val_loss=3.81743, val_acc=0.92802, time=0.72299
Epoch:0095, train_loss=2.66697, train_acc=0.99779, val_loss=3.81742, val_acc=0.92956, time=0.77199
Epoch:0096, train_loss=2.66686, train_acc=0.99779, val_loss=3.81741, val_acc=0.92956, time=0.73099
Epoch:0097, train_loss=2.66674, train_acc=0.99779, val_loss=3.81740, val_acc=0.92956, time=0.78399
Epoch:0098, train_loss=2.66663, train_acc=0.99779, val_loss=3.81739, val_acc=0.92956, time=0.78100
Epoch:0099, train_loss=2.66652, train_acc=0.99779, val_loss=3.81738, val_acc=0.92956, time=0.72300
Epoch:0100, train_loss=2.66642, train_acc=0.99779, val_loss=3.81737, val_acc=0.92956, time=0.76600
Epoch:0101, train_loss=2.66632, train_acc=0.99779, val_loss=3.81736, val_acc=0.92956, time=0.74998
Epoch:0102, train_loss=2.66622, train_acc=0.99796, val_loss=3.81735, val_acc=0.92956, time=0.91099
Epoch:0103, train_loss=2.66612, train_acc=0.99796, val_loss=3.81734, val_acc=0.92956, time=0.76298
Epoch:0104, train_loss=2.66603, train_acc=0.99796, val_loss=3.81733, val_acc=0.93109, time=0.72200
Epoch:0105, train_loss=2.66594, train_acc=0.99796, val_loss=3.81732, val_acc=0.93109, time=0.73099
Epoch:0106, train_loss=2.66586, train_acc=0.99796, val_loss=3.81731, val_acc=0.93109, time=0.76800
Epoch:0107, train_loss=2.66577, train_acc=0.99796, val_loss=3.81730, val_acc=0.92956, time=0.71798
Epoch:0108, train_loss=2.66569, train_acc=0.99796, val_loss=3.81730, val_acc=0.92956, time=0.86100
Epoch:0109, train_loss=2.66561, train_acc=0.99796, val_loss=3.81729, val_acc=0.92956, time=0.82699
Epoch:0110, train_loss=2.66553, train_acc=0.99813, val_loss=3.81728, val_acc=0.92956, time=0.82798
Epoch:0111, train_loss=2.66545, train_acc=0.99830, val_loss=3.81728, val_acc=0.92956, time=0.71501
Epoch:0112, train_loss=2.66538, train_acc=0.99830, val_loss=3.81727, val_acc=0.92956, time=0.75799
Epoch:0113, train_loss=2.66531, train_acc=0.99830, val_loss=3.81727, val_acc=0.92956, time=0.69799
Epoch:0114, train_loss=2.66524, train_acc=0.99830, val_loss=3.81726, val_acc=0.92956, time=0.72699
Epoch:0115, train_loss=2.66517, train_acc=0.99830, val_loss=3.81726, val_acc=0.92956, time=0.69397
Epoch:0116, train_loss=2.66511, train_acc=0.99830, val_loss=3.81726, val_acc=0.92956, time=0.83400
Epoch:0117, train_loss=2.66504, train_acc=0.99830, val_loss=3.81725, val_acc=0.92956, time=0.88399
Epoch:0118, train_loss=2.66498, train_acc=0.99830, val_loss=3.81725, val_acc=0.92956, time=0.74198
Epoch:0119, train_loss=2.66492, train_acc=0.99847, val_loss=3.81724, val_acc=0.92956, time=0.72998
Epoch:0120, train_loss=2.66486, train_acc=0.99847, val_loss=3.81724, val_acc=0.92802, time=0.79400
Epoch:0121, train_loss=2.66480, train_acc=0.99847, val_loss=3.81724, val_acc=0.92802, time=0.80499
Epoch:0122, train_loss=2.66474, train_acc=0.99847, val_loss=3.81723, val_acc=0.92802, time=0.81298
Epoch:0123, train_loss=2.66468, train_acc=0.99847, val_loss=3.81723, val_acc=0.92802, time=0.81699
Epoch:0124, train_loss=2.66463, train_acc=0.99847, val_loss=3.81723, val_acc=0.92802, time=0.74000
Epoch:0125, train_loss=2.66458, train_acc=0.99864, val_loss=3.81722, val_acc=0.92802, time=0.74900
Epoch:0126, train_loss=2.66453, train_acc=0.99864, val_loss=3.81722, val_acc=0.92802, time=0.75800
Epoch:0127, train_loss=2.66447, train_acc=0.99864, val_loss=3.81722, val_acc=0.92802, time=0.80199
Epoch:0128, train_loss=2.66442, train_acc=0.99864, val_loss=3.81722, val_acc=0.92802, time=0.90099
Epoch:0129, train_loss=2.66438, train_acc=0.99864, val_loss=3.81721, val_acc=0.92802, time=0.85598
Epoch:0130, train_loss=2.66433, train_acc=0.99864, val_loss=3.81721, val_acc=0.92802, time=0.80098
Epoch:0131, train_loss=2.66428, train_acc=0.99864, val_loss=3.81721, val_acc=0.92802, time=0.73199
Epoch:0132, train_loss=2.66424, train_acc=0.99864, val_loss=3.81721, val_acc=0.92802, time=0.84698
Epoch:0133, train_loss=2.66419, train_acc=0.99864, val_loss=3.81721, val_acc=0.92802, time=0.79100
Epoch:0134, train_loss=2.66415, train_acc=0.99864, val_loss=3.81721, val_acc=0.92956, time=0.76899
Epoch:0135, train_loss=2.66411, train_acc=0.99864, val_loss=3.81720, val_acc=0.92802, time=0.79999
Epoch:0136, train_loss=2.66406, train_acc=0.99864, val_loss=3.81720, val_acc=0.92802, time=0.81001
Epoch:0137, train_loss=2.66402, train_acc=0.99864, val_loss=3.81720, val_acc=0.92802, time=0.84299
Epoch:0138, train_loss=2.66398, train_acc=0.99864, val_loss=3.81720, val_acc=0.92802, time=0.82299
Epoch:0139, train_loss=2.66394, train_acc=0.99864, val_loss=3.81720, val_acc=0.92802, time=0.77400
Epoch:0140, train_loss=2.66390, train_acc=0.99864, val_loss=3.81720, val_acc=0.92802, time=0.80999
Epoch:0141, train_loss=2.66387, train_acc=0.99864, val_loss=3.81719, val_acc=0.92802, time=0.74297
Epoch:0142, train_loss=2.66383, train_acc=0.99881, val_loss=3.81719, val_acc=0.92802, time=0.75200
Epoch:0143, train_loss=2.66379, train_acc=0.99881, val_loss=3.81719, val_acc=0.92802, time=0.82899
Epoch:0144, train_loss=2.66376, train_acc=0.99881, val_loss=3.81719, val_acc=0.92802, time=0.70099
Epoch:0145, train_loss=2.66372, train_acc=0.99881, val_loss=3.81719, val_acc=0.92802, time=0.84997
Epoch:0146, train_loss=2.66369, train_acc=0.99881, val_loss=3.81719, val_acc=0.92802, time=0.79800
Epoch:0147, train_loss=2.66365, train_acc=0.99881, val_loss=3.81719, val_acc=0.92802, time=0.80399
Epoch:0148, train_loss=2.66362, train_acc=0.99881, val_loss=3.81719, val_acc=0.92802, time=0.79400
Epoch:0149, train_loss=2.66359, train_acc=0.99881, val_loss=3.81719, val_acc=0.92802, time=0.78000
Epoch:0150, train_loss=2.66356, train_acc=0.99881, val_loss=3.81719, val_acc=0.92802, time=0.79199
Epoch:0151, train_loss=2.66352, train_acc=0.99881, val_loss=3.81718, val_acc=0.92802, time=0.87199
Epoch:0152, train_loss=2.66349, train_acc=0.99881, val_loss=3.81718, val_acc=0.92802, time=0.78599
Epoch:0153, train_loss=2.66346, train_acc=0.99881, val_loss=3.81718, val_acc=0.92802, time=0.81499
Epoch:0154, train_loss=2.66343, train_acc=0.99881, val_loss=3.81718, val_acc=0.92802, time=0.81101
Epoch:0155, train_loss=2.66340, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.69899
Epoch:0156, train_loss=2.66338, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.82099
Epoch:0157, train_loss=2.66335, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.74298
Epoch:0158, train_loss=2.66332, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.82400
Epoch:0159, train_loss=2.66329, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.80998
Epoch:0160, train_loss=2.66327, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.95300
Epoch:0161, train_loss=2.66324, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.80800
Epoch:0162, train_loss=2.66321, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.68101
Epoch:0163, train_loss=2.66319, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.76899
Epoch:0164, train_loss=2.66316, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.93299
Epoch:0165, train_loss=2.66314, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.83698
Epoch:0166, train_loss=2.66311, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.74100
Epoch:0167, train_loss=2.66309, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.81598
Epoch:0168, train_loss=2.66307, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.80299
Epoch:0169, train_loss=2.66304, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.75699
Epoch:0170, train_loss=2.66302, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.79399
Epoch:0171, train_loss=2.66300, train_acc=0.99881, val_loss=3.81718, val_acc=0.92956, time=0.76599
Early stopping...

Optimization Finished!

Test set results: loss= 3.43781, accuracy= 0.91978, time= 0.25799

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8582    0.9504    0.9020       121
           1     0.9503    0.9339    0.9420       696
           2     0.8125    0.9286    0.8667        28
           3     0.7979    0.8621    0.8287        87
           4     0.9596    0.9880    0.9736      1083
           5     0.7000    0.9333    0.8000        75
           6     0.8333    0.8333    0.8333        12
           7     0.8235    0.9333    0.8750        15
           8     0.8621    0.6944    0.7692        36
           9     0.7500    0.9231    0.8276        13
          10     1.0000    0.9167    0.9565        12
          11     0.8571    0.7500    0.8000         8
          12     0.9167    1.0000    0.9565        22
          13     1.0000    0.7778    0.8750         9
          14     0.8519    0.9200    0.8846        25
          15     1.0000    1.0000    1.0000        15
          16     1.0000    0.7647    0.8667        17
          17     0.8421    0.8000    0.8205        20
          18     1.0000    1.0000    1.0000         1
          19     0.8333    0.7407    0.7843        81
          20     1.0000    0.3333    0.5000        12
          21     1.0000    1.0000    1.0000         9
          22     1.0000    0.7778    0.8750         9
          23     1.0000    0.6000    0.7500         5
          24     0.0000    0.0000    0.0000         1
          25     0.0000    0.0000    0.0000         1
          26     0.6000    0.6000    0.6000         5
          27     1.0000    0.3333    0.5000         3
          28     0.5625    0.9000    0.6923        10
          29     0.8889    0.7273    0.8000        11
          30     1.0000    0.8182    0.9000        11
          31     0.9231    1.0000    0.9600        12
          32     0.9333    0.7368    0.8235        19
          33     1.0000    1.0000    1.0000         2
          34     0.7143    0.5556    0.6250         9
          35     0.7500    1.0000    0.8571         3
          36     1.0000    0.8000    0.8889        10
          37     0.5000    0.1667    0.2500         6
          38     1.0000    0.1667    0.2857         6
          39     1.0000    0.2500    0.4000         4
          40     1.0000    1.0000    1.0000         1
          41     0.0000    0.0000    0.0000         1
          42     1.0000    1.0000    1.0000         9
          43     1.0000    1.0000    1.0000         4
          44     1.0000    0.1429    0.2500         7
          45     0.0000    0.0000    0.0000         4
          46     0.7500    0.7500    0.7500         4
          47     1.0000    0.2000    0.3333         5
          48     0.0000    0.0000    0.0000         1
          49     1.0000    0.3333    0.5000         3
          50     1.0000    0.3333    0.5000         3
          51     0.0000    0.0000    0.0000         2

    accuracy                         0.9198      2568
   macro avg     0.7937    0.6572    0.6847      2568
weighted avg     0.9205    0.9198    0.9143      2568


Macro average Test Precision, Recall and F1-Score...
(0.7936659902166991, 0.6572216191999305, 0.6846772489865425, None)

Micro average Test Precision, Recall and F1-Score...
(0.9197819314641744, 0.9197819314641744, 0.9197819314641744, None)

Embeddings:
Word_embeddings:8892
Train_doc_embeddings:6532
Test_doc_embeddings:2568
