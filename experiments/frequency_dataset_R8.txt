
==================== Torch Seed: 1117627915300
Epoch:0001, train_loss=2.09851, train_acc=0.20539, val_loss=2.06160, val_acc=0.62774, time=0.68501
Epoch:0002, train_loss=1.92270, train_acc=0.63480, val_loss=2.04914, val_acc=0.74635, time=0.60498
Epoch:0003, train_loss=1.81020, train_acc=0.74762, val_loss=2.04185, val_acc=0.77007, time=0.48401
Epoch:0004, train_loss=1.74280, train_acc=0.77476, val_loss=2.03716, val_acc=0.77920, time=0.58100
Epoch:0005, train_loss=1.69870, train_acc=0.78469, val_loss=2.03345, val_acc=0.77920, time=0.57601
Epoch:0006, train_loss=1.66410, train_acc=0.79238, val_loss=2.03021, val_acc=0.79380, time=0.59400
Epoch:0007, train_loss=1.63436, train_acc=0.80190, val_loss=2.02733, val_acc=0.81022, time=0.59500
Epoch:0008, train_loss=1.60829, train_acc=0.81851, val_loss=2.02483, val_acc=0.83759, time=0.87204
Epoch:0009, train_loss=1.58561, train_acc=0.84241, val_loss=2.02275, val_acc=0.86679, time=0.74097
Epoch:0010, train_loss=1.56657, train_acc=0.87340, val_loss=2.02110, val_acc=0.88139, time=0.64300
Epoch:0011, train_loss=1.55109, train_acc=0.89467, val_loss=2.01980, val_acc=0.88869, time=0.68801
Epoch:0012, train_loss=1.53846, train_acc=0.90784, val_loss=2.01872, val_acc=0.89234, time=0.59901
Epoch:0013, train_loss=1.52765, train_acc=0.91776, val_loss=2.01779, val_acc=0.91241, time=0.56701
Epoch:0014, train_loss=1.51806, train_acc=0.92830, val_loss=2.01700, val_acc=0.91971, time=0.62701
Epoch:0015, train_loss=1.50956, train_acc=0.93660, val_loss=2.01635, val_acc=0.93248, time=0.73201
Epoch:0016, train_loss=1.50218, train_acc=0.94025, val_loss=2.01582, val_acc=0.93613, time=0.55000
Epoch:0017, train_loss=1.49580, train_acc=0.94389, val_loss=2.01534, val_acc=0.93431, time=0.62001
Epoch:0018, train_loss=1.49005, train_acc=0.94612, val_loss=2.01487, val_acc=0.93431, time=0.50001
Epoch:0019, train_loss=1.48457, train_acc=0.94794, val_loss=2.01438, val_acc=0.93613, time=0.55602
Epoch:0020, train_loss=1.47929, train_acc=0.95058, val_loss=2.01390, val_acc=0.93978, time=0.53301
Epoch:0021, train_loss=1.47436, train_acc=0.95422, val_loss=2.01344, val_acc=0.94343, time=0.61503
Epoch:0022, train_loss=1.46998, train_acc=0.95848, val_loss=2.01304, val_acc=0.94343, time=0.58700
Epoch:0023, train_loss=1.46625, train_acc=0.96070, val_loss=2.01268, val_acc=0.94708, time=0.54900
Epoch:0024, train_loss=1.46308, train_acc=0.96233, val_loss=2.01236, val_acc=0.94891, time=0.67202
Epoch:0025, train_loss=1.46033, train_acc=0.96374, val_loss=2.01207, val_acc=0.94526, time=0.62301
Epoch:0026, train_loss=1.45781, train_acc=0.96557, val_loss=2.01177, val_acc=0.94708, time=0.57700
Epoch:0027, train_loss=1.45540, train_acc=0.96638, val_loss=2.01149, val_acc=0.94708, time=0.62001
Epoch:0028, train_loss=1.45304, train_acc=0.96840, val_loss=2.01121, val_acc=0.94891, time=0.67401
Epoch:0029, train_loss=1.45074, train_acc=0.97104, val_loss=2.01094, val_acc=0.95620, time=0.55201
Epoch:0030, train_loss=1.44853, train_acc=0.97326, val_loss=2.01069, val_acc=0.95438, time=0.53002
Epoch:0031, train_loss=1.44649, train_acc=0.97407, val_loss=2.01048, val_acc=0.95620, time=0.63400
Epoch:0032, train_loss=1.44463, train_acc=0.97610, val_loss=2.01030, val_acc=0.95438, time=0.55500
Epoch:0033, train_loss=1.44298, train_acc=0.97772, val_loss=2.01015, val_acc=0.95438, time=0.52900
Epoch:0034, train_loss=1.44152, train_acc=0.97893, val_loss=2.01004, val_acc=0.95073, time=0.53200
Epoch:0035, train_loss=1.44024, train_acc=0.97954, val_loss=2.00995, val_acc=0.95255, time=0.71400
Epoch:0036, train_loss=1.43911, train_acc=0.98035, val_loss=2.00987, val_acc=0.95255, time=0.67201
Epoch:0037, train_loss=1.43809, train_acc=0.98116, val_loss=2.00982, val_acc=0.95073, time=0.50701
Epoch:0038, train_loss=1.43715, train_acc=0.98258, val_loss=2.00976, val_acc=0.95073, time=0.56002
Epoch:0039, train_loss=1.43626, train_acc=0.98278, val_loss=2.00971, val_acc=0.95255, time=0.54201
Epoch:0040, train_loss=1.43539, train_acc=0.98420, val_loss=2.00965, val_acc=0.95438, time=0.56600
Epoch:0041, train_loss=1.43452, train_acc=0.98542, val_loss=2.00959, val_acc=0.95438, time=0.49001
Epoch:0042, train_loss=1.43366, train_acc=0.98562, val_loss=2.00952, val_acc=0.95438, time=0.53999
Epoch:0043, train_loss=1.43281, train_acc=0.98582, val_loss=2.00946, val_acc=0.95803, time=0.51101
Epoch:0044, train_loss=1.43199, train_acc=0.98663, val_loss=2.00940, val_acc=0.95803, time=0.55701
Epoch:0045, train_loss=1.43122, train_acc=0.98704, val_loss=2.00935, val_acc=0.96168, time=0.54401
Epoch:0046, train_loss=1.43051, train_acc=0.98744, val_loss=2.00931, val_acc=0.96350, time=0.60302
Epoch:0047, train_loss=1.42985, train_acc=0.98764, val_loss=2.00928, val_acc=0.96350, time=0.52601
Epoch:0048, train_loss=1.42924, train_acc=0.98825, val_loss=2.00925, val_acc=0.96168, time=0.60401
Epoch:0049, train_loss=1.42867, train_acc=0.98866, val_loss=2.00922, val_acc=0.96350, time=0.62901
Epoch:0050, train_loss=1.42815, train_acc=0.98886, val_loss=2.00920, val_acc=0.96533, time=0.48601
Epoch:0051, train_loss=1.42766, train_acc=0.98866, val_loss=2.00918, val_acc=0.96533, time=0.46901
Epoch:0052, train_loss=1.42720, train_acc=0.98967, val_loss=2.00916, val_acc=0.96533, time=0.47101
Epoch:0053, train_loss=1.42675, train_acc=0.98987, val_loss=2.00914, val_acc=0.96533, time=0.62601
Epoch:0054, train_loss=1.42632, train_acc=0.98987, val_loss=2.00911, val_acc=0.96533, time=0.54700
Epoch:0055, train_loss=1.42590, train_acc=0.99068, val_loss=2.00909, val_acc=0.96350, time=0.62501
Epoch:0056, train_loss=1.42549, train_acc=0.99129, val_loss=2.00906, val_acc=0.96350, time=0.60900
Epoch:0057, train_loss=1.42509, train_acc=0.99190, val_loss=2.00903, val_acc=0.96350, time=0.56099
Epoch:0058, train_loss=1.42471, train_acc=0.99210, val_loss=2.00901, val_acc=0.96350, time=0.55100
Epoch:0059, train_loss=1.42434, train_acc=0.99230, val_loss=2.00898, val_acc=0.96350, time=0.58599
Epoch:0060, train_loss=1.42399, train_acc=0.99230, val_loss=2.00896, val_acc=0.96350, time=0.60300
Epoch:0061, train_loss=1.42364, train_acc=0.99291, val_loss=2.00894, val_acc=0.96350, time=0.67200
Epoch:0062, train_loss=1.42331, train_acc=0.99291, val_loss=2.00893, val_acc=0.96350, time=0.65700
Epoch:0063, train_loss=1.42299, train_acc=0.99352, val_loss=2.00891, val_acc=0.96715, time=0.63801
Epoch:0064, train_loss=1.42269, train_acc=0.99372, val_loss=2.00890, val_acc=0.96715, time=0.59502
Epoch:0065, train_loss=1.42240, train_acc=0.99392, val_loss=2.00889, val_acc=0.96715, time=0.68399
Epoch:0066, train_loss=1.42212, train_acc=0.99392, val_loss=2.00887, val_acc=0.96715, time=0.56101
Epoch:0067, train_loss=1.42185, train_acc=0.99392, val_loss=2.00886, val_acc=0.96715, time=0.68001
Epoch:0068, train_loss=1.42159, train_acc=0.99453, val_loss=2.00884, val_acc=0.96715, time=0.61800
Epoch:0069, train_loss=1.42134, train_acc=0.99494, val_loss=2.00883, val_acc=0.96715, time=0.60601
Epoch:0070, train_loss=1.42110, train_acc=0.99514, val_loss=2.00881, val_acc=0.96715, time=0.65800
Epoch:0071, train_loss=1.42087, train_acc=0.99534, val_loss=2.00880, val_acc=0.96715, time=0.68401
Epoch:0072, train_loss=1.42065, train_acc=0.99534, val_loss=2.00879, val_acc=0.96715, time=0.61401
Epoch:0073, train_loss=1.42043, train_acc=0.99534, val_loss=2.00877, val_acc=0.96898, time=0.56600
Epoch:0074, train_loss=1.42022, train_acc=0.99554, val_loss=2.00876, val_acc=0.96898, time=0.56003
Epoch:0075, train_loss=1.42002, train_acc=0.99554, val_loss=2.00876, val_acc=0.96898, time=0.63499
Epoch:0076, train_loss=1.41982, train_acc=0.99554, val_loss=2.00875, val_acc=0.96898, time=0.67301
Epoch:0077, train_loss=1.41962, train_acc=0.99575, val_loss=2.00874, val_acc=0.96898, time=0.47900
Epoch:0078, train_loss=1.41944, train_acc=0.99575, val_loss=2.00874, val_acc=0.97080, time=0.56601
Epoch:0079, train_loss=1.41926, train_acc=0.99595, val_loss=2.00873, val_acc=0.97080, time=0.57701
Epoch:0080, train_loss=1.41908, train_acc=0.99595, val_loss=2.00873, val_acc=0.97080, time=0.58801
Epoch:0081, train_loss=1.41892, train_acc=0.99615, val_loss=2.00872, val_acc=0.96898, time=0.67000
Epoch:0082, train_loss=1.41875, train_acc=0.99635, val_loss=2.00872, val_acc=0.96898, time=0.58400
Epoch:0083, train_loss=1.41860, train_acc=0.99635, val_loss=2.00871, val_acc=0.96898, time=0.53401
Epoch:0084, train_loss=1.41844, train_acc=0.99635, val_loss=2.00871, val_acc=0.96898, time=0.55200
Epoch:0085, train_loss=1.41830, train_acc=0.99676, val_loss=2.00871, val_acc=0.96898, time=0.45900
Epoch:0086, train_loss=1.41815, train_acc=0.99676, val_loss=2.00870, val_acc=0.96898, time=0.66301
Epoch:0087, train_loss=1.41801, train_acc=0.99696, val_loss=2.00870, val_acc=0.96898, time=0.95003
Epoch:0088, train_loss=1.41788, train_acc=0.99696, val_loss=2.00870, val_acc=0.96898, time=0.79298
Epoch:0089, train_loss=1.41775, train_acc=0.99716, val_loss=2.00869, val_acc=0.96898, time=0.62302
Epoch:0090, train_loss=1.41763, train_acc=0.99716, val_loss=2.00869, val_acc=0.96898, time=0.72101
Epoch:0091, train_loss=1.41750, train_acc=0.99716, val_loss=2.00869, val_acc=0.96898, time=0.55899
Epoch:0092, train_loss=1.41739, train_acc=0.99737, val_loss=2.00868, val_acc=0.96898, time=0.48200
Epoch:0093, train_loss=1.41727, train_acc=0.99777, val_loss=2.00868, val_acc=0.96898, time=0.58801
Epoch:0094, train_loss=1.41716, train_acc=0.99777, val_loss=2.00868, val_acc=0.96898, time=0.52201
Epoch:0095, train_loss=1.41705, train_acc=0.99777, val_loss=2.00867, val_acc=0.96898, time=0.54100
Epoch:0096, train_loss=1.41695, train_acc=0.99797, val_loss=2.00867, val_acc=0.96898, time=0.59002
Epoch:0097, train_loss=1.41685, train_acc=0.99818, val_loss=2.00867, val_acc=0.96898, time=0.58999
Epoch:0098, train_loss=1.41675, train_acc=0.99838, val_loss=2.00866, val_acc=0.96898, time=0.57303
Epoch:0099, train_loss=1.41665, train_acc=0.99838, val_loss=2.00866, val_acc=0.96898, time=0.61498
Epoch:0100, train_loss=1.41656, train_acc=0.99838, val_loss=2.00866, val_acc=0.96898, time=0.58400
Epoch:0101, train_loss=1.41647, train_acc=0.99858, val_loss=2.00865, val_acc=0.96898, time=0.64301
Epoch:0102, train_loss=1.41638, train_acc=0.99858, val_loss=2.00865, val_acc=0.96898, time=0.51899
Epoch:0103, train_loss=1.41630, train_acc=0.99858, val_loss=2.00865, val_acc=0.96898, time=0.53101
Epoch:0104, train_loss=1.41621, train_acc=0.99858, val_loss=2.00864, val_acc=0.96898, time=0.53499
Epoch:0105, train_loss=1.41613, train_acc=0.99858, val_loss=2.00864, val_acc=0.96898, time=0.61601
Epoch:0106, train_loss=1.41605, train_acc=0.99858, val_loss=2.00864, val_acc=0.96898, time=0.61702
Epoch:0107, train_loss=1.41598, train_acc=0.99858, val_loss=2.00864, val_acc=0.96898, time=0.64901
Epoch:0108, train_loss=1.41590, train_acc=0.99858, val_loss=2.00863, val_acc=0.96898, time=0.62699
Epoch:0109, train_loss=1.41583, train_acc=0.99858, val_loss=2.00863, val_acc=0.96898, time=0.61401
Epoch:0110, train_loss=1.41576, train_acc=0.99858, val_loss=2.00863, val_acc=0.96898, time=0.59101
Epoch:0111, train_loss=1.41570, train_acc=0.99858, val_loss=2.00863, val_acc=0.96898, time=0.61901
Epoch:0112, train_loss=1.41563, train_acc=0.99858, val_loss=2.00863, val_acc=0.96898, time=0.53500
Epoch:0113, train_loss=1.41556, train_acc=0.99878, val_loss=2.00863, val_acc=0.96898, time=0.53500
Epoch:0114, train_loss=1.41550, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.54203
Epoch:0115, train_loss=1.41544, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.54300
Epoch:0116, train_loss=1.41538, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.68900
Epoch:0117, train_loss=1.41532, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.59200
Epoch:0118, train_loss=1.41527, train_acc=0.99878, val_loss=2.00862, val_acc=0.97080, time=0.55301
Epoch:0119, train_loss=1.41521, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.66100
Epoch:0120, train_loss=1.41516, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.48601
Epoch:0121, train_loss=1.41511, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.49701
Epoch:0122, train_loss=1.41506, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.55401
Epoch:0123, train_loss=1.41501, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.62801
Epoch:0124, train_loss=1.41496, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.50702
Epoch:0125, train_loss=1.41491, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.56901
Epoch:0126, train_loss=1.41486, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.52201
Epoch:0127, train_loss=1.41482, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.58201
Epoch:0128, train_loss=1.41477, train_acc=0.99878, val_loss=2.00862, val_acc=0.96898, time=0.47101
Early stopping...

Optimization Finished!

Test set results: loss= 1.79892, accuracy= 0.96848, time= 0.16099

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9286    0.7222    0.8125        36
           1     0.9790    0.9917    0.9853      1083
           2     0.9839    0.9655    0.9746       696
           3     0.9067    0.8395    0.8718        81
           4     0.8511    0.9195    0.8840        87
           5     0.9512    0.9669    0.9590       121
           6     0.9250    0.9867    0.9548        75
           7     1.0000    0.9000    0.9474        10

    accuracy                         0.9685      2189
   macro avg     0.9407    0.9115    0.9237      2189
weighted avg     0.9687    0.9685    0.9682      2189


Macro average Test Precision, Recall and F1-Score...
(0.9406812185367222, 0.9115105540557018, 0.9236795858471956, None)

Micro average Test Precision, Recall and F1-Score...
(0.968478757423481, 0.968478757423481, 0.968478757423481, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
