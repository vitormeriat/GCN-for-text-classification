
==========: 15829672846409194725
Epoch:0001, train_loss=3.96895, train_acc=0.02109, val_loss=3.93225, val_acc=0.53599, time=1.96195
Epoch:0002, train_loss=3.77283, train_acc=0.52475, val_loss=3.91256, val_acc=0.62787, time=1.89690
Epoch:0003, train_loss=3.59653, train_acc=0.61694, val_loss=3.89593, val_acc=0.63859, time=1.93773
Epoch:0004, train_loss=3.44679, train_acc=0.63820, val_loss=3.88379, val_acc=0.64931, time=1.88303
Epoch:0005, train_loss=3.33701, train_acc=0.64943, val_loss=3.87601, val_acc=0.66462, time=1.98304
Epoch:0006, train_loss=3.26601, train_acc=0.65674, val_loss=3.87097, val_acc=0.67228, time=1.99188
Epoch:0007, train_loss=3.21930, train_acc=0.66372, val_loss=3.86705, val_acc=0.67841, time=2.16036
Epoch:0008, train_loss=3.18246, train_acc=0.66814, val_loss=3.86334, val_acc=0.69066, time=2.10631
Epoch:0009, train_loss=3.14784, train_acc=0.67699, val_loss=3.85971, val_acc=0.69832, time=2.02126
Epoch:0010, train_loss=3.11426, train_acc=0.69280, val_loss=3.85642, val_acc=0.72129, time=2.56327
Epoch:0011, train_loss=3.08384, train_acc=0.72767, val_loss=3.85369, val_acc=0.73813, time=2.20023
Epoch:0012, train_loss=3.05844, train_acc=0.74690, val_loss=3.85149, val_acc=0.75191, time=2.15814
Epoch:0013, train_loss=3.03759, train_acc=0.76305, val_loss=3.84961, val_acc=0.74885, time=1.94265
Epoch:0014, train_loss=3.01929, train_acc=0.77785, val_loss=3.84785, val_acc=0.75804, time=1.92274
Epoch:0015, train_loss=3.00217, train_acc=0.79912, val_loss=3.84613, val_acc=0.77335, time=2.04305
Epoch:0016, train_loss=2.98576, train_acc=0.81408, val_loss=3.84449, val_acc=0.79939, time=1.98046
Epoch:0017, train_loss=2.97021, train_acc=0.82684, val_loss=3.84295, val_acc=0.80858, time=1.94719
Epoch:0018, train_loss=2.95578, train_acc=0.84011, val_loss=3.84156, val_acc=0.81776, time=1.99978
Epoch:0019, train_loss=2.94249, train_acc=0.84810, val_loss=3.84028, val_acc=0.82083, time=1.93832
Epoch:0020, train_loss=2.93013, train_acc=0.85236, val_loss=3.83908, val_acc=0.82542, time=1.96702
Epoch:0021, train_loss=2.91849, train_acc=0.85576, val_loss=3.83796, val_acc=0.83155, time=1.95936
Epoch:0022, train_loss=2.90738, train_acc=0.86137, val_loss=3.83691, val_acc=0.83767, time=1.97070
Epoch:0023, train_loss=2.89675, train_acc=0.86852, val_loss=3.83592, val_acc=0.84227, time=1.96971
Epoch:0024, train_loss=2.88660, train_acc=0.87549, val_loss=3.83500, val_acc=0.84227, time=1.92051
Epoch:0025, train_loss=2.87696, train_acc=0.88127, val_loss=3.83416, val_acc=0.84380, time=1.98539
Epoch:0026, train_loss=2.86782, train_acc=0.88518, val_loss=3.83338, val_acc=0.84992, time=1.93893
Epoch:0027, train_loss=2.85917, train_acc=0.89114, val_loss=3.83267, val_acc=0.84839, time=1.96803
Epoch:0028, train_loss=2.85101, train_acc=0.89403, val_loss=3.83201, val_acc=0.85911, time=2.02554
Epoch:0029, train_loss=2.84332, train_acc=0.89845, val_loss=3.83140, val_acc=0.86217, time=1.95095
Epoch:0030, train_loss=2.83608, train_acc=0.90083, val_loss=3.83082, val_acc=0.86371, time=1.94563
Epoch:0031, train_loss=2.82923, train_acc=0.90458, val_loss=3.83025, val_acc=0.86983, time=1.97399
Epoch:0032, train_loss=2.82269, train_acc=0.91036, val_loss=3.82969, val_acc=0.87289, time=1.89947
Epoch:0033, train_loss=2.81636, train_acc=0.91342, val_loss=3.82911, val_acc=0.87289, time=1.94262
Epoch:0034, train_loss=2.81020, train_acc=0.91461, val_loss=3.82852, val_acc=0.87596, time=1.90119
Epoch:0035, train_loss=2.80417, train_acc=0.91835, val_loss=3.82794, val_acc=0.88055, time=1.95572
Epoch:0036, train_loss=2.79835, train_acc=0.92142, val_loss=3.82737, val_acc=0.88974, time=1.89500
Epoch:0037, train_loss=2.79278, train_acc=0.92652, val_loss=3.82683, val_acc=0.89280, time=1.90378
Epoch:0038, train_loss=2.78747, train_acc=0.92907, val_loss=3.82631, val_acc=0.89127, time=1.94771
Epoch:0039, train_loss=2.78240, train_acc=0.93213, val_loss=3.82582, val_acc=0.89587, time=1.91459
Epoch:0040, train_loss=2.77754, train_acc=0.93519, val_loss=3.82535, val_acc=0.89740, time=1.90367
Epoch:0041, train_loss=2.77290, train_acc=0.93689, val_loss=3.82492, val_acc=0.90046, time=1.95994
Epoch:0042, train_loss=2.76849, train_acc=0.93894, val_loss=3.82452, val_acc=0.90352, time=1.93110
Epoch:0043, train_loss=2.76431, train_acc=0.94115, val_loss=3.82415, val_acc=0.90658, time=1.96315
Epoch:0044, train_loss=2.76031, train_acc=0.94336, val_loss=3.82380, val_acc=0.90812, time=1.89926
Epoch:0045, train_loss=2.75645, train_acc=0.94540, val_loss=3.82347, val_acc=0.91118, time=1.90190
Epoch:0046, train_loss=2.75270, train_acc=0.94693, val_loss=3.82315, val_acc=0.91577, time=1.95928
Epoch:0047, train_loss=2.74907, train_acc=0.94948, val_loss=3.82286, val_acc=0.91884, time=1.90594
Epoch:0048, train_loss=2.74559, train_acc=0.95118, val_loss=3.82258, val_acc=0.92037, time=1.96394
Epoch:0049, train_loss=2.74229, train_acc=0.95373, val_loss=3.82232, val_acc=0.92343, time=1.90553
Epoch:0050, train_loss=2.73920, train_acc=0.95611, val_loss=3.82209, val_acc=0.92496, time=1.89998
Epoch:0051, train_loss=2.73631, train_acc=0.95748, val_loss=3.82187, val_acc=0.92496, time=1.95552
Epoch:0052, train_loss=2.73360, train_acc=0.96020, val_loss=3.82165, val_acc=0.92496, time=1.89387
Epoch:0053, train_loss=2.73104, train_acc=0.96224, val_loss=3.82145, val_acc=0.92956, time=1.93042
Epoch:0054, train_loss=2.72859, train_acc=0.96309, val_loss=3.82124, val_acc=0.93415, time=1.92396
Epoch:0055, train_loss=2.72623, train_acc=0.96462, val_loss=3.82105, val_acc=0.93721, time=1.90884
Epoch:0056, train_loss=2.72396, train_acc=0.96615, val_loss=3.82085, val_acc=0.93721, time=1.95732
Epoch:0057, train_loss=2.72178, train_acc=0.96700, val_loss=3.82067, val_acc=0.93721, time=1.90453
Epoch:0058, train_loss=2.71967, train_acc=0.96802, val_loss=3.82049, val_acc=0.93721, time=1.90766
Epoch:0059, train_loss=2.71765, train_acc=0.96887, val_loss=3.82032, val_acc=0.93721, time=1.94895
Epoch:0060, train_loss=2.71572, train_acc=0.96989, val_loss=3.82016, val_acc=0.93721, time=1.90174
Epoch:0061, train_loss=2.71389, train_acc=0.97057, val_loss=3.82001, val_acc=0.93721, time=1.96219
Epoch:0062, train_loss=2.71215, train_acc=0.97142, val_loss=3.81987, val_acc=0.93568, time=1.90084
Epoch:0063, train_loss=2.71050, train_acc=0.97244, val_loss=3.81973, val_acc=0.93721, time=1.92282
Epoch:0064, train_loss=2.70891, train_acc=0.97363, val_loss=3.81960, val_acc=0.93721, time=1.96555
Epoch:0065, train_loss=2.70739, train_acc=0.97517, val_loss=3.81946, val_acc=0.94181, time=1.90516
Epoch:0066, train_loss=2.70593, train_acc=0.97636, val_loss=3.81932, val_acc=0.94334, time=1.91368
Epoch:0067, train_loss=2.70452, train_acc=0.97738, val_loss=3.81919, val_acc=0.94334, time=1.92974
Epoch:0068, train_loss=2.70316, train_acc=0.97823, val_loss=3.81906, val_acc=0.94334, time=1.91279
Epoch:0069, train_loss=2.70186, train_acc=0.97959, val_loss=3.81893, val_acc=0.94334, time=1.95450
Epoch:0070, train_loss=2.70059, train_acc=0.98061, val_loss=3.81881, val_acc=0.94334, time=1.91529
Epoch:0071, train_loss=2.69937, train_acc=0.98095, val_loss=3.81870, val_acc=0.94487, time=1.90421
Epoch:0072, train_loss=2.69821, train_acc=0.98129, val_loss=3.81860, val_acc=0.94487, time=1.96651
Epoch:0073, train_loss=2.69709, train_acc=0.98163, val_loss=3.81851, val_acc=0.94487, time=1.91336
Epoch:0074, train_loss=2.69602, train_acc=0.98231, val_loss=3.81842, val_acc=0.94487, time=1.96485
Epoch:0075, train_loss=2.69500, train_acc=0.98299, val_loss=3.81835, val_acc=0.94487, time=1.89638
Epoch:0076, train_loss=2.69402, train_acc=0.98367, val_loss=3.81827, val_acc=0.94487, time=1.90558
Epoch:0077, train_loss=2.69307, train_acc=0.98418, val_loss=3.81820, val_acc=0.94640, time=2.06498
Epoch:0078, train_loss=2.69217, train_acc=0.98452, val_loss=3.81813, val_acc=0.94640, time=2.02181
Epoch:0079, train_loss=2.69129, train_acc=0.98469, val_loss=3.81806, val_acc=0.94640, time=1.98506
Epoch:0080, train_loss=2.69045, train_acc=0.98537, val_loss=3.81798, val_acc=0.94640, time=1.89801
Epoch:0081, train_loss=2.68963, train_acc=0.98588, val_loss=3.81791, val_acc=0.94793, time=2.29087
Epoch:0082, train_loss=2.68885, train_acc=0.98724, val_loss=3.81784, val_acc=0.94793, time=2.32890
Epoch:0083, train_loss=2.68808, train_acc=0.98758, val_loss=3.81778, val_acc=0.94793, time=2.26076
Epoch:0084, train_loss=2.68735, train_acc=0.98809, val_loss=3.81771, val_acc=0.94793, time=2.16556
Epoch:0085, train_loss=2.68664, train_acc=0.98843, val_loss=3.81765, val_acc=0.94793, time=2.10768
Epoch:0086, train_loss=2.68595, train_acc=0.98945, val_loss=3.81759, val_acc=0.94793, time=2.37588
Epoch:0087, train_loss=2.68529, train_acc=0.98996, val_loss=3.81754, val_acc=0.94793, time=1.94865
Epoch:0088, train_loss=2.68466, train_acc=0.98996, val_loss=3.81750, val_acc=0.94793, time=2.00699
Epoch:0089, train_loss=2.68405, train_acc=0.99013, val_loss=3.81745, val_acc=0.94793, time=2.00668
Epoch:0090, train_loss=2.68346, train_acc=0.99064, val_loss=3.81741, val_acc=0.94793, time=1.92392
Epoch:0091, train_loss=2.68289, train_acc=0.99098, val_loss=3.81738, val_acc=0.94793, time=2.19494
Epoch:0092, train_loss=2.68234, train_acc=0.99098, val_loss=3.81734, val_acc=0.94793, time=2.05657
Epoch:0093, train_loss=2.68181, train_acc=0.99098, val_loss=3.81730, val_acc=0.94946, time=1.95439
Epoch:0094, train_loss=2.68130, train_acc=0.99184, val_loss=3.81727, val_acc=0.94946, time=1.96207
Epoch:0095, train_loss=2.68080, train_acc=0.99235, val_loss=3.81724, val_acc=0.94946, time=1.90623
Epoch:0096, train_loss=2.68032, train_acc=0.99235, val_loss=3.81720, val_acc=0.94946, time=1.98339
Epoch:0097, train_loss=2.67986, train_acc=0.99235, val_loss=3.81717, val_acc=0.94946, time=2.05806
Epoch:0098, train_loss=2.67941, train_acc=0.99252, val_loss=3.81714, val_acc=0.94946, time=1.94704
Epoch:0099, train_loss=2.67897, train_acc=0.99269, val_loss=3.81711, val_acc=0.94946, time=2.22412
Epoch:0100, train_loss=2.67855, train_acc=0.99269, val_loss=3.81707, val_acc=0.94946, time=2.04844
Epoch:0101, train_loss=2.67815, train_acc=0.99269, val_loss=3.81704, val_acc=0.94946, time=2.13529
Epoch:0102, train_loss=2.67775, train_acc=0.99269, val_loss=3.81701, val_acc=0.94946, time=1.91943
Epoch:0103, train_loss=2.67737, train_acc=0.99303, val_loss=3.81698, val_acc=0.94946, time=2.04120
Epoch:0104, train_loss=2.67700, train_acc=0.99354, val_loss=3.81695, val_acc=0.94946, time=2.14129
Epoch:0105, train_loss=2.67664, train_acc=0.99371, val_loss=3.81692, val_acc=0.95100, time=2.05937
Epoch:0106, train_loss=2.67630, train_acc=0.99388, val_loss=3.81689, val_acc=0.95100, time=1.99199
Epoch:0107, train_loss=2.67596, train_acc=0.99388, val_loss=3.81686, val_acc=0.95100, time=1.92287
Epoch:0108, train_loss=2.67564, train_acc=0.99388, val_loss=3.81683, val_acc=0.95100, time=1.96075
Epoch:0109, train_loss=2.67532, train_acc=0.99422, val_loss=3.81680, val_acc=0.95100, time=1.90868
Epoch:0110, train_loss=2.67501, train_acc=0.99456, val_loss=3.81677, val_acc=0.95100, time=1.91269
Epoch:0111, train_loss=2.67472, train_acc=0.99473, val_loss=3.81674, val_acc=0.95100, time=1.96982
Epoch:0112, train_loss=2.67443, train_acc=0.99490, val_loss=3.81671, val_acc=0.95100, time=1.91175
Epoch:0113, train_loss=2.67415, train_acc=0.99507, val_loss=3.81669, val_acc=0.95100, time=1.91603
Epoch:0114, train_loss=2.67389, train_acc=0.99507, val_loss=3.81667, val_acc=0.95100, time=1.96592
Epoch:0115, train_loss=2.67363, train_acc=0.99524, val_loss=3.81664, val_acc=0.95100, time=1.91121
Epoch:0116, train_loss=2.67337, train_acc=0.99524, val_loss=3.81662, val_acc=0.95100, time=1.96184
Epoch:0117, train_loss=2.67313, train_acc=0.99524, val_loss=3.81660, val_acc=0.95100, time=1.91990
Epoch:0118, train_loss=2.67289, train_acc=0.99558, val_loss=3.81658, val_acc=0.95100, time=1.91956
Epoch:0119, train_loss=2.67266, train_acc=0.99558, val_loss=3.81656, val_acc=0.95100, time=1.95879
Epoch:0120, train_loss=2.67244, train_acc=0.99558, val_loss=3.81654, val_acc=0.94946, time=1.92601
Epoch:0121, train_loss=2.67222, train_acc=0.99575, val_loss=3.81652, val_acc=0.94946, time=1.96043
Epoch:0122, train_loss=2.67201, train_acc=0.99592, val_loss=3.81650, val_acc=0.94946, time=1.91364
Epoch:0123, train_loss=2.67180, train_acc=0.99609, val_loss=3.81648, val_acc=0.94946, time=1.91728
Epoch:0124, train_loss=2.67161, train_acc=0.99660, val_loss=3.81646, val_acc=0.94793, time=1.96538
Epoch:0125, train_loss=2.67141, train_acc=0.99677, val_loss=3.81645, val_acc=0.94793, time=1.91118
Epoch:0126, train_loss=2.67122, train_acc=0.99677, val_loss=3.81643, val_acc=0.94640, time=1.91848
Epoch:0127, train_loss=2.67104, train_acc=0.99677, val_loss=3.81641, val_acc=0.94640, time=2.05536
Epoch:0128, train_loss=2.67087, train_acc=0.99711, val_loss=3.81640, val_acc=0.94640, time=1.91314
Epoch:0129, train_loss=2.67069, train_acc=0.99711, val_loss=3.81638, val_acc=0.94640, time=1.97538
Epoch:0130, train_loss=2.67053, train_acc=0.99711, val_loss=3.81637, val_acc=0.94640, time=1.90860
Epoch:0131, train_loss=2.67036, train_acc=0.99728, val_loss=3.81635, val_acc=0.94640, time=1.92488
Epoch:0132, train_loss=2.67020, train_acc=0.99728, val_loss=3.81634, val_acc=0.94640, time=1.96913
Epoch:0133, train_loss=2.67005, train_acc=0.99728, val_loss=3.81633, val_acc=0.94640, time=1.91860
Epoch:0134, train_loss=2.66990, train_acc=0.99745, val_loss=3.81632, val_acc=0.94793, time=1.97870
Epoch:0135, train_loss=2.66975, train_acc=0.99745, val_loss=3.81630, val_acc=0.94793, time=1.90936
Epoch:0136, train_loss=2.66961, train_acc=0.99745, val_loss=3.81629, val_acc=0.94793, time=1.92248
Epoch:0137, train_loss=2.66947, train_acc=0.99745, val_loss=3.81628, val_acc=0.94793, time=1.96701
Epoch:0138, train_loss=2.66933, train_acc=0.99745, val_loss=3.81627, val_acc=0.94793, time=1.91419
Epoch:0139, train_loss=2.66920, train_acc=0.99745, val_loss=3.81626, val_acc=0.94946, time=1.97385
Epoch:0140, train_loss=2.66907, train_acc=0.99745, val_loss=3.81625, val_acc=0.94946, time=1.91124
Epoch:0141, train_loss=2.66895, train_acc=0.99745, val_loss=3.81624, val_acc=0.94946, time=1.90629
Epoch:0142, train_loss=2.66882, train_acc=0.99745, val_loss=3.81623, val_acc=0.94946, time=1.97623
Epoch:0143, train_loss=2.66870, train_acc=0.99745, val_loss=3.81622, val_acc=0.94946, time=1.92137
Epoch:0144, train_loss=2.66859, train_acc=0.99745, val_loss=3.81622, val_acc=0.94946, time=1.91256
Epoch:0145, train_loss=2.66847, train_acc=0.99745, val_loss=3.81621, val_acc=0.94946, time=1.95200
Epoch:0146, train_loss=2.66836, train_acc=0.99745, val_loss=3.81620, val_acc=0.94946, time=1.91041
Epoch:0147, train_loss=2.66825, train_acc=0.99745, val_loss=3.81619, val_acc=0.94946, time=1.98505
Epoch:0148, train_loss=2.66815, train_acc=0.99745, val_loss=3.81619, val_acc=0.94946, time=1.92379
Epoch:0149, train_loss=2.66804, train_acc=0.99762, val_loss=3.81618, val_acc=0.94946, time=1.92455
Epoch:0150, train_loss=2.66794, train_acc=0.99762, val_loss=3.81617, val_acc=0.94946, time=1.97510
Epoch:0151, train_loss=2.66784, train_acc=0.99762, val_loss=3.81616, val_acc=0.94946, time=1.91262
Epoch:0152, train_loss=2.66775, train_acc=0.99762, val_loss=3.81616, val_acc=0.94946, time=1.98074
Epoch:0153, train_loss=2.66765, train_acc=0.99762, val_loss=3.81615, val_acc=0.94946, time=1.91618
Epoch:0154, train_loss=2.66756, train_acc=0.99762, val_loss=3.81614, val_acc=0.94946, time=1.91828
Epoch:0155, train_loss=2.66747, train_acc=0.99779, val_loss=3.81613, val_acc=0.94946, time=1.97455
Epoch:0156, train_loss=2.66738, train_acc=0.99779, val_loss=3.81613, val_acc=0.94946, time=1.91548
Epoch:0157, train_loss=2.66729, train_acc=0.99779, val_loss=3.81612, val_acc=0.94946, time=1.98557
Epoch:0158, train_loss=2.66721, train_acc=0.99779, val_loss=3.81611, val_acc=0.94946, time=1.90795
Epoch:0159, train_loss=2.66713, train_acc=0.99779, val_loss=3.81611, val_acc=0.94946, time=1.92724
Epoch:0160, train_loss=2.66704, train_acc=0.99779, val_loss=3.81610, val_acc=0.94946, time=1.97109
Epoch:0161, train_loss=2.66696, train_acc=0.99779, val_loss=3.81609, val_acc=0.94946, time=1.90613
Epoch:0162, train_loss=2.66689, train_acc=0.99779, val_loss=3.81609, val_acc=0.94946, time=1.90801
Epoch:0163, train_loss=2.66681, train_acc=0.99779, val_loss=3.81608, val_acc=0.94946, time=1.96898
Epoch:0164, train_loss=2.66674, train_acc=0.99796, val_loss=3.81608, val_acc=0.94946, time=1.92654
Epoch:0165, train_loss=2.66666, train_acc=0.99813, val_loss=3.81607, val_acc=0.94946, time=1.97073
Epoch:0166, train_loss=2.66659, train_acc=0.99813, val_loss=3.81606, val_acc=0.94946, time=1.90025
Epoch:0167, train_loss=2.66652, train_acc=0.99830, val_loss=3.81606, val_acc=0.94946, time=1.91244
Epoch:0168, train_loss=2.66645, train_acc=0.99830, val_loss=3.81605, val_acc=0.94946, time=1.96058
Epoch:0169, train_loss=2.66638, train_acc=0.99830, val_loss=3.81605, val_acc=0.94946, time=1.90554
Epoch:0170, train_loss=2.66632, train_acc=0.99830, val_loss=3.81605, val_acc=0.94946, time=1.98328
Epoch:0171, train_loss=2.66625, train_acc=0.99830, val_loss=3.81604, val_acc=0.94946, time=1.90903
Epoch:0172, train_loss=2.66619, train_acc=0.99830, val_loss=3.81604, val_acc=0.94946, time=1.90981
Epoch:0173, train_loss=2.66613, train_acc=0.99830, val_loss=3.81604, val_acc=0.94946, time=1.97219
Epoch:0174, train_loss=2.66607, train_acc=0.99830, val_loss=3.81603, val_acc=0.94946, time=1.92083
Epoch:0175, train_loss=2.66601, train_acc=0.99830, val_loss=3.81603, val_acc=0.94946, time=1.93513
Epoch:0176, train_loss=2.66595, train_acc=0.99830, val_loss=3.81602, val_acc=0.94946, time=1.94968
Epoch:0177, train_loss=2.66589, train_acc=0.99830, val_loss=3.81602, val_acc=0.94946, time=1.91106
Epoch:0178, train_loss=2.66583, train_acc=0.99830, val_loss=3.81602, val_acc=0.94946, time=1.98326
Epoch:0179, train_loss=2.66578, train_acc=0.99847, val_loss=3.81602, val_acc=0.94946, time=1.94822
Epoch:0180, train_loss=2.66572, train_acc=0.99847, val_loss=3.81601, val_acc=0.94946, time=1.91799
Epoch:0181, train_loss=2.66567, train_acc=0.99847, val_loss=3.81601, val_acc=0.94946, time=1.95054
Epoch:0182, train_loss=2.66561, train_acc=0.99847, val_loss=3.81601, val_acc=0.94946, time=1.93262
Epoch:0183, train_loss=2.66556, train_acc=0.99847, val_loss=3.81600, val_acc=0.94946, time=1.95703
Epoch:0184, train_loss=2.66551, train_acc=0.99847, val_loss=3.81600, val_acc=0.94946, time=1.92977
Epoch:0185, train_loss=2.66546, train_acc=0.99847, val_loss=3.81600, val_acc=0.94946, time=1.90982
Epoch:0186, train_loss=2.66541, train_acc=0.99881, val_loss=3.81600, val_acc=0.94946, time=1.93522
Epoch:0187, train_loss=2.66536, train_acc=0.99881, val_loss=3.81600, val_acc=0.94946, time=1.89569
Epoch:0188, train_loss=2.66532, train_acc=0.99881, val_loss=3.81599, val_acc=0.94946, time=1.95269
Epoch:0189, train_loss=2.66527, train_acc=0.99881, val_loss=3.81599, val_acc=0.94946, time=1.93330
Epoch:0190, train_loss=2.66523, train_acc=0.99881, val_loss=3.81599, val_acc=0.94946, time=2.00925
Epoch:0191, train_loss=2.66518, train_acc=0.99881, val_loss=3.81599, val_acc=0.94946, time=1.97240
Epoch:0192, train_loss=2.66514, train_acc=0.99881, val_loss=3.81599, val_acc=0.94946, time=1.92400
Epoch:0193, train_loss=2.66509, train_acc=0.99881, val_loss=3.81598, val_acc=0.94946, time=1.93385
Epoch:0194, train_loss=2.66505, train_acc=0.99881, val_loss=3.81598, val_acc=0.94946, time=2.02157
Epoch:0195, train_loss=2.66501, train_acc=0.99881, val_loss=3.81598, val_acc=0.94946, time=1.96239
Epoch:0196, train_loss=2.66497, train_acc=0.99881, val_loss=3.81598, val_acc=0.94946, time=2.05103
Epoch:0197, train_loss=2.66493, train_acc=0.99881, val_loss=3.81598, val_acc=0.94946, time=1.95944
Epoch:0198, train_loss=2.66489, train_acc=0.99881, val_loss=3.81598, val_acc=0.94946, time=1.98661
Epoch:0199, train_loss=2.66485, train_acc=0.99881, val_loss=3.81598, val_acc=0.94946, time=1.97245
Epoch:0200, train_loss=2.66481, train_acc=0.99881, val_loss=3.81598, val_acc=0.94946, time=2.27890

Optimization Finished!

Test set results: loss= 3.42627, accuracy= 0.93886, time= 0.96061

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9772    0.9908    0.9840      1083
           1     0.8759    0.9917    0.9302       121
           2     0.9598    0.9612    0.9605       696
           3     0.8235    0.8235    0.8235        17
           4     0.9583    0.9200    0.9388        25
           5     0.8375    0.8272    0.8323        81
           6     0.8163    0.9195    0.8649        87
           7     0.7912    0.9600    0.8675        75
           8     0.8889    0.8571    0.8727        28
           9     0.7500    0.6000    0.6667         5
          10     1.0000    0.8182    0.9000        11
          11     1.0000    1.0000    1.0000         2
          12     1.0000    0.4167    0.5882        12
          13     0.9167    0.9167    0.9167        12
          14     0.9167    1.0000    0.9565        11
          15     1.0000    1.0000    1.0000         1
          16     0.8667    0.8667    0.8667        15
          17     0.0000    0.0000    0.0000         1
          18     0.9000    0.7500    0.8182        36
          19     0.8750    0.8750    0.8750         8
          20     1.0000    1.0000    1.0000         4
          21     0.8462    0.8462    0.8462        13
          22     1.0000    0.9167    0.9565        12
          23     1.0000    1.0000    1.0000        10
          24     1.0000    1.0000    1.0000        22
          25     0.5000    1.0000    0.6667         1
          26     0.8182    0.9000    0.8571        10
          27     1.0000    0.8667    0.9286        15
          28     0.3333    0.2000    0.2500         5
          29     0.9091    0.8333    0.8696        12
          30     0.9333    0.7368    0.8235        19
          31     0.8636    0.9500    0.9048        20
          32     0.8750    0.7778    0.8235         9
          33     0.7143    0.5556    0.6250         9
          34     0.6667    0.3333    0.4444         6
          35     0.8333    1.0000    0.9091         5
          36     1.0000    1.0000    1.0000         3
          37     1.0000    1.0000    1.0000         1
          38     1.0000    0.5556    0.7143         9
          39     1.0000    1.0000    1.0000         9
          40     0.7500    0.7500    0.7500         4
          41     1.0000    1.0000    1.0000         9
          42     0.0000    0.0000    0.0000         1
          43     0.0000    0.0000    0.0000         4
          44     0.0000    0.0000    0.0000         6
          45     0.0000    0.0000    0.0000         3
          46     1.0000    0.1429    0.2500         7
          47     0.0000    0.0000    0.0000         1
          48     1.0000    1.0000    1.0000         4
          49     0.0000    0.0000    0.0000         3
          50     1.0000    0.3333    0.5000         3
          51     0.0000    0.0000    0.0000         2

    accuracy                         0.9389      2568
   macro avg     0.7538    0.6960    0.7073      2568
weighted avg     0.9336    0.9389    0.9333      2568


Macro average Test Precision, Recall and F1-Score...
(0.7537841124201, 0.6960065182826564, 0.7073378696534529, None)

Micro average Test Precision, Recall and F1-Score...
(0.9388629283489096, 0.9388629283489096, 0.9388629283489096, None)

Embeddings:
Word_embeddings:8892
Train_doc_embeddings:6532
Test_doc_embeddings:2568
