
==========: 6047897938752846153
Epoch:0001, train_loss=3.98958, train_acc=0.00867, val_loss=3.93510, val_acc=0.44564, time=1.94229
Epoch:0002, train_loss=3.79665, train_acc=0.43307, val_loss=3.91555, val_acc=0.51914, time=1.88458
Epoch:0003, train_loss=3.62152, train_acc=0.49651, val_loss=3.89863, val_acc=0.54364, time=1.93486
Epoch:0004, train_loss=3.46953, train_acc=0.53240, val_loss=3.88578, val_acc=0.59112, time=1.87035
Epoch:0005, train_loss=3.35402, train_acc=0.57731, val_loss=3.87725, val_acc=0.63400, time=1.87628
Epoch:0006, train_loss=3.27700, train_acc=0.62272, val_loss=3.87183, val_acc=0.65237, time=1.93894
Epoch:0007, train_loss=3.22731, train_acc=0.64892, val_loss=3.86803, val_acc=0.66003, time=1.87740
Epoch:0008, train_loss=3.19170, train_acc=0.65930, val_loss=3.86473, val_acc=0.66309, time=1.88492
Epoch:0009, train_loss=3.16051, train_acc=0.66746, val_loss=3.86145, val_acc=0.68300, time=2.09946
Epoch:0010, train_loss=3.12977, train_acc=0.68498, val_loss=3.85828, val_acc=0.70444, time=2.32923
Epoch:0011, train_loss=3.10027, train_acc=0.71458, val_loss=3.85540, val_acc=0.72435, time=2.14700
Epoch:0012, train_loss=3.07370, train_acc=0.73992, val_loss=3.85284, val_acc=0.74426, time=1.93929
Epoch:0013, train_loss=3.04994, train_acc=0.76169, val_loss=3.85046, val_acc=0.75191, time=1.93015
Epoch:0014, train_loss=3.02793, train_acc=0.77989, val_loss=3.84824, val_acc=0.76417, time=2.11930
Epoch:0015, train_loss=3.00734, train_acc=0.79639, val_loss=3.84619, val_acc=0.78407, time=2.09438
Epoch:0016, train_loss=2.98848, train_acc=0.81596, val_loss=3.84437, val_acc=0.79939, time=2.45973
Epoch:0017, train_loss=2.97153, train_acc=0.82463, val_loss=3.84276, val_acc=0.80398, time=2.20566
Epoch:0018, train_loss=2.95625, train_acc=0.83313, val_loss=3.84130, val_acc=0.81317, time=2.13300
Epoch:0019, train_loss=2.94214, train_acc=0.84164, val_loss=3.83998, val_acc=0.81930, time=2.11904
Epoch:0020, train_loss=2.92886, train_acc=0.85253, val_loss=3.83878, val_acc=0.82236, time=2.06204
Epoch:0021, train_loss=2.91641, train_acc=0.85814, val_loss=3.83772, val_acc=0.82695, time=2.26557
Epoch:0022, train_loss=2.90485, train_acc=0.86443, val_loss=3.83678, val_acc=0.83308, time=1.92598
Epoch:0023, train_loss=2.89417, train_acc=0.86886, val_loss=3.83595, val_acc=0.83461, time=1.95083
Epoch:0024, train_loss=2.88428, train_acc=0.87345, val_loss=3.83518, val_acc=0.84074, time=1.88168
Epoch:0025, train_loss=2.87500, train_acc=0.87668, val_loss=3.83445, val_acc=0.83920, time=2.20147
Epoch:0026, train_loss=2.86613, train_acc=0.88280, val_loss=3.83374, val_acc=0.84074, time=1.91048
Epoch:0027, train_loss=2.85755, train_acc=0.88535, val_loss=3.83302, val_acc=0.84533, time=1.90849
Epoch:0028, train_loss=2.84921, train_acc=0.88927, val_loss=3.83230, val_acc=0.85452, time=2.02235
Epoch:0029, train_loss=2.84114, train_acc=0.89709, val_loss=3.83159, val_acc=0.86064, time=1.90942
Epoch:0030, train_loss=2.83342, train_acc=0.90015, val_loss=3.83089, val_acc=0.86524, time=1.94425
Epoch:0031, train_loss=2.82612, train_acc=0.90509, val_loss=3.83021, val_acc=0.86983, time=1.88436
Epoch:0032, train_loss=2.81928, train_acc=0.90951, val_loss=3.82957, val_acc=0.86983, time=1.92205
Epoch:0033, train_loss=2.81288, train_acc=0.91223, val_loss=3.82895, val_acc=0.87136, time=1.97172
Epoch:0034, train_loss=2.80684, train_acc=0.91495, val_loss=3.82834, val_acc=0.88055, time=1.87780
Epoch:0035, train_loss=2.80105, train_acc=0.91852, val_loss=3.82776, val_acc=0.87902, time=1.88429
Epoch:0036, train_loss=2.79545, train_acc=0.92073, val_loss=3.82720, val_acc=0.88208, time=1.94964
Epoch:0037, train_loss=2.79002, train_acc=0.92431, val_loss=3.82667, val_acc=0.88515, time=1.88398
Epoch:0038, train_loss=2.78483, train_acc=0.92788, val_loss=3.82617, val_acc=0.89127, time=1.94886
Epoch:0039, train_loss=2.77992, train_acc=0.93230, val_loss=3.82572, val_acc=0.89127, time=1.87351
Epoch:0040, train_loss=2.77530, train_acc=0.93451, val_loss=3.82529, val_acc=0.88974, time=1.89068
Epoch:0041, train_loss=2.77094, train_acc=0.93706, val_loss=3.82489, val_acc=0.90046, time=2.05297
Epoch:0042, train_loss=2.76675, train_acc=0.93842, val_loss=3.82450, val_acc=0.90046, time=1.89141
Epoch:0043, train_loss=2.76269, train_acc=0.94132, val_loss=3.82413, val_acc=0.90505, time=1.94567
Epoch:0044, train_loss=2.75874, train_acc=0.94387, val_loss=3.82378, val_acc=0.90658, time=1.87415
Epoch:0045, train_loss=2.75494, train_acc=0.94608, val_loss=3.82345, val_acc=0.90965, time=1.88473
Epoch:0046, train_loss=2.75131, train_acc=0.94778, val_loss=3.82315, val_acc=0.91118, time=2.13271
Epoch:0047, train_loss=2.74787, train_acc=0.95016, val_loss=3.82288, val_acc=0.91884, time=1.87936
Epoch:0048, train_loss=2.74461, train_acc=0.95203, val_loss=3.82262, val_acc=0.91730, time=1.90437
Epoch:0049, train_loss=2.74150, train_acc=0.95288, val_loss=3.82237, val_acc=0.92343, time=1.93309
Epoch:0050, train_loss=2.73852, train_acc=0.95441, val_loss=3.82213, val_acc=0.92496, time=1.87949
Epoch:0051, train_loss=2.73567, train_acc=0.95611, val_loss=3.82190, val_acc=0.92649, time=1.94887
Epoch:0052, train_loss=2.73295, train_acc=0.95850, val_loss=3.82168, val_acc=0.92802, time=1.89688
Epoch:0053, train_loss=2.73038, train_acc=0.96020, val_loss=3.82147, val_acc=0.92649, time=1.88905
Epoch:0054, train_loss=2.72795, train_acc=0.96241, val_loss=3.82127, val_acc=0.92956, time=1.99106
Epoch:0055, train_loss=2.72563, train_acc=0.96394, val_loss=3.82108, val_acc=0.93109, time=1.88211
Epoch:0056, train_loss=2.72343, train_acc=0.96598, val_loss=3.82090, val_acc=0.92956, time=2.33075
Epoch:0057, train_loss=2.72133, train_acc=0.96717, val_loss=3.82073, val_acc=0.92956, time=1.88895
Epoch:0058, train_loss=2.71933, train_acc=0.96836, val_loss=3.82058, val_acc=0.93262, time=1.88820
Epoch:0059, train_loss=2.71741, train_acc=0.96955, val_loss=3.82043, val_acc=0.93415, time=1.99839
Epoch:0060, train_loss=2.71555, train_acc=0.97023, val_loss=3.82028, val_acc=0.93721, time=1.88222
Epoch:0061, train_loss=2.71374, train_acc=0.97176, val_loss=3.82014, val_acc=0.94028, time=2.27067
Epoch:0062, train_loss=2.71201, train_acc=0.97329, val_loss=3.81999, val_acc=0.94028, time=1.89383
Epoch:0063, train_loss=2.71034, train_acc=0.97432, val_loss=3.81984, val_acc=0.94028, time=2.20727
Epoch:0064, train_loss=2.70875, train_acc=0.97534, val_loss=3.81968, val_acc=0.94028, time=1.93955
Epoch:0065, train_loss=2.70722, train_acc=0.97568, val_loss=3.81951, val_acc=0.93721, time=1.86742
Epoch:0066, train_loss=2.70576, train_acc=0.97704, val_loss=3.81935, val_acc=0.93721, time=1.94894
Epoch:0067, train_loss=2.70436, train_acc=0.97755, val_loss=3.81919, val_acc=0.93721, time=1.88623
Epoch:0068, train_loss=2.70301, train_acc=0.97857, val_loss=3.81903, val_acc=0.93721, time=1.89675
Epoch:0069, train_loss=2.70172, train_acc=0.97959, val_loss=3.81889, val_acc=0.93721, time=2.04810
Epoch:0070, train_loss=2.70049, train_acc=0.98044, val_loss=3.81877, val_acc=0.93721, time=1.87989
Epoch:0071, train_loss=2.69929, train_acc=0.98146, val_loss=3.81866, val_acc=0.93874, time=1.91142
Epoch:0072, train_loss=2.69814, train_acc=0.98197, val_loss=3.81857, val_acc=0.94028, time=1.90723
Epoch:0073, train_loss=2.69704, train_acc=0.98248, val_loss=3.81850, val_acc=0.94028, time=1.91658
Epoch:0074, train_loss=2.69598, train_acc=0.98265, val_loss=3.81843, val_acc=0.94028, time=1.93406
Epoch:0075, train_loss=2.69496, train_acc=0.98299, val_loss=3.81838, val_acc=0.94181, time=1.88137
Epoch:0076, train_loss=2.69399, train_acc=0.98367, val_loss=3.81833, val_acc=0.94181, time=1.88381
Epoch:0077, train_loss=2.69305, train_acc=0.98418, val_loss=3.81828, val_acc=0.94181, time=1.97158
Epoch:0078, train_loss=2.69214, train_acc=0.98452, val_loss=3.81822, val_acc=0.94181, time=1.88370
Epoch:0079, train_loss=2.69126, train_acc=0.98503, val_loss=3.81816, val_acc=0.94181, time=1.95490
Epoch:0080, train_loss=2.69042, train_acc=0.98588, val_loss=3.81810, val_acc=0.94181, time=1.88152
Epoch:0081, train_loss=2.68961, train_acc=0.98622, val_loss=3.81804, val_acc=0.94181, time=1.88213
Epoch:0082, train_loss=2.68882, train_acc=0.98724, val_loss=3.81797, val_acc=0.94334, time=2.07504
Epoch:0083, train_loss=2.68807, train_acc=0.98775, val_loss=3.81790, val_acc=0.94334, time=1.88559
Epoch:0084, train_loss=2.68734, train_acc=0.98809, val_loss=3.81784, val_acc=0.94640, time=2.27926
Epoch:0085, train_loss=2.68664, train_acc=0.98843, val_loss=3.81777, val_acc=0.94640, time=1.88657
Epoch:0086, train_loss=2.68597, train_acc=0.98843, val_loss=3.81771, val_acc=0.94640, time=2.42381
Epoch:0087, train_loss=2.68531, train_acc=0.98843, val_loss=3.81765, val_acc=0.94640, time=1.96520
Epoch:0088, train_loss=2.68468, train_acc=0.98843, val_loss=3.81760, val_acc=0.94640, time=1.87522
Epoch:0089, train_loss=2.68407, train_acc=0.98928, val_loss=3.81755, val_acc=0.94487, time=1.94977
Epoch:0090, train_loss=2.68348, train_acc=0.98962, val_loss=3.81751, val_acc=0.94487, time=1.87994
Epoch:0091, train_loss=2.68291, train_acc=0.98996, val_loss=3.81747, val_acc=0.94487, time=1.87529
Epoch:0092, train_loss=2.68236, train_acc=0.99013, val_loss=3.81743, val_acc=0.94487, time=2.05938
Epoch:0093, train_loss=2.68183, train_acc=0.99064, val_loss=3.81740, val_acc=0.94487, time=1.88854
Epoch:0094, train_loss=2.68132, train_acc=0.99098, val_loss=3.81736, val_acc=0.94487, time=1.92303
Epoch:0095, train_loss=2.68083, train_acc=0.99115, val_loss=3.81733, val_acc=0.94487, time=1.88266
Epoch:0096, train_loss=2.68035, train_acc=0.99167, val_loss=3.81729, val_acc=0.94640, time=1.88850
Epoch:0097, train_loss=2.67989, train_acc=0.99201, val_loss=3.81726, val_acc=0.94640, time=1.92769
Epoch:0098, train_loss=2.67945, train_acc=0.99201, val_loss=3.81723, val_acc=0.94640, time=1.88827
Epoch:0099, train_loss=2.67902, train_acc=0.99235, val_loss=3.81720, val_acc=0.94793, time=1.89197
Epoch:0100, train_loss=2.67860, train_acc=0.99303, val_loss=3.81717, val_acc=0.94793, time=1.96080
Epoch:0101, train_loss=2.67820, train_acc=0.99337, val_loss=3.81714, val_acc=0.94793, time=1.87947
Epoch:0102, train_loss=2.67781, train_acc=0.99371, val_loss=3.81711, val_acc=0.94793, time=1.95180
Epoch:0103, train_loss=2.67743, train_acc=0.99405, val_loss=3.81708, val_acc=0.94793, time=1.87233
Epoch:0104, train_loss=2.67707, train_acc=0.99422, val_loss=3.81706, val_acc=0.94793, time=1.87250
Epoch:0105, train_loss=2.67671, train_acc=0.99422, val_loss=3.81703, val_acc=0.94793, time=2.11176
Epoch:0106, train_loss=2.67637, train_acc=0.99439, val_loss=3.81701, val_acc=0.94793, time=1.89389
Epoch:0107, train_loss=2.67604, train_acc=0.99439, val_loss=3.81699, val_acc=0.94793, time=1.90708
Epoch:0108, train_loss=2.67571, train_acc=0.99473, val_loss=3.81696, val_acc=0.94793, time=1.91093
Epoch:0109, train_loss=2.67540, train_acc=0.99473, val_loss=3.81693, val_acc=0.94793, time=1.92838
Epoch:0110, train_loss=2.67510, train_acc=0.99473, val_loss=3.81691, val_acc=0.94793, time=1.96258
Epoch:0111, train_loss=2.67480, train_acc=0.99473, val_loss=3.81688, val_acc=0.94793, time=1.91470
Epoch:0112, train_loss=2.67451, train_acc=0.99473, val_loss=3.81685, val_acc=0.94793, time=1.88347
Epoch:0113, train_loss=2.67424, train_acc=0.99473, val_loss=3.81682, val_acc=0.94793, time=1.96795
Epoch:0114, train_loss=2.67397, train_acc=0.99473, val_loss=3.81680, val_acc=0.94793, time=1.89875
Epoch:0115, train_loss=2.67371, train_acc=0.99473, val_loss=3.81677, val_acc=0.94793, time=1.93006
Epoch:0116, train_loss=2.67345, train_acc=0.99473, val_loss=3.81674, val_acc=0.94793, time=1.88732
Epoch:0117, train_loss=2.67321, train_acc=0.99490, val_loss=3.81672, val_acc=0.94793, time=1.88507
Epoch:0118, train_loss=2.67297, train_acc=0.99490, val_loss=3.81669, val_acc=0.94793, time=2.07854
Epoch:0119, train_loss=2.67274, train_acc=0.99524, val_loss=3.81667, val_acc=0.94793, time=1.88264
Epoch:0120, train_loss=2.67251, train_acc=0.99541, val_loss=3.81664, val_acc=0.94793, time=1.90675
Epoch:0121, train_loss=2.67229, train_acc=0.99558, val_loss=3.81662, val_acc=0.94793, time=1.88462
Epoch:0122, train_loss=2.67208, train_acc=0.99592, val_loss=3.81660, val_acc=0.94793, time=1.88666
Epoch:0123, train_loss=2.67188, train_acc=0.99592, val_loss=3.81658, val_acc=0.94793, time=1.93696
Epoch:0124, train_loss=2.67168, train_acc=0.99592, val_loss=3.81656, val_acc=0.94793, time=1.90042
Epoch:0125, train_loss=2.67148, train_acc=0.99626, val_loss=3.81655, val_acc=0.94793, time=2.08602
Epoch:0126, train_loss=2.67129, train_acc=0.99626, val_loss=3.81653, val_acc=0.94793, time=1.97388
Epoch:0127, train_loss=2.67111, train_acc=0.99643, val_loss=3.81651, val_acc=0.94793, time=1.91134
Epoch:0128, train_loss=2.67093, train_acc=0.99643, val_loss=3.81649, val_acc=0.94793, time=1.95228
Epoch:0129, train_loss=2.67076, train_acc=0.99643, val_loss=3.81647, val_acc=0.94793, time=1.92290
Epoch:0130, train_loss=2.67059, train_acc=0.99660, val_loss=3.81646, val_acc=0.94793, time=1.89753
Epoch:0131, train_loss=2.67043, train_acc=0.99660, val_loss=3.81644, val_acc=0.94793, time=2.01517
Epoch:0132, train_loss=2.67027, train_acc=0.99677, val_loss=3.81642, val_acc=0.94793, time=2.09056
Epoch:0133, train_loss=2.67011, train_acc=0.99694, val_loss=3.81641, val_acc=0.94793, time=2.57635
Epoch:0134, train_loss=2.66996, train_acc=0.99694, val_loss=3.81639, val_acc=0.94793, time=2.34069
Epoch:0135, train_loss=2.66981, train_acc=0.99694, val_loss=3.81638, val_acc=0.94793, time=2.31195
Epoch:0136, train_loss=2.66967, train_acc=0.99694, val_loss=3.81636, val_acc=0.94793, time=2.27969
Epoch:0137, train_loss=2.66953, train_acc=0.99694, val_loss=3.81635, val_acc=0.94793, time=2.09023
Epoch:0138, train_loss=2.66939, train_acc=0.99694, val_loss=3.81634, val_acc=0.94793, time=2.17014
Epoch:0139, train_loss=2.66926, train_acc=0.99694, val_loss=3.81632, val_acc=0.94640, time=2.42542
Epoch:0140, train_loss=2.66913, train_acc=0.99694, val_loss=3.81631, val_acc=0.94640, time=2.20941
Epoch:0141, train_loss=2.66900, train_acc=0.99694, val_loss=3.81630, val_acc=0.94640, time=1.91944
Epoch:0142, train_loss=2.66888, train_acc=0.99694, val_loss=3.81629, val_acc=0.94640, time=2.03709
Epoch:0143, train_loss=2.66876, train_acc=0.99694, val_loss=3.81628, val_acc=0.94640, time=2.04287
Epoch:0144, train_loss=2.66864, train_acc=0.99694, val_loss=3.81627, val_acc=0.94640, time=1.90139
Epoch:0145, train_loss=2.66853, train_acc=0.99694, val_loss=3.81626, val_acc=0.94640, time=1.94148
Epoch:0146, train_loss=2.66842, train_acc=0.99694, val_loss=3.81625, val_acc=0.94640, time=1.91528
Epoch:0147, train_loss=2.66831, train_acc=0.99711, val_loss=3.81624, val_acc=0.94640, time=1.96348
Epoch:0148, train_loss=2.66820, train_acc=0.99711, val_loss=3.81623, val_acc=0.94640, time=2.00475
Epoch:0149, train_loss=2.66809, train_acc=0.99711, val_loss=3.81622, val_acc=0.94640, time=2.02254
Epoch:0150, train_loss=2.66799, train_acc=0.99711, val_loss=3.81621, val_acc=0.94640, time=2.31751
Epoch:0151, train_loss=2.66789, train_acc=0.99745, val_loss=3.81620, val_acc=0.94640, time=2.08287
Epoch:0152, train_loss=2.66779, train_acc=0.99745, val_loss=3.81619, val_acc=0.94640, time=2.17226
Epoch:0153, train_loss=2.66770, train_acc=0.99745, val_loss=3.81619, val_acc=0.94640, time=2.06448
Epoch:0154, train_loss=2.66761, train_acc=0.99762, val_loss=3.81618, val_acc=0.94640, time=2.16513
Epoch:0155, train_loss=2.66752, train_acc=0.99762, val_loss=3.81617, val_acc=0.94640, time=2.11820
Epoch:0156, train_loss=2.66743, train_acc=0.99762, val_loss=3.81616, val_acc=0.94640, time=1.95524
Epoch:0157, train_loss=2.66734, train_acc=0.99762, val_loss=3.81616, val_acc=0.94640, time=2.05863
Epoch:0158, train_loss=2.66725, train_acc=0.99779, val_loss=3.81615, val_acc=0.94640, time=2.05726
Epoch:0159, train_loss=2.66717, train_acc=0.99779, val_loss=3.81614, val_acc=0.94640, time=2.01168
Epoch:0160, train_loss=2.66709, train_acc=0.99779, val_loss=3.81614, val_acc=0.94640, time=1.88100
Epoch:0161, train_loss=2.66701, train_acc=0.99779, val_loss=3.81613, val_acc=0.94640, time=2.38385
Epoch:0162, train_loss=2.66693, train_acc=0.99779, val_loss=3.81613, val_acc=0.94640, time=1.95543
Epoch:0163, train_loss=2.66685, train_acc=0.99779, val_loss=3.81612, val_acc=0.94640, time=2.13079
Epoch:0164, train_loss=2.66678, train_acc=0.99779, val_loss=3.81611, val_acc=0.94793, time=2.17368
Epoch:0165, train_loss=2.66670, train_acc=0.99796, val_loss=3.81611, val_acc=0.94793, time=2.10208
Epoch:0166, train_loss=2.66663, train_acc=0.99796, val_loss=3.81610, val_acc=0.94793, time=2.11717
Epoch:0167, train_loss=2.66656, train_acc=0.99796, val_loss=3.81610, val_acc=0.94793, time=2.16237
Epoch:0168, train_loss=2.66649, train_acc=0.99796, val_loss=3.81609, val_acc=0.94793, time=1.92715
Epoch:0169, train_loss=2.66642, train_acc=0.99813, val_loss=3.81609, val_acc=0.94793, time=2.16979
Epoch:0170, train_loss=2.66636, train_acc=0.99813, val_loss=3.81608, val_acc=0.94793, time=2.00863
Epoch:0171, train_loss=2.66629, train_acc=0.99813, val_loss=3.81608, val_acc=0.94793, time=2.25546
Epoch:0172, train_loss=2.66623, train_acc=0.99813, val_loss=3.81608, val_acc=0.94793, time=2.98023
Epoch:0173, train_loss=2.66616, train_acc=0.99813, val_loss=3.81607, val_acc=0.94793, time=2.86647
Epoch:0174, train_loss=2.66610, train_acc=0.99813, val_loss=3.81607, val_acc=0.94793, time=2.49823
Epoch:0175, train_loss=2.66604, train_acc=0.99813, val_loss=3.81606, val_acc=0.94793, time=2.09001
Epoch:0176, train_loss=2.66598, train_acc=0.99813, val_loss=3.81606, val_acc=0.94793, time=2.57021
Epoch:0177, train_loss=2.66592, train_acc=0.99830, val_loss=3.81606, val_acc=0.94793, time=2.18668
Epoch:0178, train_loss=2.66587, train_acc=0.99847, val_loss=3.81605, val_acc=0.94793, time=2.10705
Epoch:0179, train_loss=2.66581, train_acc=0.99847, val_loss=3.81605, val_acc=0.94793, time=2.70138
Epoch:0180, train_loss=2.66575, train_acc=0.99847, val_loss=3.81604, val_acc=0.94793, time=3.06217
Epoch:0181, train_loss=2.66570, train_acc=0.99847, val_loss=3.81604, val_acc=0.94793, time=2.50083
Epoch:0182, train_loss=2.66565, train_acc=0.99847, val_loss=3.81604, val_acc=0.94793, time=2.55465
Epoch:0183, train_loss=2.66559, train_acc=0.99864, val_loss=3.81604, val_acc=0.94793, time=2.76683
Epoch:0184, train_loss=2.66554, train_acc=0.99864, val_loss=3.81603, val_acc=0.94793, time=2.90642
Epoch:0185, train_loss=2.66549, train_acc=0.99864, val_loss=3.81603, val_acc=0.94793, time=2.56511
Epoch:0186, train_loss=2.66544, train_acc=0.99864, val_loss=3.81603, val_acc=0.94793, time=2.30661
Epoch:0187, train_loss=2.66539, train_acc=0.99864, val_loss=3.81603, val_acc=0.94793, time=2.08232
Epoch:0188, train_loss=2.66535, train_acc=0.99864, val_loss=3.81602, val_acc=0.94793, time=1.87070
Epoch:0189, train_loss=2.66530, train_acc=0.99864, val_loss=3.81602, val_acc=0.94793, time=2.18748
Epoch:0190, train_loss=2.66525, train_acc=0.99864, val_loss=3.81602, val_acc=0.94793, time=2.50456
Epoch:0191, train_loss=2.66521, train_acc=0.99864, val_loss=3.81602, val_acc=0.94793, time=2.61629
Epoch:0192, train_loss=2.66516, train_acc=0.99864, val_loss=3.81602, val_acc=0.94793, time=2.65224
Epoch:0193, train_loss=2.66512, train_acc=0.99864, val_loss=3.81601, val_acc=0.94793, time=2.04816
Epoch:0194, train_loss=2.66508, train_acc=0.99864, val_loss=3.81601, val_acc=0.94793, time=1.89417
Epoch:0195, train_loss=2.66503, train_acc=0.99864, val_loss=3.81601, val_acc=0.94793, time=2.44254
Epoch:0196, train_loss=2.66499, train_acc=0.99864, val_loss=3.81601, val_acc=0.94793, time=1.97059
Epoch:0197, train_loss=2.66495, train_acc=0.99864, val_loss=3.81601, val_acc=0.94793, time=2.51261
Epoch:0198, train_loss=2.66491, train_acc=0.99864, val_loss=3.81601, val_acc=0.94793, time=2.10390
Epoch:0199, train_loss=2.66487, train_acc=0.99864, val_loss=3.81601, val_acc=0.94793, time=2.52440
Epoch:0200, train_loss=2.66483, train_acc=0.99864, val_loss=3.81600, val_acc=0.94793, time=2.22734

Optimization Finished!

Test set results: loss= 3.42676, accuracy= 0.93575, time= 0.81952

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9728    0.9917    0.9822      1083
           1     0.8750    0.9835    0.9261       121
           2     0.9583    0.9569    0.9576       696
           3     0.9333    0.8235    0.8750        17
           4     0.9583    0.9200    0.9388        25
           5     0.8313    0.8519    0.8415        81
           6     0.8061    0.9080    0.8541        87
           7     0.7742    0.9600    0.8571        75
           8     0.8846    0.8214    0.8519        28
           9     1.0000    0.6000    0.7500         5
          10     1.0000    0.8182    0.9000        11
          11     1.0000    1.0000    1.0000         2
          12     1.0000    0.3333    0.5000        12
          13     0.8462    0.9167    0.8800        12
          14     0.9167    1.0000    0.9565        11
          15     1.0000    1.0000    1.0000         1
          16     0.8750    0.9333    0.9032        15
          17     0.0000    0.0000    0.0000         1
          18     0.8621    0.6944    0.7692        36
          19     1.0000    0.8750    0.9333         8
          20     1.0000    1.0000    1.0000         4
          21     0.8462    0.8462    0.8462        13
          22     1.0000    0.9167    0.9565        12
          23     1.0000    0.8000    0.8889        10
          24     1.0000    1.0000    1.0000        22
          25     0.5000    1.0000    0.6667         1
          26     0.8182    0.9000    0.8571        10
          27     1.0000    0.8667    0.9286        15
          28     0.5000    0.4000    0.4444         5
          29     0.9000    0.7500    0.8182        12
          30     0.9333    0.7368    0.8235        19
          31     0.8947    0.8500    0.8718        20
          32     0.7778    0.7778    0.7778         9
          33     0.7143    0.5556    0.6250         9
          34     0.6667    0.3333    0.4444         6
          35     1.0000    1.0000    1.0000         5
          36     1.0000    1.0000    1.0000         3
          37     1.0000    1.0000    1.0000         1
          38     1.0000    0.7778    0.8750         9
          39     1.0000    1.0000    1.0000         9
          40     0.7500    0.7500    0.7500         4
          41     1.0000    1.0000    1.0000         9
          42     0.0000    0.0000    0.0000         1
          43     0.0000    0.0000    0.0000         4
          44     0.0000    0.0000    0.0000         6
          45     0.0000    0.0000    0.0000         3
          46     1.0000    0.1429    0.2500         7
          47     0.0000    0.0000    0.0000         1
          48     1.0000    0.7500    0.8571         4
          49     0.0000    0.0000    0.0000         3
          50     1.0000    0.3333    0.5000         3
          51     0.0000    0.0000    0.0000         2

    accuracy                         0.9357      2568
   macro avg     0.7653    0.6899    0.7088      2568
weighted avg     0.9315    0.9357    0.9303      2568


Macro average Test Precision, Recall and F1-Score...
(0.7652893902874466, 0.6899007113499673, 0.7088015817536455, None)

Micro average Test Precision, Recall and F1-Score...
(0.9357476635514018, 0.9357476635514018, 0.9357476635514018, None)

Embeddings:
Word_embeddings:8892
Train_doc_embeddings:6532
Test_doc_embeddings:2568
