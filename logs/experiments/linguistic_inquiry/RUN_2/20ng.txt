
==================== Torch Seed: 8842680077300

Model parameters

Layer: layer1.W0 | Size: torch.Size([61603, 200])
Layer: layer2.W0 | Size: torch.Size([200, 20])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  61603         20            10183           1131            7532

Epoch:0001, train_loss=3.06377, train_acc=0.04596, val_loss=2.99458, val_acc=0.14943, time=3.67600
Epoch:0002, train_loss=2.98654, train_acc=0.14014, val_loss=2.98821, val_acc=0.33952, time=3.78599
Epoch:0003, train_loss=2.92628, train_acc=0.31955, val_loss=2.98280, val_acc=0.52166, time=3.70098
Epoch:0004, train_loss=2.87505, train_acc=0.53157, val_loss=2.97811, val_acc=0.63042, time=3.73199
Epoch:0005, train_loss=2.83029, train_acc=0.65580, val_loss=2.97391, val_acc=0.70292, time=3.82100
Epoch:0006, train_loss=2.78999, train_acc=0.72650, val_loss=2.97002, val_acc=0.75950, time=3.75999
Epoch:0007, train_loss=2.75265, train_acc=0.78513, val_loss=2.96640, val_acc=0.80018, time=3.53999
Epoch:0008, train_loss=2.71812, train_acc=0.84130, val_loss=2.96315, val_acc=0.83643, time=3.60100
Epoch:0009, train_loss=2.68717, train_acc=0.87951, val_loss=2.96033, val_acc=0.85500, time=3.59599
Epoch:0010, train_loss=2.66042, train_acc=0.90592, val_loss=2.95796, val_acc=0.86914, time=3.70599
Epoch:0011, train_loss=2.63788, train_acc=0.92271, val_loss=2.95598, val_acc=0.88859, time=3.85099
Epoch:0012, train_loss=2.61910, train_acc=0.93145, val_loss=2.95434, val_acc=0.89390, time=3.79298
Epoch:0013, train_loss=2.60346, train_acc=0.93843, val_loss=2.95297, val_acc=0.90186, time=3.87298
Epoch:0014, train_loss=2.59041, train_acc=0.94422, val_loss=2.95183, val_acc=0.90539, time=3.89499
Epoch:0015, train_loss=2.57952, train_acc=0.95198, val_loss=2.95088, val_acc=0.90981, time=3.69900
Epoch:0016, train_loss=2.57040, train_acc=0.95561, val_loss=2.95009, val_acc=0.91070, time=3.78400
Epoch:0017, train_loss=2.56270, train_acc=0.95875, val_loss=2.94943, val_acc=0.91335, time=3.77298
Epoch:0018, train_loss=2.55609, train_acc=0.96219, val_loss=2.94886, val_acc=0.91512, time=4.00300
Epoch:0019, train_loss=2.55035, train_acc=0.96514, val_loss=2.94838, val_acc=0.91689, time=3.75000
Epoch:0020, train_loss=2.54536, train_acc=0.96769, val_loss=2.94797, val_acc=0.91954, time=3.88499
Epoch:0021, train_loss=2.54106, train_acc=0.97024, val_loss=2.94763, val_acc=0.92131, time=3.55998
Epoch:0022, train_loss=2.53738, train_acc=0.97221, val_loss=2.94735, val_acc=0.92131, time=3.64200
Epoch:0023, train_loss=2.53422, train_acc=0.97368, val_loss=2.94712, val_acc=0.92131, time=3.96598
Epoch:0024, train_loss=2.53149, train_acc=0.97437, val_loss=2.94692, val_acc=0.92396, time=3.90499
Epoch:0025, train_loss=2.52909, train_acc=0.97614, val_loss=2.94674, val_acc=0.92485, time=3.89900
Epoch:0026, train_loss=2.52695, train_acc=0.97810, val_loss=2.94659, val_acc=0.92573, time=3.91900
Epoch:0027, train_loss=2.52501, train_acc=0.98026, val_loss=2.94646, val_acc=0.92308, time=3.73397
Epoch:0028, train_loss=2.52326, train_acc=0.98134, val_loss=2.94634, val_acc=0.92131, time=3.68799
Epoch:0029, train_loss=2.52168, train_acc=0.98301, val_loss=2.94624, val_acc=0.92396, time=3.92200
Epoch:0030, train_loss=2.52027, train_acc=0.98419, val_loss=2.94616, val_acc=0.92485, time=3.92599
Epoch:0031, train_loss=2.51899, train_acc=0.98556, val_loss=2.94610, val_acc=0.92485, time=3.93099
Epoch:0032, train_loss=2.51785, train_acc=0.98664, val_loss=2.94604, val_acc=0.92661, time=3.89598
Epoch:0033, train_loss=2.51680, train_acc=0.98743, val_loss=2.94600, val_acc=0.92661, time=3.75899
Epoch:0034, train_loss=2.51584, train_acc=0.98812, val_loss=2.94597, val_acc=0.92573, time=3.90901
Epoch:0035, train_loss=2.51495, train_acc=0.98900, val_loss=2.94594, val_acc=0.92573, time=3.61000
Epoch:0036, train_loss=2.51412, train_acc=0.98969, val_loss=2.94593, val_acc=0.92573, time=3.69299
Epoch:0037, train_loss=2.51334, train_acc=0.99028, val_loss=2.94591, val_acc=0.92396, time=3.67298
Epoch:0038, train_loss=2.51263, train_acc=0.99087, val_loss=2.94591, val_acc=0.92661, time=3.73499
Epoch:0039, train_loss=2.51198, train_acc=0.99175, val_loss=2.94590, val_acc=0.92485, time=3.85198
Epoch:0040, train_loss=2.51137, train_acc=0.99263, val_loss=2.94590, val_acc=0.92485, time=3.71700
Epoch:0041, train_loss=2.51082, train_acc=0.99283, val_loss=2.94590, val_acc=0.92573, time=3.60600
Epoch:0042, train_loss=2.51030, train_acc=0.99313, val_loss=2.94590, val_acc=0.92573, time=3.63400
Epoch:0043, train_loss=2.50983, train_acc=0.99362, val_loss=2.94590, val_acc=0.92485, time=3.61399
Epoch:0044, train_loss=2.50938, train_acc=0.99440, val_loss=2.94590, val_acc=0.92485, time=3.79899
Epoch:0045, train_loss=2.50896, train_acc=0.99499, val_loss=2.94589, val_acc=0.92750, time=3.70300
Epoch:0046, train_loss=2.50857, train_acc=0.99568, val_loss=2.94589, val_acc=0.92750, time=3.75100
Epoch:0047, train_loss=2.50820, train_acc=0.99578, val_loss=2.94589, val_acc=0.92750, time=3.76299
Epoch:0048, train_loss=2.50786, train_acc=0.99588, val_loss=2.94588, val_acc=0.92661, time=3.63099
Epoch:0049, train_loss=2.50755, train_acc=0.99607, val_loss=2.94588, val_acc=0.92750, time=3.69600
Epoch:0050, train_loss=2.50725, train_acc=0.99646, val_loss=2.94589, val_acc=0.92661, time=3.72701
Epoch:0051, train_loss=2.50698, train_acc=0.99666, val_loss=2.94589, val_acc=0.92661, time=3.80598
Epoch:0052, train_loss=2.50672, train_acc=0.99705, val_loss=2.94589, val_acc=0.92573, time=3.59599
Early stopping...

Optimization Finished!

Test set results: loss= 2.69880, accuracy= 0.84732, time= 1.19301

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8703    0.9271    0.8978       398
           1     0.7230    0.7584    0.7403       389
           2     0.8615    0.7994    0.8293       319
           3     0.9164    0.8864    0.9012       396
           4     0.8514    0.6839    0.7585       310
           5     0.7843    0.6827    0.7300       394
           6     0.9618    0.9521    0.9570       397
           7     0.9045    0.9137    0.9091       394
           8     0.9051    0.9394    0.9219       396
           9     0.9576    0.9624    0.9600       399
          10     0.9837    0.9601    0.9717       376
          11     0.8047    0.7823    0.7933       395
          12     0.7408    0.8282    0.7821       390
          13     0.8037    0.7710    0.7870       393
          14     0.6963    0.7781    0.7349       392
          15     0.8010    0.8956    0.8457       364
          16     0.8814    0.8636    0.8724       396
          17     0.8281    0.8260    0.8270       385
          18     0.9435    0.9648    0.9540       398
          19     0.6975    0.6614    0.6789       251

    accuracy                         0.8473      7532
   macro avg     0.8458    0.8418    0.8426      7532
weighted avg     0.8487    0.8473    0.8469      7532


Macro average Test Precision, Recall and F1-Score...
(0.8458367073382819, 0.8418261431248615, 0.8426100826266382, None)

Micro average Test Precision, Recall and F1-Score...
(0.8473181093998938, 0.8473181093998938, 0.8473181093998938, None)

Embeddings:
Word_embeddings: 42757
Train_doc_embeddings: 11314
Test_doc_embeddings: 7532

Elapsed time is 208.820463 seconds.
