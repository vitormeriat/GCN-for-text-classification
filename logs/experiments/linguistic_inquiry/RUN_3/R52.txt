
==================== Torch Seed: 8276898541900

Model parameters

Layer: layer1.W0 | Size: torch.Size([17992, 200])
Layer: layer2.W0 | Size: torch.Size([200, 52])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  17992         52             5879            653            2568

Epoch:0001, train_loss=4.18998, train_acc=0.00170, val_loss=3.93989, val_acc=0.24196, time=0.39200
Epoch:0002, train_loss=3.85629, train_acc=0.23014, val_loss=3.90836, val_acc=0.50995, time=0.39701
Epoch:0003, train_loss=3.57253, train_acc=0.49379, val_loss=3.88413, val_acc=0.62940, time=0.35901
Epoch:0004, train_loss=3.35493, train_acc=0.60827, val_loss=3.86880, val_acc=0.66616, time=0.41800
Epoch:0005, train_loss=3.21601, train_acc=0.65096, val_loss=3.86046, val_acc=0.67994, time=0.36200
Epoch:0006, train_loss=3.13754, train_acc=0.67324, val_loss=3.85559, val_acc=0.70904, time=0.41201
Epoch:0007, train_loss=3.08897, train_acc=0.70097, val_loss=3.85198, val_acc=0.72282, time=0.53100
Epoch:0008, train_loss=3.05131, train_acc=0.72972, val_loss=3.84879, val_acc=0.74885, time=0.51600
Epoch:0009, train_loss=3.01784, train_acc=0.75625, val_loss=3.84582, val_acc=0.76110, time=0.43899
Epoch:0010, train_loss=2.98738, train_acc=0.78432, val_loss=3.84307, val_acc=0.78867, time=0.57000
Epoch:0011, train_loss=2.96005, train_acc=0.80847, val_loss=3.84056, val_acc=0.80245, time=0.38501
Epoch:0012, train_loss=2.93580, train_acc=0.82803, val_loss=3.83832, val_acc=0.81317, time=0.35799
Epoch:0013, train_loss=2.91427, train_acc=0.84538, val_loss=3.83633, val_acc=0.82542, time=0.37599
Epoch:0014, train_loss=2.89507, train_acc=0.85780, val_loss=3.83457, val_acc=0.83920, time=0.38201
Epoch:0015, train_loss=2.87776, train_acc=0.86852, val_loss=3.83302, val_acc=0.85452, time=0.35600
Epoch:0016, train_loss=2.86197, train_acc=0.88076, val_loss=3.83167, val_acc=0.87902, time=0.40399
Epoch:0017, train_loss=2.84754, train_acc=0.89131, val_loss=3.83053, val_acc=0.88821, time=0.35400
Epoch:0018, train_loss=2.83451, train_acc=0.90236, val_loss=3.82957, val_acc=0.89433, time=0.36800
Epoch:0019, train_loss=2.82284, train_acc=0.91036, val_loss=3.82875, val_acc=0.90199, time=0.39398
Epoch:0020, train_loss=2.81240, train_acc=0.91954, val_loss=3.82803, val_acc=0.90505, time=0.38401
Epoch:0021, train_loss=2.80299, train_acc=0.92584, val_loss=3.82739, val_acc=0.90658, time=0.40600
Epoch:0022, train_loss=2.79444, train_acc=0.93077, val_loss=3.82679, val_acc=0.90352, time=0.39999
Epoch:0023, train_loss=2.78659, train_acc=0.93315, val_loss=3.82624, val_acc=0.90505, time=0.35900
Epoch:0024, train_loss=2.77929, train_acc=0.93519, val_loss=3.82570, val_acc=0.90658, time=0.40701
Epoch:0025, train_loss=2.77243, train_acc=0.93774, val_loss=3.82517, val_acc=0.90505, time=0.36601
Epoch:0026, train_loss=2.76595, train_acc=0.94098, val_loss=3.82466, val_acc=0.90812, time=0.38901
Epoch:0027, train_loss=2.75981, train_acc=0.94540, val_loss=3.82417, val_acc=0.90812, time=0.49399
Epoch:0028, train_loss=2.75404, train_acc=0.94761, val_loss=3.82370, val_acc=0.91118, time=0.37000
Epoch:0029, train_loss=2.74863, train_acc=0.94965, val_loss=3.82326, val_acc=0.91577, time=0.35301
Epoch:0030, train_loss=2.74361, train_acc=0.95288, val_loss=3.82285, val_acc=0.91577, time=0.35300
Epoch:0031, train_loss=2.73897, train_acc=0.95526, val_loss=3.82247, val_acc=0.91424, time=0.37400
Epoch:0032, train_loss=2.73471, train_acc=0.95952, val_loss=3.82213, val_acc=0.91577, time=0.48600
Epoch:0033, train_loss=2.73082, train_acc=0.96241, val_loss=3.82183, val_acc=0.91730, time=0.35300
Epoch:0034, train_loss=2.72726, train_acc=0.96411, val_loss=3.82155, val_acc=0.92649, time=0.40800
Epoch:0035, train_loss=2.72397, train_acc=0.96700, val_loss=3.82130, val_acc=0.92802, time=0.37599
Epoch:0036, train_loss=2.72090, train_acc=0.96955, val_loss=3.82106, val_acc=0.92649, time=0.36000
Epoch:0037, train_loss=2.71801, train_acc=0.97091, val_loss=3.82083, val_acc=0.92802, time=0.42201
Epoch:0038, train_loss=2.71526, train_acc=0.97329, val_loss=3.82062, val_acc=0.92802, time=0.35501
Epoch:0039, train_loss=2.71266, train_acc=0.97466, val_loss=3.82041, val_acc=0.92649, time=0.44099
Epoch:0040, train_loss=2.71020, train_acc=0.97738, val_loss=3.82022, val_acc=0.92649, time=0.35300
Epoch:0041, train_loss=2.70787, train_acc=0.97857, val_loss=3.82003, val_acc=0.92802, time=0.36099
Epoch:0042, train_loss=2.70566, train_acc=0.97925, val_loss=3.81986, val_acc=0.92802, time=0.35501
Epoch:0043, train_loss=2.70357, train_acc=0.98027, val_loss=3.81968, val_acc=0.92802, time=0.35399
Epoch:0044, train_loss=2.70158, train_acc=0.98231, val_loss=3.81951, val_acc=0.92956, time=0.35498
Epoch:0045, train_loss=2.69971, train_acc=0.98282, val_loss=3.81934, val_acc=0.92956, time=0.36700
Epoch:0046, train_loss=2.69793, train_acc=0.98316, val_loss=3.81918, val_acc=0.92956, time=0.38299
Epoch:0047, train_loss=2.69626, train_acc=0.98316, val_loss=3.81902, val_acc=0.93109, time=0.56300
Epoch:0048, train_loss=2.69469, train_acc=0.98435, val_loss=3.81887, val_acc=0.93109, time=0.36199
Epoch:0049, train_loss=2.69321, train_acc=0.98571, val_loss=3.81872, val_acc=0.93109, time=0.35200
Epoch:0050, train_loss=2.69183, train_acc=0.98605, val_loss=3.81857, val_acc=0.93109, time=0.41601
Epoch:0051, train_loss=2.69054, train_acc=0.98690, val_loss=3.81844, val_acc=0.93109, time=0.47901
Epoch:0052, train_loss=2.68932, train_acc=0.98724, val_loss=3.81831, val_acc=0.93109, time=0.50900
Epoch:0053, train_loss=2.68816, train_acc=0.98843, val_loss=3.81818, val_acc=0.93109, time=0.42401
Epoch:0054, train_loss=2.68707, train_acc=0.98860, val_loss=3.81807, val_acc=0.93415, time=0.45999
Epoch:0055, train_loss=2.68603, train_acc=0.98911, val_loss=3.81796, val_acc=0.93568, time=0.35600
Epoch:0056, train_loss=2.68504, train_acc=0.98962, val_loss=3.81785, val_acc=0.93568, time=0.35501
Epoch:0057, train_loss=2.68410, train_acc=0.98979, val_loss=3.81776, val_acc=0.93568, time=0.48499
Epoch:0058, train_loss=2.68320, train_acc=0.99047, val_loss=3.81767, val_acc=0.93568, time=0.40600
Epoch:0059, train_loss=2.68234, train_acc=0.99133, val_loss=3.81760, val_acc=0.93415, time=0.41401
Epoch:0060, train_loss=2.68152, train_acc=0.99167, val_loss=3.81752, val_acc=0.93415, time=0.39799
Epoch:0061, train_loss=2.68074, train_acc=0.99252, val_loss=3.81746, val_acc=0.93415, time=0.35300
Epoch:0062, train_loss=2.68001, train_acc=0.99286, val_loss=3.81740, val_acc=0.93568, time=0.39600
Epoch:0063, train_loss=2.67931, train_acc=0.99337, val_loss=3.81734, val_acc=0.93568, time=0.35299
Epoch:0064, train_loss=2.67865, train_acc=0.99388, val_loss=3.81729, val_acc=0.93568, time=0.35400
Epoch:0065, train_loss=2.67803, train_acc=0.99405, val_loss=3.81724, val_acc=0.93568, time=0.39101
Epoch:0066, train_loss=2.67745, train_acc=0.99439, val_loss=3.81720, val_acc=0.93568, time=0.35400
Epoch:0067, train_loss=2.67690, train_acc=0.99439, val_loss=3.81715, val_acc=0.93568, time=0.35599
Epoch:0068, train_loss=2.67637, train_acc=0.99473, val_loss=3.81711, val_acc=0.93415, time=0.44900
Epoch:0069, train_loss=2.67588, train_acc=0.99456, val_loss=3.81707, val_acc=0.93415, time=0.40100
Epoch:0070, train_loss=2.67541, train_acc=0.99490, val_loss=3.81702, val_acc=0.93415, time=0.38400
Epoch:0071, train_loss=2.67496, train_acc=0.99473, val_loss=3.81698, val_acc=0.93415, time=0.42600
Epoch:0072, train_loss=2.67453, train_acc=0.99473, val_loss=3.81694, val_acc=0.93415, time=0.44700
Epoch:0073, train_loss=2.67412, train_acc=0.99473, val_loss=3.81689, val_acc=0.93568, time=0.41398
Epoch:0074, train_loss=2.67372, train_acc=0.99490, val_loss=3.81685, val_acc=0.93568, time=0.40401
Epoch:0075, train_loss=2.67334, train_acc=0.99524, val_loss=3.81681, val_acc=0.93568, time=0.38401
Epoch:0076, train_loss=2.67298, train_acc=0.99541, val_loss=3.81676, val_acc=0.93568, time=0.42501
Epoch:0077, train_loss=2.67263, train_acc=0.99558, val_loss=3.81672, val_acc=0.93721, time=0.38999
Epoch:0078, train_loss=2.67229, train_acc=0.99592, val_loss=3.81668, val_acc=0.93568, time=0.40701
Epoch:0079, train_loss=2.67197, train_acc=0.99609, val_loss=3.81665, val_acc=0.93568, time=0.35400
Epoch:0080, train_loss=2.67166, train_acc=0.99643, val_loss=3.81661, val_acc=0.93568, time=0.53100
Epoch:0081, train_loss=2.67136, train_acc=0.99660, val_loss=3.81658, val_acc=0.93721, time=0.35499
Epoch:0082, train_loss=2.67107, train_acc=0.99660, val_loss=3.81655, val_acc=0.93721, time=0.44601
Epoch:0083, train_loss=2.67080, train_acc=0.99677, val_loss=3.81652, val_acc=0.93721, time=0.36798
Epoch:0084, train_loss=2.67053, train_acc=0.99677, val_loss=3.81649, val_acc=0.93721, time=0.38201
Epoch:0085, train_loss=2.67028, train_acc=0.99677, val_loss=3.81647, val_acc=0.93721, time=0.38500
Epoch:0086, train_loss=2.67004, train_acc=0.99694, val_loss=3.81645, val_acc=0.93721, time=0.51101
Epoch:0087, train_loss=2.66980, train_acc=0.99694, val_loss=3.81643, val_acc=0.93721, time=0.41300
Epoch:0088, train_loss=2.66958, train_acc=0.99694, val_loss=3.81641, val_acc=0.93721, time=0.41300
Epoch:0089, train_loss=2.66937, train_acc=0.99711, val_loss=3.81639, val_acc=0.93721, time=0.38099
Epoch:0090, train_loss=2.66916, train_acc=0.99711, val_loss=3.81637, val_acc=0.93721, time=0.45700
Epoch:0091, train_loss=2.66897, train_acc=0.99728, val_loss=3.81636, val_acc=0.93721, time=0.40899
Epoch:0092, train_loss=2.66878, train_acc=0.99728, val_loss=3.81634, val_acc=0.93721, time=0.44099
Epoch:0093, train_loss=2.66860, train_acc=0.99745, val_loss=3.81632, val_acc=0.93721, time=0.54400
Epoch:0094, train_loss=2.66842, train_acc=0.99762, val_loss=3.81631, val_acc=0.93721, time=0.49201
Epoch:0095, train_loss=2.66826, train_acc=0.99813, val_loss=3.81630, val_acc=0.93721, time=0.35401
Epoch:0096, train_loss=2.66810, train_acc=0.99813, val_loss=3.81628, val_acc=0.93874, time=0.35600
Epoch:0097, train_loss=2.66795, train_acc=0.99813, val_loss=3.81627, val_acc=0.93874, time=0.43998
Epoch:0098, train_loss=2.66780, train_acc=0.99813, val_loss=3.81626, val_acc=0.93874, time=0.37301
Epoch:0099, train_loss=2.66766, train_acc=0.99813, val_loss=3.81625, val_acc=0.93874, time=0.43300
Epoch:0100, train_loss=2.66752, train_acc=0.99796, val_loss=3.81624, val_acc=0.93874, time=0.35300
Epoch:0101, train_loss=2.66739, train_acc=0.99796, val_loss=3.81622, val_acc=0.93874, time=0.35300
Epoch:0102, train_loss=2.66726, train_acc=0.99796, val_loss=3.81621, val_acc=0.93874, time=0.44301
Epoch:0103, train_loss=2.66714, train_acc=0.99796, val_loss=3.81621, val_acc=0.93874, time=0.35101
Epoch:0104, train_loss=2.66702, train_acc=0.99796, val_loss=3.81620, val_acc=0.93874, time=0.38199
Epoch:0105, train_loss=2.66691, train_acc=0.99813, val_loss=3.81619, val_acc=0.93874, time=0.46498
Epoch:0106, train_loss=2.66680, train_acc=0.99830, val_loss=3.81618, val_acc=0.93874, time=0.35199
Epoch:0107, train_loss=2.66669, train_acc=0.99830, val_loss=3.81618, val_acc=0.93874, time=0.52000
Epoch:0108, train_loss=2.66658, train_acc=0.99830, val_loss=3.81617, val_acc=0.93874, time=0.38001
Epoch:0109, train_loss=2.66648, train_acc=0.99830, val_loss=3.81617, val_acc=0.94028, time=0.41999
Epoch:0110, train_loss=2.66638, train_acc=0.99830, val_loss=3.81617, val_acc=0.94028, time=0.37000
Epoch:0111, train_loss=2.66629, train_acc=0.99830, val_loss=3.81616, val_acc=0.94028, time=0.35001
Epoch:0112, train_loss=2.66619, train_acc=0.99830, val_loss=3.81616, val_acc=0.94028, time=0.53900
Epoch:0113, train_loss=2.66610, train_acc=0.99830, val_loss=3.81616, val_acc=0.94028, time=0.39700
Epoch:0114, train_loss=2.66602, train_acc=0.99830, val_loss=3.81615, val_acc=0.94028, time=0.39500
Epoch:0115, train_loss=2.66593, train_acc=0.99830, val_loss=3.81615, val_acc=0.94028, time=0.35401
Epoch:0116, train_loss=2.66585, train_acc=0.99830, val_loss=3.81615, val_acc=0.94028, time=0.35201
Epoch:0117, train_loss=2.66577, train_acc=0.99830, val_loss=3.81615, val_acc=0.94028, time=0.35499
Epoch:0118, train_loss=2.66569, train_acc=0.99830, val_loss=3.81614, val_acc=0.94028, time=0.37201
Epoch:0119, train_loss=2.66561, train_acc=0.99830, val_loss=3.81614, val_acc=0.94028, time=0.41600
Epoch:0120, train_loss=2.66554, train_acc=0.99830, val_loss=3.81614, val_acc=0.94028, time=0.48700
Epoch:0121, train_loss=2.66546, train_acc=0.99830, val_loss=3.81614, val_acc=0.93874, time=0.36701
Epoch:0122, train_loss=2.66539, train_acc=0.99830, val_loss=3.81613, val_acc=0.93874, time=0.39999
Epoch:0123, train_loss=2.66532, train_acc=0.99830, val_loss=3.81613, val_acc=0.93874, time=0.35501
Epoch:0124, train_loss=2.66526, train_acc=0.99830, val_loss=3.81613, val_acc=0.93874, time=0.35200
Epoch:0125, train_loss=2.66519, train_acc=0.99830, val_loss=3.81613, val_acc=0.94028, time=0.38700
Epoch:0126, train_loss=2.66513, train_acc=0.99830, val_loss=3.81612, val_acc=0.94028, time=0.35800
Epoch:0127, train_loss=2.66506, train_acc=0.99830, val_loss=3.81612, val_acc=0.94028, time=0.39500
Epoch:0128, train_loss=2.66500, train_acc=0.99830, val_loss=3.81612, val_acc=0.94028, time=0.48300
Epoch:0129, train_loss=2.66494, train_acc=0.99830, val_loss=3.81612, val_acc=0.94028, time=0.47199
Epoch:0130, train_loss=2.66488, train_acc=0.99830, val_loss=3.81611, val_acc=0.94028, time=0.41200
Epoch:0131, train_loss=2.66483, train_acc=0.99830, val_loss=3.81611, val_acc=0.94028, time=0.35100
Epoch:0132, train_loss=2.66477, train_acc=0.99830, val_loss=3.81611, val_acc=0.94028, time=0.41600
Epoch:0133, train_loss=2.66472, train_acc=0.99830, val_loss=3.81611, val_acc=0.94028, time=0.37200
Epoch:0134, train_loss=2.66466, train_acc=0.99847, val_loss=3.81611, val_acc=0.94028, time=0.39900
Epoch:0135, train_loss=2.66461, train_acc=0.99847, val_loss=3.81611, val_acc=0.94028, time=0.36100
Epoch:0136, train_loss=2.66456, train_acc=0.99847, val_loss=3.81610, val_acc=0.94028, time=0.35201
Epoch:0137, train_loss=2.66451, train_acc=0.99847, val_loss=3.81610, val_acc=0.94028, time=0.37498
Epoch:0138, train_loss=2.66446, train_acc=0.99847, val_loss=3.81610, val_acc=0.94028, time=0.38901
Epoch:0139, train_loss=2.66441, train_acc=0.99847, val_loss=3.81610, val_acc=0.94028, time=0.35400
Epoch:0140, train_loss=2.66436, train_acc=0.99847, val_loss=3.81610, val_acc=0.94028, time=0.36900
Epoch:0141, train_loss=2.66432, train_acc=0.99847, val_loss=3.81610, val_acc=0.94028, time=0.39800
Epoch:0142, train_loss=2.66427, train_acc=0.99847, val_loss=3.81610, val_acc=0.94028, time=0.41301
Epoch:0143, train_loss=2.66423, train_acc=0.99847, val_loss=3.81609, val_acc=0.94028, time=0.38699
Epoch:0144, train_loss=2.66418, train_acc=0.99847, val_loss=3.81609, val_acc=0.94028, time=0.37400
Epoch:0145, train_loss=2.66414, train_acc=0.99847, val_loss=3.81609, val_acc=0.94028, time=0.39299
Epoch:0146, train_loss=2.66410, train_acc=0.99847, val_loss=3.81609, val_acc=0.94028, time=0.36899
Epoch:0147, train_loss=2.66406, train_acc=0.99847, val_loss=3.81609, val_acc=0.94028, time=0.37400
Epoch:0148, train_loss=2.66402, train_acc=0.99847, val_loss=3.81609, val_acc=0.94028, time=0.40201
Epoch:0149, train_loss=2.66398, train_acc=0.99847, val_loss=3.81609, val_acc=0.94028, time=0.36301
Epoch:0150, train_loss=2.66394, train_acc=0.99847, val_loss=3.81609, val_acc=0.94028, time=0.39500
Epoch:0151, train_loss=2.66390, train_acc=0.99847, val_loss=3.81608, val_acc=0.94028, time=0.47099
Epoch:0152, train_loss=2.66386, train_acc=0.99847, val_loss=3.81608, val_acc=0.94028, time=0.50900
Epoch:0153, train_loss=2.66382, train_acc=0.99847, val_loss=3.81608, val_acc=0.94028, time=0.44800
Epoch:0154, train_loss=2.66379, train_acc=0.99847, val_loss=3.81608, val_acc=0.94028, time=0.37001
Epoch:0155, train_loss=2.66375, train_acc=0.99847, val_loss=3.81608, val_acc=0.94028, time=0.40699
Epoch:0156, train_loss=2.66372, train_acc=0.99847, val_loss=3.81608, val_acc=0.94028, time=0.37901
Epoch:0157, train_loss=2.66368, train_acc=0.99847, val_loss=3.81608, val_acc=0.94028, time=0.35800
Epoch:0158, train_loss=2.66365, train_acc=0.99847, val_loss=3.81608, val_acc=0.94028, time=0.41601
Epoch:0159, train_loss=2.66361, train_acc=0.99847, val_loss=3.81608, val_acc=0.94028, time=0.41200
Epoch:0160, train_loss=2.66358, train_acc=0.99847, val_loss=3.81608, val_acc=0.94028, time=0.37299
Epoch:0161, train_loss=2.66355, train_acc=0.99847, val_loss=3.81608, val_acc=0.94181, time=0.41900
Epoch:0162, train_loss=2.66352, train_acc=0.99847, val_loss=3.81608, val_acc=0.94181, time=0.42901
Epoch:0163, train_loss=2.66349, train_acc=0.99847, val_loss=3.81608, val_acc=0.94181, time=0.41400
Epoch:0164, train_loss=2.66346, train_acc=0.99847, val_loss=3.81608, val_acc=0.94181, time=0.35101
Epoch:0165, train_loss=2.66343, train_acc=0.99847, val_loss=3.81608, val_acc=0.94181, time=0.35299
Epoch:0166, train_loss=2.66340, train_acc=0.99847, val_loss=3.81608, val_acc=0.94181, time=0.42800
Epoch:0167, train_loss=2.66337, train_acc=0.99847, val_loss=3.81608, val_acc=0.94181, time=0.42200
Epoch:0168, train_loss=2.66334, train_acc=0.99847, val_loss=3.81608, val_acc=0.94181, time=0.41499
Epoch:0169, train_loss=2.66331, train_acc=0.99847, val_loss=3.81608, val_acc=0.94181, time=0.38400
Early stopping...

Optimization Finished!

Test set results: loss= 3.44093, accuracy= 0.91783, time= 0.11100

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9587    0.9871    0.9727      1083
           1     0.8519    0.9504    0.8984       121
           2     0.9448    0.9339    0.9393       696
           3     1.0000    0.8667    0.9286        15
           4     0.7647    0.8667    0.8125        15
           5     1.0000    0.8235    0.9032        17
           6     0.8889    0.6667    0.7619        36
           7     0.8846    0.9200    0.9020        25
           8     1.0000    0.6842    0.8125        19
           9     0.7857    0.8462    0.8148        13
          10     0.7895    0.8621    0.8242        87
          11     0.9444    0.8500    0.8947        20
          12     0.7320    0.9467    0.8256        75
          13     0.8065    0.8929    0.8475        28
          14     1.0000    1.0000    1.0000         9
          15     0.9167    1.0000    0.9565        22
          16     0.8000    0.8000    0.8000         5
          17     0.9091    0.8333    0.8696        12
          18     0.8082    0.7284    0.7662        81
          19     0.8182    0.9000    0.8571        10
          20     0.6667    1.0000    0.8000         2
          21     0.9167    0.9167    0.9167        12
          22     1.0000    1.0000    1.0000         1
          23     0.8750    0.7778    0.8235         9
          24     0.8000    0.3333    0.4706        12
          25     0.7500    0.6000    0.6667         5
          26     1.0000    0.7000    0.8235        10
          27     1.0000    0.9167    0.9565        12
          28     0.0000    0.0000    0.0000         3
          29     1.0000    1.0000    1.0000         3
          30     0.7143    0.5556    0.6250         9
          31     1.0000    1.0000    1.0000         9
          32     0.8750    0.8750    0.8750         8
          33     0.9167    1.0000    0.9565        11
          34     1.0000    0.2000    0.3333         5
          35     1.0000    0.5000    0.6667         4
          36     0.6000    0.7500    0.6667         4
          37     1.0000    0.3333    0.5000         3
          38     1.0000    1.0000    1.0000         4
          39     0.0000    0.0000    0.0000         1
          40     0.2500    0.1667    0.2000         6
          41     1.0000    0.8182    0.9000        11
          42     0.8750    0.7778    0.8235         9
          43     0.0000    0.0000    0.0000         6
          44     0.5000    1.0000    0.6667         1
          45     0.0000    0.0000    0.0000         1
          46     0.0000    0.0000    0.0000         1
          47     1.0000    0.1429    0.2500         7
          48     0.0000    0.0000    0.0000         1
          49     0.0000    0.0000    0.0000         2
          50     0.0000    0.0000    0.0000         4
          51     0.0000    0.0000    0.0000         3

    accuracy                         0.9178      2568
   macro avg     0.7181    0.6485    0.6598      2568
weighted avg     0.9139    0.9178    0.9120      2568


Macro average Test Precision, Recall and F1-Score...
(0.7181357869356683, 0.648508190534482, 0.6597735729880662, None)

Micro average Test Precision, Recall and F1-Score...
(0.9178348909657321, 0.9178348909657321, 0.9178348909657321, None)

Embeddings:
Word_embeddings: 8892
Train_doc_embeddings: 6532
Test_doc_embeddings: 2568

Elapsed time is 69.560841 seconds.
