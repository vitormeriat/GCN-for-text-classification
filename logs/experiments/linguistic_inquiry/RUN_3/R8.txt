
==================== Torch Seed: 7978325611800

Model parameters

Layer: layer1.W0 | Size: torch.Size([15362, 200])
Layer: layer2.W0 | Size: torch.Size([200, 8])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  15362          8             4937            548            2189

Epoch:0001, train_loss=2.41969, train_acc=0.04618, val_loss=2.07719, val_acc=0.38321, time=0.41901
Epoch:0002, train_loss=2.04221, train_acc=0.37796, val_loss=2.05345, val_acc=0.61861, time=0.42202
Epoch:0003, train_loss=1.82800, train_acc=0.64290, val_loss=2.04324, val_acc=0.70255, time=0.41100
Epoch:0004, train_loss=1.73586, train_acc=0.72068, val_loss=2.03890, val_acc=0.72263, time=0.40601
Epoch:0005, train_loss=1.69376, train_acc=0.75106, val_loss=2.03602, val_acc=0.73723, time=0.35801
Epoch:0006, train_loss=1.66460, train_acc=0.77051, val_loss=2.03314, val_acc=0.76642, time=0.34300
Epoch:0007, train_loss=1.63585, train_acc=0.79806, val_loss=2.03012, val_acc=0.79562, time=0.39201
Epoch:0008, train_loss=1.60646, train_acc=0.82803, val_loss=2.02728, val_acc=0.82664, time=0.34700
Epoch:0009, train_loss=1.57916, train_acc=0.86267, val_loss=2.02492, val_acc=0.84307, time=0.41500
Epoch:0010, train_loss=1.55667, train_acc=0.89082, val_loss=2.02314, val_acc=0.86861, time=0.43001
Epoch:0011, train_loss=1.53965, train_acc=0.90905, val_loss=2.02182, val_acc=0.87409, time=0.33599
Epoch:0012, train_loss=1.52661, train_acc=0.92141, val_loss=2.02072, val_acc=0.88321, time=0.37902
Epoch:0013, train_loss=1.51560, train_acc=0.92830, val_loss=2.01969, val_acc=0.88869, time=0.35300
Epoch:0014, train_loss=1.50539, train_acc=0.93620, val_loss=2.01866, val_acc=0.89416, time=0.41500
Epoch:0015, train_loss=1.49549, train_acc=0.94430, val_loss=2.01761, val_acc=0.89781, time=0.33100
Epoch:0016, train_loss=1.48584, train_acc=0.94835, val_loss=2.01656, val_acc=0.90511, time=0.35301
Epoch:0017, train_loss=1.47665, train_acc=0.95483, val_loss=2.01558, val_acc=0.91058, time=0.31100
Epoch:0018, train_loss=1.46824, train_acc=0.95989, val_loss=2.01473, val_acc=0.91423, time=0.34000
Epoch:0019, train_loss=1.46090, train_acc=0.96577, val_loss=2.01404, val_acc=0.92518, time=0.40899
Epoch:0020, train_loss=1.45475, train_acc=0.97083, val_loss=2.01350, val_acc=0.92701, time=0.41401
Epoch:0021, train_loss=1.44978, train_acc=0.97610, val_loss=2.01309, val_acc=0.93248, time=0.34799
Epoch:0022, train_loss=1.44585, train_acc=0.97914, val_loss=2.01281, val_acc=0.93248, time=0.42899
Epoch:0023, train_loss=1.44279, train_acc=0.98076, val_loss=2.01262, val_acc=0.93431, time=0.36500
Epoch:0024, train_loss=1.44041, train_acc=0.98278, val_loss=2.01250, val_acc=0.93431, time=0.33799
Epoch:0025, train_loss=1.43854, train_acc=0.98319, val_loss=2.01243, val_acc=0.94161, time=0.37200
Epoch:0026, train_loss=1.43702, train_acc=0.98380, val_loss=2.01238, val_acc=0.94161, time=0.37300
Epoch:0027, train_loss=1.43575, train_acc=0.98501, val_loss=2.01234, val_acc=0.94343, time=0.33400
Epoch:0028, train_loss=1.43464, train_acc=0.98521, val_loss=2.01230, val_acc=0.93978, time=0.35602
Epoch:0029, train_loss=1.43363, train_acc=0.98643, val_loss=2.01227, val_acc=0.93978, time=0.42799
Epoch:0030, train_loss=1.43269, train_acc=0.98704, val_loss=2.01223, val_acc=0.93978, time=0.38301
Epoch:0031, train_loss=1.43178, train_acc=0.98683, val_loss=2.01218, val_acc=0.93978, time=0.36501
Epoch:0032, train_loss=1.43090, train_acc=0.98785, val_loss=2.01212, val_acc=0.93796, time=0.39200
Epoch:0033, train_loss=1.43003, train_acc=0.98886, val_loss=2.01206, val_acc=0.93978, time=0.35199
Epoch:0034, train_loss=1.42917, train_acc=0.98947, val_loss=2.01200, val_acc=0.93978, time=0.32801
Epoch:0035, train_loss=1.42834, train_acc=0.98947, val_loss=2.01193, val_acc=0.94161, time=0.31099
Epoch:0036, train_loss=1.42753, train_acc=0.99007, val_loss=2.01186, val_acc=0.94161, time=0.33902
Epoch:0037, train_loss=1.42676, train_acc=0.99109, val_loss=2.01178, val_acc=0.94161, time=0.33902
Epoch:0038, train_loss=1.42602, train_acc=0.99210, val_loss=2.01172, val_acc=0.94526, time=0.34598
Epoch:0039, train_loss=1.42533, train_acc=0.99251, val_loss=2.01165, val_acc=0.94526, time=0.38801
Epoch:0040, train_loss=1.42469, train_acc=0.99251, val_loss=2.01159, val_acc=0.94526, time=0.43001
Epoch:0041, train_loss=1.42409, train_acc=0.99311, val_loss=2.01153, val_acc=0.94708, time=0.41600
Epoch:0042, train_loss=1.42355, train_acc=0.99332, val_loss=2.01148, val_acc=0.94891, time=0.37299
Epoch:0043, train_loss=1.42305, train_acc=0.99413, val_loss=2.01143, val_acc=0.94891, time=0.41400
Epoch:0044, train_loss=1.42258, train_acc=0.99433, val_loss=2.01139, val_acc=0.94891, time=0.36600
Epoch:0045, train_loss=1.42216, train_acc=0.99453, val_loss=2.01135, val_acc=0.95255, time=0.35099
Epoch:0046, train_loss=1.42176, train_acc=0.99494, val_loss=2.01132, val_acc=0.95073, time=0.33001
Epoch:0047, train_loss=1.42138, train_acc=0.99473, val_loss=2.01129, val_acc=0.95073, time=0.37401
Epoch:0048, train_loss=1.42103, train_acc=0.99494, val_loss=2.01126, val_acc=0.95073, time=0.32602
Epoch:0049, train_loss=1.42069, train_acc=0.99534, val_loss=2.01124, val_acc=0.95255, time=0.31602
Epoch:0050, train_loss=1.42037, train_acc=0.99534, val_loss=2.01122, val_acc=0.95255, time=0.38699
Epoch:0051, train_loss=1.42008, train_acc=0.99554, val_loss=2.01120, val_acc=0.95255, time=0.39400
Epoch:0052, train_loss=1.41979, train_acc=0.99595, val_loss=2.01118, val_acc=0.95255, time=0.35203
Epoch:0053, train_loss=1.41952, train_acc=0.99635, val_loss=2.01116, val_acc=0.95255, time=0.37497
Epoch:0054, train_loss=1.41926, train_acc=0.99635, val_loss=2.01115, val_acc=0.95255, time=0.34001
Epoch:0055, train_loss=1.41902, train_acc=0.99656, val_loss=2.01114, val_acc=0.95255, time=0.31300
Epoch:0056, train_loss=1.41879, train_acc=0.99656, val_loss=2.01113, val_acc=0.95255, time=0.35199
Epoch:0057, train_loss=1.41857, train_acc=0.99656, val_loss=2.01112, val_acc=0.95255, time=0.31700
Epoch:0058, train_loss=1.41836, train_acc=0.99676, val_loss=2.01111, val_acc=0.95438, time=0.34700
Epoch:0059, train_loss=1.41816, train_acc=0.99696, val_loss=2.01111, val_acc=0.95255, time=0.40501
Epoch:0060, train_loss=1.41797, train_acc=0.99696, val_loss=2.01110, val_acc=0.95255, time=0.41500
Epoch:0061, train_loss=1.41780, train_acc=0.99716, val_loss=2.01110, val_acc=0.95438, time=0.33400
Epoch:0062, train_loss=1.41763, train_acc=0.99737, val_loss=2.01110, val_acc=0.95438, time=0.39601
Epoch:0063, train_loss=1.41747, train_acc=0.99737, val_loss=2.01110, val_acc=0.95438, time=0.35600
Epoch:0064, train_loss=1.41732, train_acc=0.99737, val_loss=2.01110, val_acc=0.95438, time=0.33402
Epoch:0065, train_loss=1.41718, train_acc=0.99757, val_loss=2.01110, val_acc=0.95438, time=0.29901
Epoch:0066, train_loss=1.41704, train_acc=0.99757, val_loss=2.01110, val_acc=0.95438, time=0.38299
Epoch:0067, train_loss=1.41691, train_acc=0.99757, val_loss=2.01110, val_acc=0.95438, time=0.34799
Epoch:0068, train_loss=1.41678, train_acc=0.99757, val_loss=2.01110, val_acc=0.95438, time=0.31300
Early stopping...

Optimization Finished!

Test set results: loss= 1.80551, accuracy= 0.95340, time= 0.10699

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9792    0.9454    0.9620       696
           1     0.9666    0.9898    0.9781      1083
           2     0.8434    0.9333    0.8861        75
           3     0.9008    0.9752    0.9365       121
           4     0.8172    0.8736    0.8444        87
           5     0.9104    0.7531    0.8243        81
           6     0.9583    0.6389    0.7667        36
           7     0.9000    0.9000    0.9000        10

    accuracy                         0.9534      2189
   macro avg     0.9095    0.8762    0.8873      2189
weighted avg     0.9543    0.9534    0.9527      2189


Macro average Test Precision, Recall and F1-Score...
(0.9094906905727487, 0.876165474926391, 0.8872637268981313, None)

Micro average Test Precision, Recall and F1-Score...
(0.9534033805390589, 0.9534033805390589, 0.9534033805390589, None)

Embeddings:
Word_embeddings: 7688
Train_doc_embeddings: 5485
Test_doc_embeddings: 2189

Elapsed time is 26.235912 seconds.
