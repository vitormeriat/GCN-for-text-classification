
==================== Torch Seed: 7907830666500

Model parameters

Layer: layer1.W0 | Size: torch.Size([15362, 200])
Layer: layer2.W0 | Size: torch.Size([200, 8])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  15362          8             4937            548            2189

Epoch:0001, train_loss=2.01638, train_acc=0.45048, val_loss=2.05325, val_acc=0.63869, time=0.35600
Epoch:0002, train_loss=1.83746, train_acc=0.66336, val_loss=2.04153, val_acc=0.70803, time=0.37400
Epoch:0003, train_loss=1.73021, train_acc=0.73932, val_loss=2.03352, val_acc=0.76642, time=0.36500
Epoch:0004, train_loss=1.65425, train_acc=0.80109, val_loss=2.02820, val_acc=0.81022, time=0.41201
Epoch:0005, train_loss=1.60215, train_acc=0.85031, val_loss=2.02452, val_acc=0.84307, time=0.37100
Epoch:0006, train_loss=1.56593, train_acc=0.89103, val_loss=2.02176, val_acc=0.86314, time=0.46801
Epoch:0007, train_loss=1.53908, train_acc=0.91229, val_loss=2.01957, val_acc=0.89234, time=0.43800
Epoch:0008, train_loss=1.51828, train_acc=0.92850, val_loss=2.01785, val_acc=0.90876, time=0.39399
Epoch:0009, train_loss=1.50180, train_acc=0.93802, val_loss=2.01649, val_acc=0.91423, time=0.40503
Epoch:0010, train_loss=1.48847, train_acc=0.94653, val_loss=2.01542, val_acc=0.92336, time=0.41800
Epoch:0011, train_loss=1.47742, train_acc=0.95240, val_loss=2.01457, val_acc=0.93248, time=0.33600
Epoch:0012, train_loss=1.46812, train_acc=0.95929, val_loss=2.01392, val_acc=0.93248, time=0.36999
Epoch:0013, train_loss=1.46036, train_acc=0.96557, val_loss=2.01342, val_acc=0.93796, time=0.37200
Epoch:0014, train_loss=1.45410, train_acc=0.97225, val_loss=2.01306, val_acc=0.93796, time=0.30502
Epoch:0015, train_loss=1.44924, train_acc=0.97630, val_loss=2.01279, val_acc=0.93978, time=0.37700
Epoch:0016, train_loss=1.44550, train_acc=0.97752, val_loss=2.01257, val_acc=0.93978, time=0.35801
Epoch:0017, train_loss=1.44248, train_acc=0.97853, val_loss=2.01238, val_acc=0.94161, time=0.28700
Epoch:0018, train_loss=1.43985, train_acc=0.97914, val_loss=2.01221, val_acc=0.94343, time=0.39099
Epoch:0019, train_loss=1.43743, train_acc=0.98218, val_loss=2.01205, val_acc=0.94343, time=0.36901
Epoch:0020, train_loss=1.43519, train_acc=0.98400, val_loss=2.01190, val_acc=0.94708, time=0.41000
Epoch:0021, train_loss=1.43319, train_acc=0.98643, val_loss=2.01176, val_acc=0.94708, time=0.30600
Epoch:0022, train_loss=1.43147, train_acc=0.98724, val_loss=2.01165, val_acc=0.95073, time=0.38600
Epoch:0023, train_loss=1.43003, train_acc=0.98845, val_loss=2.01155, val_acc=0.94891, time=0.29401
Epoch:0024, train_loss=1.42880, train_acc=0.98947, val_loss=2.01146, val_acc=0.95255, time=0.41000
Epoch:0025, train_loss=1.42770, train_acc=0.98967, val_loss=2.01139, val_acc=0.95073, time=0.41099
Epoch:0026, train_loss=1.42665, train_acc=0.98987, val_loss=2.01133, val_acc=0.95073, time=0.41201
Epoch:0027, train_loss=1.42563, train_acc=0.99028, val_loss=2.01128, val_acc=0.94891, time=0.31299
Epoch:0028, train_loss=1.42466, train_acc=0.99109, val_loss=2.01125, val_acc=0.95073, time=0.31999
Epoch:0029, train_loss=1.42375, train_acc=0.99149, val_loss=2.01123, val_acc=0.95255, time=0.33700
Epoch:0030, train_loss=1.42294, train_acc=0.99210, val_loss=2.01122, val_acc=0.95438, time=0.35402
Epoch:0031, train_loss=1.42222, train_acc=0.99271, val_loss=2.01122, val_acc=0.95438, time=0.34100
Epoch:0032, train_loss=1.42159, train_acc=0.99453, val_loss=2.01123, val_acc=0.95620, time=0.37399
Epoch:0033, train_loss=1.42103, train_acc=0.99473, val_loss=2.01125, val_acc=0.95438, time=0.32501
Epoch:0034, train_loss=1.42051, train_acc=0.99534, val_loss=2.01127, val_acc=0.95073, time=0.41101
Epoch:0035, train_loss=1.42003, train_acc=0.99534, val_loss=2.01129, val_acc=0.95255, time=0.35900
Early stopping...

Optimization Finished!

Test set results: loss= 1.80475, accuracy= 0.95386, time= 0.11199

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9820    0.9425    0.9619       696
           1     0.9657    0.9880    0.9767      1083
           2     0.7978    0.9467    0.8659        75
           3     0.9147    0.9752    0.9440       121
           4     0.8621    0.8621    0.8621        87
           5     0.8784    0.8025    0.8387        81
           6     1.0000    0.6389    0.7797        36
           7     0.9091    1.0000    0.9524        10

    accuracy                         0.9539      2189
   macro avg     0.9137    0.8945    0.8977      2189
weighted avg     0.9553    0.9539    0.9534      2189


Macro average Test Precision, Recall and F1-Score...
(0.9137199554260851, 0.8944781638291952, 0.8976592576501862, None)

Micro average Test Precision, Recall and F1-Score...
(0.9538602101416171, 0.9538602101416171, 0.9538602101416171, None)

Embeddings:
Word_embeddings: 7688
Train_doc_embeddings: 5485
Test_doc_embeddings: 2189

Elapsed time is 14.253950 seconds.
