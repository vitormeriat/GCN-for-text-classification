
==================== Torch Seed: 8432836048800

Model parameters

Layer: layer1.W0 | Size: torch.Size([61603, 200])
Layer: layer2.W0 | Size: torch.Size([200, 20])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  61603         20            10183           1131            7532

Epoch:0001, train_loss=3.04173, train_acc=0.05372, val_loss=2.99316, val_acc=0.13970, time=3.78399
Epoch:0002, train_loss=2.97037, train_acc=0.16459, val_loss=2.98726, val_acc=0.38019, time=3.81401
Epoch:0003, train_loss=2.91486, train_acc=0.39546, val_loss=2.98218, val_acc=0.52874, time=3.86400
Epoch:0004, train_loss=2.86648, train_acc=0.55524, val_loss=2.97747, val_acc=0.65075, time=3.63199
Epoch:0005, train_loss=2.82133, train_acc=0.67799, val_loss=2.97304, val_acc=0.74094, time=3.90999
Epoch:0006, train_loss=2.77873, train_acc=0.77787, val_loss=2.96896, val_acc=0.79399, time=3.57999
Epoch:0007, train_loss=2.73964, train_acc=0.84189, val_loss=2.96534, val_acc=0.83466, time=3.61901
Epoch:0008, train_loss=2.70493, train_acc=0.88343, val_loss=2.96219, val_acc=0.85411, time=3.65398
Epoch:0009, train_loss=2.67496, train_acc=0.90965, val_loss=2.95951, val_acc=0.87533, time=3.59101
Epoch:0010, train_loss=2.64962, train_acc=0.92350, val_loss=2.95727, val_acc=0.88594, time=3.71799
Epoch:0011, train_loss=2.62844, train_acc=0.93332, val_loss=2.95539, val_acc=0.88948, time=3.74500
Epoch:0012, train_loss=2.61080, train_acc=0.93980, val_loss=2.95382, val_acc=0.90009, time=3.58201
Epoch:0013, train_loss=2.59610, train_acc=0.94520, val_loss=2.95250, val_acc=0.90451, time=3.59300
Epoch:0014, train_loss=2.58378, train_acc=0.94933, val_loss=2.95140, val_acc=0.91070, time=3.55898
Epoch:0015, train_loss=2.57344, train_acc=0.95453, val_loss=2.95048, val_acc=0.91600, time=3.68400
Epoch:0016, train_loss=2.56473, train_acc=0.95817, val_loss=2.94971, val_acc=0.91600, time=3.61499
Epoch:0017, train_loss=2.55738, train_acc=0.96229, val_loss=2.94907, val_acc=0.91954, time=3.59699
Epoch:0018, train_loss=2.55116, train_acc=0.96484, val_loss=2.94853, val_acc=0.91954, time=3.54099
Epoch:0019, train_loss=2.54589, train_acc=0.96759, val_loss=2.94809, val_acc=0.92131, time=3.58699
Epoch:0020, train_loss=2.54140, train_acc=0.96936, val_loss=2.94772, val_acc=0.92485, time=3.68101
Epoch:0021, train_loss=2.53753, train_acc=0.97123, val_loss=2.94741, val_acc=0.92661, time=3.89899
Epoch:0022, train_loss=2.53417, train_acc=0.97309, val_loss=2.94715, val_acc=0.92661, time=3.76799
Epoch:0023, train_loss=2.53125, train_acc=0.97496, val_loss=2.94693, val_acc=0.92573, time=3.86300
Epoch:0024, train_loss=2.52868, train_acc=0.97692, val_loss=2.94675, val_acc=0.92485, time=3.63299
Epoch:0025, train_loss=2.52644, train_acc=0.97869, val_loss=2.94660, val_acc=0.92485, time=3.84800
Epoch:0026, train_loss=2.52445, train_acc=0.97967, val_loss=2.94647, val_acc=0.92573, time=3.87299
Epoch:0027, train_loss=2.52268, train_acc=0.98006, val_loss=2.94636, val_acc=0.92750, time=3.91900
Epoch:0028, train_loss=2.52108, train_acc=0.98105, val_loss=2.94627, val_acc=0.92838, time=3.60499
Epoch:0029, train_loss=2.51963, train_acc=0.98252, val_loss=2.94618, val_acc=0.92573, time=3.67199
Epoch:0030, train_loss=2.51831, train_acc=0.98409, val_loss=2.94611, val_acc=0.92750, time=3.52099
Epoch:0031, train_loss=2.51710, train_acc=0.98596, val_loss=2.94605, val_acc=0.92750, time=3.78599
Epoch:0032, train_loss=2.51600, train_acc=0.98723, val_loss=2.94599, val_acc=0.92838, time=3.66699
Epoch:0033, train_loss=2.51500, train_acc=0.98822, val_loss=2.94595, val_acc=0.92838, time=3.69101
Epoch:0034, train_loss=2.51409, train_acc=0.98900, val_loss=2.94591, val_acc=0.92838, time=3.53899
Epoch:0035, train_loss=2.51326, train_acc=0.99028, val_loss=2.94588, val_acc=0.92838, time=3.83401
Epoch:0036, train_loss=2.51249, train_acc=0.99047, val_loss=2.94586, val_acc=0.92927, time=3.60699
Epoch:0037, train_loss=2.51178, train_acc=0.99146, val_loss=2.94584, val_acc=0.92927, time=3.61901
Epoch:0038, train_loss=2.51113, train_acc=0.99195, val_loss=2.94583, val_acc=0.92927, time=3.66400
Epoch:0039, train_loss=2.51053, train_acc=0.99273, val_loss=2.94582, val_acc=0.92838, time=3.64600
Epoch:0040, train_loss=2.50998, train_acc=0.99303, val_loss=2.94581, val_acc=0.92838, time=3.75798
Epoch:0041, train_loss=2.50947, train_acc=0.99401, val_loss=2.94581, val_acc=0.92838, time=3.52900
Epoch:0042, train_loss=2.50900, train_acc=0.99460, val_loss=2.94581, val_acc=0.92838, time=3.71399
Epoch:0043, train_loss=2.50857, train_acc=0.99499, val_loss=2.94581, val_acc=0.92927, time=3.54099
Epoch:0044, train_loss=2.50817, train_acc=0.99509, val_loss=2.94581, val_acc=0.93015, time=3.67099
Epoch:0045, train_loss=2.50779, train_acc=0.99617, val_loss=2.94581, val_acc=0.92838, time=3.75000
Epoch:0046, train_loss=2.50744, train_acc=0.99656, val_loss=2.94581, val_acc=0.92927, time=3.58899
Epoch:0047, train_loss=2.50712, train_acc=0.99705, val_loss=2.94581, val_acc=0.92927, time=3.75799
Epoch:0048, train_loss=2.50682, train_acc=0.99696, val_loss=2.94581, val_acc=0.92927, time=3.61100
Early stopping...

Optimization Finished!

Test set results: loss= 2.69901, accuracy= 0.84201, time= 1.26599

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8732    0.9171    0.8946       398
           1     0.7348    0.7481    0.7414       389
           2     0.8480    0.7868    0.8163       319
           3     0.9289    0.8914    0.9098       396
           4     0.8373    0.6806    0.7509       310
           5     0.7708    0.6574    0.7096       394
           6     0.9397    0.9421    0.9409       397
           7     0.8953    0.9112    0.9031       394
           8     0.9027    0.9369    0.9195       396
           9     0.9475    0.9499    0.9487       399
          10     0.9781    0.9495    0.9636       376
          11     0.7934    0.7873    0.7903       395
          12     0.7634    0.8026    0.7825       390
          13     0.8067    0.7964    0.8015       393
          14     0.6842    0.7628    0.7214       392
          15     0.7857    0.8764    0.8286       364
          16     0.8741    0.8763    0.8752       396
          17     0.8093    0.8156    0.8124       385
          18     0.9275    0.9648    0.9458       398
          19     0.6964    0.6853    0.6908       251

    accuracy                         0.8420      7532
   macro avg     0.8398    0.8369    0.8373      7532
weighted avg     0.8428    0.8420    0.8414      7532


Macro average Test Precision, Recall and F1-Score...
(0.8398481257261988, 0.8369128911244218, 0.8373362504647058, None)

Micro average Test Precision, Recall and F1-Score...
(0.8420074349442379, 0.8420074349442379, 0.8420074349442379, None)

Embeddings:
Word_embeddings: 42757
Train_doc_embeddings: 11314
Test_doc_embeddings: 7532

Elapsed time is 190.221625 seconds.
