
==================== Torch Seed: 2985767996400

Model parameters

Layer: layer1.W0 | Size: torch.Size([17992, 200])
Layer: layer2.W0 | Size: torch.Size([200, 52])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  17992         52             5879            653            2568

Epoch:0001, train_loss=3.96175, train_acc=0.00970, val_loss=3.92955, val_acc=0.54211, time=0.38701
Epoch:0002, train_loss=3.76288, train_acc=0.52968, val_loss=3.90892, val_acc=0.62021, time=0.49200
Epoch:0003, train_loss=3.58327, train_acc=0.60469, val_loss=3.89160, val_acc=0.64625, time=0.41799
Epoch:0004, train_loss=3.43380, train_acc=0.62443, val_loss=3.87900, val_acc=0.66156, time=0.48200
Epoch:0005, train_loss=3.32492, train_acc=0.64161, val_loss=3.87082, val_acc=0.67534, time=0.40300
Epoch:0006, train_loss=3.25242, train_acc=0.65198, val_loss=3.86544, val_acc=0.68147, time=0.45900
Epoch:0007, train_loss=3.20219, train_acc=0.66202, val_loss=3.86143, val_acc=0.69219, time=0.40200
Epoch:0008, train_loss=3.16209, train_acc=0.67869, val_loss=3.85807, val_acc=0.70750, time=0.38601
Epoch:0009, train_loss=3.12712, train_acc=0.70743, val_loss=3.85522, val_acc=0.72282, time=0.47000
Epoch:0010, train_loss=3.09738, train_acc=0.73023, val_loss=3.85273, val_acc=0.74273, time=0.35500
Epoch:0011, train_loss=3.07215, train_acc=0.74536, val_loss=3.85042, val_acc=0.75038, time=0.45799
Epoch:0012, train_loss=3.04952, train_acc=0.75778, val_loss=3.84821, val_acc=0.76723, time=0.59901
Epoch:0013, train_loss=3.02842, train_acc=0.77394, val_loss=3.84612, val_acc=0.78407, time=0.47499
Epoch:0014, train_loss=3.00882, train_acc=0.79078, val_loss=3.84419, val_acc=0.79632, time=0.45200
Epoch:0015, train_loss=2.99083, train_acc=0.81017, val_loss=3.84241, val_acc=0.81011, time=0.42799
Epoch:0016, train_loss=2.97439, train_acc=0.82327, val_loss=3.84080, val_acc=0.82848, time=0.35600
Epoch:0017, train_loss=2.95934, train_acc=0.83177, val_loss=3.83933, val_acc=0.83308, time=0.36001
Epoch:0018, train_loss=2.94553, train_acc=0.83790, val_loss=3.83801, val_acc=0.84533, time=0.41700
Epoch:0019, train_loss=2.93281, train_acc=0.84555, val_loss=3.83680, val_acc=0.85299, time=0.35500
Epoch:0020, train_loss=2.92103, train_acc=0.85253, val_loss=3.83568, val_acc=0.85605, time=0.38600
Epoch:0021, train_loss=2.91000, train_acc=0.85967, val_loss=3.83463, val_acc=0.86677, time=0.47601
Epoch:0022, train_loss=2.89955, train_acc=0.86681, val_loss=3.83361, val_acc=0.87289, time=0.39699
Epoch:0023, train_loss=2.88956, train_acc=0.87158, val_loss=3.83264, val_acc=0.88055, time=0.45301
Epoch:0024, train_loss=2.87998, train_acc=0.87906, val_loss=3.83170, val_acc=0.88361, time=0.42700
Epoch:0025, train_loss=2.87085, train_acc=0.88348, val_loss=3.83082, val_acc=0.88515, time=0.45600
Epoch:0026, train_loss=2.86221, train_acc=0.88808, val_loss=3.83000, val_acc=0.88668, time=0.38900
Epoch:0027, train_loss=2.85413, train_acc=0.89148, val_loss=3.82923, val_acc=0.89433, time=0.37499
Epoch:0028, train_loss=2.84658, train_acc=0.89556, val_loss=3.82851, val_acc=0.89740, time=0.52600
Epoch:0029, train_loss=2.83945, train_acc=0.89998, val_loss=3.82782, val_acc=0.90199, time=0.36900
Epoch:0030, train_loss=2.83261, train_acc=0.90287, val_loss=3.82715, val_acc=0.90505, time=0.43800
Epoch:0031, train_loss=2.82593, train_acc=0.90441, val_loss=3.82650, val_acc=0.90812, time=0.39701
Epoch:0032, train_loss=2.81933, train_acc=0.90713, val_loss=3.82587, val_acc=0.90965, time=0.37999
Epoch:0033, train_loss=2.81280, train_acc=0.91155, val_loss=3.82527, val_acc=0.90965, time=0.40100
Epoch:0034, train_loss=2.80642, train_acc=0.91444, val_loss=3.82472, val_acc=0.91424, time=0.50101
Epoch:0035, train_loss=2.80029, train_acc=0.92005, val_loss=3.82421, val_acc=0.91271, time=0.43200
Epoch:0036, train_loss=2.79450, train_acc=0.92329, val_loss=3.82376, val_acc=0.91424, time=0.46801
Epoch:0037, train_loss=2.78912, train_acc=0.92652, val_loss=3.82336, val_acc=0.91884, time=0.52599
Epoch:0038, train_loss=2.78412, train_acc=0.92771, val_loss=3.82300, val_acc=0.92190, time=0.50400
Epoch:0039, train_loss=2.77947, train_acc=0.93128, val_loss=3.82267, val_acc=0.92496, time=0.46300
Epoch:0040, train_loss=2.77510, train_acc=0.93366, val_loss=3.82235, val_acc=0.92649, time=0.40801
Epoch:0041, train_loss=2.77094, train_acc=0.93553, val_loss=3.82204, val_acc=0.92802, time=0.44199
Epoch:0042, train_loss=2.76693, train_acc=0.93859, val_loss=3.82173, val_acc=0.92496, time=0.44400
Epoch:0043, train_loss=2.76301, train_acc=0.94149, val_loss=3.82141, val_acc=0.92496, time=0.42701
Epoch:0044, train_loss=2.75918, train_acc=0.94472, val_loss=3.82110, val_acc=0.92496, time=0.52099
Epoch:0045, train_loss=2.75548, train_acc=0.94761, val_loss=3.82079, val_acc=0.92649, time=0.42401
Epoch:0046, train_loss=2.75195, train_acc=0.95016, val_loss=3.82050, val_acc=0.93109, time=0.52399
Epoch:0047, train_loss=2.74862, train_acc=0.95186, val_loss=3.82021, val_acc=0.93262, time=0.51300
Epoch:0048, train_loss=2.74549, train_acc=0.95373, val_loss=3.81994, val_acc=0.93262, time=0.48000
Epoch:0049, train_loss=2.74252, train_acc=0.95475, val_loss=3.81967, val_acc=0.93262, time=0.42600
Epoch:0050, train_loss=2.73966, train_acc=0.95697, val_loss=3.81941, val_acc=0.93415, time=0.52099
Epoch:0051, train_loss=2.73687, train_acc=0.95867, val_loss=3.81915, val_acc=0.93415, time=0.40400
Epoch:0052, train_loss=2.73416, train_acc=0.96088, val_loss=3.81891, val_acc=0.93721, time=0.47401
Epoch:0053, train_loss=2.73156, train_acc=0.96207, val_loss=3.81867, val_acc=0.93568, time=0.48399
Epoch:0054, train_loss=2.72911, train_acc=0.96292, val_loss=3.81845, val_acc=0.93874, time=0.52601
Epoch:0055, train_loss=2.72681, train_acc=0.96411, val_loss=3.81825, val_acc=0.94028, time=0.44199
Epoch:0056, train_loss=2.72466, train_acc=0.96649, val_loss=3.81805, val_acc=0.94028, time=0.42901
Epoch:0057, train_loss=2.72262, train_acc=0.96836, val_loss=3.81785, val_acc=0.94181, time=0.41699
Epoch:0058, train_loss=2.72064, train_acc=0.96904, val_loss=3.81767, val_acc=0.94181, time=0.45701
Epoch:0059, train_loss=2.71870, train_acc=0.97057, val_loss=3.81749, val_acc=0.94181, time=0.47700
Epoch:0060, train_loss=2.71681, train_acc=0.97193, val_loss=3.81731, val_acc=0.94181, time=0.40799
Epoch:0061, train_loss=2.71498, train_acc=0.97312, val_loss=3.81715, val_acc=0.94181, time=0.36800
Epoch:0062, train_loss=2.71323, train_acc=0.97415, val_loss=3.81700, val_acc=0.94334, time=0.37201
Epoch:0063, train_loss=2.71155, train_acc=0.97483, val_loss=3.81687, val_acc=0.94334, time=0.37500
Epoch:0064, train_loss=2.70995, train_acc=0.97551, val_loss=3.81674, val_acc=0.94181, time=0.46499
Epoch:0065, train_loss=2.70841, train_acc=0.97670, val_loss=3.81661, val_acc=0.94334, time=0.46001
Epoch:0066, train_loss=2.70692, train_acc=0.97670, val_loss=3.81649, val_acc=0.94640, time=0.43599
Epoch:0067, train_loss=2.70548, train_acc=0.97738, val_loss=3.81636, val_acc=0.94640, time=0.52101
Epoch:0068, train_loss=2.70408, train_acc=0.97857, val_loss=3.81624, val_acc=0.94640, time=0.42199
Epoch:0069, train_loss=2.70274, train_acc=0.97857, val_loss=3.81612, val_acc=0.94793, time=0.36200
Epoch:0070, train_loss=2.70146, train_acc=0.97942, val_loss=3.81600, val_acc=0.94640, time=0.41300
Epoch:0071, train_loss=2.70024, train_acc=0.98027, val_loss=3.81588, val_acc=0.94793, time=0.37500
Epoch:0072, train_loss=2.69908, train_acc=0.98061, val_loss=3.81576, val_acc=0.94946, time=0.40500
Epoch:0073, train_loss=2.69795, train_acc=0.98146, val_loss=3.81564, val_acc=0.94793, time=0.37800
Epoch:0074, train_loss=2.69687, train_acc=0.98231, val_loss=3.81552, val_acc=0.94946, time=0.46800
Epoch:0075, train_loss=2.69582, train_acc=0.98282, val_loss=3.81540, val_acc=0.95100, time=0.35600
Epoch:0076, train_loss=2.69481, train_acc=0.98282, val_loss=3.81530, val_acc=0.94946, time=0.36100
Epoch:0077, train_loss=2.69384, train_acc=0.98350, val_loss=3.81519, val_acc=0.94793, time=0.39600
Epoch:0078, train_loss=2.69290, train_acc=0.98486, val_loss=3.81510, val_acc=0.95100, time=0.36000
Epoch:0079, train_loss=2.69200, train_acc=0.98537, val_loss=3.81501, val_acc=0.95100, time=0.45900
Epoch:0080, train_loss=2.69113, train_acc=0.98656, val_loss=3.81493, val_acc=0.95253, time=0.46201
Epoch:0081, train_loss=2.69030, train_acc=0.98673, val_loss=3.81485, val_acc=0.95253, time=0.36299
Epoch:0082, train_loss=2.68949, train_acc=0.98741, val_loss=3.81478, val_acc=0.95253, time=0.39900
Epoch:0083, train_loss=2.68871, train_acc=0.98809, val_loss=3.81472, val_acc=0.95253, time=0.35400
Epoch:0084, train_loss=2.68795, train_acc=0.98843, val_loss=3.81466, val_acc=0.95253, time=0.50700
Epoch:0085, train_loss=2.68722, train_acc=0.98894, val_loss=3.81460, val_acc=0.95253, time=0.41500
Epoch:0086, train_loss=2.68652, train_acc=0.98911, val_loss=3.81455, val_acc=0.95253, time=0.41201
Epoch:0087, train_loss=2.68584, train_acc=0.98894, val_loss=3.81450, val_acc=0.95559, time=0.37299
Epoch:0088, train_loss=2.68518, train_acc=0.98928, val_loss=3.81445, val_acc=0.95559, time=0.37900
Epoch:0089, train_loss=2.68455, train_acc=0.98928, val_loss=3.81440, val_acc=0.95712, time=0.43500
Epoch:0090, train_loss=2.68394, train_acc=0.98996, val_loss=3.81436, val_acc=0.95712, time=0.35501
Epoch:0091, train_loss=2.68335, train_acc=0.99030, val_loss=3.81431, val_acc=0.95712, time=0.45699
Epoch:0092, train_loss=2.68278, train_acc=0.99047, val_loss=3.81427, val_acc=0.95865, time=0.41401
Epoch:0093, train_loss=2.68222, train_acc=0.99064, val_loss=3.81423, val_acc=0.95865, time=0.36400
Epoch:0094, train_loss=2.68169, train_acc=0.99081, val_loss=3.81420, val_acc=0.95865, time=0.50198
Epoch:0095, train_loss=2.68117, train_acc=0.99150, val_loss=3.81416, val_acc=0.95865, time=0.37600
Epoch:0096, train_loss=2.68067, train_acc=0.99150, val_loss=3.81413, val_acc=0.95865, time=0.38301
Epoch:0097, train_loss=2.68019, train_acc=0.99150, val_loss=3.81410, val_acc=0.95865, time=0.38901
Epoch:0098, train_loss=2.67972, train_acc=0.99167, val_loss=3.81406, val_acc=0.95865, time=0.35700
Epoch:0099, train_loss=2.67926, train_acc=0.99201, val_loss=3.81403, val_acc=0.95865, time=0.42000
Epoch:0100, train_loss=2.67882, train_acc=0.99235, val_loss=3.81400, val_acc=0.95865, time=0.35900
Epoch:0101, train_loss=2.67840, train_acc=0.99252, val_loss=3.81397, val_acc=0.95865, time=0.39700
Epoch:0102, train_loss=2.67798, train_acc=0.99252, val_loss=3.81394, val_acc=0.95865, time=0.40100
Epoch:0103, train_loss=2.67758, train_acc=0.99252, val_loss=3.81391, val_acc=0.95865, time=0.40100
Epoch:0104, train_loss=2.67719, train_acc=0.99320, val_loss=3.81388, val_acc=0.95865, time=0.43800
Epoch:0105, train_loss=2.67681, train_acc=0.99320, val_loss=3.81385, val_acc=0.95865, time=0.39701
Epoch:0106, train_loss=2.67645, train_acc=0.99320, val_loss=3.81382, val_acc=0.95865, time=0.36399
Epoch:0107, train_loss=2.67609, train_acc=0.99337, val_loss=3.81380, val_acc=0.95865, time=0.42600
Epoch:0108, train_loss=2.67575, train_acc=0.99371, val_loss=3.81377, val_acc=0.95865, time=0.38501
Epoch:0109, train_loss=2.67541, train_acc=0.99388, val_loss=3.81374, val_acc=0.95865, time=0.47299
Epoch:0110, train_loss=2.67509, train_acc=0.99405, val_loss=3.81372, val_acc=0.95865, time=0.44100
Epoch:0111, train_loss=2.67477, train_acc=0.99405, val_loss=3.81369, val_acc=0.95865, time=0.36500
Epoch:0112, train_loss=2.67447, train_acc=0.99456, val_loss=3.81367, val_acc=0.95865, time=0.40400
Epoch:0113, train_loss=2.67417, train_acc=0.99456, val_loss=3.81364, val_acc=0.95865, time=0.35700
Epoch:0114, train_loss=2.67389, train_acc=0.99456, val_loss=3.81362, val_acc=0.95865, time=0.49400
Epoch:0115, train_loss=2.67361, train_acc=0.99456, val_loss=3.81359, val_acc=0.95865, time=0.44801
Epoch:0116, train_loss=2.67334, train_acc=0.99507, val_loss=3.81357, val_acc=0.95865, time=0.43600
Epoch:0117, train_loss=2.67308, train_acc=0.99507, val_loss=3.81355, val_acc=0.95865, time=0.44100
Epoch:0118, train_loss=2.67282, train_acc=0.99507, val_loss=3.81353, val_acc=0.95865, time=0.46799
Epoch:0119, train_loss=2.67257, train_acc=0.99541, val_loss=3.81350, val_acc=0.96018, time=0.36300
Epoch:0120, train_loss=2.67233, train_acc=0.99541, val_loss=3.81348, val_acc=0.96018, time=0.35500
Epoch:0121, train_loss=2.67210, train_acc=0.99541, val_loss=3.81347, val_acc=0.96018, time=0.40801
Epoch:0122, train_loss=2.67187, train_acc=0.99575, val_loss=3.81345, val_acc=0.96018, time=0.35400
Epoch:0123, train_loss=2.67166, train_acc=0.99626, val_loss=3.81343, val_acc=0.96018, time=0.39400
Epoch:0124, train_loss=2.67144, train_acc=0.99677, val_loss=3.81341, val_acc=0.96018, time=0.43199
Epoch:0125, train_loss=2.67124, train_acc=0.99711, val_loss=3.81340, val_acc=0.96018, time=0.35500
Epoch:0126, train_loss=2.67103, train_acc=0.99728, val_loss=3.81338, val_acc=0.95865, time=0.42700
Epoch:0127, train_loss=2.67084, train_acc=0.99728, val_loss=3.81337, val_acc=0.95865, time=0.50100
Epoch:0128, train_loss=2.67065, train_acc=0.99728, val_loss=3.81335, val_acc=0.95865, time=0.37100
Epoch:0129, train_loss=2.67047, train_acc=0.99728, val_loss=3.81334, val_acc=0.95865, time=0.44000
Epoch:0130, train_loss=2.67029, train_acc=0.99745, val_loss=3.81332, val_acc=0.95865, time=0.35601
Epoch:0131, train_loss=2.67011, train_acc=0.99762, val_loss=3.81331, val_acc=0.95865, time=0.43899
Epoch:0132, train_loss=2.66994, train_acc=0.99762, val_loss=3.81330, val_acc=0.95712, time=0.41401
Epoch:0133, train_loss=2.66978, train_acc=0.99762, val_loss=3.81329, val_acc=0.95712, time=0.37899
Epoch:0134, train_loss=2.66962, train_acc=0.99779, val_loss=3.81327, val_acc=0.95712, time=0.45801
Epoch:0135, train_loss=2.66946, train_acc=0.99796, val_loss=3.81326, val_acc=0.95712, time=0.38200
Epoch:0136, train_loss=2.66931, train_acc=0.99796, val_loss=3.81325, val_acc=0.95712, time=0.42400
Epoch:0137, train_loss=2.66916, train_acc=0.99813, val_loss=3.81324, val_acc=0.95712, time=0.35300
Epoch:0138, train_loss=2.66902, train_acc=0.99813, val_loss=3.81323, val_acc=0.95712, time=0.37100
Epoch:0139, train_loss=2.66888, train_acc=0.99830, val_loss=3.81323, val_acc=0.95712, time=0.46400
Epoch:0140, train_loss=2.66874, train_acc=0.99830, val_loss=3.81322, val_acc=0.95712, time=0.41200
Epoch:0141, train_loss=2.66861, train_acc=0.99813, val_loss=3.81321, val_acc=0.95712, time=0.42899
Epoch:0142, train_loss=2.66848, train_acc=0.99830, val_loss=3.81320, val_acc=0.95712, time=0.41701
Epoch:0143, train_loss=2.66836, train_acc=0.99830, val_loss=3.81320, val_acc=0.95712, time=0.41499
Epoch:0144, train_loss=2.66823, train_acc=0.99847, val_loss=3.81319, val_acc=0.95712, time=0.35600
Epoch:0145, train_loss=2.66812, train_acc=0.99847, val_loss=3.81318, val_acc=0.95712, time=0.35601
Epoch:0146, train_loss=2.66800, train_acc=0.99847, val_loss=3.81318, val_acc=0.95712, time=0.41400
Epoch:0147, train_loss=2.66788, train_acc=0.99847, val_loss=3.81317, val_acc=0.95712, time=0.41399
Epoch:0148, train_loss=2.66777, train_acc=0.99847, val_loss=3.81316, val_acc=0.95712, time=0.35501
Epoch:0149, train_loss=2.66767, train_acc=0.99847, val_loss=3.81316, val_acc=0.95712, time=0.40099
Epoch:0150, train_loss=2.66756, train_acc=0.99847, val_loss=3.81315, val_acc=0.95712, time=0.40801
Epoch:0151, train_loss=2.66746, train_acc=0.99847, val_loss=3.81315, val_acc=0.95712, time=0.42999
Epoch:0152, train_loss=2.66736, train_acc=0.99847, val_loss=3.81314, val_acc=0.95712, time=0.35600
Epoch:0153, train_loss=2.66726, train_acc=0.99847, val_loss=3.81314, val_acc=0.95712, time=0.39301
Epoch:0154, train_loss=2.66716, train_acc=0.99847, val_loss=3.81313, val_acc=0.95712, time=0.49800
Epoch:0155, train_loss=2.66707, train_acc=0.99847, val_loss=3.81313, val_acc=0.95712, time=0.43200
Epoch:0156, train_loss=2.66698, train_acc=0.99847, val_loss=3.81312, val_acc=0.95559, time=0.41800
Epoch:0157, train_loss=2.66689, train_acc=0.99847, val_loss=3.81312, val_acc=0.95559, time=0.39400
Epoch:0158, train_loss=2.66680, train_acc=0.99864, val_loss=3.81311, val_acc=0.95559, time=0.44099
Epoch:0159, train_loss=2.66671, train_acc=0.99864, val_loss=3.81311, val_acc=0.95559, time=0.36000
Epoch:0160, train_loss=2.66663, train_acc=0.99864, val_loss=3.81311, val_acc=0.95559, time=0.36501
Epoch:0161, train_loss=2.66655, train_acc=0.99864, val_loss=3.81310, val_acc=0.95559, time=0.42899
Epoch:0162, train_loss=2.66647, train_acc=0.99881, val_loss=3.81310, val_acc=0.95559, time=0.35400
Epoch:0163, train_loss=2.66639, train_acc=0.99881, val_loss=3.81309, val_acc=0.95559, time=0.35401
Epoch:0164, train_loss=2.66631, train_acc=0.99881, val_loss=3.81309, val_acc=0.95559, time=0.35599
Epoch:0165, train_loss=2.66624, train_acc=0.99881, val_loss=3.81309, val_acc=0.95559, time=0.35401
Epoch:0166, train_loss=2.66616, train_acc=0.99881, val_loss=3.81308, val_acc=0.95559, time=0.36600
Epoch:0167, train_loss=2.66609, train_acc=0.99881, val_loss=3.81308, val_acc=0.95559, time=0.38700
Epoch:0168, train_loss=2.66602, train_acc=0.99881, val_loss=3.81308, val_acc=0.95559, time=0.35300
Epoch:0169, train_loss=2.66595, train_acc=0.99881, val_loss=3.81307, val_acc=0.95559, time=0.39099
Epoch:0170, train_loss=2.66588, train_acc=0.99881, val_loss=3.81307, val_acc=0.95559, time=0.47200
Epoch:0171, train_loss=2.66582, train_acc=0.99881, val_loss=3.81307, val_acc=0.95559, time=0.41900
Epoch:0172, train_loss=2.66575, train_acc=0.99881, val_loss=3.81307, val_acc=0.95559, time=0.52400
Epoch:0173, train_loss=2.66569, train_acc=0.99881, val_loss=3.81306, val_acc=0.95559, time=0.40001
Epoch:0174, train_loss=2.66563, train_acc=0.99881, val_loss=3.81306, val_acc=0.95559, time=0.47299
Epoch:0175, train_loss=2.66556, train_acc=0.99881, val_loss=3.81306, val_acc=0.95559, time=0.37301
Epoch:0176, train_loss=2.66550, train_acc=0.99881, val_loss=3.81306, val_acc=0.95253, time=0.36499
Epoch:0177, train_loss=2.66544, train_acc=0.99881, val_loss=3.81305, val_acc=0.95253, time=0.40100
Epoch:0178, train_loss=2.66539, train_acc=0.99881, val_loss=3.81305, val_acc=0.95253, time=0.40301
Epoch:0179, train_loss=2.66533, train_acc=0.99881, val_loss=3.81305, val_acc=0.95253, time=0.37500
Epoch:0180, train_loss=2.66527, train_acc=0.99881, val_loss=3.81305, val_acc=0.95253, time=0.39099
Epoch:0181, train_loss=2.66522, train_acc=0.99881, val_loss=3.81305, val_acc=0.95253, time=0.35401
Epoch:0182, train_loss=2.66516, train_acc=0.99881, val_loss=3.81304, val_acc=0.95253, time=0.44299
Epoch:0183, train_loss=2.66511, train_acc=0.99881, val_loss=3.81304, val_acc=0.95253, time=0.42701
Epoch:0184, train_loss=2.66506, train_acc=0.99881, val_loss=3.81304, val_acc=0.95253, time=0.54799
Epoch:0185, train_loss=2.66501, train_acc=0.99881, val_loss=3.81304, val_acc=0.95253, time=0.35701
Epoch:0186, train_loss=2.66496, train_acc=0.99881, val_loss=3.81304, val_acc=0.95253, time=0.37500
Epoch:0187, train_loss=2.66491, train_acc=0.99881, val_loss=3.81303, val_acc=0.95253, time=0.50200
Epoch:0188, train_loss=2.66486, train_acc=0.99881, val_loss=3.81303, val_acc=0.95253, time=0.51399
Epoch:0189, train_loss=2.66481, train_acc=0.99881, val_loss=3.81303, val_acc=0.95253, time=0.37101
Epoch:0190, train_loss=2.66477, train_acc=0.99881, val_loss=3.81303, val_acc=0.95253, time=0.35400
Epoch:0191, train_loss=2.66472, train_acc=0.99881, val_loss=3.81303, val_acc=0.95253, time=0.41799
Epoch:0192, train_loss=2.66468, train_acc=0.99881, val_loss=3.81303, val_acc=0.95253, time=0.37300
Epoch:0193, train_loss=2.66463, train_acc=0.99881, val_loss=3.81303, val_acc=0.95253, time=0.42300
Epoch:0194, train_loss=2.66459, train_acc=0.99881, val_loss=3.81302, val_acc=0.95406, time=0.45500
Epoch:0195, train_loss=2.66454, train_acc=0.99881, val_loss=3.81302, val_acc=0.95406, time=0.48601
Epoch:0196, train_loss=2.66450, train_acc=0.99881, val_loss=3.81302, val_acc=0.95406, time=0.42500
Epoch:0197, train_loss=2.66446, train_acc=0.99881, val_loss=3.81302, val_acc=0.95406, time=0.35100
Epoch:0198, train_loss=2.66442, train_acc=0.99881, val_loss=3.81302, val_acc=0.95406, time=0.39499
Epoch:0199, train_loss=2.66438, train_acc=0.99881, val_loss=3.81302, val_acc=0.95406, time=0.35401
Epoch:0200, train_loss=2.66434, train_acc=0.99881, val_loss=3.81302, val_acc=0.95406, time=0.35699

Optimization Finished!

Test set results: loss= 3.42551, accuracy= 0.93886, time= 0.11001

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9746    0.9917    0.9831      1083
           1     0.8824    0.9917    0.9339       121
           2     0.9613    0.9641    0.9627       696
           3     1.0000    0.8667    0.9286        15
           4     0.8235    0.9333    0.8750        15
           5     1.0000    0.8235    0.9032        17
           6     0.9000    0.7500    0.8182        36
           7     0.8846    0.9200    0.9020        25
           8     0.9333    0.7368    0.8235        19
           9     0.8462    0.8462    0.8462        13
          10     0.8387    0.8966    0.8667        87
          11     0.9048    0.9500    0.9268        20
          12     0.7802    0.9467    0.8554        75
          13     0.8889    0.8571    0.8727        28
          14     1.0000    0.8889    0.9412         9
          15     1.0000    1.0000    1.0000        22
          16     1.0000    1.0000    1.0000         5
          17     0.9000    0.7500    0.8182        12
          18     0.8250    0.8148    0.8199        81
          19     0.7500    0.9000    0.8182        10
          20     1.0000    1.0000    1.0000         2
          21     0.9167    0.9167    0.9167        12
          22     1.0000    1.0000    1.0000         1
          23     0.8889    0.8889    0.8889         9
          24     1.0000    0.4167    0.5882        12
          25     0.7500    0.6000    0.6667         5
          26     1.0000    1.0000    1.0000        10
          27     1.0000    0.9167    0.9565        12
          28     0.0000    0.0000    0.0000         3
          29     1.0000    1.0000    1.0000         3
          30     0.7143    0.5556    0.6250         9
          31     1.0000    1.0000    1.0000         9
          32     0.8750    0.8750    0.8750         8
          33     0.8462    1.0000    0.9167        11
          34     1.0000    0.2000    0.3333         5
          35     1.0000    0.7500    0.8571         4
          36     0.6000    0.7500    0.6667         4
          37     1.0000    0.3333    0.5000         3
          38     1.0000    0.7500    0.8571         4
          39     0.0000    0.0000    0.0000         1
          40     0.5000    0.1667    0.2500         6
          41     1.0000    0.8182    0.9000        11
          42     1.0000    1.0000    1.0000         9
          43     0.0000    0.0000    0.0000         6
          44     1.0000    1.0000    1.0000         1
          45     0.5000    1.0000    0.6667         1
          46     0.0000    0.0000    0.0000         1
          47     1.0000    0.1429    0.2500         7
          48     0.0000    0.0000    0.0000         1
          49     0.0000    0.0000    0.0000         2
          50     0.0000    0.0000    0.0000         4
          51     0.0000    0.0000    0.0000         3

    accuracy                         0.9389      2568
   macro avg     0.7632    0.6905    0.7040      2568
weighted avg     0.9342    0.9389    0.9331      2568


Macro average Test Precision, Recall and F1-Score...
(0.7631628843739878, 0.6905496051532498, 0.7040364990764411, None)

Micro average Test Precision, Recall and F1-Score...
(0.9388629283489096, 0.9388629283489096, 0.9388629283489096, None)

Embeddings:
Word_embeddings: 8892
Train_doc_embeddings: 6532
Test_doc_embeddings: 2568

Elapsed time is 85.841805 seconds.
