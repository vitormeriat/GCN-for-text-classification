
==================== Torch Seed: 2811705964900

Model parameters

Layer: layer1.W0 | Size: torch.Size([17992, 200])
Layer: layer2.W0 | Size: torch.Size([200, 52])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  17992         52             5879            653            2568

Epoch:0001, train_loss=3.93558, train_acc=0.03317, val_loss=3.92424, val_acc=0.47933, time=0.37601
Epoch:0002, train_loss=3.72429, train_acc=0.43460, val_loss=3.90300, val_acc=0.49158, time=0.37100
Epoch:0003, train_loss=3.54074, train_acc=0.44633, val_loss=3.88684, val_acc=0.51761, time=0.44099
Epoch:0004, train_loss=3.39991, train_acc=0.47491, val_loss=3.87627, val_acc=0.59418, time=0.45600
Epoch:0005, train_loss=3.30416, train_acc=0.56149, val_loss=3.86974, val_acc=0.66616, time=0.39399
Epoch:0006, train_loss=3.24234, train_acc=0.63480, val_loss=3.86568, val_acc=0.67228, time=0.39001
Epoch:0007, train_loss=3.20235, train_acc=0.64790, val_loss=3.86250, val_acc=0.66769, time=0.36000
Epoch:0008, train_loss=3.16974, train_acc=0.65385, val_loss=3.85933, val_acc=0.68300, time=0.38200
Epoch:0009, train_loss=3.13701, train_acc=0.67069, val_loss=3.85622, val_acc=0.70904, time=0.36100
Epoch:0010, train_loss=3.10542, train_acc=0.70386, val_loss=3.85343, val_acc=0.73507, time=0.39000
Epoch:0011, train_loss=3.07781, train_acc=0.73329, val_loss=3.85096, val_acc=0.75804, time=0.52800
Epoch:0012, train_loss=3.05411, train_acc=0.75897, val_loss=3.84872, val_acc=0.77335, time=0.45100
Epoch:0013, train_loss=3.03295, train_acc=0.77224, val_loss=3.84665, val_acc=0.78714, time=0.37300
Epoch:0014, train_loss=3.01350, train_acc=0.79146, val_loss=3.84473, val_acc=0.81164, time=0.39199
Epoch:0015, train_loss=2.99558, train_acc=0.81136, val_loss=3.84298, val_acc=0.81623, time=0.38300
Epoch:0016, train_loss=2.97917, train_acc=0.82531, val_loss=3.84139, val_acc=0.82236, time=0.38501
Epoch:0017, train_loss=2.96431, train_acc=0.83177, val_loss=3.83997, val_acc=0.83614, time=0.37700
Epoch:0018, train_loss=2.95091, train_acc=0.83875, val_loss=3.83867, val_acc=0.84380, time=0.40600
Epoch:0019, train_loss=2.93861, train_acc=0.84317, val_loss=3.83745, val_acc=0.85145, time=0.37700
Epoch:0020, train_loss=2.92699, train_acc=0.84606, val_loss=3.83627, val_acc=0.85758, time=0.35700
Epoch:0021, train_loss=2.91572, train_acc=0.85048, val_loss=3.83513, val_acc=0.86371, time=0.36200
Epoch:0022, train_loss=2.90474, train_acc=0.85797, val_loss=3.83403, val_acc=0.87289, time=0.35600
Epoch:0023, train_loss=2.89415, train_acc=0.86562, val_loss=3.83299, val_acc=0.87902, time=0.35999
Epoch:0024, train_loss=2.88414, train_acc=0.87447, val_loss=3.83202, val_acc=0.88668, time=0.36701
Epoch:0025, train_loss=2.87477, train_acc=0.88161, val_loss=3.83113, val_acc=0.88821, time=0.35699
Epoch:0026, train_loss=2.86602, train_acc=0.88638, val_loss=3.83029, val_acc=0.89280, time=0.36301
Epoch:0027, train_loss=2.85775, train_acc=0.89216, val_loss=3.82951, val_acc=0.89587, time=0.35699
Epoch:0028, train_loss=2.84987, train_acc=0.89573, val_loss=3.82876, val_acc=0.90046, time=0.43200
Epoch:0029, train_loss=2.84232, train_acc=0.89777, val_loss=3.82805, val_acc=0.90352, time=0.52999
Epoch:0030, train_loss=2.83507, train_acc=0.90185, val_loss=3.82738, val_acc=0.90352, time=0.38700
Epoch:0031, train_loss=2.82810, train_acc=0.90475, val_loss=3.82673, val_acc=0.90199, time=0.40201
Epoch:0032, train_loss=2.82137, train_acc=0.90679, val_loss=3.82611, val_acc=0.90352, time=0.38900
Epoch:0033, train_loss=2.81482, train_acc=0.90849, val_loss=3.82552, val_acc=0.90812, time=0.41500
Epoch:0034, train_loss=2.80845, train_acc=0.91189, val_loss=3.82496, val_acc=0.91424, time=0.37400
Epoch:0035, train_loss=2.80231, train_acc=0.91580, val_loss=3.82444, val_acc=0.91577, time=0.41400
Epoch:0036, train_loss=2.79644, train_acc=0.91886, val_loss=3.82396, val_acc=0.92037, time=0.44699
Epoch:0037, train_loss=2.79090, train_acc=0.92142, val_loss=3.82353, val_acc=0.92190, time=0.42600
Epoch:0038, train_loss=2.78570, train_acc=0.92533, val_loss=3.82313, val_acc=0.92343, time=0.38400
Epoch:0039, train_loss=2.78083, train_acc=0.93009, val_loss=3.82276, val_acc=0.92649, time=0.46901
Epoch:0040, train_loss=2.77622, train_acc=0.93298, val_loss=3.82241, val_acc=0.92649, time=0.36200
Epoch:0041, train_loss=2.77183, train_acc=0.93672, val_loss=3.82207, val_acc=0.92649, time=0.38900
Epoch:0042, train_loss=2.76758, train_acc=0.94013, val_loss=3.82174, val_acc=0.92956, time=0.39400
Epoch:0043, train_loss=2.76347, train_acc=0.94183, val_loss=3.82142, val_acc=0.92956, time=0.43300
Epoch:0044, train_loss=2.75950, train_acc=0.94370, val_loss=3.82111, val_acc=0.92802, time=0.52199
Epoch:0045, train_loss=2.75572, train_acc=0.94523, val_loss=3.82082, val_acc=0.93109, time=0.44600
Epoch:0046, train_loss=2.75213, train_acc=0.94812, val_loss=3.82053, val_acc=0.93262, time=0.42200
Epoch:0047, train_loss=2.74873, train_acc=0.95016, val_loss=3.82026, val_acc=0.93262, time=0.35500
Epoch:0048, train_loss=2.74551, train_acc=0.95288, val_loss=3.82000, val_acc=0.93568, time=0.35801
Epoch:0049, train_loss=2.74241, train_acc=0.95492, val_loss=3.81974, val_acc=0.93721, time=0.37201
Epoch:0050, train_loss=2.73943, train_acc=0.95543, val_loss=3.81950, val_acc=0.93721, time=0.35500
Epoch:0051, train_loss=2.73656, train_acc=0.95629, val_loss=3.81926, val_acc=0.93874, time=0.37799
Epoch:0052, train_loss=2.73382, train_acc=0.95850, val_loss=3.81904, val_acc=0.94028, time=0.39301
Epoch:0053, train_loss=2.73121, train_acc=0.96037, val_loss=3.81883, val_acc=0.94181, time=0.35600
Epoch:0054, train_loss=2.72874, train_acc=0.96258, val_loss=3.81863, val_acc=0.94028, time=0.40000
Epoch:0055, train_loss=2.72639, train_acc=0.96275, val_loss=3.81843, val_acc=0.94028, time=0.48100
Epoch:0056, train_loss=2.72416, train_acc=0.96360, val_loss=3.81823, val_acc=0.94181, time=0.42500
Epoch:0057, train_loss=2.72200, train_acc=0.96547, val_loss=3.81803, val_acc=0.94334, time=0.38399
Epoch:0058, train_loss=2.71993, train_acc=0.96751, val_loss=3.81783, val_acc=0.94334, time=0.35500
Epoch:0059, train_loss=2.71794, train_acc=0.96921, val_loss=3.81763, val_acc=0.94334, time=0.42001
Epoch:0060, train_loss=2.71603, train_acc=0.96972, val_loss=3.81744, val_acc=0.94487, time=0.35500
Epoch:0061, train_loss=2.71420, train_acc=0.97074, val_loss=3.81725, val_acc=0.94640, time=0.35500
Epoch:0062, train_loss=2.71244, train_acc=0.97227, val_loss=3.81707, val_acc=0.94640, time=0.36300
Epoch:0063, train_loss=2.71075, train_acc=0.97261, val_loss=3.81690, val_acc=0.94793, time=0.59000
Epoch:0064, train_loss=2.70912, train_acc=0.97415, val_loss=3.81673, val_acc=0.94946, time=0.39899
Epoch:0065, train_loss=2.70756, train_acc=0.97568, val_loss=3.81657, val_acc=0.95253, time=0.35900
Epoch:0066, train_loss=2.70606, train_acc=0.97653, val_loss=3.81642, val_acc=0.95100, time=0.35701
Epoch:0067, train_loss=2.70462, train_acc=0.97721, val_loss=3.81627, val_acc=0.95100, time=0.55799
Epoch:0068, train_loss=2.70323, train_acc=0.97755, val_loss=3.81613, val_acc=0.95100, time=0.38101
Epoch:0069, train_loss=2.70190, train_acc=0.97908, val_loss=3.81599, val_acc=0.95253, time=0.37100
Epoch:0070, train_loss=2.70062, train_acc=0.98010, val_loss=3.81586, val_acc=0.95406, time=0.35600
Epoch:0071, train_loss=2.69939, train_acc=0.98112, val_loss=3.81573, val_acc=0.95406, time=0.42100
Epoch:0072, train_loss=2.69821, train_acc=0.98146, val_loss=3.81561, val_acc=0.95406, time=0.35400
Epoch:0073, train_loss=2.69709, train_acc=0.98197, val_loss=3.81550, val_acc=0.95406, time=0.35400
Epoch:0074, train_loss=2.69601, train_acc=0.98265, val_loss=3.81538, val_acc=0.95559, time=0.37602
Epoch:0075, train_loss=2.69498, train_acc=0.98367, val_loss=3.81528, val_acc=0.95559, time=0.49199
Epoch:0076, train_loss=2.69399, train_acc=0.98418, val_loss=3.81517, val_acc=0.95559, time=0.35800
Epoch:0077, train_loss=2.69304, train_acc=0.98469, val_loss=3.81508, val_acc=0.95559, time=0.37598
Epoch:0078, train_loss=2.69212, train_acc=0.98554, val_loss=3.81499, val_acc=0.95559, time=0.35600
Epoch:0079, train_loss=2.69123, train_acc=0.98639, val_loss=3.81490, val_acc=0.95559, time=0.36400
Epoch:0080, train_loss=2.69037, train_acc=0.98639, val_loss=3.81482, val_acc=0.95559, time=0.49200
Epoch:0081, train_loss=2.68954, train_acc=0.98690, val_loss=3.81474, val_acc=0.95712, time=0.36701
Epoch:0082, train_loss=2.68874, train_acc=0.98724, val_loss=3.81467, val_acc=0.95712, time=0.44500
Epoch:0083, train_loss=2.68797, train_acc=0.98809, val_loss=3.81461, val_acc=0.95865, time=0.41200
Epoch:0084, train_loss=2.68723, train_acc=0.98860, val_loss=3.81455, val_acc=0.95865, time=0.36799
Epoch:0085, train_loss=2.68651, train_acc=0.98877, val_loss=3.81449, val_acc=0.95865, time=0.51400
Epoch:0086, train_loss=2.68582, train_acc=0.98894, val_loss=3.81443, val_acc=0.95865, time=0.42300
Epoch:0087, train_loss=2.68516, train_acc=0.98911, val_loss=3.81438, val_acc=0.95712, time=0.46400
Epoch:0088, train_loss=2.68452, train_acc=0.98928, val_loss=3.81433, val_acc=0.95865, time=0.43301
Epoch:0089, train_loss=2.68390, train_acc=0.98962, val_loss=3.81428, val_acc=0.95865, time=0.36199
Epoch:0090, train_loss=2.68330, train_acc=0.99013, val_loss=3.81423, val_acc=0.95865, time=0.35400
Epoch:0091, train_loss=2.68273, train_acc=0.99047, val_loss=3.81419, val_acc=0.95865, time=0.35201
Epoch:0092, train_loss=2.68217, train_acc=0.99081, val_loss=3.81415, val_acc=0.95865, time=0.46000
Epoch:0093, train_loss=2.68163, train_acc=0.99081, val_loss=3.81411, val_acc=0.95865, time=0.39900
Epoch:0094, train_loss=2.68111, train_acc=0.99098, val_loss=3.81408, val_acc=0.95865, time=0.41100
Epoch:0095, train_loss=2.68060, train_acc=0.99150, val_loss=3.81404, val_acc=0.95712, time=0.37900
Epoch:0096, train_loss=2.68011, train_acc=0.99184, val_loss=3.81401, val_acc=0.95712, time=0.35500
Epoch:0097, train_loss=2.67963, train_acc=0.99184, val_loss=3.81397, val_acc=0.95712, time=0.39799
Epoch:0098, train_loss=2.67917, train_acc=0.99218, val_loss=3.81394, val_acc=0.95712, time=0.35201
Epoch:0099, train_loss=2.67872, train_acc=0.99252, val_loss=3.81391, val_acc=0.95712, time=0.38999
Epoch:0100, train_loss=2.67829, train_acc=0.99269, val_loss=3.81388, val_acc=0.95712, time=0.42900
Epoch:0101, train_loss=2.67787, train_acc=0.99269, val_loss=3.81385, val_acc=0.95712, time=0.39600
Epoch:0102, train_loss=2.67747, train_acc=0.99269, val_loss=3.81382, val_acc=0.95712, time=0.43400
Epoch:0103, train_loss=2.67708, train_acc=0.99320, val_loss=3.81379, val_acc=0.95559, time=0.36901
Epoch:0104, train_loss=2.67670, train_acc=0.99337, val_loss=3.81377, val_acc=0.95559, time=0.45799
Epoch:0105, train_loss=2.67633, train_acc=0.99354, val_loss=3.81375, val_acc=0.95559, time=0.56301
Epoch:0106, train_loss=2.67598, train_acc=0.99354, val_loss=3.81372, val_acc=0.95559, time=0.46099
Epoch:0107, train_loss=2.67563, train_acc=0.99371, val_loss=3.81370, val_acc=0.95559, time=0.43100
Epoch:0108, train_loss=2.67530, train_acc=0.99388, val_loss=3.81368, val_acc=0.95559, time=0.36999
Epoch:0109, train_loss=2.67497, train_acc=0.99388, val_loss=3.81366, val_acc=0.95559, time=0.42200
Epoch:0110, train_loss=2.67465, train_acc=0.99405, val_loss=3.81364, val_acc=0.95406, time=0.43100
Epoch:0111, train_loss=2.67435, train_acc=0.99405, val_loss=3.81361, val_acc=0.95406, time=0.37701
Epoch:0112, train_loss=2.67405, train_acc=0.99422, val_loss=3.81359, val_acc=0.95559, time=0.47100
Epoch:0113, train_loss=2.67376, train_acc=0.99439, val_loss=3.81357, val_acc=0.95559, time=0.39499
Epoch:0114, train_loss=2.67348, train_acc=0.99473, val_loss=3.81355, val_acc=0.95712, time=0.37900
Epoch:0115, train_loss=2.67321, train_acc=0.99507, val_loss=3.81353, val_acc=0.95712, time=0.43600
Epoch:0116, train_loss=2.67295, train_acc=0.99524, val_loss=3.81351, val_acc=0.95712, time=0.42100
Epoch:0117, train_loss=2.67269, train_acc=0.99558, val_loss=3.81349, val_acc=0.95712, time=0.42601
Epoch:0118, train_loss=2.67244, train_acc=0.99558, val_loss=3.81347, val_acc=0.95712, time=0.41000
Epoch:0119, train_loss=2.67220, train_acc=0.99575, val_loss=3.81345, val_acc=0.95712, time=0.52099
Epoch:0120, train_loss=2.67197, train_acc=0.99609, val_loss=3.81343, val_acc=0.95712, time=0.47300
Epoch:0121, train_loss=2.67174, train_acc=0.99609, val_loss=3.81341, val_acc=0.95712, time=0.36700
Epoch:0122, train_loss=2.67152, train_acc=0.99626, val_loss=3.81339, val_acc=0.95712, time=0.37400
Epoch:0123, train_loss=2.67131, train_acc=0.99626, val_loss=3.81337, val_acc=0.95712, time=0.42701
Epoch:0124, train_loss=2.67110, train_acc=0.99643, val_loss=3.81336, val_acc=0.95712, time=0.36401
Epoch:0125, train_loss=2.67090, train_acc=0.99660, val_loss=3.81334, val_acc=0.95712, time=0.36199
Epoch:0126, train_loss=2.67070, train_acc=0.99694, val_loss=3.81333, val_acc=0.95712, time=0.43100
Epoch:0127, train_loss=2.67051, train_acc=0.99694, val_loss=3.81331, val_acc=0.95712, time=0.43200
Epoch:0128, train_loss=2.67032, train_acc=0.99728, val_loss=3.81330, val_acc=0.95712, time=0.40201
Epoch:0129, train_loss=2.67014, train_acc=0.99728, val_loss=3.81328, val_acc=0.95712, time=0.35600
Epoch:0130, train_loss=2.66997, train_acc=0.99745, val_loss=3.81327, val_acc=0.95712, time=0.38599
Epoch:0131, train_loss=2.66980, train_acc=0.99762, val_loss=3.81326, val_acc=0.95712, time=0.45100
Epoch:0132, train_loss=2.66963, train_acc=0.99779, val_loss=3.81324, val_acc=0.95559, time=0.45100
Epoch:0133, train_loss=2.66947, train_acc=0.99779, val_loss=3.81323, val_acc=0.95559, time=0.40701
Epoch:0134, train_loss=2.66932, train_acc=0.99779, val_loss=3.81322, val_acc=0.95559, time=0.39799
Epoch:0135, train_loss=2.66917, train_acc=0.99779, val_loss=3.81321, val_acc=0.95559, time=0.42600
Epoch:0136, train_loss=2.66902, train_acc=0.99796, val_loss=3.81320, val_acc=0.95559, time=0.38200
Epoch:0137, train_loss=2.66888, train_acc=0.99779, val_loss=3.81319, val_acc=0.95559, time=0.35200
Epoch:0138, train_loss=2.66874, train_acc=0.99796, val_loss=3.81318, val_acc=0.95559, time=0.35500
Epoch:0139, train_loss=2.66860, train_acc=0.99796, val_loss=3.81317, val_acc=0.95559, time=0.45200
Epoch:0140, train_loss=2.66847, train_acc=0.99796, val_loss=3.81316, val_acc=0.95559, time=0.43000
Epoch:0141, train_loss=2.66834, train_acc=0.99830, val_loss=3.81315, val_acc=0.95559, time=0.39700
Epoch:0142, train_loss=2.66822, train_acc=0.99830, val_loss=3.81314, val_acc=0.95559, time=0.37100
Epoch:0143, train_loss=2.66809, train_acc=0.99830, val_loss=3.81313, val_acc=0.95559, time=0.35700
Epoch:0144, train_loss=2.66797, train_acc=0.99830, val_loss=3.81312, val_acc=0.95559, time=0.57500
Epoch:0145, train_loss=2.66786, train_acc=0.99830, val_loss=3.81311, val_acc=0.95559, time=0.59000
Epoch:0146, train_loss=2.66775, train_acc=0.99830, val_loss=3.81311, val_acc=0.95712, time=0.35000
Epoch:0147, train_loss=2.66764, train_acc=0.99864, val_loss=3.81310, val_acc=0.95712, time=0.35400
Epoch:0148, train_loss=2.66753, train_acc=0.99864, val_loss=3.81309, val_acc=0.95712, time=0.40400
Epoch:0149, train_loss=2.66742, train_acc=0.99864, val_loss=3.81308, val_acc=0.95712, time=0.48300
Epoch:0150, train_loss=2.66732, train_acc=0.99864, val_loss=3.81308, val_acc=0.95865, time=0.35300
Epoch:0151, train_loss=2.66722, train_acc=0.99864, val_loss=3.81307, val_acc=0.95865, time=0.35600
Epoch:0152, train_loss=2.66712, train_acc=0.99864, val_loss=3.81307, val_acc=0.95865, time=0.39800
Epoch:0153, train_loss=2.66703, train_acc=0.99847, val_loss=3.81306, val_acc=0.95865, time=0.41001
Epoch:0154, train_loss=2.66694, train_acc=0.99847, val_loss=3.81306, val_acc=0.95865, time=0.45799
Epoch:0155, train_loss=2.66685, train_acc=0.99847, val_loss=3.81305, val_acc=0.95865, time=0.35600
Epoch:0156, train_loss=2.66676, train_acc=0.99847, val_loss=3.81305, val_acc=0.95865, time=0.42801
Epoch:0157, train_loss=2.66667, train_acc=0.99847, val_loss=3.81304, val_acc=0.95865, time=0.37300
Epoch:0158, train_loss=2.66659, train_acc=0.99847, val_loss=3.81304, val_acc=0.95865, time=0.46000
Epoch:0159, train_loss=2.66650, train_acc=0.99847, val_loss=3.81304, val_acc=0.95865, time=0.43400
Epoch:0160, train_loss=2.66642, train_acc=0.99847, val_loss=3.81303, val_acc=0.96018, time=0.35100
Epoch:0161, train_loss=2.66634, train_acc=0.99847, val_loss=3.81303, val_acc=0.96018, time=0.37500
Epoch:0162, train_loss=2.66627, train_acc=0.99847, val_loss=3.81302, val_acc=0.96018, time=0.47699
Epoch:0163, train_loss=2.66619, train_acc=0.99847, val_loss=3.81302, val_acc=0.96018, time=0.40700
Epoch:0164, train_loss=2.66612, train_acc=0.99864, val_loss=3.81302, val_acc=0.96018, time=0.46900
Epoch:0165, train_loss=2.66604, train_acc=0.99864, val_loss=3.81301, val_acc=0.96018, time=0.35301
Epoch:0166, train_loss=2.66597, train_acc=0.99864, val_loss=3.81301, val_acc=0.95865, time=0.44900
Epoch:0167, train_loss=2.66590, train_acc=0.99864, val_loss=3.81301, val_acc=0.95865, time=0.37300
Epoch:0168, train_loss=2.66583, train_acc=0.99864, val_loss=3.81300, val_acc=0.95865, time=0.35900
Epoch:0169, train_loss=2.66577, train_acc=0.99864, val_loss=3.81300, val_acc=0.95865, time=0.38399
Epoch:0170, train_loss=2.66570, train_acc=0.99864, val_loss=3.81300, val_acc=0.95865, time=0.38000
Epoch:0171, train_loss=2.66564, train_acc=0.99864, val_loss=3.81300, val_acc=0.95865, time=0.47200
Epoch:0172, train_loss=2.66558, train_acc=0.99864, val_loss=3.81299, val_acc=0.96018, time=0.35400
Epoch:0173, train_loss=2.66551, train_acc=0.99864, val_loss=3.81299, val_acc=0.96018, time=0.42200
Epoch:0174, train_loss=2.66545, train_acc=0.99864, val_loss=3.81299, val_acc=0.96018, time=0.37400
Epoch:0175, train_loss=2.66539, train_acc=0.99864, val_loss=3.81299, val_acc=0.96018, time=0.35600
Epoch:0176, train_loss=2.66534, train_acc=0.99864, val_loss=3.81298, val_acc=0.96018, time=0.35600
Epoch:0177, train_loss=2.66528, train_acc=0.99864, val_loss=3.81298, val_acc=0.96018, time=0.35500
Epoch:0178, train_loss=2.66522, train_acc=0.99864, val_loss=3.81298, val_acc=0.96018, time=0.35400
Epoch:0179, train_loss=2.66517, train_acc=0.99864, val_loss=3.81298, val_acc=0.96018, time=0.37000
Epoch:0180, train_loss=2.66511, train_acc=0.99864, val_loss=3.81298, val_acc=0.96018, time=0.40301
Epoch:0181, train_loss=2.66506, train_acc=0.99864, val_loss=3.81297, val_acc=0.96018, time=0.35800
Epoch:0182, train_loss=2.66501, train_acc=0.99864, val_loss=3.81297, val_acc=0.96018, time=0.38199
Epoch:0183, train_loss=2.66496, train_acc=0.99864, val_loss=3.81297, val_acc=0.96018, time=0.35400
Epoch:0184, train_loss=2.66491, train_acc=0.99864, val_loss=3.81297, val_acc=0.96018, time=0.35200
Epoch:0185, train_loss=2.66486, train_acc=0.99864, val_loss=3.81297, val_acc=0.96018, time=0.36900
Epoch:0186, train_loss=2.66481, train_acc=0.99864, val_loss=3.81297, val_acc=0.96018, time=0.41400
Epoch:0187, train_loss=2.66476, train_acc=0.99864, val_loss=3.81297, val_acc=0.96018, time=0.42801
Epoch:0188, train_loss=2.66472, train_acc=0.99864, val_loss=3.81296, val_acc=0.96018, time=0.39800
Epoch:0189, train_loss=2.66467, train_acc=0.99864, val_loss=3.81296, val_acc=0.96018, time=0.38399
Epoch:0190, train_loss=2.66463, train_acc=0.99864, val_loss=3.81296, val_acc=0.96018, time=0.37801
Epoch:0191, train_loss=2.66458, train_acc=0.99864, val_loss=3.81296, val_acc=0.96018, time=0.35500
Epoch:0192, train_loss=2.66454, train_acc=0.99864, val_loss=3.81296, val_acc=0.96018, time=0.42299
Epoch:0193, train_loss=2.66450, train_acc=0.99864, val_loss=3.81296, val_acc=0.96018, time=0.37500
Epoch:0194, train_loss=2.66445, train_acc=0.99864, val_loss=3.81296, val_acc=0.96018, time=0.35501
Epoch:0195, train_loss=2.66441, train_acc=0.99864, val_loss=3.81296, val_acc=0.96018, time=0.35700
Epoch:0196, train_loss=2.66437, train_acc=0.99864, val_loss=3.81296, val_acc=0.96018, time=0.38300
Epoch:0197, train_loss=2.66433, train_acc=0.99864, val_loss=3.81296, val_acc=0.96018, time=0.35300
Epoch:0198, train_loss=2.66429, train_acc=0.99864, val_loss=3.81295, val_acc=0.96018, time=0.44300
Epoch:0199, train_loss=2.66425, train_acc=0.99864, val_loss=3.81295, val_acc=0.96018, time=0.39400
Epoch:0200, train_loss=2.66421, train_acc=0.99864, val_loss=3.81295, val_acc=0.96018, time=0.44390

Optimization Finished!

Test set results: loss= 3.42422, accuracy= 0.93692, time= 0.10900

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9781    0.9917    0.9849      1083
           1     0.8881    0.9835    0.9333       121
           2     0.9598    0.9612    0.9605       696
           3     1.0000    0.8667    0.9286        15
           4     0.8125    0.8667    0.8387        15
           5     1.0000    0.8235    0.9032        17
           6     0.9286    0.7222    0.8125        36
           7     0.8846    0.9200    0.9020        25
           8     0.9375    0.7895    0.8571        19
           9     0.8462    0.8462    0.8462        13
          10     0.8105    0.8851    0.8462        87
          11     0.8636    0.9500    0.9048        20
          12     0.7579    0.9600    0.8471        75
          13     0.8889    0.8571    0.8727        28
          14     1.0000    0.8889    0.9412         9
          15     1.0000    1.0000    1.0000        22
          16     1.0000    1.0000    1.0000         5
          17     0.9000    0.7500    0.8182        12
          18     0.7927    0.8025    0.7975        81
          19     0.7500    0.9000    0.8182        10
          20     1.0000    1.0000    1.0000         2
          21     0.9091    0.8333    0.8696        12
          22     1.0000    1.0000    1.0000         1
          23     0.8750    0.7778    0.8235         9
          24     1.0000    0.4167    0.5882        12
          25     0.6000    0.6000    0.6000         5
          26     1.0000    0.9000    0.9474        10
          27     1.0000    0.9167    0.9565        12
          28     0.0000    0.0000    0.0000         3
          29     1.0000    1.0000    1.0000         3
          30     0.7143    0.5556    0.6250         9
          31     1.0000    1.0000    1.0000         9
          32     0.8750    0.8750    0.8750         8
          33     0.8462    1.0000    0.9167        11
          34     0.5000    0.2000    0.2857         5
          35     1.0000    1.0000    1.0000         4
          36     0.7500    0.7500    0.7500         4
          37     1.0000    0.3333    0.5000         3
          38     1.0000    1.0000    1.0000         4
          39     0.0000    0.0000    0.0000         1
          40     0.6667    0.3333    0.4444         6
          41     1.0000    0.8182    0.9000        11
          42     1.0000    1.0000    1.0000         9
          43     0.0000    0.0000    0.0000         6
          44     1.0000    1.0000    1.0000         1
          45     0.5000    1.0000    0.6667         1
          46     0.0000    0.0000    0.0000         1
          47     1.0000    0.1429    0.2500         7
          48     0.0000    0.0000    0.0000         1
          49     0.0000    0.0000    0.0000         2
          50     0.0000    0.0000    0.0000         4
          51     0.0000    0.0000    0.0000         3

    accuracy                         0.9369      2568
   macro avg     0.7545    0.6965    0.7079      2568
weighted avg     0.9322    0.9369    0.9316      2568


Macro average Test Precision, Recall and F1-Score...
(0.7545230122902236, 0.6964873884637165, 0.7079131546690587, None)

Micro average Test Precision, Recall and F1-Score...
(0.9369158878504673, 0.9369158878504673, 0.9369158878504673, None)

Embeddings:
Word_embeddings: 8892
Train_doc_embeddings: 6532
Test_doc_embeddings: 2568

Elapsed time is 82.893785 seconds.
