
==================== Torch Seed: 24844088019800
Epoch:0001, train_loss=4.36973, train_acc=0.20881, val_loss=2.09692, val_acc=0.15584, time=0.15500
Epoch:0002, train_loss=3.69120, train_acc=0.24521, val_loss=2.07507, val_acc=0.12987, time=0.15101
Epoch:0003, train_loss=3.17931, train_acc=0.29406, val_loss=2.06131, val_acc=0.13420, time=0.16901
Epoch:0004, train_loss=2.79420, train_acc=0.35441, val_loss=2.05095, val_acc=0.12121, time=0.13400
Epoch:0005, train_loss=2.47621, train_acc=0.43247, val_loss=2.04230, val_acc=0.11688, time=0.12400
Epoch:0006, train_loss=2.21017, train_acc=0.49425, val_loss=2.03545, val_acc=0.11688, time=0.18901
Epoch:0007, train_loss=1.99976, train_acc=0.57280, val_loss=2.03066, val_acc=0.11688, time=0.19100
Epoch:0008, train_loss=1.84524, train_acc=0.64464, val_loss=2.02783, val_acc=0.11688, time=0.17301
Epoch:0009, train_loss=1.72826, train_acc=0.69636, val_loss=2.02623, val_acc=0.11688, time=0.18000
Epoch:0010, train_loss=1.62977, train_acc=0.74904, val_loss=2.02502, val_acc=0.12121, time=0.13900
Epoch:0011, train_loss=1.54127, train_acc=0.79358, val_loss=2.02381, val_acc=0.12121, time=0.11600
Epoch:0012, train_loss=1.46376, train_acc=0.84100, val_loss=2.02259, val_acc=0.12987, time=0.11800
Epoch:0013, train_loss=1.40063, train_acc=0.88410, val_loss=2.02149, val_acc=0.13853, time=0.11600
Epoch:0014, train_loss=1.35308, train_acc=0.91667, val_loss=2.02061, val_acc=0.14286, time=0.11500
Epoch:0015, train_loss=1.31926, train_acc=0.94349, val_loss=2.02000, val_acc=0.14286, time=0.11700
Epoch:0016, train_loss=1.29602, train_acc=0.95833, val_loss=2.01960, val_acc=0.13853, time=0.15900
Epoch:0017, train_loss=1.28029, train_acc=0.96935, val_loss=2.01933, val_acc=0.13853, time=0.11601
Epoch:0018, train_loss=1.26958, train_acc=0.97893, val_loss=2.01915, val_acc=0.14719, time=0.11900
Epoch:0019, train_loss=1.26221, train_acc=0.98659, val_loss=2.01901, val_acc=0.14719, time=0.14000
Epoch:0020, train_loss=1.25702, train_acc=0.98946, val_loss=2.01889, val_acc=0.14719, time=0.12401
Epoch:0021, train_loss=1.25327, train_acc=0.99234, val_loss=2.01880, val_acc=0.14719, time=0.16700
Epoch:0022, train_loss=1.25053, train_acc=0.99425, val_loss=2.01872, val_acc=0.15152, time=0.11800
Epoch:0023, train_loss=1.24849, train_acc=0.99473, val_loss=2.01866, val_acc=0.15152, time=0.12500
Epoch:0024, train_loss=1.24699, train_acc=0.99617, val_loss=2.01860, val_acc=0.15152, time=0.12000
Epoch:0025, train_loss=1.24596, train_acc=0.99904, val_loss=2.01856, val_acc=0.14719, time=0.11300
Epoch:0026, train_loss=1.24529, train_acc=0.99952, val_loss=2.01853, val_acc=0.14719, time=0.11401
Epoch:0027, train_loss=1.24486, train_acc=0.99952, val_loss=2.01851, val_acc=0.14719, time=0.11400
Epoch:0028, train_loss=1.24456, train_acc=0.99952, val_loss=2.01849, val_acc=0.15152, time=0.11602
Epoch:0029, train_loss=1.24433, train_acc=0.99952, val_loss=2.01849, val_acc=0.15152, time=0.11500
Epoch:0030, train_loss=1.24416, train_acc=0.99952, val_loss=2.01849, val_acc=0.15152, time=0.11700
Epoch:0031, train_loss=1.24402, train_acc=1.00000, val_loss=2.01849, val_acc=0.15152, time=0.11400
Epoch:0032, train_loss=1.24392, train_acc=1.00000, val_loss=2.01849, val_acc=0.15152, time=0.12301
Epoch:0033, train_loss=1.24386, train_acc=1.00000, val_loss=2.01850, val_acc=0.15152, time=0.11399
Epoch:0034, train_loss=1.24383, train_acc=1.00000, val_loss=2.01851, val_acc=0.15152, time=0.11300
Epoch:0035, train_loss=1.24381, train_acc=1.00000, val_loss=2.01852, val_acc=0.15152, time=0.15000
Early stopping...

Optimization Finished!

Test set results: loss= 2.66979, accuracy= 0.20040, time= 0.05601

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.2215    0.1908    0.2050       173
           1     0.1802    0.1640    0.1717       189
           2     0.1351    0.1449    0.1399        69
           3     0.2121    0.1373    0.1667       204
           4     0.2775    0.2788    0.2782       208
           5     0.1518    0.2600    0.1916       150

    accuracy                         0.2004       993
   macro avg     0.1964    0.1960    0.1922       993
weighted avg     0.2069    0.2004    0.1996       993


Macro average Test Precision, Recall and F1-Score...
(0.19637139165802173, 0.19596686685778195, 0.19217742544342012, None)

Micro average Test Precision, Recall and F1-Score...
(0.20040281973816718, 0.20040281973816718, 0.20040281973816718, None)

Embeddings:
Word_embeddings:3515
Train_doc_embeddings:2319
Test_doc_embeddings:993
