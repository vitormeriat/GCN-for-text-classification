
==================== Torch Seed: 149225205950700
Epoch:0001, train_loss=2.16444, train_acc=0.17055, val_loss=2.06105, val_acc=0.56569, time=0.64900
Epoch:0002, train_loss=1.90286, train_acc=0.58193, val_loss=2.04462, val_acc=0.69161, time=0.53898
Epoch:0003, train_loss=1.75554, train_acc=0.70002, val_loss=2.03707, val_acc=0.70255, time=0.48599
Epoch:0004, train_loss=1.68710, train_acc=0.71987, val_loss=2.03135, val_acc=0.75912, time=0.50000
Epoch:0005, train_loss=1.63555, train_acc=0.77152, val_loss=2.02649, val_acc=0.82847, time=0.44101
Epoch:0006, train_loss=1.59092, train_acc=0.83958, val_loss=2.02306, val_acc=0.86131, time=0.50797
Epoch:0007, train_loss=1.55745, train_acc=0.87806, val_loss=2.02065, val_acc=0.86861, time=0.53799
Epoch:0008, train_loss=1.53224, train_acc=0.89953, val_loss=2.01878, val_acc=0.88504, time=0.55399
Epoch:0009, train_loss=1.51170, train_acc=0.92141, val_loss=2.01732, val_acc=0.89416, time=0.45799
Epoch:0010, train_loss=1.49517, train_acc=0.93903, val_loss=2.01624, val_acc=0.90511, time=0.47600
Epoch:0011, train_loss=1.48266, train_acc=0.94936, val_loss=2.01548, val_acc=0.91788, time=0.51597
Epoch:0012, train_loss=1.47360, train_acc=0.95848, val_loss=2.01494, val_acc=0.92336, time=0.47300
Epoch:0013, train_loss=1.46703, train_acc=0.96395, val_loss=2.01452, val_acc=0.92883, time=0.51598
Epoch:0014, train_loss=1.46193, train_acc=0.96698, val_loss=2.01414, val_acc=0.93248, time=0.51099
Epoch:0015, train_loss=1.45761, train_acc=0.96941, val_loss=2.01378, val_acc=0.93431, time=0.47698
Epoch:0016, train_loss=1.45368, train_acc=0.97225, val_loss=2.01342, val_acc=0.93613, time=0.45599
Epoch:0017, train_loss=1.45001, train_acc=0.97387, val_loss=2.01307, val_acc=0.93978, time=0.62299
Epoch:0018, train_loss=1.44656, train_acc=0.97590, val_loss=2.01272, val_acc=0.94161, time=0.55400
Epoch:0019, train_loss=1.44336, train_acc=0.97752, val_loss=2.01240, val_acc=0.94526, time=0.51899
Epoch:0020, train_loss=1.44044, train_acc=0.97974, val_loss=2.01210, val_acc=0.94708, time=0.47401
Epoch:0021, train_loss=1.43783, train_acc=0.98157, val_loss=2.01184, val_acc=0.94526, time=0.44099
Epoch:0022, train_loss=1.43556, train_acc=0.98380, val_loss=2.01162, val_acc=0.94526, time=0.48200
Epoch:0023, train_loss=1.43361, train_acc=0.98602, val_loss=2.01143, val_acc=0.94891, time=0.47198
Epoch:0024, train_loss=1.43197, train_acc=0.98704, val_loss=2.01127, val_acc=0.95255, time=0.48702
Epoch:0025, train_loss=1.43060, train_acc=0.98704, val_loss=2.01114, val_acc=0.95073, time=0.43200
Epoch:0026, train_loss=1.42944, train_acc=0.98785, val_loss=2.01102, val_acc=0.95255, time=0.49101
Epoch:0027, train_loss=1.42843, train_acc=0.98845, val_loss=2.01092, val_acc=0.95438, time=0.51599
Epoch:0028, train_loss=1.42753, train_acc=0.98866, val_loss=2.01083, val_acc=0.95438, time=0.54798
Epoch:0029, train_loss=1.42669, train_acc=0.98947, val_loss=2.01075, val_acc=0.95438, time=0.53901
Epoch:0030, train_loss=1.42591, train_acc=0.99028, val_loss=2.01068, val_acc=0.95438, time=0.43098
Epoch:0031, train_loss=1.42516, train_acc=0.99109, val_loss=2.01062, val_acc=0.95438, time=0.56500
Epoch:0032, train_loss=1.42446, train_acc=0.99149, val_loss=2.01057, val_acc=0.95255, time=0.53599
Epoch:0033, train_loss=1.42380, train_acc=0.99210, val_loss=2.01053, val_acc=0.94891, time=0.52000
Epoch:0034, train_loss=1.42319, train_acc=0.99311, val_loss=2.01049, val_acc=0.95073, time=0.51199
Epoch:0035, train_loss=1.42262, train_acc=0.99332, val_loss=2.01047, val_acc=0.95073, time=0.48501
Epoch:0036, train_loss=1.42210, train_acc=0.99332, val_loss=2.01044, val_acc=0.95255, time=0.46897
Epoch:0037, train_loss=1.42160, train_acc=0.99392, val_loss=2.01042, val_acc=0.95255, time=0.56498
Epoch:0038, train_loss=1.42114, train_acc=0.99413, val_loss=2.01040, val_acc=0.95255, time=0.41100
Epoch:0039, train_loss=1.42070, train_acc=0.99433, val_loss=2.01038, val_acc=0.95438, time=0.42299
Epoch:0040, train_loss=1.42028, train_acc=0.99453, val_loss=2.01036, val_acc=0.95438, time=0.42701
Epoch:0041, train_loss=1.41989, train_acc=0.99494, val_loss=2.01034, val_acc=0.95438, time=0.59096
Epoch:0042, train_loss=1.41951, train_acc=0.99595, val_loss=2.01033, val_acc=0.95438, time=0.53999
Epoch:0043, train_loss=1.41917, train_acc=0.99635, val_loss=2.01031, val_acc=0.95438, time=0.53399
Epoch:0044, train_loss=1.41884, train_acc=0.99656, val_loss=2.01029, val_acc=0.95620, time=0.51000
Epoch:0045, train_loss=1.41855, train_acc=0.99676, val_loss=2.01027, val_acc=0.95620, time=0.48999
Epoch:0046, train_loss=1.41828, train_acc=0.99716, val_loss=2.01026, val_acc=0.95803, time=0.44600
Epoch:0047, train_loss=1.41804, train_acc=0.99716, val_loss=2.01025, val_acc=0.95803, time=0.50299
Epoch:0048, train_loss=1.41781, train_acc=0.99716, val_loss=2.01024, val_acc=0.95803, time=0.42401
Epoch:0049, train_loss=1.41760, train_acc=0.99757, val_loss=2.01023, val_acc=0.95803, time=0.43801
Epoch:0050, train_loss=1.41741, train_acc=0.99777, val_loss=2.01023, val_acc=0.95803, time=0.54399
Epoch:0051, train_loss=1.41722, train_acc=0.99797, val_loss=2.01022, val_acc=0.95803, time=0.43900
Epoch:0052, train_loss=1.41705, train_acc=0.99777, val_loss=2.01022, val_acc=0.95803, time=0.41399
Epoch:0053, train_loss=1.41689, train_acc=0.99777, val_loss=2.01022, val_acc=0.95803, time=0.61599
Epoch:0054, train_loss=1.41673, train_acc=0.99797, val_loss=2.01022, val_acc=0.95803, time=0.55800
Epoch:0055, train_loss=1.41659, train_acc=0.99818, val_loss=2.01022, val_acc=0.95803, time=0.51700
Epoch:0056, train_loss=1.41645, train_acc=0.99818, val_loss=2.01021, val_acc=0.95803, time=0.46300
Epoch:0057, train_loss=1.41632, train_acc=0.99818, val_loss=2.01021, val_acc=0.95803, time=0.47298
Epoch:0058, train_loss=1.41619, train_acc=0.99818, val_loss=2.01020, val_acc=0.95803, time=0.41100
Epoch:0059, train_loss=1.41607, train_acc=0.99818, val_loss=2.01019, val_acc=0.95803, time=0.51699
Epoch:0060, train_loss=1.41596, train_acc=0.99818, val_loss=2.01019, val_acc=0.95803, time=0.46600
Epoch:0061, train_loss=1.41585, train_acc=0.99838, val_loss=2.01018, val_acc=0.95803, time=0.46400
Epoch:0062, train_loss=1.41574, train_acc=0.99838, val_loss=2.01017, val_acc=0.95803, time=0.49398
Epoch:0063, train_loss=1.41564, train_acc=0.99838, val_loss=2.01016, val_acc=0.95985, time=0.44799
Epoch:0064, train_loss=1.41555, train_acc=0.99838, val_loss=2.01015, val_acc=0.95985, time=0.47099
Epoch:0065, train_loss=1.41546, train_acc=0.99878, val_loss=2.01014, val_acc=0.95985, time=0.51799
Epoch:0066, train_loss=1.41537, train_acc=0.99878, val_loss=2.01013, val_acc=0.95985, time=0.41899
Epoch:0067, train_loss=1.41529, train_acc=0.99878, val_loss=2.01013, val_acc=0.95985, time=0.56800
Epoch:0068, train_loss=1.41521, train_acc=0.99878, val_loss=2.01012, val_acc=0.95985, time=0.56898
Epoch:0069, train_loss=1.41514, train_acc=0.99878, val_loss=2.01011, val_acc=0.95985, time=0.54700
Epoch:0070, train_loss=1.41506, train_acc=0.99878, val_loss=2.01011, val_acc=0.95985, time=0.53299
Epoch:0071, train_loss=1.41499, train_acc=0.99878, val_loss=2.01011, val_acc=0.95985, time=0.45902
Epoch:0072, train_loss=1.41493, train_acc=0.99878, val_loss=2.01010, val_acc=0.95985, time=0.41300
Epoch:0073, train_loss=1.41486, train_acc=0.99878, val_loss=2.01010, val_acc=0.95803, time=0.58200
Epoch:0074, train_loss=1.41480, train_acc=0.99878, val_loss=2.01009, val_acc=0.95803, time=0.41399
Epoch:0075, train_loss=1.41474, train_acc=0.99878, val_loss=2.01009, val_acc=0.95803, time=0.48200
Epoch:0076, train_loss=1.41469, train_acc=0.99878, val_loss=2.01009, val_acc=0.95620, time=0.47098
Epoch:0077, train_loss=1.41463, train_acc=0.99878, val_loss=2.01008, val_acc=0.95620, time=0.51599
Epoch:0078, train_loss=1.41458, train_acc=0.99878, val_loss=2.01008, val_acc=0.95620, time=0.44600
Epoch:0079, train_loss=1.41453, train_acc=0.99878, val_loss=2.01008, val_acc=0.95620, time=0.60798
Epoch:0080, train_loss=1.41448, train_acc=0.99878, val_loss=2.01007, val_acc=0.95620, time=0.41399
Epoch:0081, train_loss=1.41443, train_acc=0.99878, val_loss=2.01007, val_acc=0.95620, time=0.47799
Epoch:0082, train_loss=1.41438, train_acc=0.99899, val_loss=2.01007, val_acc=0.95620, time=0.43199
Epoch:0083, train_loss=1.41434, train_acc=0.99899, val_loss=2.01006, val_acc=0.95620, time=0.49300
Epoch:0084, train_loss=1.41429, train_acc=0.99899, val_loss=2.01006, val_acc=0.95620, time=0.57499
Epoch:0085, train_loss=1.41425, train_acc=0.99899, val_loss=2.01006, val_acc=0.95620, time=0.54799
Epoch:0086, train_loss=1.41421, train_acc=0.99899, val_loss=2.01006, val_acc=0.95620, time=0.50999
Epoch:0087, train_loss=1.41417, train_acc=0.99899, val_loss=2.01006, val_acc=0.95620, time=0.55701
Epoch:0088, train_loss=1.41413, train_acc=0.99899, val_loss=2.01006, val_acc=0.95803, time=0.56697
Epoch:0089, train_loss=1.41409, train_acc=0.99899, val_loss=2.01006, val_acc=0.95803, time=0.46299
Epoch:0090, train_loss=1.41406, train_acc=0.99899, val_loss=2.01006, val_acc=0.95803, time=0.43199
Epoch:0091, train_loss=1.41402, train_acc=0.99878, val_loss=2.01006, val_acc=0.95803, time=0.51702
Epoch:0092, train_loss=1.41399, train_acc=0.99878, val_loss=2.01005, val_acc=0.95803, time=0.44901
Epoch:0093, train_loss=1.41395, train_acc=0.99878, val_loss=2.01005, val_acc=0.95803, time=0.54200
Epoch:0094, train_loss=1.41392, train_acc=0.99878, val_loss=2.01005, val_acc=0.95803, time=0.64499
Epoch:0095, train_loss=1.41389, train_acc=0.99878, val_loss=2.01005, val_acc=0.95803, time=0.54198
Epoch:0096, train_loss=1.41386, train_acc=0.99899, val_loss=2.01005, val_acc=0.95803, time=0.53099
Epoch:0097, train_loss=1.41383, train_acc=0.99899, val_loss=2.01005, val_acc=0.95803, time=0.60801
Epoch:0098, train_loss=1.41380, train_acc=0.99899, val_loss=2.01005, val_acc=0.95803, time=0.41498
Epoch:0099, train_loss=1.41377, train_acc=0.99899, val_loss=2.01005, val_acc=0.95803, time=0.47701
Epoch:0100, train_loss=1.41374, train_acc=0.99899, val_loss=2.01005, val_acc=0.95803, time=0.42500
Epoch:0101, train_loss=1.41371, train_acc=0.99899, val_loss=2.01005, val_acc=0.95803, time=0.49600
Epoch:0102, train_loss=1.41368, train_acc=0.99899, val_loss=2.01005, val_acc=0.95803, time=0.40299
Epoch:0103, train_loss=1.41366, train_acc=0.99899, val_loss=2.01005, val_acc=0.95803, time=0.49200
Early stopping...

Optimization Finished!

Test set results: loss= 1.80464, accuracy= 0.95432, time= 0.18500

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.8140    0.9333    0.8696        75
           1     0.9684    0.9898    0.9790      1083
           2     0.9120    0.9421    0.9268       121
           3     0.8523    0.8621    0.8571        87
           4     0.9792    0.9483    0.9635       696
           5     0.8767    0.7901    0.8312        81
           6     1.0000    0.9000    0.9474        10
           7     0.9259    0.6944    0.7937        36

    accuracy                         0.9543      2189
   macro avg     0.9161    0.8825    0.8960      2189
weighted avg     0.9549    0.9543    0.9539      2189


Macro average Test Precision, Recall and F1-Score...
(0.9160594967685324, 0.8825297313886099, 0.8960280590155114, None)

Micro average Test Precision, Recall and F1-Score...
(0.9543170397441755, 0.9543170397441755, 0.9543170397441755, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189

Elapsed time is 52.549168 seconds.
