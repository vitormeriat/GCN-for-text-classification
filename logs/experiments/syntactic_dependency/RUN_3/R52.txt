
==================== Torch Seed: 6194897535900

Model parameters

Layer: layer1.W0 | Size: torch.Size([17992, 200])
Layer: layer2.W0 | Size: torch.Size([200, 52])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  17992         52             5879            653            2568

Epoch:0001, train_loss=4.18429, train_acc=0.01701, val_loss=3.94072, val_acc=0.30781, time=0.37001
Epoch:0002, train_loss=3.84707, train_acc=0.29903, val_loss=3.90850, val_acc=0.49158, time=0.36900
Epoch:0003, train_loss=3.55682, train_acc=0.47967, val_loss=3.88503, val_acc=0.58346, time=0.48199
Epoch:0004, train_loss=3.34672, train_acc=0.57204, val_loss=3.87133, val_acc=0.62940, time=0.36600
Epoch:0005, train_loss=3.22387, train_acc=0.62358, val_loss=3.86389, val_acc=0.65850, time=0.39301
Epoch:0006, train_loss=3.15632, train_acc=0.65368, val_loss=3.85907, val_acc=0.66922, time=0.39800
Epoch:0007, train_loss=3.11065, train_acc=0.67222, val_loss=3.85487, val_acc=0.67688, time=0.36199
Epoch:0008, train_loss=3.06918, train_acc=0.69842, val_loss=3.85076, val_acc=0.70597, time=0.37001
Epoch:0009, train_loss=3.02801, train_acc=0.73142, val_loss=3.84683, val_acc=0.73813, time=0.35700
Epoch:0010, train_loss=2.98917, train_acc=0.76799, val_loss=3.84338, val_acc=0.78714, time=0.37200
Epoch:0011, train_loss=2.95534, train_acc=0.80133, val_loss=3.84057, val_acc=0.81930, time=0.45300
Epoch:0012, train_loss=2.92774, train_acc=0.83245, val_loss=3.83839, val_acc=0.84074, time=0.35700
Epoch:0013, train_loss=2.90591, train_acc=0.85014, val_loss=3.83669, val_acc=0.84839, time=0.48300
Epoch:0014, train_loss=2.88849, train_acc=0.86749, val_loss=3.83531, val_acc=0.85605, time=0.35500
Epoch:0015, train_loss=2.87400, train_acc=0.87804, val_loss=3.83410, val_acc=0.85605, time=0.36000
Epoch:0016, train_loss=2.86122, train_acc=0.88689, val_loss=3.83297, val_acc=0.85911, time=0.35600
Epoch:0017, train_loss=2.84927, train_acc=0.89471, val_loss=3.83187, val_acc=0.86371, time=0.35500
Epoch:0018, train_loss=2.83760, train_acc=0.90321, val_loss=3.83078, val_acc=0.86830, time=0.39301
Epoch:0019, train_loss=2.82601, train_acc=0.90917, val_loss=3.82971, val_acc=0.88208, time=0.47599
Epoch:0020, train_loss=2.81458, train_acc=0.91614, val_loss=3.82866, val_acc=0.88821, time=0.35701
Epoch:0021, train_loss=2.80355, train_acc=0.92142, val_loss=3.82769, val_acc=0.89127, time=0.45701
Epoch:0022, train_loss=2.79317, train_acc=0.92601, val_loss=3.82679, val_acc=0.89433, time=0.35200
Epoch:0023, train_loss=2.78368, train_acc=0.93162, val_loss=3.82599, val_acc=0.89587, time=0.40299
Epoch:0024, train_loss=2.77517, train_acc=0.93621, val_loss=3.82529, val_acc=0.90352, time=0.42901
Epoch:0025, train_loss=2.76765, train_acc=0.94115, val_loss=3.82466, val_acc=0.90812, time=0.36199
Epoch:0026, train_loss=2.76098, train_acc=0.94421, val_loss=3.82410, val_acc=0.91118, time=0.52500
Epoch:0027, train_loss=2.75500, train_acc=0.94625, val_loss=3.82360, val_acc=0.91424, time=0.45100
Epoch:0028, train_loss=2.74955, train_acc=0.94897, val_loss=3.82313, val_acc=0.91730, time=0.49000
Epoch:0029, train_loss=2.74452, train_acc=0.95067, val_loss=3.82270, val_acc=0.92037, time=0.47000
Epoch:0030, train_loss=2.73985, train_acc=0.95390, val_loss=3.82229, val_acc=0.92037, time=0.50100
Epoch:0031, train_loss=2.73548, train_acc=0.95799, val_loss=3.82192, val_acc=0.92037, time=0.40299
Epoch:0032, train_loss=2.73141, train_acc=0.96105, val_loss=3.82158, val_acc=0.92190, time=0.46500
Epoch:0033, train_loss=2.72762, train_acc=0.96496, val_loss=3.82126, val_acc=0.92190, time=0.50000
Epoch:0034, train_loss=2.72410, train_acc=0.96700, val_loss=3.82097, val_acc=0.92190, time=0.43201
Epoch:0035, train_loss=2.72082, train_acc=0.96751, val_loss=3.82069, val_acc=0.92496, time=0.47101
Epoch:0036, train_loss=2.71774, train_acc=0.96989, val_loss=3.82043, val_acc=0.92649, time=0.52200
Epoch:0037, train_loss=2.71484, train_acc=0.97091, val_loss=3.82017, val_acc=0.92496, time=0.53301
Epoch:0038, train_loss=2.71208, train_acc=0.97295, val_loss=3.81992, val_acc=0.92649, time=0.45100
Epoch:0039, train_loss=2.70945, train_acc=0.97534, val_loss=3.81968, val_acc=0.92649, time=0.56102
Epoch:0040, train_loss=2.70695, train_acc=0.97721, val_loss=3.81944, val_acc=0.92802, time=0.44300
Epoch:0041, train_loss=2.70458, train_acc=0.97908, val_loss=3.81922, val_acc=0.93109, time=0.46000
Epoch:0042, train_loss=2.70234, train_acc=0.98061, val_loss=3.81900, val_acc=0.93262, time=0.58200
Epoch:0043, train_loss=2.70025, train_acc=0.98112, val_loss=3.81879, val_acc=0.93109, time=0.49599
Epoch:0044, train_loss=2.69830, train_acc=0.98367, val_loss=3.81860, val_acc=0.93262, time=0.38801
Epoch:0045, train_loss=2.69650, train_acc=0.98503, val_loss=3.81843, val_acc=0.93415, time=0.48700
Epoch:0046, train_loss=2.69482, train_acc=0.98622, val_loss=3.81826, val_acc=0.93568, time=0.46700
Epoch:0047, train_loss=2.69327, train_acc=0.98690, val_loss=3.81811, val_acc=0.93415, time=0.37500
Epoch:0048, train_loss=2.69183, train_acc=0.98741, val_loss=3.81796, val_acc=0.93415, time=0.44201
Epoch:0049, train_loss=2.69048, train_acc=0.98894, val_loss=3.81782, val_acc=0.93415, time=0.37299
Epoch:0050, train_loss=2.68922, train_acc=0.98911, val_loss=3.81769, val_acc=0.93262, time=0.39001
Epoch:0051, train_loss=2.68804, train_acc=0.98911, val_loss=3.81756, val_acc=0.93415, time=0.49400
Epoch:0052, train_loss=2.68692, train_acc=0.98928, val_loss=3.81744, val_acc=0.93568, time=0.44200
Epoch:0053, train_loss=2.68586, train_acc=0.98962, val_loss=3.81732, val_acc=0.93568, time=0.51099
Epoch:0054, train_loss=2.68486, train_acc=0.99013, val_loss=3.81720, val_acc=0.93568, time=0.40701
Epoch:0055, train_loss=2.68390, train_acc=0.99030, val_loss=3.81709, val_acc=0.93721, time=0.40300
Epoch:0056, train_loss=2.68299, train_acc=0.99133, val_loss=3.81699, val_acc=0.94028, time=0.41500
Epoch:0057, train_loss=2.68213, train_acc=0.99184, val_loss=3.81689, val_acc=0.94028, time=0.41000
Epoch:0058, train_loss=2.68131, train_acc=0.99201, val_loss=3.81679, val_acc=0.94181, time=0.48599
Epoch:0059, train_loss=2.68054, train_acc=0.99252, val_loss=3.81670, val_acc=0.94181, time=0.46901
Epoch:0060, train_loss=2.67981, train_acc=0.99269, val_loss=3.81662, val_acc=0.94181, time=0.44800
Epoch:0061, train_loss=2.67912, train_acc=0.99337, val_loss=3.81654, val_acc=0.94181, time=0.38600
Epoch:0062, train_loss=2.67847, train_acc=0.99320, val_loss=3.81647, val_acc=0.94181, time=0.35900
Epoch:0063, train_loss=2.67786, train_acc=0.99371, val_loss=3.81640, val_acc=0.94181, time=0.40299
Epoch:0064, train_loss=2.67728, train_acc=0.99371, val_loss=3.81633, val_acc=0.94181, time=0.41901
Epoch:0065, train_loss=2.67673, train_acc=0.99371, val_loss=3.81627, val_acc=0.94487, time=0.39300
Epoch:0066, train_loss=2.67621, train_acc=0.99405, val_loss=3.81620, val_acc=0.94334, time=0.40999
Epoch:0067, train_loss=2.67571, train_acc=0.99405, val_loss=3.81614, val_acc=0.94334, time=0.35300
Epoch:0068, train_loss=2.67523, train_acc=0.99456, val_loss=3.81609, val_acc=0.94334, time=0.38501
Epoch:0069, train_loss=2.67477, train_acc=0.99490, val_loss=3.81603, val_acc=0.94334, time=0.52400
Epoch:0070, train_loss=2.67432, train_acc=0.99507, val_loss=3.81598, val_acc=0.94487, time=0.39799
Epoch:0071, train_loss=2.67390, train_acc=0.99507, val_loss=3.81593, val_acc=0.94487, time=0.38901
Epoch:0072, train_loss=2.67349, train_acc=0.99507, val_loss=3.81588, val_acc=0.94487, time=0.55600
Epoch:0073, train_loss=2.67310, train_acc=0.99507, val_loss=3.81584, val_acc=0.94487, time=0.35900
Epoch:0074, train_loss=2.67273, train_acc=0.99558, val_loss=3.81580, val_acc=0.94487, time=0.56401
Epoch:0075, train_loss=2.67237, train_acc=0.99558, val_loss=3.81577, val_acc=0.94487, time=0.46200
Epoch:0076, train_loss=2.67203, train_acc=0.99558, val_loss=3.81573, val_acc=0.94487, time=0.52101
Epoch:0077, train_loss=2.67170, train_acc=0.99575, val_loss=3.81570, val_acc=0.94640, time=0.42000
Epoch:0078, train_loss=2.67140, train_acc=0.99592, val_loss=3.81567, val_acc=0.94334, time=0.43200
Epoch:0079, train_loss=2.67110, train_acc=0.99592, val_loss=3.81565, val_acc=0.94334, time=0.52699
Epoch:0080, train_loss=2.67082, train_acc=0.99592, val_loss=3.81562, val_acc=0.94334, time=0.47800
Epoch:0081, train_loss=2.67056, train_acc=0.99643, val_loss=3.81560, val_acc=0.94334, time=0.48900
Epoch:0082, train_loss=2.67030, train_acc=0.99660, val_loss=3.81557, val_acc=0.94334, time=0.48800
Epoch:0083, train_loss=2.67006, train_acc=0.99660, val_loss=3.81555, val_acc=0.94181, time=0.55299
Epoch:0084, train_loss=2.66983, train_acc=0.99694, val_loss=3.81553, val_acc=0.94028, time=0.51499
Epoch:0085, train_loss=2.66961, train_acc=0.99694, val_loss=3.81551, val_acc=0.94181, time=0.44800
Epoch:0086, train_loss=2.66940, train_acc=0.99694, val_loss=3.81549, val_acc=0.94181, time=0.52100
Epoch:0087, train_loss=2.66919, train_acc=0.99711, val_loss=3.81547, val_acc=0.94181, time=0.57899
Epoch:0088, train_loss=2.66900, train_acc=0.99711, val_loss=3.81545, val_acc=0.94181, time=0.45500
Epoch:0089, train_loss=2.66882, train_acc=0.99728, val_loss=3.81544, val_acc=0.94181, time=0.51400
Epoch:0090, train_loss=2.66864, train_acc=0.99728, val_loss=3.81542, val_acc=0.94181, time=0.50099
Epoch:0091, train_loss=2.66847, train_acc=0.99728, val_loss=3.81541, val_acc=0.94181, time=0.50500
Epoch:0092, train_loss=2.66831, train_acc=0.99745, val_loss=3.81540, val_acc=0.94181, time=0.44601
Epoch:0093, train_loss=2.66815, train_acc=0.99745, val_loss=3.81539, val_acc=0.94181, time=0.48899
Epoch:0094, train_loss=2.66801, train_acc=0.99762, val_loss=3.81538, val_acc=0.94028, time=0.44701
Epoch:0095, train_loss=2.66786, train_acc=0.99762, val_loss=3.81537, val_acc=0.94028, time=0.48200
Epoch:0096, train_loss=2.66772, train_acc=0.99762, val_loss=3.81536, val_acc=0.94028, time=0.43500
Epoch:0097, train_loss=2.66759, train_acc=0.99762, val_loss=3.81536, val_acc=0.94028, time=0.53401
Epoch:0098, train_loss=2.66746, train_acc=0.99762, val_loss=3.81535, val_acc=0.94028, time=0.55100
Epoch:0099, train_loss=2.66733, train_acc=0.99779, val_loss=3.81534, val_acc=0.93874, time=0.52999
Epoch:0100, train_loss=2.66721, train_acc=0.99762, val_loss=3.81534, val_acc=0.93874, time=0.51100
Epoch:0101, train_loss=2.66709, train_acc=0.99762, val_loss=3.81533, val_acc=0.93874, time=0.48700
Epoch:0102, train_loss=2.66698, train_acc=0.99779, val_loss=3.81533, val_acc=0.93874, time=0.54900
Epoch:0103, train_loss=2.66686, train_acc=0.99779, val_loss=3.81532, val_acc=0.93874, time=0.53799
Epoch:0104, train_loss=2.66676, train_acc=0.99779, val_loss=3.81532, val_acc=0.93874, time=0.54700
Epoch:0105, train_loss=2.66665, train_acc=0.99796, val_loss=3.81531, val_acc=0.93874, time=0.51801
Epoch:0106, train_loss=2.66655, train_acc=0.99796, val_loss=3.81531, val_acc=0.93874, time=0.53399
Epoch:0107, train_loss=2.66645, train_acc=0.99796, val_loss=3.81530, val_acc=0.93874, time=0.55701
Epoch:0108, train_loss=2.66635, train_acc=0.99796, val_loss=3.81530, val_acc=0.93874, time=0.49398
Epoch:0109, train_loss=2.66626, train_acc=0.99796, val_loss=3.81530, val_acc=0.93874, time=0.40700
Epoch:0110, train_loss=2.66617, train_acc=0.99796, val_loss=3.81529, val_acc=0.93874, time=0.50300
Epoch:0111, train_loss=2.66608, train_acc=0.99796, val_loss=3.81529, val_acc=0.93874, time=0.43200
Epoch:0112, train_loss=2.66599, train_acc=0.99813, val_loss=3.81529, val_acc=0.93874, time=0.56301
Epoch:0113, train_loss=2.66591, train_acc=0.99813, val_loss=3.81528, val_acc=0.93874, time=0.58401
Epoch:0114, train_loss=2.66582, train_acc=0.99830, val_loss=3.81528, val_acc=0.93874, time=0.46400
Epoch:0115, train_loss=2.66575, train_acc=0.99830, val_loss=3.81527, val_acc=0.93874, time=0.36799
Epoch:0116, train_loss=2.66567, train_acc=0.99830, val_loss=3.81527, val_acc=0.93874, time=0.37800
Epoch:0117, train_loss=2.66559, train_acc=0.99813, val_loss=3.81527, val_acc=0.93874, time=0.44001
Epoch:0118, train_loss=2.66552, train_acc=0.99830, val_loss=3.81526, val_acc=0.93874, time=0.39000
Epoch:0119, train_loss=2.66545, train_acc=0.99830, val_loss=3.81526, val_acc=0.93874, time=0.45500
Epoch:0120, train_loss=2.66538, train_acc=0.99830, val_loss=3.81526, val_acc=0.93874, time=0.42100
Epoch:0121, train_loss=2.66531, train_acc=0.99830, val_loss=3.81526, val_acc=0.93874, time=0.37300
Epoch:0122, train_loss=2.66524, train_acc=0.99830, val_loss=3.81525, val_acc=0.93874, time=0.45199
Epoch:0123, train_loss=2.66518, train_acc=0.99830, val_loss=3.81525, val_acc=0.93874, time=0.42800
Epoch:0124, train_loss=2.66511, train_acc=0.99830, val_loss=3.81525, val_acc=0.93874, time=0.49701
Epoch:0125, train_loss=2.66505, train_acc=0.99830, val_loss=3.81524, val_acc=0.93874, time=0.41200
Epoch:0126, train_loss=2.66499, train_acc=0.99830, val_loss=3.81524, val_acc=0.93874, time=0.39301
Epoch:0127, train_loss=2.66493, train_acc=0.99830, val_loss=3.81524, val_acc=0.93874, time=0.44699
Epoch:0128, train_loss=2.66487, train_acc=0.99830, val_loss=3.81523, val_acc=0.93874, time=0.41601
Epoch:0129, train_loss=2.66482, train_acc=0.99830, val_loss=3.81523, val_acc=0.93874, time=0.40599
Epoch:0130, train_loss=2.66476, train_acc=0.99830, val_loss=3.81523, val_acc=0.93874, time=0.50001
Epoch:0131, train_loss=2.66471, train_acc=0.99830, val_loss=3.81523, val_acc=0.93874, time=0.41900
Epoch:0132, train_loss=2.66465, train_acc=0.99830, val_loss=3.81522, val_acc=0.93874, time=0.41000
Epoch:0133, train_loss=2.66460, train_acc=0.99830, val_loss=3.81522, val_acc=0.93874, time=0.40800
Epoch:0134, train_loss=2.66455, train_acc=0.99830, val_loss=3.81522, val_acc=0.93874, time=0.50499
Epoch:0135, train_loss=2.66450, train_acc=0.99830, val_loss=3.81522, val_acc=0.93874, time=0.41201
Epoch:0136, train_loss=2.66445, train_acc=0.99830, val_loss=3.81522, val_acc=0.93874, time=0.38300
Epoch:0137, train_loss=2.66440, train_acc=0.99830, val_loss=3.81521, val_acc=0.93874, time=0.41699
Epoch:0138, train_loss=2.66436, train_acc=0.99830, val_loss=3.81521, val_acc=0.93874, time=0.47702
Epoch:0139, train_loss=2.66431, train_acc=0.99830, val_loss=3.81521, val_acc=0.93874, time=0.46600
Epoch:0140, train_loss=2.66426, train_acc=0.99830, val_loss=3.81521, val_acc=0.93874, time=0.43300
Epoch:0141, train_loss=2.66422, train_acc=0.99830, val_loss=3.81521, val_acc=0.93874, time=0.47699
Epoch:0142, train_loss=2.66418, train_acc=0.99830, val_loss=3.81521, val_acc=0.93874, time=0.38201
Epoch:0143, train_loss=2.66413, train_acc=0.99847, val_loss=3.81521, val_acc=0.93874, time=0.43600
Epoch:0144, train_loss=2.66409, train_acc=0.99847, val_loss=3.81521, val_acc=0.93874, time=0.38900
Epoch:0145, train_loss=2.66405, train_acc=0.99847, val_loss=3.81520, val_acc=0.93874, time=0.46799
Epoch:0146, train_loss=2.66401, train_acc=0.99847, val_loss=3.81520, val_acc=0.93874, time=0.44601
Epoch:0147, train_loss=2.66397, train_acc=0.99847, val_loss=3.81520, val_acc=0.93874, time=0.42299
Epoch:0148, train_loss=2.66393, train_acc=0.99847, val_loss=3.81520, val_acc=0.93874, time=0.43600
Epoch:0149, train_loss=2.66390, train_acc=0.99847, val_loss=3.81520, val_acc=0.93874, time=0.48001
Epoch:0150, train_loss=2.66386, train_acc=0.99864, val_loss=3.81520, val_acc=0.93874, time=0.48000
Epoch:0151, train_loss=2.66382, train_acc=0.99864, val_loss=3.81520, val_acc=0.93874, time=0.41600
Epoch:0152, train_loss=2.66379, train_acc=0.99864, val_loss=3.81520, val_acc=0.93874, time=0.40900
Epoch:0153, train_loss=2.66375, train_acc=0.99864, val_loss=3.81520, val_acc=0.93874, time=0.35900
Epoch:0154, train_loss=2.66372, train_acc=0.99864, val_loss=3.81520, val_acc=0.93874, time=0.45500
Epoch:0155, train_loss=2.66368, train_acc=0.99864, val_loss=3.81520, val_acc=0.93874, time=0.37600
Epoch:0156, train_loss=2.66365, train_acc=0.99864, val_loss=3.81520, val_acc=0.93874, time=0.43900
Epoch:0157, train_loss=2.66361, train_acc=0.99864, val_loss=3.81520, val_acc=0.93874, time=0.42600
Epoch:0158, train_loss=2.66358, train_acc=0.99864, val_loss=3.81520, val_acc=0.93874, time=0.48199
Epoch:0159, train_loss=2.66355, train_acc=0.99881, val_loss=3.81520, val_acc=0.93874, time=0.38500
Epoch:0160, train_loss=2.66352, train_acc=0.99881, val_loss=3.81520, val_acc=0.93874, time=0.37701
Epoch:0161, train_loss=2.66349, train_acc=0.99881, val_loss=3.81520, val_acc=0.93874, time=0.39299
Epoch:0162, train_loss=2.66346, train_acc=0.99881, val_loss=3.81520, val_acc=0.93874, time=0.47701
Epoch:0163, train_loss=2.66343, train_acc=0.99881, val_loss=3.81520, val_acc=0.93874, time=0.40300
Epoch:0164, train_loss=2.66340, train_acc=0.99881, val_loss=3.81520, val_acc=0.93874, time=0.42500
Early stopping...

Optimization Finished!

Test set results: loss= 3.44040, accuracy= 0.92056, time= 0.18700

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9563    0.9889    0.9723      1083
           1     0.8286    0.9587    0.8889       121
           2     0.9585    0.9282    0.9431       696
           3     1.0000    0.8667    0.9286        15
           4     0.7778    0.9333    0.8485        15
           5     1.0000    0.8235    0.9032        17
           6     0.8276    0.6667    0.7385        36
           7     0.9200    0.9200    0.9200        25
           8     1.0000    0.6842    0.8125        19
           9     0.8462    0.8462    0.8462        13
          10     0.8211    0.8966    0.8571        87
          11     0.8889    0.8000    0.8421        20
          12     0.7368    0.9333    0.8235        75
          13     0.7879    0.9286    0.8525        28
          14     1.0000    0.8889    0.9412         9
          15     0.8800    1.0000    0.9362        22
          16     0.8333    1.0000    0.9091         5
          17     0.9000    0.7500    0.8182        12
          18     0.8133    0.7531    0.7821        81
          19     0.8333    1.0000    0.9091        10
          20     1.0000    1.0000    1.0000         2
          21     0.8462    0.9167    0.8800        12
          22     1.0000    1.0000    1.0000         1
          23     1.0000    0.7778    0.8750         9
          24     1.0000    0.3333    0.5000        12
          25     0.6000    0.6000    0.6000         5
          26     1.0000    0.8000    0.8889        10
          27     1.0000    0.9167    0.9565        12
          28     0.0000    0.0000    0.0000         3
          29     1.0000    1.0000    1.0000         3
          30     0.7143    0.5556    0.6250         9
          31     1.0000    1.0000    1.0000         9
          32     0.7778    0.8750    0.8235         8
          33     0.8462    1.0000    0.9167        11
          34     1.0000    0.2000    0.3333         5
          35     1.0000    0.5000    0.6667         4
          36     0.7500    0.7500    0.7500         4
          37     1.0000    0.6667    0.8000         3
          38     1.0000    1.0000    1.0000         4
          39     0.0000    0.0000    0.0000         1
          40     0.2500    0.1667    0.2000         6
          41     1.0000    0.7273    0.8421        11
          42     1.0000    0.8889    0.9412         9
          43     0.0000    0.0000    0.0000         6
          44     1.0000    1.0000    1.0000         1
          45     0.5000    1.0000    0.6667         1
          46     0.0000    0.0000    0.0000         1
          47     1.0000    0.1429    0.2500         7
          48     0.0000    0.0000    0.0000         1
          49     0.0000    0.0000    0.0000         2
          50     0.0000    0.0000    0.0000         4
          51     0.0000    0.0000    0.0000         3

    accuracy                         0.9206      2568
   macro avg     0.7480    0.6805    0.6921      2568
weighted avg     0.9173    0.9206    0.9147      2568


Macro average Test Precision, Recall and F1-Score...
(0.7479582659745064, 0.6804635117503545, 0.6920810729468392, None)

Micro average Test Precision, Recall and F1-Score...
(0.9205607476635514, 0.9205607476635514, 0.9205607476635514, None)

Embeddings:
Word_embeddings: 8892
Train_doc_embeddings: 6532
Test_doc_embeddings: 2568

Elapsed time is 75.058835 seconds.
