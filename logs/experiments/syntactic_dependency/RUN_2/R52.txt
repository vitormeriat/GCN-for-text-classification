
==================== Torch Seed: 6120880567100

Model parameters

Layer: layer1.W0 | Size: torch.Size([17992, 200])
Layer: layer2.W0 | Size: torch.Size([200, 52])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  17992         52             5879            653            2568

Epoch:0001, train_loss=4.10884, train_acc=0.01939, val_loss=3.93674, val_acc=0.25574, time=0.48701
Epoch:0002, train_loss=3.79285, train_acc=0.26671, val_loss=3.90936, val_acc=0.47014, time=0.40800
Epoch:0003, train_loss=3.54742, train_acc=0.48239, val_loss=3.88782, val_acc=0.55590, time=0.39400
Epoch:0004, train_loss=3.35723, train_acc=0.57136, val_loss=3.87158, val_acc=0.63553, time=0.36300
Epoch:0005, train_loss=3.21401, train_acc=0.65385, val_loss=3.86156, val_acc=0.68300, time=0.36000
Epoch:0006, train_loss=3.12499, train_acc=0.70165, val_loss=3.85630, val_acc=0.69372, time=0.40199
Epoch:0007, train_loss=3.07769, train_acc=0.71101, val_loss=3.85270, val_acc=0.69985, time=0.44299
Epoch:0008, train_loss=3.04435, train_acc=0.72716, val_loss=3.84909, val_acc=0.73047, time=0.36701
Epoch:0009, train_loss=3.01062, train_acc=0.75353, val_loss=3.84539, val_acc=0.76876, time=0.45401
Epoch:0010, train_loss=2.97639, train_acc=0.78704, val_loss=3.84201, val_acc=0.80245, time=0.35400
Epoch:0011, train_loss=2.94546, train_acc=0.81647, val_loss=3.83926, val_acc=0.81011, time=0.45799
Epoch:0012, train_loss=2.92008, train_acc=0.83773, val_loss=3.83713, val_acc=0.82083, time=0.60301
Epoch:0013, train_loss=2.90011, train_acc=0.85202, val_loss=3.83548, val_acc=0.84380, time=0.50600
Epoch:0014, train_loss=2.88404, train_acc=0.86783, val_loss=3.83410, val_acc=0.85605, time=0.35200
Epoch:0015, train_loss=2.87019, train_acc=0.87855, val_loss=3.83284, val_acc=0.86371, time=0.36800
Epoch:0016, train_loss=2.85733, train_acc=0.88944, val_loss=3.83163, val_acc=0.87902, time=0.42100
Epoch:0017, train_loss=2.84496, train_acc=0.89964, val_loss=3.83047, val_acc=0.88821, time=0.50500
Epoch:0018, train_loss=2.83305, train_acc=0.90866, val_loss=3.82939, val_acc=0.89740, time=0.51299
Epoch:0019, train_loss=2.82175, train_acc=0.91665, val_loss=3.82841, val_acc=0.90046, time=0.37300
Epoch:0020, train_loss=2.81123, train_acc=0.92431, val_loss=3.82755, val_acc=0.90812, time=0.44901
Epoch:0021, train_loss=2.80159, train_acc=0.93043, val_loss=3.82683, val_acc=0.91118, time=0.37400
Epoch:0022, train_loss=2.79280, train_acc=0.93451, val_loss=3.82621, val_acc=0.91577, time=0.35000
Epoch:0023, train_loss=2.78478, train_acc=0.93757, val_loss=3.82568, val_acc=0.91424, time=0.42900
Epoch:0024, train_loss=2.77741, train_acc=0.94132, val_loss=3.82522, val_acc=0.91118, time=0.40000
Epoch:0025, train_loss=2.77061, train_acc=0.94421, val_loss=3.82480, val_acc=0.91118, time=0.45800
Epoch:0026, train_loss=2.76431, train_acc=0.94625, val_loss=3.82441, val_acc=0.91271, time=0.43400
Epoch:0027, train_loss=2.75843, train_acc=0.94795, val_loss=3.82404, val_acc=0.91424, time=0.42099
Epoch:0028, train_loss=2.75291, train_acc=0.94999, val_loss=3.82368, val_acc=0.91424, time=0.35301
Epoch:0029, train_loss=2.74767, train_acc=0.95254, val_loss=3.82331, val_acc=0.91424, time=0.38300
Epoch:0030, train_loss=2.74263, train_acc=0.95424, val_loss=3.82293, val_acc=0.91730, time=0.37600
Epoch:0031, train_loss=2.73779, train_acc=0.95543, val_loss=3.82256, val_acc=0.91884, time=0.47100
Epoch:0032, train_loss=2.73318, train_acc=0.95731, val_loss=3.82220, val_acc=0.91884, time=0.46599
Epoch:0033, train_loss=2.72887, train_acc=0.96020, val_loss=3.82186, val_acc=0.91884, time=0.42900
Epoch:0034, train_loss=2.72489, train_acc=0.96394, val_loss=3.82155, val_acc=0.92190, time=0.39601
Epoch:0035, train_loss=2.72126, train_acc=0.96700, val_loss=3.82126, val_acc=0.92190, time=0.44799
Epoch:0036, train_loss=2.71798, train_acc=0.96904, val_loss=3.82101, val_acc=0.92037, time=0.43901
Epoch:0037, train_loss=2.71499, train_acc=0.97040, val_loss=3.82078, val_acc=0.92496, time=0.45000
Epoch:0038, train_loss=2.71225, train_acc=0.97312, val_loss=3.82056, val_acc=0.92343, time=0.60200
Epoch:0039, train_loss=2.70971, train_acc=0.97466, val_loss=3.82035, val_acc=0.92496, time=0.45200
Epoch:0040, train_loss=2.70734, train_acc=0.97636, val_loss=3.82014, val_acc=0.92343, time=0.44500
Epoch:0041, train_loss=2.70509, train_acc=0.97772, val_loss=3.81994, val_acc=0.92496, time=0.52099
Epoch:0042, train_loss=2.70296, train_acc=0.98044, val_loss=3.81974, val_acc=0.92802, time=0.35801
Epoch:0043, train_loss=2.70093, train_acc=0.98146, val_loss=3.81954, val_acc=0.92802, time=0.52500
Epoch:0044, train_loss=2.69900, train_acc=0.98197, val_loss=3.81935, val_acc=0.92802, time=0.35199
Epoch:0045, train_loss=2.69717, train_acc=0.98384, val_loss=3.81917, val_acc=0.92802, time=0.38701
Epoch:0046, train_loss=2.69546, train_acc=0.98469, val_loss=3.81899, val_acc=0.92956, time=0.45600
Epoch:0047, train_loss=2.69386, train_acc=0.98605, val_loss=3.81883, val_acc=0.93262, time=0.39900
Epoch:0048, train_loss=2.69237, train_acc=0.98724, val_loss=3.81868, val_acc=0.93262, time=0.40100
Epoch:0049, train_loss=2.69098, train_acc=0.98809, val_loss=3.81854, val_acc=0.93415, time=0.35200
Epoch:0050, train_loss=2.68969, train_acc=0.98826, val_loss=3.81841, val_acc=0.93721, time=0.44900
Epoch:0051, train_loss=2.68849, train_acc=0.98843, val_loss=3.81828, val_acc=0.93721, time=0.35700
Epoch:0052, train_loss=2.68735, train_acc=0.98860, val_loss=3.81817, val_acc=0.93721, time=0.40701
Epoch:0053, train_loss=2.68628, train_acc=0.98928, val_loss=3.81805, val_acc=0.93721, time=0.39500
Epoch:0054, train_loss=2.68525, train_acc=0.98945, val_loss=3.81794, val_acc=0.93721, time=0.49000
Epoch:0055, train_loss=2.68428, train_acc=0.99013, val_loss=3.81783, val_acc=0.93721, time=0.41299
Epoch:0056, train_loss=2.68334, train_acc=0.99030, val_loss=3.81772, val_acc=0.93568, time=0.49200
Epoch:0057, train_loss=2.68244, train_acc=0.99098, val_loss=3.81762, val_acc=0.93415, time=0.35201
Epoch:0058, train_loss=2.68158, train_acc=0.99167, val_loss=3.81751, val_acc=0.93568, time=0.40300
Epoch:0059, train_loss=2.68076, train_acc=0.99235, val_loss=3.81741, val_acc=0.93568, time=0.37600
Epoch:0060, train_loss=2.67998, train_acc=0.99286, val_loss=3.81730, val_acc=0.93721, time=0.37500
Epoch:0061, train_loss=2.67925, train_acc=0.99320, val_loss=3.81721, val_acc=0.93568, time=0.43300
Epoch:0062, train_loss=2.67856, train_acc=0.99337, val_loss=3.81711, val_acc=0.93568, time=0.48900
Epoch:0063, train_loss=2.67790, train_acc=0.99337, val_loss=3.81702, val_acc=0.93568, time=0.46400
Epoch:0064, train_loss=2.67729, train_acc=0.99388, val_loss=3.81694, val_acc=0.93568, time=0.43000
Epoch:0065, train_loss=2.67671, train_acc=0.99388, val_loss=3.81686, val_acc=0.93721, time=0.35099
Epoch:0066, train_loss=2.67616, train_acc=0.99439, val_loss=3.81678, val_acc=0.93721, time=0.35400
Epoch:0067, train_loss=2.67565, train_acc=0.99456, val_loss=3.81671, val_acc=0.93721, time=0.43900
Epoch:0068, train_loss=2.67516, train_acc=0.99456, val_loss=3.81664, val_acc=0.93874, time=0.36901
Epoch:0069, train_loss=2.67469, train_acc=0.99456, val_loss=3.81658, val_acc=0.93874, time=0.35500
Epoch:0070, train_loss=2.67425, train_acc=0.99473, val_loss=3.81652, val_acc=0.93721, time=0.40900
Epoch:0071, train_loss=2.67382, train_acc=0.99507, val_loss=3.81646, val_acc=0.93721, time=0.38600
Epoch:0072, train_loss=2.67341, train_acc=0.99507, val_loss=3.81641, val_acc=0.93721, time=0.36500
Epoch:0073, train_loss=2.67302, train_acc=0.99524, val_loss=3.81635, val_acc=0.93874, time=0.35300
Epoch:0074, train_loss=2.67265, train_acc=0.99541, val_loss=3.81631, val_acc=0.94028, time=0.40100
Epoch:0075, train_loss=2.67229, train_acc=0.99575, val_loss=3.81627, val_acc=0.94028, time=0.59000
Epoch:0076, train_loss=2.67195, train_acc=0.99575, val_loss=3.81623, val_acc=0.94028, time=0.45500
Epoch:0077, train_loss=2.67163, train_acc=0.99592, val_loss=3.81619, val_acc=0.94028, time=0.40100
Epoch:0078, train_loss=2.67132, train_acc=0.99592, val_loss=3.81616, val_acc=0.94028, time=0.39600
Epoch:0079, train_loss=2.67103, train_acc=0.99643, val_loss=3.81613, val_acc=0.94181, time=0.50699
Epoch:0080, train_loss=2.67075, train_acc=0.99643, val_loss=3.81611, val_acc=0.94181, time=0.39900
Epoch:0081, train_loss=2.67048, train_acc=0.99626, val_loss=3.81609, val_acc=0.94181, time=0.42100
Epoch:0082, train_loss=2.67023, train_acc=0.99660, val_loss=3.81607, val_acc=0.94181, time=0.37601
Epoch:0083, train_loss=2.66999, train_acc=0.99660, val_loss=3.81605, val_acc=0.94181, time=0.51600
Epoch:0084, train_loss=2.66976, train_acc=0.99660, val_loss=3.81603, val_acc=0.94181, time=0.38000
Epoch:0085, train_loss=2.66954, train_acc=0.99660, val_loss=3.81601, val_acc=0.94181, time=0.47799
Epoch:0086, train_loss=2.66933, train_acc=0.99677, val_loss=3.81600, val_acc=0.94181, time=0.41601
Epoch:0087, train_loss=2.66913, train_acc=0.99694, val_loss=3.81598, val_acc=0.94181, time=0.39000
Epoch:0088, train_loss=2.66894, train_acc=0.99694, val_loss=3.81597, val_acc=0.94028, time=0.44800
Epoch:0089, train_loss=2.66875, train_acc=0.99728, val_loss=3.81596, val_acc=0.94181, time=0.37900
Epoch:0090, train_loss=2.66857, train_acc=0.99745, val_loss=3.81595, val_acc=0.94181, time=0.41799
Epoch:0091, train_loss=2.66840, train_acc=0.99762, val_loss=3.81594, val_acc=0.94181, time=0.41800
Epoch:0092, train_loss=2.66824, train_acc=0.99745, val_loss=3.81593, val_acc=0.94334, time=0.41400
Epoch:0093, train_loss=2.66808, train_acc=0.99745, val_loss=3.81592, val_acc=0.94334, time=0.36000
Epoch:0094, train_loss=2.66792, train_acc=0.99762, val_loss=3.81591, val_acc=0.94334, time=0.42301
Epoch:0095, train_loss=2.66777, train_acc=0.99762, val_loss=3.81590, val_acc=0.94334, time=0.38600
Epoch:0096, train_loss=2.66763, train_acc=0.99779, val_loss=3.81589, val_acc=0.94334, time=0.37699
Epoch:0097, train_loss=2.66749, train_acc=0.99779, val_loss=3.81588, val_acc=0.94181, time=0.37500
Epoch:0098, train_loss=2.66736, train_acc=0.99813, val_loss=3.81587, val_acc=0.94181, time=0.45300
Epoch:0099, train_loss=2.66723, train_acc=0.99813, val_loss=3.81586, val_acc=0.94181, time=0.48501
Epoch:0100, train_loss=2.66710, train_acc=0.99813, val_loss=3.81585, val_acc=0.94181, time=0.45600
Epoch:0101, train_loss=2.66698, train_acc=0.99813, val_loss=3.81584, val_acc=0.94181, time=0.42400
Epoch:0102, train_loss=2.66686, train_acc=0.99813, val_loss=3.81583, val_acc=0.94181, time=0.37000
Epoch:0103, train_loss=2.66675, train_acc=0.99813, val_loss=3.81583, val_acc=0.94181, time=0.35099
Epoch:0104, train_loss=2.66664, train_acc=0.99813, val_loss=3.81582, val_acc=0.94181, time=0.43801
Epoch:0105, train_loss=2.66653, train_acc=0.99796, val_loss=3.81581, val_acc=0.94181, time=0.48300
Epoch:0106, train_loss=2.66642, train_acc=0.99796, val_loss=3.81581, val_acc=0.94181, time=0.41900
Epoch:0107, train_loss=2.66632, train_acc=0.99796, val_loss=3.81580, val_acc=0.94181, time=0.36100
Epoch:0108, train_loss=2.66623, train_acc=0.99813, val_loss=3.81579, val_acc=0.94334, time=0.49900
Epoch:0109, train_loss=2.66613, train_acc=0.99813, val_loss=3.81579, val_acc=0.94334, time=0.43300
Epoch:0110, train_loss=2.66604, train_acc=0.99813, val_loss=3.81578, val_acc=0.94334, time=0.39700
Epoch:0111, train_loss=2.66595, train_acc=0.99813, val_loss=3.81578, val_acc=0.94334, time=0.35500
Epoch:0112, train_loss=2.66586, train_acc=0.99813, val_loss=3.81577, val_acc=0.94334, time=0.41401
Epoch:0113, train_loss=2.66577, train_acc=0.99847, val_loss=3.81577, val_acc=0.94334, time=0.40200
Epoch:0114, train_loss=2.66569, train_acc=0.99847, val_loss=3.81576, val_acc=0.94334, time=0.35400
Epoch:0115, train_loss=2.66561, train_acc=0.99847, val_loss=3.81576, val_acc=0.94334, time=0.38700
Epoch:0116, train_loss=2.66553, train_acc=0.99847, val_loss=3.81576, val_acc=0.94334, time=0.46000
Epoch:0117, train_loss=2.66546, train_acc=0.99847, val_loss=3.81575, val_acc=0.94334, time=0.42600
Epoch:0118, train_loss=2.66538, train_acc=0.99847, val_loss=3.81575, val_acc=0.94334, time=0.45500
Epoch:0119, train_loss=2.66531, train_acc=0.99847, val_loss=3.81575, val_acc=0.94334, time=0.47500
Epoch:0120, train_loss=2.66524, train_acc=0.99847, val_loss=3.81574, val_acc=0.94334, time=0.39800
Epoch:0121, train_loss=2.66517, train_acc=0.99847, val_loss=3.81574, val_acc=0.94334, time=0.46900
Epoch:0122, train_loss=2.66510, train_acc=0.99847, val_loss=3.81574, val_acc=0.94334, time=0.41199
Epoch:0123, train_loss=2.66504, train_acc=0.99847, val_loss=3.81573, val_acc=0.94334, time=0.45801
Epoch:0124, train_loss=2.66497, train_acc=0.99847, val_loss=3.81573, val_acc=0.94334, time=0.35200
Epoch:0125, train_loss=2.66491, train_acc=0.99847, val_loss=3.81573, val_acc=0.94334, time=0.40200
Epoch:0126, train_loss=2.66485, train_acc=0.99847, val_loss=3.81573, val_acc=0.94487, time=0.35300
Epoch:0127, train_loss=2.66479, train_acc=0.99847, val_loss=3.81572, val_acc=0.94487, time=0.36500
Epoch:0128, train_loss=2.66473, train_acc=0.99847, val_loss=3.81572, val_acc=0.94487, time=0.36099
Epoch:0129, train_loss=2.66468, train_acc=0.99847, val_loss=3.81572, val_acc=0.94487, time=0.35201
Epoch:0130, train_loss=2.66462, train_acc=0.99847, val_loss=3.81572, val_acc=0.94487, time=0.41599
Epoch:0131, train_loss=2.66457, train_acc=0.99847, val_loss=3.81572, val_acc=0.94487, time=0.49299
Epoch:0132, train_loss=2.66451, train_acc=0.99847, val_loss=3.81572, val_acc=0.94487, time=0.48501
Epoch:0133, train_loss=2.66446, train_acc=0.99847, val_loss=3.81571, val_acc=0.94487, time=0.41099
Epoch:0134, train_loss=2.66441, train_acc=0.99847, val_loss=3.81571, val_acc=0.94487, time=0.38300
Epoch:0135, train_loss=2.66436, train_acc=0.99847, val_loss=3.81571, val_acc=0.94487, time=0.42799
Epoch:0136, train_loss=2.66431, train_acc=0.99847, val_loss=3.81571, val_acc=0.94487, time=0.50400
Epoch:0137, train_loss=2.66426, train_acc=0.99847, val_loss=3.81571, val_acc=0.94487, time=0.43599
Epoch:0138, train_loss=2.66422, train_acc=0.99847, val_loss=3.81571, val_acc=0.94487, time=0.45300
Epoch:0139, train_loss=2.66417, train_acc=0.99847, val_loss=3.81571, val_acc=0.94487, time=0.36499
Epoch:0140, train_loss=2.66413, train_acc=0.99847, val_loss=3.81571, val_acc=0.94487, time=0.38201
Epoch:0141, train_loss=2.66408, train_acc=0.99847, val_loss=3.81571, val_acc=0.94487, time=0.35300
Epoch:0142, train_loss=2.66404, train_acc=0.99847, val_loss=3.81570, val_acc=0.94487, time=0.40600
Epoch:0143, train_loss=2.66400, train_acc=0.99847, val_loss=3.81570, val_acc=0.94487, time=0.41000
Epoch:0144, train_loss=2.66395, train_acc=0.99847, val_loss=3.81570, val_acc=0.94487, time=0.35000
Epoch:0145, train_loss=2.66391, train_acc=0.99847, val_loss=3.81570, val_acc=0.94487, time=0.48300
Epoch:0146, train_loss=2.66387, train_acc=0.99847, val_loss=3.81570, val_acc=0.94487, time=0.49300
Epoch:0147, train_loss=2.66383, train_acc=0.99847, val_loss=3.81570, val_acc=0.94487, time=0.35700
Epoch:0148, train_loss=2.66380, train_acc=0.99847, val_loss=3.81570, val_acc=0.94487, time=0.36601
Epoch:0149, train_loss=2.66376, train_acc=0.99847, val_loss=3.81570, val_acc=0.94487, time=0.35500
Epoch:0150, train_loss=2.66372, train_acc=0.99847, val_loss=3.81570, val_acc=0.94334, time=0.47000
Epoch:0151, train_loss=2.66369, train_acc=0.99847, val_loss=3.81570, val_acc=0.94334, time=0.53800
Epoch:0152, train_loss=2.66365, train_acc=0.99847, val_loss=3.81570, val_acc=0.94334, time=0.38200
Epoch:0153, train_loss=2.66362, train_acc=0.99847, val_loss=3.81570, val_acc=0.94334, time=0.35000
Epoch:0154, train_loss=2.66358, train_acc=0.99847, val_loss=3.81570, val_acc=0.94334, time=0.39300
Epoch:0155, train_loss=2.66355, train_acc=0.99847, val_loss=3.81570, val_acc=0.94334, time=0.53500
Epoch:0156, train_loss=2.66351, train_acc=0.99847, val_loss=3.81570, val_acc=0.94334, time=0.37300
Epoch:0157, train_loss=2.66348, train_acc=0.99847, val_loss=3.81570, val_acc=0.94334, time=0.40900
Epoch:0158, train_loss=2.66345, train_acc=0.99847, val_loss=3.81570, val_acc=0.94334, time=0.35400
Epoch:0159, train_loss=2.66342, train_acc=0.99881, val_loss=3.81570, val_acc=0.94334, time=0.42700
Epoch:0160, train_loss=2.66339, train_acc=0.99881, val_loss=3.81570, val_acc=0.94334, time=0.42600
Epoch:0161, train_loss=2.66336, train_acc=0.99881, val_loss=3.81570, val_acc=0.94334, time=0.40699
Epoch:0162, train_loss=2.66333, train_acc=0.99881, val_loss=3.81570, val_acc=0.94334, time=0.42499
Epoch:0163, train_loss=2.66330, train_acc=0.99881, val_loss=3.81570, val_acc=0.94334, time=0.36301
Early stopping...

Optimization Finished!

Test set results: loss= 3.44009, accuracy= 0.92368, time= 0.10900

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9589    0.9898    0.9741      1083
           1     0.8647    0.9504    0.9055       121
           2     0.9631    0.9368    0.9497       696
           3     1.0000    0.8000    0.8889        15
           4     0.9286    0.8667    0.8966        15
           5     1.0000    0.8235    0.9032        17
           6     0.8125    0.7222    0.7647        36
           7     0.8519    0.9200    0.8846        25
           8     0.9333    0.7368    0.8235        19
           9     0.8462    0.8462    0.8462        13
          10     0.7800    0.8966    0.8342        87
          11     0.9412    0.8000    0.8649        20
          12     0.7474    0.9467    0.8353        75
          13     0.8387    0.9286    0.8814        28
          14     1.0000    0.8889    0.9412         9
          15     0.9167    1.0000    0.9565        22
          16     0.8333    1.0000    0.9091         5
          17     0.8182    0.7500    0.7826        12
          18     0.8000    0.7407    0.7692        81
          19     0.8182    0.9000    0.8571        10
          20     1.0000    1.0000    1.0000         2
          21     0.8571    1.0000    0.9231        12
          22     1.0000    1.0000    1.0000         1
          23     1.0000    0.7778    0.8750         9
          24     0.8000    0.3333    0.4706        12
          25     1.0000    0.6000    0.7500         5
          26     1.0000    0.9000    0.9474        10
          27     1.0000    0.9167    0.9565        12
          28     0.0000    0.0000    0.0000         3
          29     1.0000    1.0000    1.0000         3
          30     0.6667    0.4444    0.5333         9
          31     1.0000    1.0000    1.0000         9
          32     0.7778    0.8750    0.8235         8
          33     0.8462    1.0000    0.9167        11
          34     1.0000    0.2000    0.3333         5
          35     1.0000    0.5000    0.6667         4
          36     0.6000    0.7500    0.6667         4
          37     1.0000    0.3333    0.5000         3
          38     1.0000    1.0000    1.0000         4
          39     1.0000    1.0000    1.0000         1
          40     0.2500    0.1667    0.2000         6
          41     0.9000    0.8182    0.8571        11
          42     1.0000    0.8889    0.9412         9
          43     0.0000    0.0000    0.0000         6
          44     1.0000    1.0000    1.0000         1
          45     0.5000    1.0000    0.6667         1
          46     0.0000    0.0000    0.0000         1
          47     1.0000    0.1429    0.2500         7
          48     0.0000    0.0000    0.0000         1
          49     0.0000    0.0000    0.0000         2
          50     0.0000    0.0000    0.0000         4
          51     0.0000    0.0000    0.0000         3

    accuracy                         0.9237      2568
   macro avg     0.7664    0.6941    0.7067      2568
weighted avg     0.9196    0.9237    0.9179      2568


Macro average Test Precision, Recall and F1-Score...
(0.7663530566103776, 0.6940581083497388, 0.706659208954063, None)

Micro average Test Precision, Recall and F1-Score...
(0.9236760124610592, 0.9236760124610592, 0.9236760124610592, None)

Embeddings:
Word_embeddings: 8892
Train_doc_embeddings: 6532
Test_doc_embeddings: 2568

Elapsed time is 69.899858 seconds.
