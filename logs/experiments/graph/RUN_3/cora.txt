
==================== Torch Seed: 14203424620800

Model parameters

Layer: layer1.W0 | Size: torch.Size([4051, 200])
Layer: layer2.W0 | Size: torch.Size([200, 7])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
   4051          7             1707            189             812

Epoch:0001, train_loss=4.13059, train_acc=0.16637, val_loss=2.19841, val_acc=0.16931, time=0.03801
Epoch:0002, train_loss=3.56164, train_acc=0.24194, val_loss=2.18998, val_acc=0.18519, time=0.03800
Epoch:0003, train_loss=3.12859, train_acc=0.31869, val_loss=2.18392, val_acc=0.17460, time=0.03701
Epoch:0004, train_loss=2.76372, train_acc=0.38840, val_loss=2.17898, val_acc=0.17989, time=0.03501
Epoch:0005, train_loss=2.44923, train_acc=0.46924, val_loss=2.17507, val_acc=0.19577, time=0.02702
Epoch:0006, train_loss=2.17863, train_acc=0.53837, val_loss=2.17183, val_acc=0.20635, time=0.02801
Epoch:0007, train_loss=1.94722, train_acc=0.61394, val_loss=2.16918, val_acc=0.20635, time=0.02701
Epoch:0008, train_loss=1.75472, train_acc=0.68600, val_loss=2.16712, val_acc=0.19048, time=0.02801
Epoch:0009, train_loss=1.60134, train_acc=0.76333, val_loss=2.16571, val_acc=0.19048, time=0.02701
Epoch:0010, train_loss=1.48310, train_acc=0.81371, val_loss=2.16483, val_acc=0.19048, time=0.02701
Epoch:0011, train_loss=1.39247, train_acc=0.85237, val_loss=2.16436, val_acc=0.20635, time=0.02702
Epoch:0012, train_loss=1.32258, train_acc=0.89045, val_loss=2.16419, val_acc=0.19577, time=0.02801
Epoch:0013, train_loss=1.26851, train_acc=0.91916, val_loss=2.16422, val_acc=0.20106, time=0.02701
Epoch:0014, train_loss=1.22722, train_acc=0.94552, val_loss=2.16441, val_acc=0.20106, time=0.02701
Epoch:0015, train_loss=1.19663, train_acc=0.96134, val_loss=2.16471, val_acc=0.20635, time=0.02701
Epoch:0016, train_loss=1.17453, train_acc=0.96954, val_loss=2.16511, val_acc=0.21164, time=0.02901
Epoch:0017, train_loss=1.15874, train_acc=0.98125, val_loss=2.16564, val_acc=0.22222, time=0.03000
Early stopping...

Optimization Finished!

Test set results: loss= 2.85736, accuracy= 0.22537, time= 0.01001

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.3856    0.3906    0.3881       233
           1     0.2212    0.1643    0.1885       140
           2     0.0842    0.1231    0.1000        65
           3     0.1589    0.1405    0.1491       121
           4     0.2471    0.1810    0.2090       116
           5     0.1546    0.1630    0.1587        92
           6     0.0909    0.1778    0.1203        45

    accuracy                         0.2254       812
   macro avg     0.1918    0.1915    0.1877       812
weighted avg     0.2370    0.2254    0.2286       812


Macro average Test Precision, Recall and F1-Score...
(0.19177759816825007, 0.1914674548346662, 0.18767046188063866, None)

Micro average Test Precision, Recall and F1-Score...
(0.22536945812807882, 0.22536945812807882, 0.22536945812807882, None)

Embeddings:
Word_embeddings: 1343
Train_doc_embeddings: 1896
Test_doc_embeddings: 812

Elapsed time is 0.731999 seconds.
