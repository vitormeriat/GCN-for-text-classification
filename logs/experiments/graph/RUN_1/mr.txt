
==================== Torch Seed: 14092665796500

Model parameters

Layer: layer1.W0 | Size: torch.Size([29426, 200])
Layer: layer2.W0 | Size: torch.Size([200, 2])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  29426          2             6398            710            3554

Epoch:0001, train_loss=1.43759, train_acc=0.50250, val_loss=0.77504, val_acc=0.50000, time=0.86101
Epoch:0002, train_loss=1.22088, train_acc=0.57956, val_loss=0.77518, val_acc=0.50000, time=0.78000
Epoch:0003, train_loss=1.05647, train_acc=0.65380, val_loss=0.77380, val_acc=0.50000, time=0.78599
Epoch:0004, train_loss=0.91919, train_acc=0.72257, val_loss=0.77181, val_acc=0.49296, time=0.80499
Epoch:0005, train_loss=0.81041, train_acc=0.78634, val_loss=0.77027, val_acc=0.49155, time=0.79001
Epoch:0006, train_loss=0.72972, train_acc=0.83948, val_loss=0.76935, val_acc=0.49859, time=0.77301
Epoch:0007, train_loss=0.67164, train_acc=0.88309, val_loss=0.76875, val_acc=0.50000, time=0.83800
Epoch:0008, train_loss=0.62989, train_acc=0.91701, val_loss=0.76823, val_acc=0.50141, time=0.84701
Epoch:0009, train_loss=0.60007, train_acc=0.94092, val_loss=0.76772, val_acc=0.50563, time=0.80900
Epoch:0010, train_loss=0.57903, train_acc=0.95921, val_loss=0.76726, val_acc=0.49859, time=0.97299
Epoch:0011, train_loss=0.56471, train_acc=0.97374, val_loss=0.76688, val_acc=0.49718, time=0.88200
Epoch:0012, train_loss=0.55553, train_acc=0.98484, val_loss=0.76659, val_acc=0.49718, time=0.86601
Epoch:0013, train_loss=0.55005, train_acc=0.99093, val_loss=0.76640, val_acc=0.49718, time=0.90102
Epoch:0014, train_loss=0.54689, train_acc=0.99531, val_loss=0.76628, val_acc=0.50000, time=0.95799
Epoch:0015, train_loss=0.54512, train_acc=0.99734, val_loss=0.76620, val_acc=0.49718, time=0.87802
Epoch:0016, train_loss=0.54410, train_acc=0.99828, val_loss=0.76617, val_acc=0.49577, time=0.80800
Epoch:0017, train_loss=0.54347, train_acc=0.99891, val_loss=0.76616, val_acc=0.49296, time=0.78300
Epoch:0018, train_loss=0.54305, train_acc=0.99922, val_loss=0.76616, val_acc=0.49437, time=0.90199
Epoch:0019, train_loss=0.54276, train_acc=0.99922, val_loss=0.76618, val_acc=0.49577, time=0.84300
Epoch:0020, train_loss=0.54258, train_acc=0.99969, val_loss=0.76621, val_acc=0.49155, time=0.83601
Epoch:0021, train_loss=0.54249, train_acc=0.99984, val_loss=0.76625, val_acc=0.49577, time=0.77100
Epoch:0022, train_loss=0.54246, train_acc=1.00000, val_loss=0.76630, val_acc=0.49718, time=0.82000
Early stopping...

Optimization Finished!

Test set results: loss= 1.04444, accuracy= 0.49690, time= 0.27400

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.4972    0.5464    0.5206      1777
           1     0.4966    0.4474    0.4707      1777

    accuracy                         0.4969      3554
   macro avg     0.4969    0.4969    0.4957      3554
weighted avg     0.4969    0.4969    0.4957      3554


Macro average Test Precision, Recall and F1-Score...
(0.4968742334300151, 0.49690489589195275, 0.49566807460987905, None)

Micro average Test Precision, Recall and F1-Score...
(0.49690489589195275, 0.49690489589195275, 0.49690489589195275, None)

Embeddings:
Word_embeddings: 18764
Train_doc_embeddings: 7108
Test_doc_embeddings: 3554

Elapsed time is 21.967942 seconds.
