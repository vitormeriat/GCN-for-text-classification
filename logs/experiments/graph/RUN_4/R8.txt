
==================== Torch Seed: 10613734828900

Model parameters

Layer: layer1.W0 | Size: torch.Size([15362, 200])
Layer: layer2.W0 | Size: torch.Size([200, 8])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  15362          8             4937            548            2189

Epoch:0001, train_loss=5.31875, train_acc=0.08041, val_loss=2.38193, val_acc=0.12409, time=0.43200
Epoch:0002, train_loss=4.44462, train_acc=0.14685, val_loss=2.33119, val_acc=0.18248, time=0.29200
Epoch:0003, train_loss=3.73659, train_acc=0.23152, val_loss=2.29047, val_acc=0.23723, time=0.40000
Epoch:0004, train_loss=3.16276, train_acc=0.34090, val_loss=2.25661, val_acc=0.27555, time=0.36403
Epoch:0005, train_loss=2.69825, train_acc=0.44764, val_loss=2.22987, val_acc=0.31569, time=0.28902
Epoch:0006, train_loss=2.34398, train_acc=0.55904, val_loss=2.21076, val_acc=0.34307, time=0.33098
Epoch:0007, train_loss=2.09842, train_acc=0.65039, val_loss=2.19899, val_acc=0.37226, time=0.32500
Epoch:0008, train_loss=1.94563, train_acc=0.72129, val_loss=2.19282, val_acc=0.40511, time=0.28801
Epoch:0009, train_loss=1.85086, train_acc=0.76666, val_loss=2.18983, val_acc=0.44526, time=0.35399
Epoch:0010, train_loss=1.78122, train_acc=0.79927, val_loss=2.18822, val_acc=0.44891, time=0.39301
Epoch:0011, train_loss=1.71877, train_acc=0.83148, val_loss=2.18696, val_acc=0.45803, time=0.29000
Epoch:0012, train_loss=1.65994, train_acc=0.86186, val_loss=2.18560, val_acc=0.47263, time=0.33599
Epoch:0013, train_loss=1.60663, train_acc=0.88941, val_loss=2.18405, val_acc=0.48358, time=0.28700
Epoch:0014, train_loss=1.56097, train_acc=0.91229, val_loss=2.18236, val_acc=0.48358, time=0.28601
Epoch:0015, train_loss=1.52361, train_acc=0.92971, val_loss=2.18058, val_acc=0.48905, time=0.38800
Epoch:0016, train_loss=1.49429, train_acc=0.94754, val_loss=2.17878, val_acc=0.49270, time=0.33500
Epoch:0017, train_loss=1.47213, train_acc=0.96111, val_loss=2.17700, val_acc=0.49453, time=0.28700
Epoch:0018, train_loss=1.45559, train_acc=0.97022, val_loss=2.17527, val_acc=0.49818, time=0.29501
Epoch:0019, train_loss=1.44321, train_acc=0.97671, val_loss=2.17362, val_acc=0.50365, time=0.34600
Epoch:0020, train_loss=1.43408, train_acc=0.98420, val_loss=2.17206, val_acc=0.50730, time=0.39100
Epoch:0021, train_loss=1.42763, train_acc=0.98967, val_loss=2.17062, val_acc=0.50912, time=0.29300
Epoch:0022, train_loss=1.42309, train_acc=0.99271, val_loss=2.16930, val_acc=0.50912, time=0.36301
Epoch:0023, train_loss=1.41983, train_acc=0.99453, val_loss=2.16812, val_acc=0.51095, time=0.28601
Epoch:0024, train_loss=1.41746, train_acc=0.99534, val_loss=2.16706, val_acc=0.51460, time=0.35200
Epoch:0025, train_loss=1.41572, train_acc=0.99696, val_loss=2.16612, val_acc=0.51825, time=0.35201
Epoch:0026, train_loss=1.41450, train_acc=0.99777, val_loss=2.16529, val_acc=0.52007, time=0.42200
Epoch:0027, train_loss=1.41365, train_acc=0.99838, val_loss=2.16457, val_acc=0.52372, time=0.31300
Epoch:0028, train_loss=1.41303, train_acc=0.99858, val_loss=2.16393, val_acc=0.52372, time=0.28900
Epoch:0029, train_loss=1.41256, train_acc=0.99919, val_loss=2.16337, val_acc=0.52555, time=0.28699
Epoch:0030, train_loss=1.41221, train_acc=0.99919, val_loss=2.16288, val_acc=0.52555, time=0.28700
Epoch:0031, train_loss=1.41194, train_acc=0.99939, val_loss=2.16244, val_acc=0.52737, time=0.28900
Epoch:0032, train_loss=1.41175, train_acc=0.99959, val_loss=2.16206, val_acc=0.52920, time=0.41001
Epoch:0033, train_loss=1.41161, train_acc=0.99980, val_loss=2.16172, val_acc=0.52737, time=0.29700
Epoch:0034, train_loss=1.41150, train_acc=0.99980, val_loss=2.16141, val_acc=0.53102, time=0.34799
Epoch:0035, train_loss=1.41142, train_acc=0.99980, val_loss=2.16115, val_acc=0.53102, time=0.31600
Epoch:0036, train_loss=1.41134, train_acc=0.99980, val_loss=2.16091, val_acc=0.53650, time=0.28900
Epoch:0037, train_loss=1.41129, train_acc=0.99980, val_loss=2.16069, val_acc=0.53650, time=0.29000
Epoch:0038, train_loss=1.41124, train_acc=1.00000, val_loss=2.16050, val_acc=0.53650, time=0.29401
Epoch:0039, train_loss=1.41121, train_acc=1.00000, val_loss=2.16033, val_acc=0.53467, time=0.34400
Epoch:0040, train_loss=1.41120, train_acc=1.00000, val_loss=2.16018, val_acc=0.53467, time=0.31600
Epoch:0041, train_loss=1.41119, train_acc=1.00000, val_loss=2.16004, val_acc=0.53285, time=0.30000
Epoch:0042, train_loss=1.41118, train_acc=1.00000, val_loss=2.15992, val_acc=0.53285, time=0.28602
Epoch:0043, train_loss=1.41118, train_acc=1.00000, val_loss=2.15981, val_acc=0.53285, time=0.28899
Epoch:0044, train_loss=1.41118, train_acc=1.00000, val_loss=2.15971, val_acc=0.53285, time=0.33700
Epoch:0045, train_loss=1.41118, train_acc=1.00000, val_loss=2.15962, val_acc=0.53285, time=0.34401
Epoch:0046, train_loss=1.41118, train_acc=1.00000, val_loss=2.15954, val_acc=0.53285, time=0.30500
Epoch:0047, train_loss=1.41117, train_acc=1.00000, val_loss=2.15947, val_acc=0.53285, time=0.32199
Epoch:0048, train_loss=1.41117, train_acc=1.00000, val_loss=2.15940, val_acc=0.53285, time=0.35502
Epoch:0049, train_loss=1.41117, train_acc=1.00000, val_loss=2.15935, val_acc=0.53285, time=0.36898
Epoch:0050, train_loss=1.41117, train_acc=1.00000, val_loss=2.15929, val_acc=0.53285, time=0.35600
Epoch:0051, train_loss=1.41117, train_acc=1.00000, val_loss=2.15925, val_acc=0.53285, time=0.29201
Epoch:0052, train_loss=1.41117, train_acc=1.00000, val_loss=2.15920, val_acc=0.53467, time=0.28601
Epoch:0053, train_loss=1.41117, train_acc=1.00000, val_loss=2.15916, val_acc=0.53285, time=0.29499
Epoch:0054, train_loss=1.41117, train_acc=1.00000, val_loss=2.15913, val_acc=0.53285, time=0.35801
Epoch:0055, train_loss=1.41117, train_acc=1.00000, val_loss=2.15909, val_acc=0.53285, time=0.28701
Epoch:0056, train_loss=1.41117, train_acc=1.00000, val_loss=2.15907, val_acc=0.53285, time=0.32199
Epoch:0057, train_loss=1.41117, train_acc=1.00000, val_loss=2.15904, val_acc=0.53285, time=0.34801
Epoch:0058, train_loss=1.41117, train_acc=1.00000, val_loss=2.15902, val_acc=0.53285, time=0.28700
Epoch:0059, train_loss=1.41117, train_acc=1.00000, val_loss=2.15899, val_acc=0.53285, time=0.28899
Epoch:0060, train_loss=1.41117, train_acc=1.00000, val_loss=2.15897, val_acc=0.53285, time=0.30900
Epoch:0061, train_loss=1.41117, train_acc=1.00000, val_loss=2.15896, val_acc=0.53285, time=0.28800
Epoch:0062, train_loss=1.41117, train_acc=1.00000, val_loss=2.15894, val_acc=0.53285, time=0.28501
Epoch:0063, train_loss=1.41117, train_acc=1.00000, val_loss=2.15893, val_acc=0.53285, time=0.33499
Epoch:0064, train_loss=1.41117, train_acc=1.00000, val_loss=2.15891, val_acc=0.53285, time=0.29000
Epoch:0065, train_loss=1.41117, train_acc=1.00000, val_loss=2.15890, val_acc=0.53467, time=0.28600
Epoch:0066, train_loss=1.41117, train_acc=1.00000, val_loss=2.15889, val_acc=0.53467, time=0.32200
Epoch:0067, train_loss=1.41117, train_acc=1.00000, val_loss=2.15888, val_acc=0.53467, time=0.39700
Epoch:0068, train_loss=1.41117, train_acc=1.00000, val_loss=2.15887, val_acc=0.53467, time=0.30801
Epoch:0069, train_loss=1.41117, train_acc=1.00000, val_loss=2.15886, val_acc=0.53467, time=0.37399
Epoch:0070, train_loss=1.41117, train_acc=1.00000, val_loss=2.15885, val_acc=0.53467, time=0.28501
Epoch:0071, train_loss=1.41117, train_acc=1.00000, val_loss=2.15885, val_acc=0.53467, time=0.29100
Epoch:0072, train_loss=1.41117, train_acc=1.00000, val_loss=2.15884, val_acc=0.53467, time=0.33500
Epoch:0073, train_loss=1.41117, train_acc=1.00000, val_loss=2.15883, val_acc=0.53467, time=0.32201
Epoch:0074, train_loss=1.41117, train_acc=1.00000, val_loss=2.15883, val_acc=0.53467, time=0.28700
Epoch:0075, train_loss=1.41117, train_acc=1.00000, val_loss=2.15882, val_acc=0.53467, time=0.28800
Epoch:0076, train_loss=1.41117, train_acc=1.00000, val_loss=2.15882, val_acc=0.53467, time=0.32199
Epoch:0077, train_loss=1.41117, train_acc=1.00000, val_loss=2.15881, val_acc=0.53467, time=0.28701
Epoch:0078, train_loss=1.41117, train_acc=1.00000, val_loss=2.15881, val_acc=0.53467, time=0.28700
Epoch:0079, train_loss=1.41117, train_acc=1.00000, val_loss=2.15881, val_acc=0.53467, time=0.35100
Epoch:0080, train_loss=1.41117, train_acc=1.00000, val_loss=2.15880, val_acc=0.53467, time=0.29500
Epoch:0081, train_loss=1.41117, train_acc=1.00000, val_loss=2.15880, val_acc=0.53467, time=0.28803
Epoch:0082, train_loss=1.41117, train_acc=1.00000, val_loss=2.15880, val_acc=0.53467, time=0.29099
Epoch:0083, train_loss=1.41117, train_acc=1.00000, val_loss=2.15879, val_acc=0.53467, time=0.31199
Epoch:0084, train_loss=1.41117, train_acc=1.00000, val_loss=2.15879, val_acc=0.53467, time=0.28600
Epoch:0085, train_loss=1.41117, train_acc=1.00000, val_loss=2.15879, val_acc=0.53467, time=0.28501
Epoch:0086, train_loss=1.41117, train_acc=1.00000, val_loss=2.15879, val_acc=0.53467, time=0.28900
Epoch:0087, train_loss=1.41117, train_acc=1.00000, val_loss=2.15878, val_acc=0.53467, time=0.28600
Epoch:0088, train_loss=1.41117, train_acc=1.00000, val_loss=2.15878, val_acc=0.53467, time=0.28701
Epoch:0089, train_loss=1.41117, train_acc=1.00000, val_loss=2.15878, val_acc=0.53467, time=0.28700
Epoch:0090, train_loss=1.41117, train_acc=1.00000, val_loss=2.15878, val_acc=0.53467, time=0.29401
Epoch:0091, train_loss=1.41117, train_acc=1.00000, val_loss=2.15878, val_acc=0.53467, time=0.28901
Epoch:0092, train_loss=1.41117, train_acc=1.00000, val_loss=2.15878, val_acc=0.53467, time=0.28602
Epoch:0093, train_loss=1.41117, train_acc=1.00000, val_loss=2.15877, val_acc=0.53467, time=0.33400
Epoch:0094, train_loss=1.41117, train_acc=1.00000, val_loss=2.15877, val_acc=0.53467, time=0.28502
Epoch:0095, train_loss=1.41117, train_acc=1.00000, val_loss=2.15877, val_acc=0.53467, time=0.28800
Epoch:0096, train_loss=1.41117, train_acc=1.00000, val_loss=2.15877, val_acc=0.53467, time=0.30599
Epoch:0097, train_loss=1.41117, train_acc=1.00000, val_loss=2.15877, val_acc=0.53467, time=0.32600
Epoch:0098, train_loss=1.41117, train_acc=1.00000, val_loss=2.15877, val_acc=0.53467, time=0.28900
Epoch:0099, train_loss=1.41117, train_acc=1.00000, val_loss=2.15877, val_acc=0.53467, time=0.29300
Epoch:0100, train_loss=1.41117, train_acc=1.00000, val_loss=2.15876, val_acc=0.53467, time=0.39200
Epoch:0101, train_loss=1.41117, train_acc=1.00000, val_loss=2.15876, val_acc=0.53467, time=0.29000
Epoch:0102, train_loss=1.41117, train_acc=1.00000, val_loss=2.15876, val_acc=0.53467, time=0.29300
Epoch:0103, train_loss=1.41117, train_acc=1.00000, val_loss=2.15876, val_acc=0.53467, time=0.37301
Epoch:0104, train_loss=1.41117, train_acc=1.00000, val_loss=2.15876, val_acc=0.53467, time=0.44900
Epoch:0105, train_loss=1.41117, train_acc=1.00000, val_loss=2.15876, val_acc=0.53467, time=0.42801
Epoch:0106, train_loss=1.41117, train_acc=1.00000, val_loss=2.15876, val_acc=0.53467, time=0.36400
Epoch:0107, train_loss=1.41117, train_acc=1.00000, val_loss=2.15876, val_acc=0.53467, time=0.36100
Epoch:0108, train_loss=1.41117, train_acc=1.00000, val_loss=2.15876, val_acc=0.53467, time=0.36499
Epoch:0109, train_loss=1.41117, train_acc=1.00000, val_loss=2.15875, val_acc=0.53467, time=0.30201
Epoch:0110, train_loss=1.41117, train_acc=1.00000, val_loss=2.15875, val_acc=0.53467, time=0.28900
Epoch:0111, train_loss=1.41117, train_acc=1.00000, val_loss=2.15875, val_acc=0.53467, time=0.32000
Epoch:0112, train_loss=1.41117, train_acc=1.00000, val_loss=2.15875, val_acc=0.53467, time=0.34801
Epoch:0113, train_loss=1.41117, train_acc=1.00000, val_loss=2.15875, val_acc=0.53467, time=0.28701
Epoch:0114, train_loss=1.41117, train_acc=1.00000, val_loss=2.15875, val_acc=0.53467, time=0.33600
Epoch:0115, train_loss=1.41117, train_acc=1.00000, val_loss=2.15875, val_acc=0.53467, time=0.30900
Epoch:0116, train_loss=1.41117, train_acc=1.00000, val_loss=2.15875, val_acc=0.53467, time=0.28800
Epoch:0117, train_loss=1.41117, train_acc=1.00000, val_loss=2.15875, val_acc=0.53467, time=0.32700
Epoch:0118, train_loss=1.41117, train_acc=1.00000, val_loss=2.15875, val_acc=0.53467, time=0.34399
Epoch:0119, train_loss=1.41117, train_acc=1.00000, val_loss=2.15875, val_acc=0.53467, time=0.28600
Epoch:0120, train_loss=1.41116, train_acc=1.00000, val_loss=2.15875, val_acc=0.53467, time=0.31800
Epoch:0121, train_loss=1.41116, train_acc=1.00000, val_loss=2.15874, val_acc=0.53467, time=0.36501
Epoch:0122, train_loss=1.41116, train_acc=1.00000, val_loss=2.15874, val_acc=0.53467, time=0.29302
Epoch:0123, train_loss=1.41116, train_acc=1.00000, val_loss=2.15874, val_acc=0.53467, time=0.32898
Epoch:0124, train_loss=1.41116, train_acc=1.00000, val_loss=2.15874, val_acc=0.53467, time=0.32100
Epoch:0125, train_loss=1.41116, train_acc=1.00000, val_loss=2.15874, val_acc=0.53467, time=0.28601
Epoch:0126, train_loss=1.41116, train_acc=1.00000, val_loss=2.15874, val_acc=0.53467, time=0.29299
Epoch:0127, train_loss=1.41116, train_acc=1.00000, val_loss=2.15874, val_acc=0.53467, time=0.29201
Epoch:0128, train_loss=1.41116, train_acc=1.00000, val_loss=2.15874, val_acc=0.53467, time=0.28800
Epoch:0129, train_loss=1.41116, train_acc=1.00000, val_loss=2.15874, val_acc=0.53467, time=0.28600
Epoch:0130, train_loss=1.41116, train_acc=1.00000, val_loss=2.15874, val_acc=0.53467, time=0.36200
Epoch:0131, train_loss=1.41116, train_acc=1.00000, val_loss=2.15874, val_acc=0.53467, time=0.29001
Epoch:0132, train_loss=1.41116, train_acc=1.00000, val_loss=2.15874, val_acc=0.53467, time=0.28500
Epoch:0133, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.29500
Epoch:0134, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.35999
Epoch:0135, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.36400
Epoch:0136, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.36900
Epoch:0137, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.37801
Epoch:0138, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.29399
Epoch:0139, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.28800
Epoch:0140, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.32100
Epoch:0141, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.34001
Epoch:0142, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.36101
Epoch:0143, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.31199
Epoch:0144, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.35800
Epoch:0145, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.41201
Epoch:0146, train_loss=1.41116, train_acc=1.00000, val_loss=2.15873, val_acc=0.53467, time=0.36000
Epoch:0147, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.28700
Epoch:0148, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.28699
Epoch:0149, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.35601
Epoch:0150, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.35199
Epoch:0151, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.29400
Epoch:0152, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.35100
Epoch:0153, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.28700
Epoch:0154, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.29300
Epoch:0155, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.29401
Epoch:0156, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.36399
Epoch:0157, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.33001
Epoch:0158, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.28800
Epoch:0159, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.37600
Epoch:0160, train_loss=1.41116, train_acc=1.00000, val_loss=2.15872, val_acc=0.53467, time=0.33000
Epoch:0161, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53467, time=0.38401
Epoch:0162, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53467, time=0.33899
Epoch:0163, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53467, time=0.36201
Epoch:0164, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53467, time=0.31200
Epoch:0165, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53467, time=0.36101
Epoch:0166, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53467, time=0.33499
Epoch:0167, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53467, time=0.35901
Epoch:0168, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53467, time=0.43799
Epoch:0169, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53467, time=0.34800
Epoch:0170, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53467, time=0.40401
Epoch:0171, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53467, time=0.32199
Epoch:0172, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53285, time=0.36400
Epoch:0173, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53285, time=0.39300
Epoch:0174, train_loss=1.41116, train_acc=1.00000, val_loss=2.15871, val_acc=0.53285, time=0.44001
Epoch:0175, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.40399
Epoch:0176, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.36801
Epoch:0177, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.29500
Epoch:0178, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.37900
Epoch:0179, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.30499
Epoch:0180, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.32901
Epoch:0181, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.34700
Epoch:0182, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.42001
Epoch:0183, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.29600
Epoch:0184, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.33300
Epoch:0185, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.40900
Epoch:0186, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.30901
Epoch:0187, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.34600
Epoch:0188, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.32300
Epoch:0189, train_loss=1.41116, train_acc=1.00000, val_loss=2.15870, val_acc=0.53285, time=0.28700
Epoch:0190, train_loss=1.41116, train_acc=1.00000, val_loss=2.15869, val_acc=0.53285, time=0.31701
Epoch:0191, train_loss=1.41116, train_acc=1.00000, val_loss=2.15869, val_acc=0.53285, time=0.29800
Epoch:0192, train_loss=1.41116, train_acc=1.00000, val_loss=2.15869, val_acc=0.53285, time=0.28900
Epoch:0193, train_loss=1.41116, train_acc=1.00000, val_loss=2.15869, val_acc=0.53467, time=0.28901
Epoch:0194, train_loss=1.41116, train_acc=1.00000, val_loss=2.15869, val_acc=0.53467, time=0.35000
Epoch:0195, train_loss=1.41116, train_acc=1.00000, val_loss=2.15869, val_acc=0.53467, time=0.37901
Epoch:0196, train_loss=1.41116, train_acc=1.00000, val_loss=2.15869, val_acc=0.53467, time=0.31999
Epoch:0197, train_loss=1.41116, train_acc=1.00000, val_loss=2.15869, val_acc=0.53467, time=0.32300
Epoch:0198, train_loss=1.41116, train_acc=1.00000, val_loss=2.15869, val_acc=0.53467, time=0.28800
Epoch:0199, train_loss=1.41116, train_acc=1.00000, val_loss=2.15869, val_acc=0.53467, time=0.29300
Epoch:0200, train_loss=1.41116, train_acc=1.00000, val_loss=2.15869, val_acc=0.53467, time=0.32400

Optimization Finished!

Test set results: loss= 2.36956, accuracy= 0.54317, time= 0.09900

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.5825    0.4971    0.5364       696
           1     0.6712    0.7276    0.6983      1083
           2     0.1031    0.1333    0.1163        75
           3     0.2658    0.1736    0.2100       121
           4     0.1512    0.1494    0.1503        87
           5     0.0758    0.1235    0.0939        81
           6     0.0385    0.0278    0.0323        36
           7     0.0000    0.0000    0.0000        10

    accuracy                         0.5432      2189
   macro avg     0.2360    0.2290    0.2297      2189
weighted avg     0.5450    0.5432    0.5416      2189


Macro average Test Precision, Recall and F1-Score...
(0.23599982446971546, 0.22903522991278474, 0.22967862703763803, None)

Micro average Test Precision, Recall and F1-Score...
(0.5431703974417542, 0.5431703974417542, 0.5431703974417542, None)

Embeddings:
Word_embeddings: 7688
Train_doc_embeddings: 5485
Test_doc_embeddings: 2189

Elapsed time is 66.934857 seconds.
