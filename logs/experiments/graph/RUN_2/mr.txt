
==================== Torch Seed: 14121290985400

Model parameters

Layer: layer1.W0 | Size: torch.Size([29426, 200])
Layer: layer2.W0 | Size: torch.Size([200, 2])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  29426          2             6398            710            3554

Epoch:0001, train_loss=1.53730, train_acc=0.49641, val_loss=0.77637, val_acc=0.49859, time=0.78800
Epoch:0002, train_loss=1.25772, train_acc=0.57080, val_loss=0.77631, val_acc=0.50282, time=0.88701
Epoch:0003, train_loss=1.06947, train_acc=0.64473, val_loss=0.78090, val_acc=0.51408, time=0.84799
Epoch:0004, train_loss=0.94568, train_acc=0.71554, val_loss=0.78406, val_acc=0.52958, time=0.87101
Epoch:0005, train_loss=0.84550, train_acc=0.77602, val_loss=0.78435, val_acc=0.52676, time=0.78600
Epoch:0006, train_loss=0.75978, train_acc=0.83260, val_loss=0.78269, val_acc=0.53099, time=0.81100
Epoch:0007, train_loss=0.69129, train_acc=0.87293, val_loss=0.78024, val_acc=0.51831, time=0.82799
Epoch:0008, train_loss=0.64033, train_acc=0.91107, val_loss=0.77784, val_acc=0.50704, time=0.82501
Epoch:0009, train_loss=0.60563, train_acc=0.94076, val_loss=0.77591, val_acc=0.50986, time=0.94499
Epoch:0010, train_loss=0.58326, train_acc=0.96046, val_loss=0.77455, val_acc=0.50000, time=0.78800
Epoch:0011, train_loss=0.56879, train_acc=0.97280, val_loss=0.77370, val_acc=0.49859, time=1.05199
Epoch:0012, train_loss=0.55932, train_acc=0.98203, val_loss=0.77321, val_acc=0.50282, time=0.91900
Epoch:0013, train_loss=0.55296, train_acc=0.98765, val_loss=0.77298, val_acc=0.50282, time=0.81602
Epoch:0014, train_loss=0.54895, train_acc=0.99265, val_loss=0.77291, val_acc=0.50141, time=0.96000
Epoch:0015, train_loss=0.54662, train_acc=0.99625, val_loss=0.77296, val_acc=0.50141, time=0.91100
Epoch:0016, train_loss=0.54522, train_acc=0.99719, val_loss=0.77306, val_acc=0.50423, time=0.82499
Epoch:0017, train_loss=0.54426, train_acc=0.99750, val_loss=0.77320, val_acc=0.50141, time=0.82501
Epoch:0018, train_loss=0.54359, train_acc=0.99859, val_loss=0.77335, val_acc=0.50000, time=0.77199
Epoch:0019, train_loss=0.54316, train_acc=0.99906, val_loss=0.77351, val_acc=0.50282, time=0.83301
Epoch:0020, train_loss=0.54288, train_acc=0.99953, val_loss=0.77366, val_acc=0.50423, time=0.78401
Early stopping...

Optimization Finished!

Test set results: loss= 1.09367, accuracy= 0.50591, time= 0.24100

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.5056    0.5290    0.5171      1777
           1     0.5062    0.4828    0.4942      1777

    accuracy                         0.5059      3554
   macro avg     0.5059    0.5059    0.5056      3554
weighted avg     0.5059    0.5059    0.5056      3554


Macro average Test Precision, Recall and F1-Score...
(0.5059214441106885, 0.505908835115363, 0.5056456682534614, None)

Micro average Test Precision, Recall and F1-Score...
(0.505908835115363, 0.505908835115363, 0.505908835115363, None)

Embeddings:
Word_embeddings: 18764
Train_doc_embeddings: 7108
Test_doc_embeddings: 3554

Elapsed time is 20.434957 seconds.
