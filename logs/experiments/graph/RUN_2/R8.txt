
==================== Torch Seed: 10477500954700

Model parameters

Layer: layer1.W0 | Size: torch.Size([15362, 200])
Layer: layer2.W0 | Size: torch.Size([200, 8])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  15362          8             4937            548            2189

Epoch:0001, train_loss=4.68632, train_acc=0.10938, val_loss=2.30876, val_acc=0.15693, time=0.35059
Epoch:0002, train_loss=3.86286, train_acc=0.19465, val_loss=2.26743, val_acc=0.21533, time=0.30200
Epoch:0003, train_loss=3.22992, train_acc=0.30646, val_loss=2.23811, val_acc=0.28285, time=0.28900
Epoch:0004, train_loss=2.77251, train_acc=0.42111, val_loss=2.21762, val_acc=0.33212, time=0.37399
Epoch:0005, train_loss=2.44190, train_acc=0.52096, val_loss=2.20397, val_acc=0.37774, time=0.28600
Epoch:0006, train_loss=2.20399, train_acc=0.61150, val_loss=2.19561, val_acc=0.41606, time=0.31101
Epoch:0007, train_loss=2.03610, train_acc=0.68645, val_loss=2.19089, val_acc=0.44343, time=0.39600
Epoch:0008, train_loss=1.91392, train_acc=0.73567, val_loss=2.18821, val_acc=0.45985, time=0.40200
Epoch:0009, train_loss=1.81625, train_acc=0.77881, val_loss=2.18647, val_acc=0.46350, time=0.32400
Epoch:0010, train_loss=1.73409, train_acc=0.81892, val_loss=2.18511, val_acc=0.47993, time=0.29000
Epoch:0011, train_loss=1.66566, train_acc=0.85538, val_loss=2.18374, val_acc=0.47993, time=0.28799
Epoch:0012, train_loss=1.61026, train_acc=0.88353, val_loss=2.18212, val_acc=0.47810, time=0.38001
Epoch:0013, train_loss=1.56558, train_acc=0.90946, val_loss=2.18024, val_acc=0.48540, time=0.35000
Epoch:0014, train_loss=1.52965, train_acc=0.92728, val_loss=2.17828, val_acc=0.49818, time=0.31999
Epoch:0015, train_loss=1.50128, train_acc=0.94288, val_loss=2.17639, val_acc=0.49818, time=0.28500
Epoch:0016, train_loss=1.47927, train_acc=0.95665, val_loss=2.17467, val_acc=0.50182, time=0.29900
Epoch:0017, train_loss=1.46230, train_acc=0.96739, val_loss=2.17317, val_acc=0.51095, time=0.28700
Epoch:0018, train_loss=1.44924, train_acc=0.97549, val_loss=2.17187, val_acc=0.52190, time=0.30001
Epoch:0019, train_loss=1.43921, train_acc=0.98258, val_loss=2.17076, val_acc=0.52920, time=0.28800
Epoch:0020, train_loss=1.43158, train_acc=0.98643, val_loss=2.16980, val_acc=0.52920, time=0.28901
Epoch:0021, train_loss=1.42580, train_acc=0.98987, val_loss=2.16898, val_acc=0.53285, time=0.28500
Epoch:0022, train_loss=1.42144, train_acc=0.99210, val_loss=2.16827, val_acc=0.53650, time=0.28900
Epoch:0023, train_loss=1.41821, train_acc=0.99413, val_loss=2.16766, val_acc=0.53650, time=0.30500
Epoch:0024, train_loss=1.41590, train_acc=0.99615, val_loss=2.16714, val_acc=0.54197, time=0.39899
Epoch:0025, train_loss=1.41433, train_acc=0.99777, val_loss=2.16670, val_acc=0.54380, time=0.30800
Epoch:0026, train_loss=1.41329, train_acc=0.99838, val_loss=2.16631, val_acc=0.54380, time=0.30404
Epoch:0027, train_loss=1.41260, train_acc=0.99878, val_loss=2.16598, val_acc=0.54562, time=0.32699
Epoch:0028, train_loss=1.41210, train_acc=0.99899, val_loss=2.16569, val_acc=0.54562, time=0.40900
Epoch:0029, train_loss=1.41176, train_acc=0.99939, val_loss=2.16544, val_acc=0.54745, time=0.32701
Epoch:0030, train_loss=1.41154, train_acc=0.99980, val_loss=2.16523, val_acc=0.55109, time=0.29001
Epoch:0031, train_loss=1.41141, train_acc=0.99980, val_loss=2.16504, val_acc=0.55474, time=0.29700
Epoch:0032, train_loss=1.41132, train_acc=1.00000, val_loss=2.16487, val_acc=0.55657, time=0.29500
Epoch:0033, train_loss=1.41127, train_acc=1.00000, val_loss=2.16473, val_acc=0.55839, time=0.38500
Epoch:0034, train_loss=1.41124, train_acc=1.00000, val_loss=2.16460, val_acc=0.55839, time=0.33300
Epoch:0035, train_loss=1.41122, train_acc=1.00000, val_loss=2.16449, val_acc=0.55839, time=0.28901
Epoch:0036, train_loss=1.41121, train_acc=1.00000, val_loss=2.16440, val_acc=0.55839, time=0.38699
Epoch:0037, train_loss=1.41121, train_acc=1.00000, val_loss=2.16431, val_acc=0.56022, time=0.29501
Epoch:0038, train_loss=1.41120, train_acc=1.00000, val_loss=2.16423, val_acc=0.56204, time=0.28701
Epoch:0039, train_loss=1.41120, train_acc=1.00000, val_loss=2.16417, val_acc=0.56204, time=0.29700
Epoch:0040, train_loss=1.41119, train_acc=1.00000, val_loss=2.16411, val_acc=0.56204, time=0.37799
Epoch:0041, train_loss=1.41119, train_acc=1.00000, val_loss=2.16405, val_acc=0.56387, time=0.32300
Epoch:0042, train_loss=1.41119, train_acc=1.00000, val_loss=2.16401, val_acc=0.56204, time=0.29000
Epoch:0043, train_loss=1.41119, train_acc=1.00000, val_loss=2.16396, val_acc=0.56204, time=0.36000
Epoch:0044, train_loss=1.41119, train_acc=1.00000, val_loss=2.16392, val_acc=0.56204, time=0.28800
Epoch:0045, train_loss=1.41119, train_acc=1.00000, val_loss=2.16389, val_acc=0.56204, time=0.32100
Epoch:0046, train_loss=1.41118, train_acc=1.00000, val_loss=2.16386, val_acc=0.56204, time=0.33599
Epoch:0047, train_loss=1.41118, train_acc=1.00000, val_loss=2.16383, val_acc=0.56204, time=0.28601
Epoch:0048, train_loss=1.41118, train_acc=1.00000, val_loss=2.16380, val_acc=0.56204, time=0.28800
Epoch:0049, train_loss=1.41118, train_acc=1.00000, val_loss=2.16378, val_acc=0.56387, time=0.31900
Epoch:0050, train_loss=1.41118, train_acc=1.00000, val_loss=2.16376, val_acc=0.56387, time=0.28400
Epoch:0051, train_loss=1.41118, train_acc=1.00000, val_loss=2.16374, val_acc=0.56387, time=0.29301
Epoch:0052, train_loss=1.41118, train_acc=1.00000, val_loss=2.16372, val_acc=0.56387, time=0.34799
Epoch:0053, train_loss=1.41118, train_acc=1.00000, val_loss=2.16370, val_acc=0.56387, time=0.28800
Epoch:0054, train_loss=1.41118, train_acc=1.00000, val_loss=2.16369, val_acc=0.56204, time=0.28700
Epoch:0055, train_loss=1.41118, train_acc=1.00000, val_loss=2.16367, val_acc=0.56204, time=0.30201
Epoch:0056, train_loss=1.41118, train_acc=1.00000, val_loss=2.16366, val_acc=0.56204, time=0.28900
Epoch:0057, train_loss=1.41118, train_acc=1.00000, val_loss=2.16365, val_acc=0.56204, time=0.28600
Epoch:0058, train_loss=1.41118, train_acc=1.00000, val_loss=2.16364, val_acc=0.56204, time=0.28801
Epoch:0059, train_loss=1.41118, train_acc=1.00000, val_loss=2.16363, val_acc=0.56204, time=0.29000
Epoch:0060, train_loss=1.41118, train_acc=1.00000, val_loss=2.16362, val_acc=0.56204, time=0.34201
Epoch:0061, train_loss=1.41118, train_acc=1.00000, val_loss=2.16361, val_acc=0.56204, time=0.28700
Epoch:0062, train_loss=1.41118, train_acc=1.00000, val_loss=2.16360, val_acc=0.56204, time=0.38099
Epoch:0063, train_loss=1.41117, train_acc=1.00000, val_loss=2.16359, val_acc=0.56204, time=0.28700
Epoch:0064, train_loss=1.41117, train_acc=1.00000, val_loss=2.16359, val_acc=0.56204, time=0.28401
Epoch:0065, train_loss=1.41117, train_acc=1.00000, val_loss=2.16358, val_acc=0.56204, time=0.35300
Epoch:0066, train_loss=1.41117, train_acc=1.00000, val_loss=2.16357, val_acc=0.56204, time=0.31702
Epoch:0067, train_loss=1.41117, train_acc=1.00000, val_loss=2.16357, val_acc=0.56204, time=0.28602
Epoch:0068, train_loss=1.41117, train_acc=1.00000, val_loss=2.16356, val_acc=0.56204, time=0.29200
Epoch:0069, train_loss=1.41117, train_acc=1.00000, val_loss=2.16356, val_acc=0.56387, time=0.29299
Epoch:0070, train_loss=1.41117, train_acc=1.00000, val_loss=2.16355, val_acc=0.56387, time=0.28600
Epoch:0071, train_loss=1.41117, train_acc=1.00000, val_loss=2.16355, val_acc=0.56387, time=0.28500
Epoch:0072, train_loss=1.41117, train_acc=1.00000, val_loss=2.16354, val_acc=0.56387, time=0.35400
Epoch:0073, train_loss=1.41117, train_acc=1.00000, val_loss=2.16354, val_acc=0.56387, time=0.28800
Epoch:0074, train_loss=1.41117, train_acc=1.00000, val_loss=2.16354, val_acc=0.56387, time=0.34000
Epoch:0075, train_loss=1.41117, train_acc=1.00000, val_loss=2.16353, val_acc=0.56387, time=0.34400
Epoch:0076, train_loss=1.41117, train_acc=1.00000, val_loss=2.16353, val_acc=0.56387, time=0.31300
Epoch:0077, train_loss=1.41117, train_acc=1.00000, val_loss=2.16352, val_acc=0.56387, time=0.29900
Epoch:0078, train_loss=1.41117, train_acc=1.00000, val_loss=2.16352, val_acc=0.56387, time=0.32300
Epoch:0079, train_loss=1.41117, train_acc=1.00000, val_loss=2.16352, val_acc=0.56387, time=0.29300
Epoch:0080, train_loss=1.41117, train_acc=1.00000, val_loss=2.16352, val_acc=0.56387, time=0.28601
Epoch:0081, train_loss=1.41117, train_acc=1.00000, val_loss=2.16351, val_acc=0.56387, time=0.29099
Epoch:0082, train_loss=1.41117, train_acc=1.00000, val_loss=2.16351, val_acc=0.56387, time=0.36801
Epoch:0083, train_loss=1.41117, train_acc=1.00000, val_loss=2.16351, val_acc=0.56387, time=0.28800
Epoch:0084, train_loss=1.41117, train_acc=1.00000, val_loss=2.16351, val_acc=0.56387, time=0.28500
Epoch:0085, train_loss=1.41117, train_acc=1.00000, val_loss=2.16350, val_acc=0.56387, time=0.42000
Epoch:0086, train_loss=1.41117, train_acc=1.00000, val_loss=2.16350, val_acc=0.56387, time=0.29800
Epoch:0087, train_loss=1.41117, train_acc=1.00000, val_loss=2.16350, val_acc=0.56387, time=0.28700
Epoch:0088, train_loss=1.41117, train_acc=1.00000, val_loss=2.16350, val_acc=0.56387, time=0.32700
Epoch:0089, train_loss=1.41117, train_acc=1.00000, val_loss=2.16349, val_acc=0.56387, time=0.29100
Epoch:0090, train_loss=1.41117, train_acc=1.00000, val_loss=2.16349, val_acc=0.56387, time=0.28501
Epoch:0091, train_loss=1.41117, train_acc=1.00000, val_loss=2.16349, val_acc=0.56387, time=0.32499
Epoch:0092, train_loss=1.41117, train_acc=1.00000, val_loss=2.16349, val_acc=0.56387, time=0.42701
Epoch:0093, train_loss=1.41117, train_acc=1.00000, val_loss=2.16349, val_acc=0.56387, time=0.44801
Epoch:0094, train_loss=1.41117, train_acc=1.00000, val_loss=2.16348, val_acc=0.56387, time=0.31599
Epoch:0095, train_loss=1.41117, train_acc=1.00000, val_loss=2.16348, val_acc=0.56387, time=0.28700
Epoch:0096, train_loss=1.41117, train_acc=1.00000, val_loss=2.16348, val_acc=0.56387, time=0.28600
Epoch:0097, train_loss=1.41117, train_acc=1.00000, val_loss=2.16348, val_acc=0.56387, time=0.30200
Epoch:0098, train_loss=1.41117, train_acc=1.00000, val_loss=2.16348, val_acc=0.56387, time=0.28500
Epoch:0099, train_loss=1.41117, train_acc=1.00000, val_loss=2.16348, val_acc=0.56387, time=0.31500
Epoch:0100, train_loss=1.41117, train_acc=1.00000, val_loss=2.16347, val_acc=0.56387, time=0.28801
Epoch:0101, train_loss=1.41117, train_acc=1.00000, val_loss=2.16347, val_acc=0.56387, time=0.28500
Epoch:0102, train_loss=1.41117, train_acc=1.00000, val_loss=2.16347, val_acc=0.56387, time=0.28900
Epoch:0103, train_loss=1.41117, train_acc=1.00000, val_loss=2.16347, val_acc=0.56387, time=0.32900
Epoch:0104, train_loss=1.41117, train_acc=1.00000, val_loss=2.16347, val_acc=0.56387, time=0.29101
Epoch:0105, train_loss=1.41117, train_acc=1.00000, val_loss=2.16347, val_acc=0.56387, time=0.28401
Epoch:0106, train_loss=1.41117, train_acc=1.00000, val_loss=2.16346, val_acc=0.56387, time=0.30700
Epoch:0107, train_loss=1.41117, train_acc=1.00000, val_loss=2.16346, val_acc=0.56387, time=0.32401
Epoch:0108, train_loss=1.41117, train_acc=1.00000, val_loss=2.16346, val_acc=0.56387, time=0.28600
Epoch:0109, train_loss=1.41117, train_acc=1.00000, val_loss=2.16346, val_acc=0.56387, time=0.28800
Epoch:0110, train_loss=1.41117, train_acc=1.00000, val_loss=2.16346, val_acc=0.56387, time=0.28800
Epoch:0111, train_loss=1.41117, train_acc=1.00000, val_loss=2.16346, val_acc=0.56387, time=0.35201
Epoch:0112, train_loss=1.41117, train_acc=1.00000, val_loss=2.16346, val_acc=0.56387, time=0.32300
Epoch:0113, train_loss=1.41117, train_acc=1.00000, val_loss=2.16346, val_acc=0.56387, time=0.29300
Epoch:0114, train_loss=1.41117, train_acc=1.00000, val_loss=2.16345, val_acc=0.56387, time=0.36799
Epoch:0115, train_loss=1.41117, train_acc=1.00000, val_loss=2.16345, val_acc=0.56387, time=0.36100
Epoch:0116, train_loss=1.41117, train_acc=1.00000, val_loss=2.16345, val_acc=0.56387, time=0.28900
Epoch:0117, train_loss=1.41117, train_acc=1.00000, val_loss=2.16345, val_acc=0.56387, time=0.32099
Epoch:0118, train_loss=1.41117, train_acc=1.00000, val_loss=2.16345, val_acc=0.56387, time=0.28501
Epoch:0119, train_loss=1.41117, train_acc=1.00000, val_loss=2.16345, val_acc=0.56387, time=0.29200
Epoch:0120, train_loss=1.41117, train_acc=1.00000, val_loss=2.16345, val_acc=0.56387, time=0.30600
Epoch:0121, train_loss=1.41117, train_acc=1.00000, val_loss=2.16344, val_acc=0.56387, time=0.35500
Epoch:0122, train_loss=1.41117, train_acc=1.00000, val_loss=2.16344, val_acc=0.56387, time=0.28500
Epoch:0123, train_loss=1.41117, train_acc=1.00000, val_loss=2.16344, val_acc=0.56387, time=0.28699
Epoch:0124, train_loss=1.41117, train_acc=1.00000, val_loss=2.16344, val_acc=0.56387, time=0.34101
Epoch:0125, train_loss=1.41117, train_acc=1.00000, val_loss=2.16344, val_acc=0.56387, time=0.28699
Epoch:0126, train_loss=1.41117, train_acc=1.00000, val_loss=2.16344, val_acc=0.56387, time=0.28601
Epoch:0127, train_loss=1.41117, train_acc=1.00000, val_loss=2.16344, val_acc=0.56387, time=0.37199
Epoch:0128, train_loss=1.41117, train_acc=1.00000, val_loss=2.16344, val_acc=0.56387, time=0.37100
Epoch:0129, train_loss=1.41117, train_acc=1.00000, val_loss=2.16344, val_acc=0.56387, time=0.28501
Epoch:0130, train_loss=1.41117, train_acc=1.00000, val_loss=2.16343, val_acc=0.56387, time=0.28799
Epoch:0131, train_loss=1.41117, train_acc=1.00000, val_loss=2.16343, val_acc=0.56387, time=0.28401
Epoch:0132, train_loss=1.41117, train_acc=1.00000, val_loss=2.16343, val_acc=0.56387, time=0.28602
Epoch:0133, train_loss=1.41117, train_acc=1.00000, val_loss=2.16343, val_acc=0.56387, time=0.29799
Epoch:0134, train_loss=1.41117, train_acc=1.00000, val_loss=2.16343, val_acc=0.56387, time=0.37300
Epoch:0135, train_loss=1.41117, train_acc=1.00000, val_loss=2.16343, val_acc=0.56387, time=0.29301
Epoch:0136, train_loss=1.41117, train_acc=1.00000, val_loss=2.16343, val_acc=0.56387, time=0.29000
Epoch:0137, train_loss=1.41117, train_acc=1.00000, val_loss=2.16343, val_acc=0.56387, time=0.35200
Epoch:0138, train_loss=1.41117, train_acc=1.00000, val_loss=2.16343, val_acc=0.56387, time=0.30100
Epoch:0139, train_loss=1.41117, train_acc=1.00000, val_loss=2.16343, val_acc=0.56387, time=0.31000
Epoch:0140, train_loss=1.41117, train_acc=1.00000, val_loss=2.16342, val_acc=0.56387, time=0.38701
Epoch:0141, train_loss=1.41117, train_acc=1.00000, val_loss=2.16342, val_acc=0.56387, time=0.41300
Epoch:0142, train_loss=1.41117, train_acc=1.00000, val_loss=2.16342, val_acc=0.56387, time=0.41799
Epoch:0143, train_loss=1.41117, train_acc=1.00000, val_loss=2.16342, val_acc=0.56387, time=0.35100
Epoch:0144, train_loss=1.41117, train_acc=1.00000, val_loss=2.16342, val_acc=0.56387, time=0.28601
Epoch:0145, train_loss=1.41117, train_acc=1.00000, val_loss=2.16342, val_acc=0.56387, time=0.32399
Epoch:0146, train_loss=1.41117, train_acc=1.00000, val_loss=2.16342, val_acc=0.56387, time=0.29401
Epoch:0147, train_loss=1.41117, train_acc=1.00000, val_loss=2.16342, val_acc=0.56387, time=0.28600
Epoch:0148, train_loss=1.41117, train_acc=1.00000, val_loss=2.16342, val_acc=0.56387, time=0.33901
Epoch:0149, train_loss=1.41117, train_acc=1.00000, val_loss=2.16342, val_acc=0.56387, time=0.41099
Epoch:0150, train_loss=1.41117, train_acc=1.00000, val_loss=2.16342, val_acc=0.56387, time=0.31800
Epoch:0151, train_loss=1.41117, train_acc=1.00000, val_loss=2.16342, val_acc=0.56387, time=0.28801
Epoch:0152, train_loss=1.41117, train_acc=1.00000, val_loss=2.16341, val_acc=0.56387, time=0.36500
Epoch:0153, train_loss=1.41117, train_acc=1.00000, val_loss=2.16341, val_acc=0.56387, time=0.39999
Epoch:0154, train_loss=1.41117, train_acc=1.00000, val_loss=2.16341, val_acc=0.56387, time=0.40001
Epoch:0155, train_loss=1.41117, train_acc=1.00000, val_loss=2.16341, val_acc=0.56387, time=0.42201
Epoch:0156, train_loss=1.41117, train_acc=1.00000, val_loss=2.16341, val_acc=0.56387, time=0.30500
Epoch:0157, train_loss=1.41117, train_acc=1.00000, val_loss=2.16341, val_acc=0.56387, time=0.32499
Epoch:0158, train_loss=1.41117, train_acc=1.00000, val_loss=2.16341, val_acc=0.56387, time=0.33701
Epoch:0159, train_loss=1.41117, train_acc=1.00000, val_loss=2.16341, val_acc=0.56387, time=0.34900
Epoch:0160, train_loss=1.41117, train_acc=1.00000, val_loss=2.16341, val_acc=0.56387, time=0.32599
Epoch:0161, train_loss=1.41117, train_acc=1.00000, val_loss=2.16341, val_acc=0.56387, time=0.36900
Epoch:0162, train_loss=1.41117, train_acc=1.00000, val_loss=2.16341, val_acc=0.56387, time=0.41101
Epoch:0163, train_loss=1.41117, train_acc=1.00000, val_loss=2.16341, val_acc=0.56387, time=0.30999
Epoch:0164, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.35600
Epoch:0165, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.32501
Epoch:0166, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.28700
Epoch:0167, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.28700
Epoch:0168, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.34699
Epoch:0169, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.32701
Epoch:0170, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.34602
Epoch:0171, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.31000
Epoch:0172, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.28600
Epoch:0173, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.36600
Epoch:0174, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.28899
Epoch:0175, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.28701
Epoch:0176, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.34700
Epoch:0177, train_loss=1.41117, train_acc=1.00000, val_loss=2.16340, val_acc=0.56387, time=0.29501
Epoch:0178, train_loss=1.41117, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.28600
Epoch:0179, train_loss=1.41117, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.31599
Epoch:0180, train_loss=1.41117, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.32500
Epoch:0181, train_loss=1.41117, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.28900
Epoch:0182, train_loss=1.41117, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.28600
Epoch:0183, train_loss=1.41117, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.42399
Epoch:0184, train_loss=1.41117, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.31801
Epoch:0185, train_loss=1.41117, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.29099
Epoch:0186, train_loss=1.41117, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.38100
Epoch:0187, train_loss=1.41116, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.32400
Epoch:0188, train_loss=1.41116, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.29000
Epoch:0189, train_loss=1.41116, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.28800
Epoch:0190, train_loss=1.41116, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.28700
Epoch:0191, train_loss=1.41116, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.28501
Epoch:0192, train_loss=1.41116, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.30800
Epoch:0193, train_loss=1.41116, train_acc=1.00000, val_loss=2.16339, val_acc=0.56387, time=0.35500
Epoch:0194, train_loss=1.41116, train_acc=1.00000, val_loss=2.16338, val_acc=0.56387, time=0.30500
Epoch:0195, train_loss=1.41116, train_acc=1.00000, val_loss=2.16338, val_acc=0.56387, time=0.30601
Epoch:0196, train_loss=1.41116, train_acc=1.00000, val_loss=2.16338, val_acc=0.56387, time=0.32699
Epoch:0197, train_loss=1.41116, train_acc=1.00000, val_loss=2.16338, val_acc=0.56387, time=0.28700
Epoch:0198, train_loss=1.41116, train_acc=1.00000, val_loss=2.16338, val_acc=0.56387, time=0.28701
Epoch:0199, train_loss=1.41116, train_acc=1.00000, val_loss=2.16338, val_acc=0.56387, time=0.35399
Epoch:0200, train_loss=1.41116, train_acc=1.00000, val_loss=2.16338, val_acc=0.56387, time=0.35401

Optimization Finished!

Test set results: loss= 2.34504, accuracy= 0.57104, time= 0.10100

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.5401    0.5517    0.5458       696
           1     0.6900    0.7461    0.7169      1083
           2     0.0698    0.0800    0.0745        75
           3     0.3370    0.2562    0.2911       121
           4     0.3953    0.1954    0.2615        87
           5     0.0769    0.0494    0.0602        81
           6     0.0000    0.0000    0.0000        36
           7     0.0000    0.0000    0.0000        10

    accuracy                         0.5710      2189
   macro avg     0.2636    0.2348    0.2438      2189
weighted avg     0.5527    0.5710    0.5595      2189


Macro average Test Precision, Recall and F1-Score...
(0.2636361007034098, 0.23484790194290395, 0.24376158466053038, None)

Micro average Test Precision, Recall and F1-Score...
(0.5710370031978073, 0.5710370031978073, 0.5710370031978073, None)

Embeddings:
Word_embeddings: 7688
Train_doc_embeddings: 5485
Test_doc_embeddings: 2189

Elapsed time is 65.598873 seconds.
