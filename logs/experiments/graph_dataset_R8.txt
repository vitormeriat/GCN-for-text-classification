
==================== Torch Seed: 24264897806800
Epoch:0001, train_loss=5.17669, train_acc=0.09257, val_loss=2.35819, val_acc=0.13139, time=0.62100
Epoch:0002, train_loss=4.34285, train_acc=0.16285, val_loss=2.31581, val_acc=0.16788, time=0.58900
Epoch:0003, train_loss=3.66416, train_acc=0.24954, val_loss=2.27948, val_acc=0.20985, time=0.48503
Epoch:0004, train_loss=3.08977, train_acc=0.34535, val_loss=2.24927, val_acc=0.25182, time=0.51301
Epoch:0005, train_loss=2.62277, train_acc=0.45432, val_loss=2.22679, val_acc=0.31022, time=0.56900
Epoch:0006, train_loss=2.28073, train_acc=0.56978, val_loss=2.21225, val_acc=0.33759, time=0.63301
Epoch:0007, train_loss=2.05958, train_acc=0.65850, val_loss=2.20473, val_acc=0.38504, time=0.47201
Epoch:0008, train_loss=1.92834, train_acc=0.70995, val_loss=2.20186, val_acc=0.43248, time=0.55003
Epoch:0009, train_loss=1.84680, train_acc=0.75228, val_loss=2.20116, val_acc=0.44891, time=0.52601
Epoch:0010, train_loss=1.78277, train_acc=0.78084, val_loss=2.20093, val_acc=0.45985, time=0.49000
Epoch:0011, train_loss=1.71948, train_acc=0.81527, val_loss=2.20028, val_acc=0.46898, time=0.52000
Epoch:0012, train_loss=1.65624, train_acc=0.85923, val_loss=2.19905, val_acc=0.48175, time=0.47900
Epoch:0013, train_loss=1.59856, train_acc=0.88819, val_loss=2.19741, val_acc=0.48540, time=0.57201
Epoch:0014, train_loss=1.54982, train_acc=0.91351, val_loss=2.19559, val_acc=0.49088, time=0.47001
Epoch:0015, train_loss=1.51089, train_acc=0.93316, val_loss=2.19374, val_acc=0.48358, time=0.48101
Epoch:0016, train_loss=1.48129, train_acc=0.95017, val_loss=2.19194, val_acc=0.48905, time=0.51502
Epoch:0017, train_loss=1.45979, train_acc=0.96455, val_loss=2.19024, val_acc=0.48723, time=0.48401
Epoch:0018, train_loss=1.44466, train_acc=0.97509, val_loss=2.18866, val_acc=0.48723, time=0.79001
Epoch:0019, train_loss=1.43409, train_acc=0.98157, val_loss=2.18721, val_acc=0.48905, time=0.65000
Epoch:0020, train_loss=1.42679, train_acc=0.98724, val_loss=2.18589, val_acc=0.48723, time=0.58601
Epoch:0021, train_loss=1.42182, train_acc=0.99230, val_loss=2.18470, val_acc=0.49270, time=0.56300
Epoch:0022, train_loss=1.41849, train_acc=0.99453, val_loss=2.18364, val_acc=0.49270, time=0.48100
Epoch:0023, train_loss=1.41620, train_acc=0.99595, val_loss=2.18271, val_acc=0.49635, time=0.60801
Epoch:0024, train_loss=1.41460, train_acc=0.99737, val_loss=2.18189, val_acc=0.49635, time=0.48600
Epoch:0025, train_loss=1.41348, train_acc=0.99777, val_loss=2.18117, val_acc=0.49635, time=0.47200
Epoch:0026, train_loss=1.41269, train_acc=0.99858, val_loss=2.18054, val_acc=0.49635, time=0.48400
Epoch:0027, train_loss=1.41214, train_acc=0.99899, val_loss=2.17999, val_acc=0.49453, time=0.55700
Epoch:0028, train_loss=1.41178, train_acc=0.99980, val_loss=2.17951, val_acc=0.49088, time=0.52602
Epoch:0029, train_loss=1.41155, train_acc=0.99980, val_loss=2.17910, val_acc=0.48905, time=0.97300
Epoch:0030, train_loss=1.41141, train_acc=1.00000, val_loss=2.17873, val_acc=0.49270, time=0.56200
Epoch:0031, train_loss=1.41133, train_acc=1.00000, val_loss=2.17841, val_acc=0.48905, time=0.55401
Epoch:0032, train_loss=1.41129, train_acc=1.00000, val_loss=2.17813, val_acc=0.48540, time=0.63500
Epoch:0033, train_loss=1.41126, train_acc=1.00000, val_loss=2.17789, val_acc=0.48540, time=0.51201
Epoch:0034, train_loss=1.41125, train_acc=1.00000, val_loss=2.17767, val_acc=0.48905, time=0.46401
Epoch:0035, train_loss=1.41124, train_acc=1.00000, val_loss=2.17749, val_acc=0.49088, time=0.54199
Epoch:0036, train_loss=1.41123, train_acc=1.00000, val_loss=2.17732, val_acc=0.48905, time=0.46401
Epoch:0037, train_loss=1.41122, train_acc=1.00000, val_loss=2.17718, val_acc=0.48905, time=0.59401
Epoch:0038, train_loss=1.41122, train_acc=1.00000, val_loss=2.17705, val_acc=0.48723, time=0.50601
Epoch:0039, train_loss=1.41121, train_acc=1.00000, val_loss=2.17694, val_acc=0.48723, time=0.64601
Epoch:0040, train_loss=1.41121, train_acc=1.00000, val_loss=2.17683, val_acc=0.48723, time=0.46900
Epoch:0041, train_loss=1.41121, train_acc=1.00000, val_loss=2.17674, val_acc=0.48723, time=0.52399
Epoch:0042, train_loss=1.41120, train_acc=1.00000, val_loss=2.17667, val_acc=0.48540, time=0.46600
Epoch:0043, train_loss=1.41120, train_acc=1.00000, val_loss=2.17659, val_acc=0.48358, time=0.59002
Epoch:0044, train_loss=1.41120, train_acc=1.00000, val_loss=2.17653, val_acc=0.48358, time=0.47301
Epoch:0045, train_loss=1.41120, train_acc=1.00000, val_loss=2.17647, val_acc=0.48358, time=0.57100
Epoch:0046, train_loss=1.41120, train_acc=1.00000, val_loss=2.17642, val_acc=0.48540, time=0.46300
Epoch:0047, train_loss=1.41119, train_acc=1.00000, val_loss=2.17637, val_acc=0.48540, time=0.73003
Epoch:0048, train_loss=1.41119, train_acc=1.00000, val_loss=2.17633, val_acc=0.48540, time=0.53702
Epoch:0049, train_loss=1.41119, train_acc=1.00000, val_loss=2.17629, val_acc=0.48540, time=0.53202
Epoch:0050, train_loss=1.41119, train_acc=1.00000, val_loss=2.17626, val_acc=0.48723, time=0.50702
Epoch:0051, train_loss=1.41119, train_acc=1.00000, val_loss=2.17623, val_acc=0.48723, time=0.52699
Epoch:0052, train_loss=1.41119, train_acc=1.00000, val_loss=2.17620, val_acc=0.48540, time=0.54801
Epoch:0053, train_loss=1.41119, train_acc=1.00000, val_loss=2.17617, val_acc=0.48540, time=0.47399
Epoch:0054, train_loss=1.41119, train_acc=1.00000, val_loss=2.17615, val_acc=0.48540, time=0.54000
Epoch:0055, train_loss=1.41119, train_acc=1.00000, val_loss=2.17613, val_acc=0.48540, time=0.56000
Epoch:0056, train_loss=1.41119, train_acc=1.00000, val_loss=2.17611, val_acc=0.48723, time=0.55301
Epoch:0057, train_loss=1.41119, train_acc=1.00000, val_loss=2.17609, val_acc=0.48723, time=0.57200
Epoch:0058, train_loss=1.41119, train_acc=1.00000, val_loss=2.17607, val_acc=0.48723, time=0.49800
Epoch:0059, train_loss=1.41119, train_acc=1.00000, val_loss=2.17605, val_acc=0.48723, time=0.48602
Epoch:0060, train_loss=1.41118, train_acc=1.00000, val_loss=2.17604, val_acc=0.48723, time=0.60500
Epoch:0061, train_loss=1.41118, train_acc=1.00000, val_loss=2.17603, val_acc=0.48723, time=0.55800
Epoch:0062, train_loss=1.41118, train_acc=1.00000, val_loss=2.17601, val_acc=0.48723, time=0.67401
Epoch:0063, train_loss=1.41118, train_acc=1.00000, val_loss=2.17600, val_acc=0.48723, time=0.47700
Epoch:0064, train_loss=1.41118, train_acc=1.00000, val_loss=2.17599, val_acc=0.48723, time=0.46699
Epoch:0065, train_loss=1.41118, train_acc=1.00000, val_loss=2.17598, val_acc=0.48723, time=0.56102
Epoch:0066, train_loss=1.41118, train_acc=1.00000, val_loss=2.17597, val_acc=0.48723, time=0.72599
Epoch:0067, train_loss=1.41118, train_acc=1.00000, val_loss=2.17596, val_acc=0.48723, time=0.73801
Epoch:0068, train_loss=1.41118, train_acc=1.00000, val_loss=2.17595, val_acc=0.48723, time=0.52801
Epoch:0069, train_loss=1.41118, train_acc=1.00000, val_loss=2.17594, val_acc=0.48723, time=0.46600
Epoch:0070, train_loss=1.41118, train_acc=1.00000, val_loss=2.17593, val_acc=0.48723, time=0.49999
Epoch:0071, train_loss=1.41118, train_acc=1.00000, val_loss=2.17593, val_acc=0.48723, time=0.63302
Epoch:0072, train_loss=1.41118, train_acc=1.00000, val_loss=2.17592, val_acc=0.48723, time=0.48602
Epoch:0073, train_loss=1.41118, train_acc=1.00000, val_loss=2.17591, val_acc=0.48723, time=0.56000
Epoch:0074, train_loss=1.41118, train_acc=1.00000, val_loss=2.17591, val_acc=0.48723, time=0.58301
Epoch:0075, train_loss=1.41118, train_acc=1.00000, val_loss=2.17590, val_acc=0.48723, time=0.56202
Epoch:0076, train_loss=1.41118, train_acc=1.00000, val_loss=2.17590, val_acc=0.48723, time=0.55599
Epoch:0077, train_loss=1.41118, train_acc=1.00000, val_loss=2.17589, val_acc=0.48723, time=0.47300
Epoch:0078, train_loss=1.41118, train_acc=1.00000, val_loss=2.17588, val_acc=0.48723, time=0.60802
Epoch:0079, train_loss=1.41118, train_acc=1.00000, val_loss=2.17588, val_acc=0.48723, time=0.49598
Epoch:0080, train_loss=1.41118, train_acc=1.00000, val_loss=2.17587, val_acc=0.48723, time=0.61502
Epoch:0081, train_loss=1.41118, train_acc=1.00000, val_loss=2.17587, val_acc=0.48723, time=0.55500
Epoch:0082, train_loss=1.41118, train_acc=1.00000, val_loss=2.17586, val_acc=0.48723, time=0.53500
Epoch:0083, train_loss=1.41118, train_acc=1.00000, val_loss=2.17586, val_acc=0.48723, time=0.50100
Epoch:0084, train_loss=1.41118, train_acc=1.00000, val_loss=2.17585, val_acc=0.48723, time=0.49201
Epoch:0085, train_loss=1.41118, train_acc=1.00000, val_loss=2.17585, val_acc=0.48723, time=0.48500
Epoch:0086, train_loss=1.41118, train_acc=1.00000, val_loss=2.17584, val_acc=0.48723, time=0.99502
Epoch:0087, train_loss=1.41118, train_acc=1.00000, val_loss=2.17584, val_acc=0.48723, time=0.61502
Epoch:0088, train_loss=1.41118, train_acc=1.00000, val_loss=2.17584, val_acc=0.48723, time=0.57000
Epoch:0089, train_loss=1.41118, train_acc=1.00000, val_loss=2.17583, val_acc=0.48723, time=0.49002
Epoch:0090, train_loss=1.41118, train_acc=1.00000, val_loss=2.17583, val_acc=0.48723, time=0.49500
Epoch:0091, train_loss=1.41118, train_acc=1.00000, val_loss=2.17582, val_acc=0.48723, time=0.46801
Epoch:0092, train_loss=1.41118, train_acc=1.00000, val_loss=2.17582, val_acc=0.48723, time=0.51899
Epoch:0093, train_loss=1.41118, train_acc=1.00000, val_loss=2.17581, val_acc=0.48723, time=0.53101
Epoch:0094, train_loss=1.41118, train_acc=1.00000, val_loss=2.17581, val_acc=0.48905, time=0.48800
Epoch:0095, train_loss=1.41118, train_acc=1.00000, val_loss=2.17581, val_acc=0.48905, time=0.46900
Epoch:0096, train_loss=1.41118, train_acc=1.00000, val_loss=2.17580, val_acc=0.48905, time=0.49501
Epoch:0097, train_loss=1.41118, train_acc=1.00000, val_loss=2.17580, val_acc=0.48905, time=0.46501
Epoch:0098, train_loss=1.41118, train_acc=1.00000, val_loss=2.17580, val_acc=0.48905, time=0.57199
Epoch:0099, train_loss=1.41118, train_acc=1.00000, val_loss=2.17579, val_acc=0.48905, time=0.54500
Epoch:0100, train_loss=1.41118, train_acc=1.00000, val_loss=2.17579, val_acc=0.48905, time=0.55401
Epoch:0101, train_loss=1.41118, train_acc=1.00000, val_loss=2.17578, val_acc=0.48905, time=0.46900
Epoch:0102, train_loss=1.41118, train_acc=1.00000, val_loss=2.17578, val_acc=0.48905, time=0.54000
Epoch:0103, train_loss=1.41118, train_acc=1.00000, val_loss=2.17578, val_acc=0.48905, time=0.46700
Epoch:0104, train_loss=1.41118, train_acc=1.00000, val_loss=2.17577, val_acc=0.48905, time=0.51401
Epoch:0105, train_loss=1.41118, train_acc=1.00000, val_loss=2.17577, val_acc=0.48905, time=0.46200
Epoch:0106, train_loss=1.41118, train_acc=1.00000, val_loss=2.17577, val_acc=0.48905, time=0.48000
Epoch:0107, train_loss=1.41118, train_acc=1.00000, val_loss=2.17576, val_acc=0.48905, time=0.48101
Epoch:0108, train_loss=1.41117, train_acc=1.00000, val_loss=2.17576, val_acc=0.48905, time=0.51201
Epoch:0109, train_loss=1.41117, train_acc=1.00000, val_loss=2.17576, val_acc=0.48905, time=0.46302
Epoch:0110, train_loss=1.41117, train_acc=1.00000, val_loss=2.17575, val_acc=0.48905, time=0.50701
Epoch:0111, train_loss=1.41117, train_acc=1.00000, val_loss=2.17575, val_acc=0.48905, time=0.48500
Epoch:0112, train_loss=1.41117, train_acc=1.00000, val_loss=2.17574, val_acc=0.49088, time=0.48200
Epoch:0113, train_loss=1.41117, train_acc=1.00000, val_loss=2.17574, val_acc=0.49270, time=0.90105
Epoch:0114, train_loss=1.41117, train_acc=1.00000, val_loss=2.17574, val_acc=0.49270, time=0.66599
Epoch:0115, train_loss=1.41117, train_acc=1.00000, val_loss=2.17573, val_acc=0.49270, time=0.54300
Epoch:0116, train_loss=1.41117, train_acc=1.00000, val_loss=2.17573, val_acc=0.49270, time=0.62200
Epoch:0117, train_loss=1.41117, train_acc=1.00000, val_loss=2.17573, val_acc=0.49270, time=0.76001
Epoch:0118, train_loss=1.41117, train_acc=1.00000, val_loss=2.17572, val_acc=0.49270, time=0.53200
Epoch:0119, train_loss=1.41117, train_acc=1.00000, val_loss=2.17572, val_acc=0.49270, time=0.51699
Epoch:0120, train_loss=1.41117, train_acc=1.00000, val_loss=2.17572, val_acc=0.49270, time=0.46201
Epoch:0121, train_loss=1.41117, train_acc=1.00000, val_loss=2.17571, val_acc=0.49270, time=0.56001
Epoch:0122, train_loss=1.41117, train_acc=1.00000, val_loss=2.17571, val_acc=0.49270, time=0.59399
Epoch:0123, train_loss=1.41117, train_acc=1.00000, val_loss=2.17571, val_acc=0.49270, time=0.51500
Epoch:0124, train_loss=1.41117, train_acc=1.00000, val_loss=2.17570, val_acc=0.49270, time=0.46800
Epoch:0125, train_loss=1.41117, train_acc=1.00000, val_loss=2.17570, val_acc=0.49270, time=0.62401
Epoch:0126, train_loss=1.41117, train_acc=1.00000, val_loss=2.17570, val_acc=0.49270, time=0.48701
Epoch:0127, train_loss=1.41117, train_acc=1.00000, val_loss=2.17570, val_acc=0.49270, time=0.85001
Epoch:0128, train_loss=1.41117, train_acc=1.00000, val_loss=2.17569, val_acc=0.49270, time=0.71000
Epoch:0129, train_loss=1.41117, train_acc=1.00000, val_loss=2.17569, val_acc=0.49270, time=0.46801
Epoch:0130, train_loss=1.41117, train_acc=1.00000, val_loss=2.17569, val_acc=0.49270, time=0.53402
Epoch:0131, train_loss=1.41117, train_acc=1.00000, val_loss=2.17568, val_acc=0.49270, time=0.47202
Epoch:0132, train_loss=1.41117, train_acc=1.00000, val_loss=2.17568, val_acc=0.49270, time=0.69399
Epoch:0133, train_loss=1.41117, train_acc=1.00000, val_loss=2.17568, val_acc=0.49270, time=0.66800
Epoch:0134, train_loss=1.41117, train_acc=1.00000, val_loss=2.17567, val_acc=0.49270, time=0.46499
Epoch:0135, train_loss=1.41117, train_acc=1.00000, val_loss=2.17567, val_acc=0.49270, time=0.54001
Epoch:0136, train_loss=1.41117, train_acc=1.00000, val_loss=2.17567, val_acc=0.49270, time=0.54101
Epoch:0137, train_loss=1.41117, train_acc=1.00000, val_loss=2.17566, val_acc=0.49270, time=0.51901
Epoch:0138, train_loss=1.41117, train_acc=1.00000, val_loss=2.17566, val_acc=0.49270, time=0.46702
Epoch:0139, train_loss=1.41117, train_acc=1.00000, val_loss=2.17566, val_acc=0.49270, time=0.47799
Epoch:0140, train_loss=1.41117, train_acc=1.00000, val_loss=2.17565, val_acc=0.49270, time=0.55100
Epoch:0141, train_loss=1.41117, train_acc=1.00000, val_loss=2.17565, val_acc=0.49270, time=0.52100
Epoch:0142, train_loss=1.41117, train_acc=1.00000, val_loss=2.17565, val_acc=0.49270, time=0.50602
Epoch:0143, train_loss=1.41117, train_acc=1.00000, val_loss=2.17565, val_acc=0.49270, time=0.50400
Epoch:0144, train_loss=1.41117, train_acc=1.00000, val_loss=2.17564, val_acc=0.49270, time=0.51100
Epoch:0145, train_loss=1.41117, train_acc=1.00000, val_loss=2.17564, val_acc=0.49270, time=0.55601
Epoch:0146, train_loss=1.41117, train_acc=1.00000, val_loss=2.17564, val_acc=0.49270, time=0.47200
Epoch:0147, train_loss=1.41117, train_acc=1.00000, val_loss=2.17563, val_acc=0.49270, time=0.57803
Epoch:0148, train_loss=1.41117, train_acc=1.00000, val_loss=2.17563, val_acc=0.49270, time=0.58803
Epoch:0149, train_loss=1.41117, train_acc=1.00000, val_loss=2.17563, val_acc=0.49270, time=0.48702
Epoch:0150, train_loss=1.41117, train_acc=1.00000, val_loss=2.17563, val_acc=0.49270, time=0.46901
Epoch:0151, train_loss=1.41117, train_acc=1.00000, val_loss=2.17562, val_acc=0.49270, time=0.48401
Epoch:0152, train_loss=1.41117, train_acc=1.00000, val_loss=2.17562, val_acc=0.49270, time=0.46503
Epoch:0153, train_loss=1.41117, train_acc=1.00000, val_loss=2.17562, val_acc=0.49270, time=0.47800
Epoch:0154, train_loss=1.41117, train_acc=1.00000, val_loss=2.17561, val_acc=0.49270, time=0.48801
Epoch:0155, train_loss=1.41117, train_acc=1.00000, val_loss=2.17561, val_acc=0.49270, time=0.47703
Epoch:0156, train_loss=1.41117, train_acc=1.00000, val_loss=2.17561, val_acc=0.49270, time=0.46902
Epoch:0157, train_loss=1.41117, train_acc=1.00000, val_loss=2.17560, val_acc=0.49270, time=0.57700
Epoch:0158, train_loss=1.41117, train_acc=1.00000, val_loss=2.17560, val_acc=0.49270, time=0.91102
Epoch:0159, train_loss=1.41117, train_acc=1.00000, val_loss=2.17560, val_acc=0.49453, time=0.60000
Epoch:0160, train_loss=1.41117, train_acc=1.00000, val_loss=2.17560, val_acc=0.49453, time=0.58099
Epoch:0161, train_loss=1.41117, train_acc=1.00000, val_loss=2.17559, val_acc=0.49453, time=0.54700
Epoch:0162, train_loss=1.41117, train_acc=1.00000, val_loss=2.17559, val_acc=0.49453, time=0.53701
Epoch:0163, train_loss=1.41117, train_acc=1.00000, val_loss=2.17559, val_acc=0.49453, time=0.61700
Epoch:0164, train_loss=1.41117, train_acc=1.00000, val_loss=2.17559, val_acc=0.49453, time=0.62001
Epoch:0165, train_loss=1.41117, train_acc=1.00000, val_loss=2.17558, val_acc=0.49453, time=0.56600
Epoch:0166, train_loss=1.41117, train_acc=1.00000, val_loss=2.17558, val_acc=0.49453, time=0.49201
Epoch:0167, train_loss=1.41117, train_acc=1.00000, val_loss=2.17558, val_acc=0.49453, time=0.46100
Epoch:0168, train_loss=1.41117, train_acc=1.00000, val_loss=2.17557, val_acc=0.49453, time=0.47600
Epoch:0169, train_loss=1.41117, train_acc=1.00000, val_loss=2.17557, val_acc=0.49453, time=0.48101
Epoch:0170, train_loss=1.41117, train_acc=1.00000, val_loss=2.17557, val_acc=0.49453, time=0.60201
Epoch:0171, train_loss=1.41117, train_acc=1.00000, val_loss=2.17557, val_acc=0.49453, time=0.54003
Epoch:0172, train_loss=1.41117, train_acc=1.00000, val_loss=2.17556, val_acc=0.49635, time=0.46101
Epoch:0173, train_loss=1.41117, train_acc=1.00000, val_loss=2.17556, val_acc=0.49635, time=0.46501
Epoch:0174, train_loss=1.41117, train_acc=1.00000, val_loss=2.17556, val_acc=0.49635, time=0.46898
Epoch:0175, train_loss=1.41117, train_acc=1.00000, val_loss=2.17556, val_acc=0.49635, time=0.46200
Epoch:0176, train_loss=1.41117, train_acc=1.00000, val_loss=2.17555, val_acc=0.49635, time=0.55301
Epoch:0177, train_loss=1.41117, train_acc=1.00000, val_loss=2.17555, val_acc=0.49635, time=0.75500
Epoch:0178, train_loss=1.41117, train_acc=1.00000, val_loss=2.17555, val_acc=0.49635, time=0.46701
Epoch:0179, train_loss=1.41117, train_acc=1.00000, val_loss=2.17555, val_acc=0.49635, time=0.49201
Epoch:0180, train_loss=1.41117, train_acc=1.00000, val_loss=2.17554, val_acc=0.49635, time=0.46800
Epoch:0181, train_loss=1.41117, train_acc=1.00000, val_loss=2.17554, val_acc=0.49635, time=0.48100
Epoch:0182, train_loss=1.41117, train_acc=1.00000, val_loss=2.17554, val_acc=0.49635, time=0.49900
Epoch:0183, train_loss=1.41117, train_acc=1.00000, val_loss=2.17554, val_acc=0.49635, time=0.48001
Epoch:0184, train_loss=1.41117, train_acc=1.00000, val_loss=2.17553, val_acc=0.49635, time=0.47101
Epoch:0185, train_loss=1.41117, train_acc=1.00000, val_loss=2.17553, val_acc=0.49635, time=0.55802
Epoch:0186, train_loss=1.41117, train_acc=1.00000, val_loss=2.17553, val_acc=0.49635, time=0.53901
Epoch:0187, train_loss=1.41117, train_acc=1.00000, val_loss=2.17553, val_acc=0.49635, time=0.49300
Epoch:0188, train_loss=1.41117, train_acc=1.00000, val_loss=2.17552, val_acc=0.49635, time=0.54201
Epoch:0189, train_loss=1.41117, train_acc=1.00000, val_loss=2.17552, val_acc=0.49818, time=0.54502
Epoch:0190, train_loss=1.41117, train_acc=1.00000, val_loss=2.17552, val_acc=0.49818, time=0.53002
Epoch:0191, train_loss=1.41117, train_acc=1.00000, val_loss=2.17552, val_acc=0.49818, time=0.60201
Epoch:0192, train_loss=1.41117, train_acc=1.00000, val_loss=2.17551, val_acc=0.49818, time=0.46903
Epoch:0193, train_loss=1.41117, train_acc=1.00000, val_loss=2.17551, val_acc=0.49818, time=0.48201
Epoch:0194, train_loss=1.41117, train_acc=1.00000, val_loss=2.17551, val_acc=0.49818, time=0.54602
Epoch:0195, train_loss=1.41117, train_acc=1.00000, val_loss=2.17551, val_acc=0.49818, time=0.64001
Epoch:0196, train_loss=1.41117, train_acc=1.00000, val_loss=2.17550, val_acc=0.50000, time=0.52502
Epoch:0197, train_loss=1.41117, train_acc=1.00000, val_loss=2.17550, val_acc=0.50000, time=0.48401
Epoch:0198, train_loss=1.41117, train_acc=1.00000, val_loss=2.17550, val_acc=0.50000, time=0.47701
Epoch:0199, train_loss=1.41117, train_acc=1.00000, val_loss=2.17550, val_acc=0.50000, time=0.57301
Epoch:0200, train_loss=1.41117, train_acc=1.00000, val_loss=2.17549, val_acc=0.50000, time=0.48201

Optimization Finished!

Test set results: loss= 2.35164, accuracy= 0.53952, time= 0.18199

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.5730    0.5187    0.5445       696
           1     0.7116    0.6925    0.7019      1083
           2     0.1200    0.0370    0.0566        81
           3     0.0611    0.1067    0.0777        75
           4     0.1667    0.2069    0.1846        87
           5     0.0417    0.0833    0.0556        36
           6     0.2639    0.3140    0.2868       121
           7     0.0000    0.0000    0.0000        10

    accuracy                         0.5395      2189
   macro avg     0.2422    0.2449    0.2385      2189
weighted avg     0.5627    0.5395    0.5493      2189


Macro average Test Precision, Recall and F1-Score...
(0.24223521876123016, 0.24489776401010543, 0.2384562959886227, None)

Micro average Test Precision, Recall and F1-Score...
(0.5395157606212883, 0.5395157606212883, 0.5395157606212883, None)

Embeddings:
Word_embeddings:7688
Train_doc_embeddings:5485
Test_doc_embeddings:2189
