
==================== Torch Seed: 313204745800

Model parameters

Layer: layer1.W0 | Size: torch.Size([15362, 200])
Layer: layer2.W0 | Size: torch.Size([200, 8])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  15362          8             4937            548            2189

Epoch:0001, train_loss=2.10262, train_acc=0.20903, val_loss=2.05633, val_acc=0.66241, time=0.38099
Epoch:0002, train_loss=1.86235, train_acc=0.63763, val_loss=2.04429, val_acc=0.66241, time=0.40200
Epoch:0003, train_loss=1.74368, train_acc=0.68746, val_loss=2.03753, val_acc=0.70620, time=0.29200
Epoch:0004, train_loss=1.67708, train_acc=0.72757, val_loss=2.03144, val_acc=0.77920, time=0.39303
Epoch:0005, train_loss=1.62102, train_acc=0.80373, val_loss=2.02656, val_acc=0.82117, time=0.40700
Epoch:0006, train_loss=1.57874, train_acc=0.85680, val_loss=2.02300, val_acc=0.84307, time=0.40400
Epoch:0007, train_loss=1.54819, train_acc=0.88333, val_loss=2.02033, val_acc=0.86861, time=0.31101
Epoch:0008, train_loss=1.52411, train_acc=0.90905, val_loss=2.01839, val_acc=0.90328, time=0.33699
Epoch:0009, train_loss=1.50506, train_acc=0.93194, val_loss=2.01712, val_acc=0.91423, time=0.30901
Epoch:0010, train_loss=1.49104, train_acc=0.94632, val_loss=2.01636, val_acc=0.92153, time=0.35302
Epoch:0011, train_loss=1.48121, train_acc=0.95341, val_loss=2.01590, val_acc=0.91971, time=0.34700
Epoch:0012, train_loss=1.47404, train_acc=0.95908, val_loss=2.01556, val_acc=0.91971, time=0.40299
Epoch:0013, train_loss=1.46827, train_acc=0.96293, val_loss=2.01523, val_acc=0.92518, time=0.39900
Epoch:0014, train_loss=1.46311, train_acc=0.96577, val_loss=2.01484, val_acc=0.92336, time=0.35701
Epoch:0015, train_loss=1.45816, train_acc=0.96881, val_loss=2.01440, val_acc=0.92336, time=0.41298
Epoch:0016, train_loss=1.45332, train_acc=0.97144, val_loss=2.01393, val_acc=0.92883, time=0.35701
Epoch:0017, train_loss=1.44873, train_acc=0.97448, val_loss=2.01348, val_acc=0.92883, time=0.38799
Epoch:0018, train_loss=1.44460, train_acc=0.97671, val_loss=2.01309, val_acc=0.93066, time=0.41501
Epoch:0019, train_loss=1.44107, train_acc=0.97893, val_loss=2.01277, val_acc=0.93248, time=0.41499
Epoch:0020, train_loss=1.43814, train_acc=0.98035, val_loss=2.01252, val_acc=0.93613, time=0.35901
Epoch:0021, train_loss=1.43574, train_acc=0.98177, val_loss=2.01233, val_acc=0.93796, time=0.36600
Epoch:0022, train_loss=1.43374, train_acc=0.98319, val_loss=2.01218, val_acc=0.93796, time=0.40300
Epoch:0023, train_loss=1.43203, train_acc=0.98420, val_loss=2.01208, val_acc=0.93978, time=0.34800
Epoch:0024, train_loss=1.43053, train_acc=0.98521, val_loss=2.01200, val_acc=0.93978, time=0.40600
Epoch:0025, train_loss=1.42920, train_acc=0.98704, val_loss=2.01196, val_acc=0.93978, time=0.41400
Epoch:0026, train_loss=1.42801, train_acc=0.98926, val_loss=2.01193, val_acc=0.93978, time=0.33899
Epoch:0027, train_loss=1.42696, train_acc=0.98967, val_loss=2.01192, val_acc=0.93978, time=0.32401
Epoch:0028, train_loss=1.42603, train_acc=0.99089, val_loss=2.01192, val_acc=0.93613, time=0.33699
Epoch:0029, train_loss=1.42522, train_acc=0.99251, val_loss=2.01192, val_acc=0.93613, time=0.40301
Epoch:0030, train_loss=1.42450, train_acc=0.99271, val_loss=2.01192, val_acc=0.93431, time=0.38301
Epoch:0031, train_loss=1.42385, train_acc=0.99291, val_loss=2.01191, val_acc=0.93613, time=0.31400
Epoch:0032, train_loss=1.42324, train_acc=0.99251, val_loss=2.01189, val_acc=0.93613, time=0.36699
Epoch:0033, train_loss=1.42264, train_acc=0.99332, val_loss=2.01187, val_acc=0.93796, time=0.34301
Epoch:0034, train_loss=1.42206, train_acc=0.99352, val_loss=2.01183, val_acc=0.93796, time=0.28200
Epoch:0035, train_loss=1.42151, train_acc=0.99372, val_loss=2.01180, val_acc=0.94161, time=0.32901
Epoch:0036, train_loss=1.42098, train_acc=0.99392, val_loss=2.01176, val_acc=0.94161, time=0.28000
Epoch:0037, train_loss=1.42048, train_acc=0.99413, val_loss=2.01171, val_acc=0.94526, time=0.36901
Epoch:0038, train_loss=1.42003, train_acc=0.99473, val_loss=2.01168, val_acc=0.94526, time=0.31399
Epoch:0039, train_loss=1.41962, train_acc=0.99575, val_loss=2.01164, val_acc=0.94708, time=0.32100
Epoch:0040, train_loss=1.41925, train_acc=0.99595, val_loss=2.01161, val_acc=0.94708, time=0.37200
Epoch:0041, train_loss=1.41890, train_acc=0.99595, val_loss=2.01158, val_acc=0.94891, time=0.29803
Epoch:0042, train_loss=1.41859, train_acc=0.99635, val_loss=2.01156, val_acc=0.94891, time=0.36500
Epoch:0043, train_loss=1.41829, train_acc=0.99656, val_loss=2.01154, val_acc=0.95073, time=0.37901
Epoch:0044, train_loss=1.41802, train_acc=0.99656, val_loss=2.01153, val_acc=0.95073, time=0.29800
Epoch:0045, train_loss=1.41777, train_acc=0.99656, val_loss=2.01152, val_acc=0.95073, time=0.41001
Epoch:0046, train_loss=1.41754, train_acc=0.99676, val_loss=2.01152, val_acc=0.95073, time=0.38303
Epoch:0047, train_loss=1.41732, train_acc=0.99676, val_loss=2.01151, val_acc=0.95073, time=0.35601
Epoch:0048, train_loss=1.41712, train_acc=0.99696, val_loss=2.01151, val_acc=0.95073, time=0.27900
Epoch:0049, train_loss=1.41693, train_acc=0.99696, val_loss=2.01151, val_acc=0.95073, time=0.28500
Epoch:0050, train_loss=1.41675, train_acc=0.99797, val_loss=2.01152, val_acc=0.95073, time=0.28599
Epoch:0051, train_loss=1.41657, train_acc=0.99777, val_loss=2.01152, val_acc=0.95073, time=0.31101
Epoch:0052, train_loss=1.41641, train_acc=0.99757, val_loss=2.01153, val_acc=0.95073, time=0.31001
Early stopping...

Optimization Finished!

Test set results: loss= 1.80426, accuracy= 0.95158, time= 0.10000

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9864    0.9411    0.9632       696
           1     0.9649    0.9889    0.9767      1083
           2     0.8471    0.9600    0.9000        75
           3     0.9048    0.9421    0.9231       121
           4     0.8043    0.8506    0.8268        87
           5     0.8857    0.7654    0.8212        81
           6     0.8621    0.6944    0.7692        36
           7     0.7692    1.0000    0.8696        10

    accuracy                         0.9516      2189
   macro avg     0.8781    0.8928    0.8812      2189
weighted avg     0.9525    0.9516    0.9512      2189


Macro average Test Precision, Recall and F1-Score...
(0.8780616528547456, 0.8928264547246436, 0.8812325106626736, None)

Micro average Test Precision, Recall and F1-Score...
(0.951576062128826, 0.951576062128826, 0.951576062128826, None)

Embeddings:
Word_embeddings: 7688
Train_doc_embeddings: 5485
Test_doc_embeddings: 2189

Elapsed time is 19.668961 seconds.
