
==================== Torch Seed: 1964709196500

Model parameters

Layer: layer1.W0 | Size: torch.Size([29426, 200])
Layer: layer2.W0 | Size: torch.Size([200, 2])

Data statistics

  Edges    Classes    Train samples    Val samples    Test samples
-------  ---------  ---------------  -------------  --------------
  29426          2             6398            710            3554

Epoch:0001, train_loss=1.15980, train_acc=0.49594, val_loss=0.71371, val_acc=0.53099, time=0.99802
Epoch:0002, train_loss=0.88695, train_acc=0.50281, val_loss=0.70611, val_acc=0.47746, time=0.87000
Epoch:0003, train_loss=0.78068, train_acc=0.52391, val_loss=0.71239, val_acc=0.47324, time=0.87902
Epoch:0004, train_loss=0.80199, train_acc=0.54251, val_loss=0.71480, val_acc=0.48169, time=1.03800
Epoch:0005, train_loss=0.79834, train_acc=0.56393, val_loss=0.71156, val_acc=0.50423, time=0.91400
Epoch:0006, train_loss=0.75250, train_acc=0.60581, val_loss=0.70576, val_acc=0.51831, time=0.82600
Epoch:0007, train_loss=0.69182, train_acc=0.67787, val_loss=0.70060, val_acc=0.56761, time=1.00600
Epoch:0008, train_loss=0.64281, train_acc=0.77524, val_loss=0.69803, val_acc=0.62394, time=0.80201
Epoch:0009, train_loss=0.61708, train_acc=0.84198, val_loss=0.69799, val_acc=0.63662, time=0.76699
Epoch:0010, train_loss=0.60985, train_acc=0.86887, val_loss=0.69908, val_acc=0.64648, time=0.93003
Epoch:0011, train_loss=0.61013, train_acc=0.86246, val_loss=0.70010, val_acc=0.66056, time=0.85398
Epoch:0012, train_loss=0.60973, train_acc=0.85480, val_loss=0.70047, val_acc=0.66761, time=0.89800
Epoch:0013, train_loss=0.60552, train_acc=0.86465, val_loss=0.70013, val_acc=0.67324, time=0.80000
Epoch:0014, train_loss=0.59806, train_acc=0.88825, val_loss=0.69932, val_acc=0.68310, time=0.85798
Epoch:0015, train_loss=0.58940, train_acc=0.91482, val_loss=0.69832, val_acc=0.68451, time=0.85001
Epoch:0016, train_loss=0.58142, train_acc=0.93670, val_loss=0.69739, val_acc=0.69296, time=0.81001
Epoch:0017, train_loss=0.57515, train_acc=0.95264, val_loss=0.69669, val_acc=0.69437, time=0.82201
Epoch:0018, train_loss=0.57083, train_acc=0.96061, val_loss=0.69626, val_acc=0.69155, time=0.83099
Epoch:0019, train_loss=0.56817, train_acc=0.96546, val_loss=0.69609, val_acc=0.69014, time=0.94102
Epoch:0020, train_loss=0.56672, train_acc=0.96624, val_loss=0.69612, val_acc=0.69014, time=0.94603
Epoch:0021, train_loss=0.56600, train_acc=0.96702, val_loss=0.69627, val_acc=0.68310, time=0.83099
Epoch:0022, train_loss=0.56562, train_acc=0.96530, val_loss=0.69646, val_acc=0.68169, time=0.92100
Epoch:0023, train_loss=0.56526, train_acc=0.96468, val_loss=0.69665, val_acc=0.68169, time=0.82402
Epoch:0024, train_loss=0.56476, train_acc=0.96546, val_loss=0.69681, val_acc=0.68592, time=0.83299
Epoch:0025, train_loss=0.56403, train_acc=0.96640, val_loss=0.69691, val_acc=0.68873, time=0.84100
Early stopping...

Optimization Finished!

Test set results: loss= 0.70573, accuracy= 0.69893, time= 0.24701

Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.6850    0.7366    0.7099      1777
           1     0.7152    0.6612    0.6871      1777

    accuracy                         0.6989      3554
   macro avg     0.7001    0.6989    0.6985      3554
weighted avg     0.7001    0.6989    0.6985      3554


Macro average Test Precision, Recall and F1-Score...
(0.7000684444384992, 0.69893078221722, 0.6985021755400793, None)

Micro average Test Precision, Recall and F1-Score...
(0.69893078221722, 0.69893078221722, 0.69893078221722, None)

Embeddings:
Word_embeddings: 18764
Train_doc_embeddings: 7108
Test_doc_embeddings: 3554

Elapsed time is 25.520933 seconds.
